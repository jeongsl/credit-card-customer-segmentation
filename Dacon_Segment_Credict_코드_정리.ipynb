{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "6CxI21i9tjl7",
        "YKoy3B4ptmQE",
        "XL28V-ndDcPG",
        "AZ8xPBZBDsc7",
        "7KQvAVAKDsfO",
        "lnurOakNPkNL",
        "npfA9-zTPo5T",
        "63EOZW4VDsha",
        "VlxYszFKDsjv",
        "4K4YLvcTDsl8",
        "ocJRgnz7DsoQ",
        "Bj70Da6rEumg",
        "lKkiV1RDHdi4",
        "z10FeYofoAYU",
        "a9ZwexQ7oDqY",
        "4DODECiKoGXB",
        "lGSTmyKLIAKS",
        "KGFGRkYlIEhP",
        "MLU53AxJIHbl",
        "Zp_J2JZcIagp",
        "Suv5QAKMIagq",
        "w983dFctU8Yy",
        "HbgzqQ5oUVWk",
        "bUFu4-MXoJu-",
        "mFBetY0UoO7I",
        "AXJIhMuLoQwA"
      ],
      "machine_shape": "hm",
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Import"
      ],
      "metadata": {
        "id": "6CxI21i9tjl7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import platform\n",
        "import sys\n",
        "print(f\"개발환경 (OS) : {platform.platform()}\")\n",
        "print(f\"Python Version : {sys.version}\")\n",
        "# T4 GPU, 고용량 RAM 설정"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wujeLwakRbAI",
        "outputId": "5989f79c-650c-4cc9-e6ea-f14776b7606b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "개발환경 (OS) : Linux-6.1.123+-x86_64-with-glibc2.35\n",
            "Python Version : 3.11.12 (main, Apr  9 2025, 08:55:54) [GCC 11.4.0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ofyn_q3QRBV5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fe63af21-2968-491c-8510-b531bc756db1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import gc\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# LightGBM을 위한 GPU driver 설치 코드\n",
        "!mkdir -p /etc/OpenCL/vendors && echo \"libnvidia-opencl.so.1\" > /etc/OpenCL/vendors/nvidia.icd\n",
        "!sudo apt install nvidia-driver-460 nvidia-cuda-toolkit clinfo\n",
        "!apt-get update --fix-missing\n",
        "!pip install -q  lightgbm==4.1.0 \\\n",
        "  --config-settings=cmake.define.USE_GPU=ON \\\n",
        "  --config-settings=cmake.define.OpenCL_INCLUDE_DIR=\"/usr/local/cuda/include/\" \\\n",
        "  --config-settings=cmake.define.OpenCL_LIBRARY=\"/usr/local/cuda/lib64/libOpenCL.so\"\n",
        "\n",
        "# catboost 설치\n",
        "!pip install catboost\n",
        "\n",
        "# !pip install imbalanced-learn"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "ANg-MbRpLb4e",
        "outputId": "8198db58-2497-4ba0-b089-6a239ebab5f7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "clinfo is already the newest version (3.0.21.02.21-1).\n",
            "Some packages could not be installed. This may mean that you have\n",
            "requested an impossible situation or if you are using the unstable\n",
            "distribution that some required packages have not yet been created\n",
            "or been moved out of Incoming.\n",
            "The following information may help to resolve the situation:\n",
            "\n",
            "The following packages have unmet dependencies:\n",
            " libnvidia-compute-510 : Depends: libnvidia-compute-535 but it is not installable\n",
            " nvidia-cuda-dev : Breaks: libcuda1 (< 495)\n",
            "                   Recommends: libnvcuvid1 but it is not installable\n",
            "\u001b[1;31mE: \u001b[0mUnable to correct problems, you have held broken packages.\u001b[0m\n",
            "Hit:1 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease\n",
            "Hit:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n",
            "Hit:3 http://security.ubuntu.com/ubuntu jammy-security InRelease\n",
            "Hit:4 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Hit:5 http://archive.ubuntu.com/ubuntu jammy-updates InRelease\n",
            "Hit:6 http://archive.ubuntu.com/ubuntu jammy-backports InRelease\n",
            "Hit:7 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Hit:8 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:9 https://r2u.stat.illinois.edu/ubuntu jammy InRelease\n",
            "Hit:10 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Reading package lists... Done\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "Requirement already satisfied: catboost in /usr/local/lib/python3.11/dist-packages (1.2.8)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.11/dist-packages (from catboost) (0.20.3)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from catboost) (3.10.0)\n",
            "Requirement already satisfied: numpy<3.0,>=1.16.0 in /usr/local/lib/python3.11/dist-packages (from catboost) (2.0.2)\n",
            "Requirement already satisfied: pandas>=0.24 in /usr/local/lib/python3.11/dist-packages (from catboost) (2.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from catboost) (1.15.2)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.11/dist-packages (from catboost) (5.24.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from catboost) (1.17.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.24->catboost) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.24->catboost) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.24->catboost) (2025.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (4.57.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (11.2.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (3.2.3)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from plotly->catboost) (9.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sklearn\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "import imblearn\n",
        "from imblearn.over_sampling import SMOTE\n",
        "import xgboost as xgb\n",
        "from xgboost import XGBClassifier\n",
        "import catboost\n",
        "from catboost import CatBoostClassifier\n",
        "import lightgbm as lgb\n",
        "from lightgbm import early_stopping, log_evaluation, LGBMClassifier"
      ],
      "metadata": {
        "id": "PId0UusIH594"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"pandas version: {pd.__version__}\")\n",
        "print(f\"numpy version: {np.__version__}\")\n",
        "print(f\"lightgbm version: {lgb.__version__}\")\n",
        "print(f\"catboost version: {catboost.__version__}\")\n",
        "print(f\"xgboost version: {xgb.__version__}\")\n",
        "print(f\"sklearn version: {sklearn.__version__}\")\n",
        "print(f\"imblearn version: {imblearn.__version__}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aFyqjR54M70-",
        "outputId": "5f99f235-a665-423a-8f29-ff66b7649221"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "pandas version: 2.2.2\n",
            "numpy version: 2.0.2\n",
            "lightgbm version: 4.1.0\n",
            "catboost version: 1.2.8\n",
            "xgboost version: 2.1.4\n",
            "sklearn version: 1.6.1\n",
            "imblearn version: 0.13.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data load & Preprocessing (1) - train data"
      ],
      "metadata": {
        "id": "YKoy3B4ptmQE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 회원정보 (customer)"
      ],
      "metadata": {
        "id": "XL28V-ndDcPG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- customer_train_df 생성"
      ],
      "metadata": {
        "id": "KWzQPL3fFiwp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Google Drive에 있는 데이터 경로\n",
        "base_dir = \"/content/drive/MyDrive/Data\"\n",
        "\n",
        "# 데이터 분할(폴더) 구분\n",
        "data_splits = [\"train\"] # train 만!\n",
        "\n",
        "# 각 데이터 유형별 폴더명, 파일 접미사, 변수 접두어 설정\n",
        "data_categories = {\n",
        "    \"회원정보\": {\"folder\": \"1.회원정보\", \"suffix\": \"회원정보\", \"var_prefix\": \"customer\"}\n",
        "}\n",
        "\n",
        "# 2018년 7월부터 12월까지의 월 리스트\n",
        "months = ['07', '08', '09', '10', '11', '12']\n",
        "\n",
        "for split in data_splits:\n",
        "    for category, info in data_categories.items():\n",
        "        folder = info[\"folder\"]\n",
        "        suffix = info[\"suffix\"]\n",
        "        var_prefix = info[\"var_prefix\"]\n",
        "\n",
        "        for month in months:\n",
        "            # 파일명 형식: 2018{month}_{split}_{suffix}.parquet\n",
        "            file_path = f\"{base_dir}/{split}/{folder}/2018{month}_{split}_{suffix}.parquet\"\n",
        "\n",
        "            # 변수명 형식: {var_prefix}_{split}_{month}\n",
        "            variable_name = f\"{var_prefix}_{split}_{month}\"\n",
        "\n",
        "            globals()[variable_name] = pd.read_parquet(file_path)\n",
        "            print(f\"{variable_name} is loaded from {file_path}\")\n",
        "\n",
        "gc.collect()"
      ],
      "metadata": {
        "id": "Qrfx2l8yDlxi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "96d24b54-a214-4242-dfe9-0d2a7a26f153"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "customer_train_07 is loaded from /content/drive/MyDrive/Data/train/1.회원정보/201807_train_회원정보.parquet\n",
            "customer_train_08 is loaded from /content/drive/MyDrive/Data/train/1.회원정보/201808_train_회원정보.parquet\n",
            "customer_train_09 is loaded from /content/drive/MyDrive/Data/train/1.회원정보/201809_train_회원정보.parquet\n",
            "customer_train_10 is loaded from /content/drive/MyDrive/Data/train/1.회원정보/201810_train_회원정보.parquet\n",
            "customer_train_11 is loaded from /content/drive/MyDrive/Data/train/1.회원정보/201811_train_회원정보.parquet\n",
            "customer_train_12 is loaded from /content/drive/MyDrive/Data/train/1.회원정보/201812_train_회원정보.parquet\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "93"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터 유형별 설정\n",
        "info_categories = [\"customer\"]\n",
        "\n",
        "# 월 설정\n",
        "months = ['07', '08', '09', '10', '11', '12']\n",
        "\n",
        "# 각 유형별로 월별 데이터를 합쳐서 새로운 변수에 저장\n",
        "train_dfs = {}\n",
        "\n",
        "for prefix in info_categories:\n",
        "    # globals()에서 동적 변수명으로 데이터프레임들을 가져와 리스트에 저장\n",
        "    df_list = [globals()[f\"{prefix}_train_{month}\"] for month in months]\n",
        "    train_dfs[f\"{prefix}_train_df\"] = pd.concat(df_list, axis=0)\n",
        "    gc.collect()\n",
        "    print(f\"{prefix}_train_df is created with shape: {train_dfs[f'{prefix}_train_df'].shape}\")\n",
        "\n",
        "customer_train_df = train_dfs[\"customer_train_df\"]\n",
        "gc.collect()"
      ],
      "metadata": {
        "id": "MMh4GyLPJKjG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3c735371-fb48-4cc2-bf81-3640db30715f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "customer_train_df is created with shape: (2400000, 78)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 전처리"
      ],
      "metadata": {
        "id": "WLZvlUHADx5b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "##### 1. 결측치 처리\n",
        "# '_1순위신용체크구분', '_2순위신용체크구분’\n",
        "#    → 결측치 '기타'로 채우기\n",
        "#    → '_1순위신용체크구분_인코딩', '_2순위신용체크구분_인코딩’\n",
        "customer_train_df['_1순위신용체크구분'] = customer_train_df['_1순위신용체크구분'].fillna('기타')\n",
        "customer_train_df['_2순위신용체크구분'] = customer_train_df['_2순위신용체크구분'].fillna('기타')\n",
        "mapping = {'신용': 1, '체크': 0, '기타': -1}\n",
        "customer_train_df['1순위신용체크구분_인코딩'] = customer_train_df['_1순위신용체크구분'].map(mapping)\n",
        "customer_train_df['2순위신용체크구분_인코딩'] = customer_train_df['_2순위신용체크구분'].map(mapping)\n",
        "customer_train_df.drop(columns=['_1순위신용체크구분','_2순위신용체크구분'], inplace=True)\n",
        "\n",
        "# 가입통신회사코드 → 가입통신회사_S사여부\n",
        "customer_train_df['가입통신회사_S사여부'] = (customer_train_df['가입통신회사코드'] == 'S사').astype(int)\n",
        "customer_train_df = customer_train_df.drop(columns=['가입통신회사코드'])\n",
        "\n",
        "# 직장시도명 → 직장_수도권여부\n",
        "customer_train_df['직장_수도권여부'] = customer_train_df['직장시도명'].isin(['서울', '경기']).astype(int)\n",
        "customer_train_df = customer_train_df.drop(columns=['직장시도명'])\n",
        "\n",
        "# 결측치 많은 변수 삭제!\n",
        "customer_train_df = customer_train_df.drop(columns=['최종카드발급일자','최종유효년월_신용_이용가능', '최종유효년월_신용_이용'])\n",
        "\n",
        "\n",
        "##### 2. 자료형 변환\n",
        "# 거주시도명 → 거주지_수도권여부\n",
        "customer_train_df['거주지_수도권여부'] = customer_train_df['거주시도명'].isin(['서울', '경기']).astype(int)\n",
        "customer_train_df = customer_train_df.drop(columns=['거주시도명'])\n",
        "\n",
        "# 연회비발생카드수_B0M → 연회비발생카드수_B0M_이진\n",
        "customer_train_df['연회비발생카드수_B0M_이진'] = customer_train_df['연회비발생카드수_B0M'].isin(['1개이상']).astype(int)\n",
        "customer_train_df = customer_train_df.drop(columns=['연회비발생카드수_B0M'])\n",
        "\n",
        "# 데이터 다 동일한 변수 4개 삭제!\n",
        "columns_drop = ['상품관련면제카드수_B0M','임직원면제카드수_B0M', '우수회원면제카드수_B0M', '기타면제카드수_B0M']\n",
        "customer_train_df = customer_train_df.drop(columns=columns_drop)\n",
        "\n",
        "# Life_Stage: 파생변수(Life_Stage_자녀성장_여부) 생성 후 변수 삭제\n",
        "customer_train_df['Life_Stage_자녀성장_여부'] = customer_train_df['Life_Stage'].isin(['자녀성장(1)', '자녀성장(2)']).astype(int)\n",
        "customer_train_df = customer_train_df.drop(columns=['Life_Stage'])\n",
        "\n",
        "# 연령에서 숫자만 추출 후 int형으로 변환\n",
        "customer_train_df['연령'] = customer_train_df['연령'].str.extract(r'(\\d+)').astype(float).astype('Int64')\n",
        "\n",
        "##### 3.상관관계 분석\n",
        "# 데이터 다 동일한 변수 4개 삭제\n",
        "columns_drop = ['이용금액_R3M_체크_가족','연회비할인카드수_B0M','할인금액_기본연회비_B0M','할인금액_제휴연회비_B0M']\n",
        "customer_train_df = customer_train_df.drop(columns=columns_drop)\n",
        "\n",
        "##### 4. 변수 별로 확인\n",
        "# 4개의 변수 삭제\n",
        "# '입회일자_신용' 삭제 (입회경과개월수_신용 있음)\n",
        "# 데이터 다 동일한 변수 '이용카드수_체크_가족' 삭제\n",
        "# '청구금액_기본연회비_B0M','청구금액_제휴연회비_B0M’삭제 (의미 같은 변수 있음)\n",
        "columns_drop = ['입회일자_신용','이용카드수_체크_가족','청구금액_기본연회비_B0M','청구금액_제휴연회비_B0M']\n",
        "customer_train_df = customer_train_df.drop(columns=columns_drop)"
      ],
      "metadata": {
        "id": "JwFQZHB1Hb60"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 파일 저장"
      ],
      "metadata": {
        "id": "HUK5ch7ED3lo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# int64 -> int32로 변경 (메모리 줄이기 위함)\n",
        "for col in customer_train_df.select_dtypes(include='int64').columns:\n",
        "    if customer_train_df[col].max() < 2_147_483_647:\n",
        "        customer_train_df[col] = customer_train_df[col].astype('int32')\n",
        "\n",
        "# float64 -> float 32로 변경 (메모리 줄이기 위함)\n",
        "for col in customer_train_df.select_dtypes(include='float64').columns:\n",
        "    customer_train_df[col] = customer_train_df[col].astype('float32')\n",
        "\n",
        "#customer_train_df = customer_train_df.drop(columns=['Segment'])\n",
        "customer_train_df.to_parquet(\"/content/drive/MyDrive/Dacon/customer_train_cleaned.parquet\")"
      ],
      "metadata": {
        "id": "yFeo8bKjMwnY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 신용정보 (credit)"
      ],
      "metadata": {
        "id": "AZ8xPBZBDsc7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- credit_with_seg 생성"
      ],
      "metadata": {
        "id": "BNcfd_klKtHX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Google Drive에 있는 데이터 경로\n",
        "base_dir = \"/content/drive/MyDrive/Data\"\n",
        "\n",
        "# 데이터 분할(폴더) 구분\n",
        "data_splits = [\"train\"] # train 만!\n",
        "\n",
        "# 각 데이터 유형별 폴더명, 파일 접미사, 변수 접두어 설정\n",
        "data_categories = {\n",
        "    \"신용정보\": {\"folder\": \"2.신용정보\", \"suffix\": \"신용정보\", \"var_prefix\": \"credit\"}\n",
        "}\n",
        "\n",
        "# 2018년 7월부터 12월까지의 월 리스트\n",
        "months = ['07', '08', '09', '10', '11', '12']\n",
        "\n",
        "for split in data_splits:\n",
        "    for category, info in data_categories.items():\n",
        "        folder = info[\"folder\"]\n",
        "        suffix = info[\"suffix\"]\n",
        "        var_prefix = info[\"var_prefix\"]\n",
        "\n",
        "        for month in months:\n",
        "            # 파일명 형식: 2018{month}_{split}_{suffix}.parquet\n",
        "            file_path = f\"{base_dir}/{split}/{folder}/2018{month}_{split}_{suffix}.parquet\"\n",
        "\n",
        "            # 변수명 형식: {var_prefix}_{split}_{month}\n",
        "            variable_name = f\"{var_prefix}_{split}_{month}\"\n",
        "\n",
        "            globals()[variable_name] = pd.read_parquet(file_path)\n",
        "            print(f\"{variable_name} is loaded from {file_path}\")\n",
        "\n",
        "gc.collect()"
      ],
      "metadata": {
        "id": "1yNJeUnrKsnf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "19482cae-396b-4e32-f3b7-fa79d941922d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "credit_train_07 is loaded from /content/drive/MyDrive/Data/train/2.신용정보/201807_train_신용정보.parquet\n",
            "credit_train_08 is loaded from /content/drive/MyDrive/Data/train/2.신용정보/201808_train_신용정보.parquet\n",
            "credit_train_09 is loaded from /content/drive/MyDrive/Data/train/2.신용정보/201809_train_신용정보.parquet\n",
            "credit_train_10 is loaded from /content/drive/MyDrive/Data/train/2.신용정보/201810_train_신용정보.parquet\n",
            "credit_train_11 is loaded from /content/drive/MyDrive/Data/train/2.신용정보/201811_train_신용정보.parquet\n",
            "credit_train_12 is loaded from /content/drive/MyDrive/Data/train/2.신용정보/201812_train_신용정보.parquet\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "19"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터 유형별 설정\n",
        "info_categories = [\"credit\"]\n",
        "\n",
        "# 월 설정\n",
        "months = ['07', '08', '09', '10', '11', '12']\n",
        "\n",
        "# 각 유형별로 월별 데이터를 합쳐서 새로운 변수에 저장\n",
        "train_dfs = {}\n",
        "\n",
        "for prefix in info_categories:\n",
        "    # globals()에서 동적 변수명으로 데이터프레임들을 가져와 리스트에 저장\n",
        "    df_list = [globals()[f\"{prefix}_train_{month}\"] for month in months]\n",
        "    train_dfs[f\"{prefix}_train_df\"] = pd.concat(df_list, axis=0)\n",
        "    gc.collect()\n",
        "    print(f\"{prefix}_train_df is created with shape: {train_dfs[f'{prefix}_train_df'].shape}\")\n",
        "\n",
        "credit_train_df = train_dfs[\"credit_train_df\"]\n",
        "gc.collect()"
      ],
      "metadata": {
        "id": "L-6zq9JEKspz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "26da3bd6-360e-4535-dff7-45155e273e58"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "credit_train_df is created with shape: (2400000, 42)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "customer_train_df = pd.read_parquet('/content/drive/MyDrive/Dacon/customer_train_cleaned.parquet')\n",
        "customer_train_df_seg = customer_train_df[['기준년월','ID','Segment']]\n",
        "\n",
        "credit_with_seg = customer_train_df_seg.merge(credit_train_df, on=['기준년월', 'ID'], how='left') # segment 변수 추가\n",
        "#credit_with_seg.to_parquet('/content/drive/MyDrive/DACON/rawdata/credit_with_seg.parquet')"
      ],
      "metadata": {
        "id": "wHL_KLekKsrv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 전처리"
      ],
      "metadata": {
        "id": "s6OU1uaMLrhB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "##### 1. 결측치 처리\n",
        "# 'RV신청일자' 변수 삭제\n",
        "credit_with_seg = credit_with_seg.drop(columns=['RV신청일자'])\n",
        "\n",
        "# 'RV전환가능여부' → 'RV전환불가능여부'\n",
        "credit_with_seg['RV_전환가능여부_이진'] = (credit_with_seg['RV전환가능여부'] == 'N').astype(int)\n",
        "credit_with_seg = credit_with_seg.drop(columns='RV전환가능여부')\n",
        "\n",
        "##### 2. 자료형 변환\n",
        "# 자발한도감액횟수_R12M: '0회' → 0, '1회' → 1, '2회' → 2\n",
        "credit_with_seg['자발한도감액횟수_R12M'] = (\n",
        "    credit_with_seg['자발한도감액횟수_R12M']\n",
        "    .str.replace('회', '', regex=False)  # '회' 제거\n",
        "    .astype(int)  # 바로 int로 변환!\n",
        ")\n",
        "\n",
        "#‘한도증액횟수_R12M’ → '한도증액_R12M_여부': '0회' → 0, '1회이상' → 1\n",
        "credit_with_seg['한도증액_R12M_여부'] = credit_with_seg['한도증액횟수_R12M'].map({\n",
        "    '0회': 0,\n",
        "    '1회이상': 1\n",
        "    }).astype(int)\n",
        "credit_with_seg.drop(columns=['한도증액횟수_R12M'], inplace=True)\n",
        "\n",
        "# '카드론동의여부': 'Y' → 1, 'N' → 0\n",
        "credit_with_seg['카드론동의여부'] = credit_with_seg['카드론동의여부'].map({\n",
        "    'Y': 1,\n",
        "    'N': 0\n",
        "    }).astype(int)\n",
        "\n",
        "# '한도심사요청건수' → '한도심사요청여부': '0회' → 0, '1회이상' → 1\n",
        "credit_with_seg['한도심사요청여부'] = credit_with_seg['한도심사요청건수'].map({\n",
        "    '0회': 0,\n",
        "    '1회이상': 1\n",
        "    }).astype(int)\n",
        "credit_with_seg.drop(columns=['한도심사요청건수'], inplace=True)"
      ],
      "metadata": {
        "id": "s0SpQrZrL4et"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##### 3. 상관관계 분석\n",
        "# 데이터 모두 동일한 변수 1개 삭제\n",
        "credit_with_seg = credit_with_seg.drop(columns=['시장연체상환여부_R3M'])\n",
        "\n",
        "##### 4. 변수 별로 확인\n",
        "# 'RV실사용여부' 변수 추가\n",
        "credit_with_seg['RV실사용여부'] = (credit_with_seg['RV약정청구율'] > 0).astype(int)\n",
        "\n",
        "# '강제한도감액횟수_2회이상여부' 변수 추가\n",
        "credit_with_seg['강제한도감액횟수_2회이상여부'] = (credit_with_seg['강제한도감액횟수_R12M'] > 1).astype(int)\n",
        "\n",
        "# '강제한도감액금액_R12M_3이상여부' 변수 추가\n",
        "credit_with_seg['강제한도감액금액_R12M_3이상여부'] = (credit_with_seg['강제한도감액금액_R12M'] > 2).astype(int)\n",
        "\n",
        "# '상향가능CA한도금액_1여부' 변수 추가\n",
        "credit_with_seg['상향가능CA한도금액_1여부'] = (credit_with_seg['상향가능CA한도금액'] == 1).astype(int)\n",
        "\n",
        "# '카드이용한도금액_A수준복합' 변수 추가\n",
        "a_limit = credit_with_seg[credit_with_seg['Segment'] == 'A']['카드이용한도금액_B1M']\n",
        "q1 = a_limit.quantile(0.25)\n",
        "q3 = a_limit.quantile(0.75)\n",
        "iqr = q3 - q1\n",
        "lower_bound = q1 - 1.5 * iqr\n",
        "upper_bound = q3 + 1.5 * iqr\n",
        "a_no_outlier = a_limit[(a_limit >= lower_bound) & (a_limit <= upper_bound)]\n",
        "a_B1M = a_no_outlier.min()\n",
        "print(f\"A의 이상치 제외 후 최솟값: {a_B1M:,}\")  # 170,344\n",
        "\n",
        "a_limit = credit_with_seg[credit_with_seg['Segment'] == 'A']['카드이용한도금액_B2M']\n",
        "q1 = a_limit.quantile(0.25)\n",
        "q3 = a_limit.quantile(0.75)\n",
        "iqr = q3 - q1\n",
        "lower_bound = q1 - 1.5 * iqr\n",
        "upper_bound = q3 + 1.5 * iqr\n",
        "a_no_outlier = a_limit[(a_limit >= lower_bound) & (a_limit <= upper_bound)]\n",
        "a_B2M = a_no_outlier.min()\n",
        "print(f\"A의 이상치 제외 후 최솟값: {a_B2M:,}\")  # 170,344\n",
        "\n",
        "def classify_dual_limit(row):\n",
        "    b1 = row['카드이용한도금액_B1M'] >= a_B1M\n",
        "    b2 = row['카드이용한도금액_B2M'] >= a_B2M\n",
        "    if b1 and b2:\n",
        "        return 2     # 둘 다 170,344 이상\n",
        "    elif b1 or b2:\n",
        "        return 1     # 하나만 170,344 이상\n",
        "    else:\n",
        "        return 0    # 둘 다 170,344 미만\n",
        "\n",
        "credit_with_seg['카드이용한도금액_A수준복합'] = credit_with_seg.apply(classify_dual_limit, axis=1)"
      ],
      "metadata": {
        "id": "23IQtcEpM44w",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "67d1629b-80d4-4bcc-c3a6-ce805185d246"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "A의 이상치 제외 후 최솟값: 170,344\n",
            "A의 이상치 제외 후 최솟값: 170,344\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 파일 저장"
      ],
      "metadata": {
        "id": "d83HX5sIE-A8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# int64 -> int32로 변경 (메모리 줄이기 위함)\n",
        "for col in credit_with_seg.select_dtypes(include='int64').columns:\n",
        "    if credit_with_seg[col].max() < 2_147_483_647:\n",
        "        credit_with_seg[col] = credit_with_seg[col].astype('int32')\n",
        "\n",
        "# float64 -> float 32로 변경 (메모리 줄이기 위함)\n",
        "for col in credit_with_seg.select_dtypes(include='float64').columns:\n",
        "    credit_with_seg[col] = credit_with_seg[col].astype('float32')"
      ],
      "metadata": {
        "id": "YPEKXPYqTyeI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "credit_with_seg = credit_with_seg.drop(columns=['Segment'])\n",
        "credit_with_seg.to_parquet(\"/content/drive/MyDrive/Dacon/credit_train_cleaned.parquet\")"
      ],
      "metadata": {
        "id": "SB8NI5NAL4Q9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 승인매출정보 (sales)"
      ],
      "metadata": {
        "id": "7KQvAVAKDsfO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import gc\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1DDPAN8VqLNA",
        "outputId": "04ebae5d-4dcf-474e-fd1f-535fea35a8c9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- sales_with_seg 생성"
      ],
      "metadata": {
        "id": "tPclCI96NyIJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Google Drive에 있는 데이터 경로\n",
        "base_dir = \"/content/drive/MyDrive/Data\"\n",
        "\n",
        "# 데이터 분할(폴더) 구분\n",
        "data_splits = [\"train\"] # train 만!\n",
        "\n",
        "# 각 데이터 유형별 폴더명, 파일 접미사, 변수 접두어 설정\n",
        "data_categories = {\n",
        "    \"승인매출정보\": {\"folder\": \"3.승인매출정보\", \"suffix\": \"승인매출정보\", \"var_prefix\": \"sales\"}\n",
        "}\n",
        "\n",
        "# 2018년 7월부터 12월까지의 월 리스트\n",
        "months = ['07', '08', '09', '10', '11', '12']\n",
        "\n",
        "for split in data_splits:\n",
        "    for category, info in data_categories.items():\n",
        "        folder = info[\"folder\"]\n",
        "        suffix = info[\"suffix\"]\n",
        "        var_prefix = info[\"var_prefix\"]\n",
        "\n",
        "        for month in months:\n",
        "            # 파일명 형식: 2018{month}_{split}_{suffix}.parquet\n",
        "            #file_path = f\"./{split}/{folder}/2018{month}_{split}_{suffix}.parquet\"\n",
        "            file_path = f\"{base_dir}/{split}/{folder}/2018{month}_{split}_{suffix}.parquet\"\n",
        "\n",
        "            # 변수명 형식: {var_prefix}_{split}_{month}\n",
        "            variable_name = f\"{var_prefix}_{split}_{month}\"\n",
        "\n",
        "            globals()[variable_name] = pd.read_parquet(file_path)\n",
        "            print(f\"{variable_name} is loaded from {file_path}\")\n",
        "\n",
        "gc.collect()"
      ],
      "metadata": {
        "id": "40qacUK-HUbh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b84f1f18-8430-48dc-d5e6-3ce45421a4ba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sales_train_07 is loaded from /content/drive/MyDrive/Data/train/3.승인매출정보/201807_train_승인매출정보.parquet\n",
            "sales_train_08 is loaded from /content/drive/MyDrive/Data/train/3.승인매출정보/201808_train_승인매출정보.parquet\n",
            "sales_train_09 is loaded from /content/drive/MyDrive/Data/train/3.승인매출정보/201809_train_승인매출정보.parquet\n",
            "sales_train_10 is loaded from /content/drive/MyDrive/Data/train/3.승인매출정보/201810_train_승인매출정보.parquet\n",
            "sales_train_11 is loaded from /content/drive/MyDrive/Data/train/3.승인매출정보/201811_train_승인매출정보.parquet\n",
            "sales_train_12 is loaded from /content/drive/MyDrive/Data/train/3.승인매출정보/201812_train_승인매출정보.parquet\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "90"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터 유형별 설정\n",
        "info_categories = [\"sales\"]\n",
        "\n",
        "# 월 설정\n",
        "months = ['07', '08', '09', '10', '11', '12']\n",
        "\n",
        "# 각 유형별로 월별 데이터를 합쳐서 새로운 변수에 저장\n",
        "train_dfs = {}\n",
        "\n",
        "for prefix in info_categories:\n",
        "    # globals()에서 동적 변수명으로 데이터프레임들을 가져와 리스트에 저장\n",
        "    df_list = [globals()[f\"{prefix}_train_{month}\"] for month in months]\n",
        "    train_dfs[f\"{prefix}_train_df\"] = pd.concat(df_list, axis=0)\n",
        "    gc.collect()\n",
        "    print(f\"{prefix}_train_df is created with shape: {train_dfs[f'{prefix}_train_df'].shape}\")\n",
        "\n",
        "sales_train_df = train_dfs[\"sales_train_df\"]\n",
        "gc.collect()"
      ],
      "metadata": {
        "id": "0O5EAgZiOJP3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "efbc1a6e-cb7b-483b-a139-87d3344fee6e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sales_train_df is created with shape: (2400000, 406)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "customer_train_df = pd.read_parquet('/content/drive/MyDrive/Dacon/customer_train_cleaned.parquet')\n",
        "customer_train_df_seg = customer_train_df[['기준년월','ID','Segment']]\n",
        "\n",
        "sales_with_seg = customer_train_df_seg.merge(sales_train_df, on=['기준년월', 'ID'], how='left') # segment 변수 추가\n",
        "\n",
        "del sales_train_df\n",
        "del customer_train_df\n",
        "del customer_train_df_seg\n",
        "gc.collect()"
      ],
      "metadata": {
        "id": "c3cAEcyWObAS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b8deb67d-dbf7-4700-d399-5143d285cd19"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 전처리"
      ],
      "metadata": {
        "id": "3C-eqwTdO4_q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. 결측치 처리"
      ],
      "metadata": {
        "id": "KPbjWF7lPc-i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# '_n순위@@업종' 변수(총 15개 변수) 결측치는 '없음'으로 채우기\n",
        "upjong_cols = [\n",
        "    '_1순위업종','_2순위업종','_3순위업종',\n",
        "    '_1순위쇼핑업종','_2순위쇼핑업종','_3순위쇼핑업종',\n",
        "    '_1순위교통업종','_2순위교통업종','_3순위교통업종',\n",
        "    '_1순위여유업종','_2순위여유업종','_3순위여유업종',\n",
        "    '_1순위납부업종','_2순위납부업종','_3순위납부업종'\n",
        "]\n",
        "\n",
        "sales_with_seg[upjong_cols] = sales_with_seg[upjong_cols].fillna('없음')"
      ],
      "metadata": {
        "id": "ju7NYcPOO6W6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# '_n순위업종_AB' 변수 추가 (상관계수 -0.3030)\n",
        "\n",
        "'''\n",
        "- 1순위 업종이 쇼핑\t+1\n",
        "- 2순위 업종이 사교활동\t+1\n",
        "- 2순위 업종이 교육\t+0.5\n",
        "- 2순위 업종이 의료\t+1.5 (A, B에서 더 강하게 나타나므로)\n",
        "- 3순위 업종이 사교활동\t+1\n",
        "- 3순위 업종이 의료\t+1.5 (A, B에서 더 강하게 나타나므로)\n",
        "\n",
        "- 2순위 업종이 없음 -1\n",
        "- 3순위 업종이 없음 -1\n",
        "- 2순위 업종이 교통 -0.5\n",
        "- 2순위 업종이 납부 -0.5\n",
        "'''\n",
        "\n",
        "def compute_ab_score(row):\n",
        "    score = 0\n",
        "    # 가점 조건\n",
        "    if row['_1순위업종'] == '쇼핑':\n",
        "        score += 1\n",
        "    if row['_2순위업종'] == '사교활동':\n",
        "        score += 1\n",
        "    if row['_2순위업종'] == '교육':\n",
        "        score += 0.5\n",
        "    if row['_2순위업종'] == '의료':\n",
        "        score += 1\n",
        "    if row['_3순위업종'] == '사교활동':\n",
        "        score += 1\n",
        "    if row['_3순위업종'] == '의료':\n",
        "        score += 1\n",
        "\n",
        "    # 감점 조건\n",
        "    if row['_2순위업종'] == '없음':\n",
        "        score -= 1\n",
        "    if row['_3순위업종'] == '없음':\n",
        "        score -= 1\n",
        "    if row['_2순위업종'] == '교통':\n",
        "        score -= 0.5\n",
        "    if row['_2순위업종'] == '납부':\n",
        "        score -= 0.5\n",
        "\n",
        "    return score\n",
        "\n",
        "sales_with_seg['_n순위업종_AB'] = sales_with_seg.apply(compute_ab_score, axis=1)"
      ],
      "metadata": {
        "id": "nf7M1PRSO6Zo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# '_n순위쇼핑업종_AB' 변수 추가 (상관계수 -0.3304)\n",
        "\n",
        "'''\n",
        "- 1순위 쇼핑업종이 온라인 +1\n",
        "- 2순위 쇼핑업종이 도소매 +1\n",
        "- 3순위 쇼핑업종이 마트 +1\n",
        "\n",
        "- 1순위 쇼핑업종이 없음 -1\n",
        "- 2순위 쇼핑업종이 슈퍼마켓 -0.5\n",
        "- 2순위 쇼핑업종이 없음 -0.5\n",
        "- 3순위 쇼핑업종이 없음 -1\n",
        "'''\n",
        "\n",
        "def compute_ab_score(row):\n",
        "    score = 0\n",
        "    # 가점 조건\n",
        "    if row['_1순위쇼핑업종'] == '온라인':\n",
        "        score += 1\n",
        "    if row['_2순위쇼핑업종'] == '도소매':\n",
        "        score += 1\n",
        "    if row['_3순위쇼핑업종'] == '마트':\n",
        "        score += 1\n",
        "\n",
        "    # 감점 조건\n",
        "    if row['_1순위쇼핑업종'] == '없음':\n",
        "        score -= 1\n",
        "    if row['_2순위쇼핑업종'] == '슈퍼마켓':\n",
        "        score -= 0.5\n",
        "    if row['_2순위쇼핑업종'] == '없음':\n",
        "        score -= 0.5\n",
        "    if row['_3순위쇼핑업종'] == '없음':\n",
        "        score -= 1\n",
        "\n",
        "    return score\n",
        "\n",
        "sales_with_seg['_n순위쇼핑업종_AB'] = sales_with_seg.apply(compute_ab_score, axis=1)"
      ],
      "metadata": {
        "id": "c4I5jXBaPQt5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# '_n순위교통업종_AB' 변수 추가 (상관계수 -0.34514)\n",
        "\n",
        "'''\n",
        "- 1순위 교통업종이 주유 +1\n",
        "- 2순위 교통업종이 정비 +1\n",
        "- 3순위 교통업종이 택시 +0.5\n",
        "- 3순위 교통업종이 정비 +0.5\n",
        "- 3순위 교통업종이 철도버스 +0.5\n",
        "\n",
        "- 1순위 교통업종이 없음 -1\n",
        "- 2순위 교통업종이 없음 -1\n",
        "'''\n",
        "\n",
        "def compute_ab_score(row):\n",
        "    score = 0\n",
        "    # 가점 조건\n",
        "    if row['_1순위교통업종'] == '주유':\n",
        "        score += 1\n",
        "    if row['_2순위교통업종'] == '정비':\n",
        "        score += 1\n",
        "    if row['_3순위교통업종'] == '택시':\n",
        "        score += 0.5\n",
        "    if row['_3순위교통업종'] == '정비':\n",
        "        score += 0.5\n",
        "    if row['_3순위교통업종'] == '철도버스':\n",
        "        score += 0.5\n",
        "\n",
        "    # 감점 조건\n",
        "    if row['_1순위교통업종'] == '없음':\n",
        "        score -= 1\n",
        "    if row['_2순위교통업종'] == '없음':\n",
        "        score -= 1\n",
        "\n",
        "    return score\n",
        "\n",
        "sales_with_seg['_n순위교통업종_AB'] = sales_with_seg.apply(compute_ab_score, axis=1)"
      ],
      "metadata": {
        "id": "q66wJFMpPQwe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# '_n순위여유업종_AB' 변수 추가 (상관계수 -0.26628)\n",
        "\n",
        "'''\n",
        "- 1순위 여유업종이 운동 +1\n",
        "- 1순위 여유업종이 항공 +1\n",
        "- 2순위 여유업종이 숙박 +1\n",
        "- 2순위 여유업종이 공연 +1\n",
        "- 3순위 여유업종이 숙박 +1\n",
        "- 3순위 여유업종이 공연 +1\n",
        "- 3순위 여유업종이 여유기타 +1\n",
        "\n",
        "- 1순위 여유업종이 없음 -0.5\n",
        "- 2순위 여유업종이 없음 -0.5\n",
        "- 3순위 여유업종이 없음 -0.5\n",
        "'''\n",
        "\n",
        "def compute_ab_score(row):\n",
        "    score = 0\n",
        "    # 가점 조건\n",
        "    if row['_1순위여유업종'] == '운동':\n",
        "        score += 1\n",
        "    if row['_1순위여유업종'] == '항공':\n",
        "        score += 1\n",
        "    if row['_2순위여유업종'] == '숙박':\n",
        "        score += 1\n",
        "    if row['_2순위여유업종'] == '공연':\n",
        "        score += 1\n",
        "    if row['_3순위여유업종'] == '숙박':\n",
        "        score += 1\n",
        "    if row['_3순위여유업종'] == '공연':\n",
        "        score += 1\n",
        "    if row['_3순위여유업종'] == '여유기타':\n",
        "        score += 1\n",
        "\n",
        "    # 감점 조건\n",
        "    if row['_1순위여유업종'] == '없음':\n",
        "        score -= 0.5\n",
        "    if row['_2순위여유업종'] == '없음':\n",
        "        score -= 0.5\n",
        "    if row['_3순위여유업종'] == '없음':\n",
        "        score -= 0.5\n",
        "\n",
        "    return score\n",
        "\n",
        "sales_with_seg['_n순위여유업종_AB'] = sales_with_seg.apply(compute_ab_score, axis=1)"
      ],
      "metadata": {
        "id": "VI0G6tyEPQzS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# '_n순위납부업종_AB' 변수 추가 (상관계수 -0.2579)\n",
        "\n",
        "'''\n",
        "- 1순위 납부업종이 납부기타 +0.5\n",
        "- 1순위 납부업종이 보험료 +0.5\n",
        "- 1순위 납부업종이 통신비 +0.5\n",
        "- 2순위 납부업종이 납부기타 +0.5\n",
        "- 2순위 납부업종이 보험료 +0.5\n",
        "- 2순위 납부업종이 통신비 +0.5\n",
        "- 3순위 납부업종이 납부기타 +0.5\n",
        "\n",
        "- 1순위 납부업종이 없음 -0.5\n",
        "- 2순위 납부업종이 없음 -0.5\n",
        "- 3순위 납부업종이 없음 -0.5\n",
        "'''\n",
        "\n",
        "def compute_ab_score(row):\n",
        "    score = 0\n",
        "    # 가점 조건\n",
        "    if row['_1순위납부업종'] == '납부기타':\n",
        "        score += 0.5\n",
        "    if row['_1순위납부업종'] == '보험료':\n",
        "        score += 0.5\n",
        "    if row['_1순위납부업종'] == '통신비':\n",
        "        score += 0.5\n",
        "    if row['_2순위납부업종'] == '납부기타':\n",
        "        score += 0.5\n",
        "    if row['_2순위납부업종'] == '보험료':\n",
        "        score += 0.5\n",
        "    if row['_2순위납부업종'] == '통신비':\n",
        "        score += 0.5\n",
        "    if row['_3순위납부업종'] == '납부기타':\n",
        "        score += 0.5\n",
        "\n",
        "    # 감점 조건\n",
        "    if row['_1순위납부업종'] == '없음':\n",
        "        score -= 0.5\n",
        "    if row['_2순위납부업종'] == '없음':\n",
        "        score -= 0.5\n",
        "    if row['_3순위납부업종'] == '없음':\n",
        "        score -= 0.5\n",
        "\n",
        "    return score\n",
        "\n",
        "sales_with_seg['_n순위납부업종_AB'] = sales_with_seg.apply(compute_ab_score, axis=1)"
      ],
      "metadata": {
        "id": "fgKI-MTAPQ3N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# '_n순위@@업종_AB' 5개 변수 합친 변수 '_n순위업종_AB_총합' 추가 (상관계수 -0.3927)\n",
        "sales_with_seg['_n순위업종_AB_총합'] = (\n",
        "    sales_with_seg['_n순위업종_AB'] +\n",
        "    sales_with_seg['_n순위쇼핑업종_AB'] +\n",
        "    sales_with_seg['_n순위교통업종_AB'] +\n",
        "    sales_with_seg['_n순위여유업종_AB'] +\n",
        "    sales_with_seg['_n순위납부업종_AB']\n",
        ")\n",
        "\n",
        "# '_n순위@@업종' 변수 삭제\n",
        "cols_to_drop = [\n",
        "    '_1순위업종','_2순위업종','_3순위업종',\n",
        "    '_1순위쇼핑업종','_2순위쇼핑업종','_3순위쇼핑업종',\n",
        "    '_1순위교통업종','_2순위교통업종','_3순위교통업종',\n",
        "    '_1순위여유업종','_2순위여유업종','_3순위여유업종',\n",
        "    '_1순위납부업종','_2순위납부업종','_3순위납부업종'\n",
        "]\n",
        "\n",
        "sales_with_seg.drop(columns=cols_to_drop, inplace=True)"
      ],
      "metadata": {
        "id": "cu1zt124PX6u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 결측치 80% 이상인 최종카드론 관련 변수 삭제\n",
        "cols_to_drop = ['최종카드론_대출일자','최종카드론_신청경로코드','최종카드론_금융상환방식코드']\n",
        "sales_with_seg = sales_with_seg.drop(columns=cols_to_drop)"
      ],
      "metadata": {
        "id": "SyPsp2cvPX9Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. 자료형 변환"
      ],
      "metadata": {
        "id": "lnurOakNPkNL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# '이용금액대_점수' 변수 생성 (상관계수 -0.6026)\n",
        "amount_mapping = {\n",
        "    '01.100만원+': 18,\n",
        "    '02.50만원+': 5,\n",
        "    '03.30만원+': 2,\n",
        "    '04.10만원+': 2,\n",
        "    '05.10만원-': 1,\n",
        "    '09.미사용': 1\n",
        "}\n",
        "\n",
        "sales_with_seg['이용금액대_점수'] = sales_with_seg['이용금액대'].map(amount_mapping)\n",
        "\n",
        "# 원래 변수 '이용금액대' 삭제\n",
        "sales_with_seg = sales_with_seg.drop(columns=['이용금액대'])"
      ],
      "metadata": {
        "id": "lTN4s_xhPX_r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. 상관관계 분석"
      ],
      "metadata": {
        "id": "npfA9-zTPo5T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터 값이 모두 같은 변수 2개 제거\n",
        "sales_with_seg = sales_with_seg.drop(columns=['승인거절건수_입력오류_B0M','승인거절건수_기타_B0M'])"
      ],
      "metadata": {
        "id": "MPHoHADOPqym"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 변수 별로 데이터 살펴보기"
      ],
      "metadata": {
        "id": "qHMx9BF7ac93"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# '이용여부_@@' 변수 생성\n",
        "sales_with_seg['이용여부_기본']   = (sales_with_seg['최종이용일자_기본'] != 10101).astype(int)\n",
        "sales_with_seg['이용여부_신판']   = (sales_with_seg['최종이용일자_신판'] != 10101).astype(int)\n",
        "sales_with_seg['이용여부_CA']    = (sales_with_seg['최종이용일자_CA'] != 10101).astype(int)\n",
        "sales_with_seg['이용여부_카드론'] = (sales_with_seg['최종이용일자_카드론'] != 10101).astype(int)\n",
        "sales_with_seg['이용여부_체크']   = (sales_with_seg['최종이용일자_체크'] != 10101).astype(int)\n",
        "sales_with_seg['이용여부_일시불'] = (sales_with_seg['최종이용일자_일시불'] != 10101).astype(int)\n",
        "sales_with_seg['이용여부_할부']   = (sales_with_seg['최종이용일자_할부'] != 10101).astype(int)\n",
        "\n",
        "# 원래 '최종이용일자_@@' 변수 삭제\n",
        "for i in ['최종이용일자_기본','최종이용일자_신판','최종이용일자_CA','최종이용일자_카드론','최종이용일자_체크','최종이용일자_일시불','최종이용일자_할부']:\n",
        "  sales_with_seg = sales_with_seg.drop(columns=[i])"
      ],
      "metadata": {
        "id": "ipc3A1le-OrM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- BOM 변수"
      ],
      "metadata": {
        "id": "Ok4UxVuZgN6z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "##### 이용건수 #####\n",
        "\n",
        "# 데이터 값이 모두 같은 변수 제거\n",
        "sales_with_seg = sales_with_seg.drop(columns=['이용건수_부분무이자_B0M'])\n",
        "\n",
        "# '이용건수_신용_B0M' 변수 값 보정\n",
        "sales_with_seg['이용건수_신용_B0M'] = sales_with_seg['이용건수_신용_B0M'] + sales_with_seg['이용건수_카드론_B0M']\n",
        "\n",
        "\n",
        "\n",
        "##### 이용금액 #####\n",
        "\n",
        "# 데이터 값이 모두 같은 변수 제거\n",
        "sales_with_seg = sales_with_seg.drop(columns=['이용금액_부분무이자_B0M'])\n",
        "\n",
        "# '이용금액_신용_B0M', '이용금액_신판_B0M' 변수 생성\n",
        "sales_with_seg['이용금액_신용_B0M'] = sales_with_seg['이용금액_일시불_B0M'] + sales_with_seg['이용금액_할부_B0M'] + sales_with_seg['이용금액_CA_B0M'] + sales_with_seg['이용금액_카드론_B0M']\n",
        "sales_with_seg['이용금액_신판_B0M'] = sales_with_seg['이용금액_일시불_B0M'] + sales_with_seg['이용금액_할부_B0M']"
      ],
      "metadata": {
        "id": "G_Ww01xJ-Otb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 건수별평균이용금액 변수 생성\n",
        "sales_with_seg['건수별평균이용금액_신용_B0M'] = np.where(\n",
        "    (sales_with_seg['이용건수_신용_B0M'] == 0) | (sales_with_seg['이용금액_신용_B0M'] == 0), 0,\n",
        "    sales_with_seg['이용금액_신용_B0M'] / sales_with_seg['이용건수_신용_B0M'].abs()\n",
        ")\n",
        "\n",
        "sales_with_seg['건수별평균이용금액_신판_B0M'] = np.where(\n",
        "    (sales_with_seg['이용건수_신판_B0M'] == 0) | (sales_with_seg['이용금액_신판_B0M'] == 0), 0,\n",
        "    sales_with_seg['이용금액_신판_B0M'] / sales_with_seg['이용건수_신판_B0M'].abs()\n",
        ")\n",
        "\n",
        "sales_with_seg['건수별평균이용금액_일시불_B0M'] = np.where(\n",
        "    (sales_with_seg['이용건수_일시불_B0M'] == 0) | (sales_with_seg['이용금액_일시불_B0M'] == 0), 0,\n",
        "    sales_with_seg['이용금액_일시불_B0M'] / sales_with_seg['이용건수_일시불_B0M'].abs()\n",
        ")\n",
        "\n",
        "sales_with_seg['건수별평균이용금액_할부_B0M'] = np.where(\n",
        "    (sales_with_seg['이용건수_할부_B0M'] == 0) | (sales_with_seg['이용금액_할부_B0M'] == 0), 0,\n",
        "    sales_with_seg['이용금액_할부_B0M'] / sales_with_seg['이용건수_할부_B0M'].abs()\n",
        ")\n",
        "\n",
        "sales_with_seg['건수별평균이용금액_할부_유이자_B0M'] = np.where(\n",
        "    (sales_with_seg['이용건수_할부_유이자_B0M'] == 0) | (sales_with_seg['이용금액_할부_유이자_B0M'] == 0), 0,\n",
        "    sales_with_seg['이용금액_할부_유이자_B0M'] / sales_with_seg['이용건수_할부_유이자_B0M'].abs()\n",
        ")\n",
        "\n",
        "sales_with_seg['건수별평균이용금액_할부_무이자_B0M'] = np.where(\n",
        "    (sales_with_seg['이용건수_할부_무이자_B0M'] == 0) | (sales_with_seg['이용금액_할부_무이자_B0M'] == 0), 0,\n",
        "    sales_with_seg['이용금액_할부_무이자_B0M'] / sales_with_seg['이용건수_할부_무이자_B0M'].abs()\n",
        ")\n",
        "\n",
        "sales_with_seg['건수별평균이용금액_CA_B0M'] = np.where(\n",
        "    (sales_with_seg['이용건수_CA_B0M'] == 0) | (sales_with_seg['이용금액_CA_B0M'] == 0), 0,\n",
        "    sales_with_seg['이용금액_CA_B0M'] / sales_with_seg['이용건수_CA_B0M'].abs()\n",
        ")\n",
        "\n",
        "sales_with_seg['건수별평균이용금액_체크_B0M'] = np.where(\n",
        "    (sales_with_seg['이용건수_체크_B0M'] == 0) | (sales_with_seg['이용금액_체크_B0M'] == 0), 0,\n",
        "    sales_with_seg['이용금액_체크_B0M'] / sales_with_seg['이용건수_체크_B0M'].abs()\n",
        ")\n",
        "\n",
        "sales_with_seg['건수별평균이용금액_카드론_B0M'] = np.where(\n",
        "    (sales_with_seg['이용건수_카드론_B0M'] == 0) | (sales_with_seg['이용금액_카드론_B0M'] == 0), 0,\n",
        "    sales_with_seg['이용금액_카드론_B0M'] / sales_with_seg['이용건수_카드론_B0M'].abs()\n",
        ")"
      ],
      "metadata": {
        "id": "-nR9Z-TqT0jW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 최근3개월이용여부 변수 생성\n",
        "sales_with_seg['최근3개월이용여부_신용'] = (sales_with_seg['이용후경과월_신용'] <= 3).astype(int)\n",
        "sales_with_seg['최근3개월이용여부_신판'] = (sales_with_seg['이용후경과월_신판'] <= 3).astype(int)\n",
        "sales_with_seg['최근3개월이용여부_일시불'] = (sales_with_seg['이용후경과월_일시불'] <= 3).astype(int)\n",
        "sales_with_seg['최근3개월이용여부_할부'] = (sales_with_seg['이용후경과월_할부'] <= 3).astype(int)\n",
        "sales_with_seg['최근3개월이용여부_할부_유이자'] = (sales_with_seg['이용후경과월_할부_유이자'] <= 3).astype(int)\n",
        "sales_with_seg['최근3개월이용여부_할부_무이자'] = (sales_with_seg['이용후경과월_할부_무이자'] <= 3).astype(int)\n",
        "sales_with_seg['최근3개월이용여부_CA'] = (sales_with_seg['이용후경과월_CA'] <= 3).astype(int)\n",
        "sales_with_seg['최근3개월이용여부_체크'] = (sales_with_seg['이용후경과월_체크'] <= 3).astype(int)\n",
        "sales_with_seg['최근3개월이용여부_카드론'] = (sales_with_seg['이용후경과월_카드론'] <= 3).astype(int)"
      ],
      "metadata": {
        "id": "6aGZpU7UhSv1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- R12M 변수"
      ],
      "metadata": {
        "id": "Xyreai1jWMXf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "##### 이용건수 #####\n",
        "\n",
        "# '이용건수_신용_R12M' 변수 값 보정\n",
        "sales_with_seg['이용건수_신용_R12M'] = sales_with_seg['이용건수_신용_R12M'] + sales_with_seg['이용건수_카드론_R12M']\n",
        "\n",
        "\n",
        "##### 이용금액 #####\n",
        "\n",
        "# '이용금액_신용_R12M', '이용금액_신판_R12M' 변수 생성\n",
        "sales_with_seg['이용금액_신용_R12M'] = sales_with_seg['이용금액_일시불_R12M'] + sales_with_seg['이용금액_할부_R12M'] + sales_with_seg['이용금액_CA_R12M'] + sales_with_seg['이용금액_카드론_R12M']\n",
        "sales_with_seg['이용금액_신판_R12M'] = sales_with_seg['이용금액_일시불_R12M'] + sales_with_seg['이용금액_할부_R12M']\n"
      ],
      "metadata": {
        "id": "KYz0T9pq-OwS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 건수별평균이용금액 변수 생성 (R12M 기준)\n",
        "sales_with_seg['건수별평균이용금액_신용_R12M'] = np.where(\n",
        "    (sales_with_seg['이용건수_신용_R12M'] == 0) | (sales_with_seg['이용금액_신용_R12M'] == 0), 0,\n",
        "    sales_with_seg['이용금액_신용_R12M'] / sales_with_seg['이용건수_신용_R12M'].abs()\n",
        ")\n",
        "\n",
        "sales_with_seg['건수별평균이용금액_신판_R12M'] = np.where(\n",
        "    (sales_with_seg['이용건수_신판_R12M'] == 0) | (sales_with_seg['이용금액_신판_R12M'] == 0), 0,\n",
        "    sales_with_seg['이용금액_신판_R12M'] / sales_with_seg['이용건수_신판_R12M'].abs()\n",
        ")\n",
        "\n",
        "sales_with_seg['건수별평균이용금액_일시불_R12M'] = np.where(\n",
        "    (sales_with_seg['이용건수_일시불_R12M'] == 0) | (sales_with_seg['이용금액_일시불_R12M'] == 0), 0,\n",
        "    sales_with_seg['이용금액_일시불_R12M'] / sales_with_seg['이용건수_일시불_R12M'].abs()\n",
        ")\n",
        "\n",
        "sales_with_seg['건수별평균이용금액_할부_R12M'] = np.where(\n",
        "    (sales_with_seg['이용건수_할부_R12M'] == 0) | (sales_with_seg['이용금액_할부_R12M'] == 0), 0,\n",
        "    sales_with_seg['이용금액_할부_R12M'] / sales_with_seg['이용건수_할부_R12M'].abs()\n",
        ")\n",
        "\n",
        "sales_with_seg['건수별평균이용금액_할부_유이자_R12M'] = np.where(\n",
        "    (sales_with_seg['이용건수_할부_유이자_R12M'] == 0) | (sales_with_seg['이용금액_할부_유이자_R12M'] == 0), 0,\n",
        "    sales_with_seg['이용금액_할부_유이자_R12M'] / sales_with_seg['이용건수_할부_유이자_R12M'].abs()\n",
        ")\n",
        "\n",
        "sales_with_seg['건수별평균이용금액_할부_무이자_R12M'] = np.where(\n",
        "    (sales_with_seg['이용건수_할부_무이자_R12M'] == 0) | (sales_with_seg['이용금액_할부_무이자_R12M'] == 0), 0,\n",
        "    sales_with_seg['이용금액_할부_무이자_R12M'] / sales_with_seg['이용건수_할부_무이자_R12M'].abs()\n",
        ")\n",
        "\n",
        "sales_with_seg['건수별평균이용금액_CA_R12M'] = np.where(\n",
        "    (sales_with_seg['이용건수_CA_R12M'] == 0) | (sales_with_seg['이용금액_CA_R12M'] == 0), 0,\n",
        "    sales_with_seg['이용금액_CA_R12M'] / sales_with_seg['이용건수_CA_R12M'].abs()\n",
        ")\n",
        "\n",
        "sales_with_seg['건수별평균이용금액_체크_R12M'] = np.where(\n",
        "    (sales_with_seg['이용건수_체크_R12M'] == 0) | (sales_with_seg['이용금액_체크_R12M'] == 0), 0,\n",
        "    sales_with_seg['이용금액_체크_R12M'] / sales_with_seg['이용건수_체크_R12M'].abs()\n",
        ")\n",
        "\n",
        "sales_with_seg['건수별평균이용금액_카드론_R12M'] = np.where(\n",
        "    (sales_with_seg['이용건수_카드론_R12M'] == 0) | (sales_with_seg['이용금액_카드론_R12M'] == 0), 0,\n",
        "    sales_with_seg['이용금액_카드론_R12M'] / sales_with_seg['이용건수_카드론_R12M'].abs()\n",
        ")"
      ],
      "metadata": {
        "id": "xeKFaf7mgVzw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 이용월평균이용금액 변수 생성 (R12M 기)\n",
        "sales_with_seg['이용월평균이용금액_신용_R12M'] = np.where(\n",
        "    sales_with_seg['이용개월수_신용_R12M'] == 0, 0,\n",
        "    sales_with_seg['이용금액_신용_R12M'] / sales_with_seg['이용개월수_신용_R12M']\n",
        ")\n",
        "\n",
        "sales_with_seg['이용월평균이용금액_신판_R12M'] = np.where(\n",
        "    sales_with_seg['이용개월수_신판_R12M'] == 0, 0,\n",
        "    sales_with_seg['이용금액_신판_R12M'] / sales_with_seg['이용개월수_신판_R12M']\n",
        ")\n",
        "\n",
        "sales_with_seg['이용월평균이용금액_일시불_R12M'] = np.where(\n",
        "    sales_with_seg['이용개월수_일시불_R12M'] == 0, 0,\n",
        "    sales_with_seg['이용금액_일시불_R12M'] / sales_with_seg['이용개월수_일시불_R12M']\n",
        ")\n",
        "\n",
        "sales_with_seg['이용월평균이용금액_할부_R12M'] = np.where(\n",
        "    sales_with_seg['이용개월수_할부_R12M'] == 0, 0,\n",
        "    sales_with_seg['이용금액_할부_R12M'] / sales_with_seg['이용개월수_할부_R12M']\n",
        ")\n",
        "\n",
        "sales_with_seg['이용월평균이용금액_할부_유이자_R12M'] = np.where(\n",
        "    sales_with_seg['이용개월수_할부_유이자_R12M'] == 0, 0,\n",
        "    sales_with_seg['이용금액_할부_유이자_R12M'] / sales_with_seg['이용개월수_할부_유이자_R12M']\n",
        ")\n",
        "\n",
        "sales_with_seg['이용월평균이용금액_할부_무이자_R12M'] = np.where(\n",
        "    sales_with_seg['이용개월수_할부_무이자_R12M'] == 0, 0,\n",
        "    sales_with_seg['이용금액_할부_무이자_R12M'] / sales_with_seg['이용개월수_할부_무이자_R12M']\n",
        ")\n",
        "\n",
        "sales_with_seg['이용월평균이용금액_부분무이자_R12M'] = np.where(\n",
        "    sales_with_seg['이용개월수_부분무이자_R12M'] == 0, 0,\n",
        "    sales_with_seg['이용금액_부분무이자_R12M'] / sales_with_seg['이용개월수_부분무이자_R12M']\n",
        ")\n",
        "\n",
        "sales_with_seg['이용월평균이용금액_CA_R12M'] = np.where(\n",
        "    sales_with_seg['이용개월수_CA_R12M'] == 0, 0,\n",
        "    sales_with_seg['이용금액_CA_R12M'] / sales_with_seg['이용개월수_CA_R12M']\n",
        ")\n",
        "\n",
        "sales_with_seg['이용월평균이용금액_체크_R12M'] = np.where(\n",
        "    sales_with_seg['이용개월수_체크_R12M'] == 0, 0,\n",
        "    sales_with_seg['이용금액_체크_R12M'] / sales_with_seg['이용개월수_체크_R12M']\n",
        ")\n",
        "\n",
        "sales_with_seg['이용월평균이용금액_카드론_R12M'] = np.where(\n",
        "    sales_with_seg['이용개월수_카드론_R12M'] == 0, 0,\n",
        "    sales_with_seg['이용금액_카드론_R12M'] / sales_with_seg['이용개월수_카드론_R12M']\n",
        ")"
      ],
      "metadata": {
        "id": "CNBz8NhRgV2a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 이용월평균이용건수 변수 생성 (R12M 기준)\n",
        "sales_with_seg['이용월평균이용건수_신용_R12M'] = np.where(\n",
        "    sales_with_seg['이용개월수_신용_R12M'] == 0, 0,\n",
        "    sales_with_seg['이용건수_신용_R12M'] / sales_with_seg['이용개월수_신용_R12M']\n",
        ")\n",
        "\n",
        "sales_with_seg['이용월평균이용건수_신판_R12M'] = np.where(\n",
        "    sales_with_seg['이용개월수_신판_R12M'] == 0, 0,\n",
        "    sales_with_seg['이용건수_신판_R12M'] / sales_with_seg['이용개월수_신판_R12M']\n",
        ")\n",
        "\n",
        "sales_with_seg['이용월평균이용건수_일시불_R12M'] = np.where(\n",
        "    sales_with_seg['이용개월수_일시불_R12M'] == 0, 0,\n",
        "    sales_with_seg['이용건수_일시불_R12M'] / sales_with_seg['이용개월수_일시불_R12M']\n",
        ")\n",
        "\n",
        "sales_with_seg['이용월평균이용건수_할부_R12M'] = np.where(\n",
        "    sales_with_seg['이용개월수_할부_R12M'] == 0, 0,\n",
        "    sales_with_seg['이용건수_할부_R12M'] / sales_with_seg['이용개월수_할부_R12M']\n",
        ")\n",
        "\n",
        "sales_with_seg['이용월평균이용건수_할부_유이자_R12M'] = np.where(\n",
        "    sales_with_seg['이용개월수_할부_유이자_R12M'] == 0, 0,\n",
        "    sales_with_seg['이용건수_할부_유이자_R12M'] / sales_with_seg['이용개월수_할부_유이자_R12M']\n",
        ")\n",
        "\n",
        "sales_with_seg['이용월평균이용건수_할부_무이자_R12M'] = np.where(\n",
        "    sales_with_seg['이용개월수_할부_무이자_R12M'] == 0, 0,\n",
        "    sales_with_seg['이용건수_할부_무이자_R12M'] / sales_with_seg['이용개월수_할부_무이자_R12M']\n",
        ")\n",
        "\n",
        "sales_with_seg['이용월평균이용건수_부분무이자_R12M'] = np.where(\n",
        "    sales_with_seg['이용개월수_부분무이자_R12M'] == 0, 0,\n",
        "    sales_with_seg['이용건수_부분무이자_R12M'] / sales_with_seg['이용개월수_부분무이자_R12M']\n",
        ")\n",
        "\n",
        "sales_with_seg['이용월평균이용건수_CA_R12M'] = np.where(\n",
        "    sales_with_seg['이용개월수_CA_R12M'] == 0, 0,\n",
        "    sales_with_seg['이용건수_CA_R12M'] / sales_with_seg['이용개월수_CA_R12M']\n",
        ")\n",
        "\n",
        "sales_with_seg['이용월평균이용건수_체크_R12M'] = np.where(\n",
        "    sales_with_seg['이용개월수_체크_R12M'] == 0, 0,\n",
        "    sales_with_seg['이용건수_체크_R12M'] / sales_with_seg['이용개월수_체크_R12M']\n",
        ")\n",
        "\n",
        "sales_with_seg['이용월평균이용건수_카드론_R12M'] = np.where(\n",
        "    sales_with_seg['이용개월수_카드론_R12M'] == 0, 0,\n",
        "    sales_with_seg['이용건수_카드론_R12M'] / sales_with_seg['이용개월수_카드론_R12M']\n",
        ")"
      ],
      "metadata": {
        "id": "dJIEwx6rZJLQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- R6M 변수"
      ],
      "metadata": {
        "id": "FaGiZG6QbZhP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "##### 이용건수 #####\n",
        "\n",
        "# '이용건수_신용_R6M' 변수 값 보정\n",
        "sales_with_seg['이용건수_신용_R6M'] = sales_with_seg['이용건수_신용_R6M'] + sales_with_seg['이용건수_카드론_R6M']\n",
        "\n",
        "\n",
        "##### 이용금액 #####\n",
        "\n",
        "# '이용금액_신용_R6M', '이용금액_신판_R6M' 변수 생성\n",
        "sales_with_seg['이용금액_신용_R6M'] = sales_with_seg['이용금액_일시불_R6M'] + sales_with_seg['이용금액_할부_R6M'] + sales_with_seg['이용금액_CA_R6M'] + sales_with_seg['이용금액_카드론_R6M']\n",
        "sales_with_seg['이용금액_신판_R6M'] = sales_with_seg['이용금액_일시불_R6M'] + sales_with_seg['이용금액_할부_R6M']"
      ],
      "metadata": {
        "id": "KODxkxGDZJNt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 건수별평균이용금액 변수 생성 (R6M 기준)\n",
        "sales_with_seg['건수별평균이용금액_신용_R6M'] = np.where(\n",
        "    (sales_with_seg['이용건수_신용_R6M'] == 0) | (sales_with_seg['이용금액_신용_R6M'] == 0), 0,\n",
        "    sales_with_seg['이용금액_신용_R6M'] / sales_with_seg['이용건수_신용_R6M'].abs()\n",
        ")\n",
        "\n",
        "sales_with_seg['건수별평균이용금액_신판_R6M'] = np.where(\n",
        "    (sales_with_seg['이용건수_신판_R6M'] == 0) | (sales_with_seg['이용금액_신판_R6M'] == 0), 0,\n",
        "    sales_with_seg['이용금액_신판_R6M'] / sales_with_seg['이용건수_신판_R6M'].abs()\n",
        ")\n",
        "\n",
        "sales_with_seg['건수별평균이용금액_일시불_R6M'] = np.where(\n",
        "    (sales_with_seg['이용건수_일시불_R6M'] == 0) | (sales_with_seg['이용금액_일시불_R6M'] == 0), 0,\n",
        "    sales_with_seg['이용금액_일시불_R6M'] / sales_with_seg['이용건수_일시불_R6M'].abs()\n",
        ")\n",
        "\n",
        "sales_with_seg['건수별평균이용금액_할부_R6M'] = np.where(\n",
        "    (sales_with_seg['이용건수_할부_R6M'] == 0) | (sales_with_seg['이용금액_할부_R6M'] == 0), 0,\n",
        "    sales_with_seg['이용금액_할부_R6M'] / sales_with_seg['이용건수_할부_R6M'].abs()\n",
        ")\n",
        "\n",
        "sales_with_seg['건수별평균이용금액_할부_유이자_R6M'] = np.where(\n",
        "    (sales_with_seg['이용건수_할부_유이자_R6M'] == 0) | (sales_with_seg['이용금액_할부_유이자_R6M'] == 0), 0,\n",
        "    sales_with_seg['이용금액_할부_유이자_R6M'] / sales_with_seg['이용건수_할부_유이자_R6M'].abs()\n",
        ")\n",
        "\n",
        "sales_with_seg['건수별평균이용금액_할부_무이자_R6M'] = np.where(\n",
        "    (sales_with_seg['이용건수_할부_무이자_R6M'] == 0) | (sales_with_seg['이용금액_할부_무이자_R6M'] == 0), 0,\n",
        "    sales_with_seg['이용금액_할부_무이자_R6M'] / sales_with_seg['이용건수_할부_무이자_R6M'].abs()\n",
        ")\n",
        "\n",
        "sales_with_seg['건수별평균이용금액_부분무이자_R6M'] = np.where(\n",
        "    (sales_with_seg['이용건수_부분무이자_R6M'] == 0) | (sales_with_seg['이용금액_부분무이자_R6M'] == 0), 0,\n",
        "    sales_with_seg['이용금액_부분무이자_R6M'] / sales_with_seg['이용건수_부분무이자_R6M'].abs()\n",
        ")\n",
        "\n",
        "sales_with_seg['건수별평균이용금액_CA_R6M'] = np.where(\n",
        "    (sales_with_seg['이용건수_CA_R6M'] == 0) | (sales_with_seg['이용금액_CA_R6M'] == 0), 0,\n",
        "    sales_with_seg['이용금액_CA_R6M'] / sales_with_seg['이용건수_CA_R6M'].abs()\n",
        ")\n",
        "\n",
        "sales_with_seg['건수별평균이용금액_체크_R6M'] = np.where(\n",
        "    (sales_with_seg['이용건수_체크_R6M'] == 0) | (sales_with_seg['이용금액_체크_R6M'] == 0), 0,\n",
        "    sales_with_seg['이용금액_체크_R6M'] / sales_with_seg['이용건수_체크_R6M'].abs()\n",
        ")\n",
        "\n",
        "sales_with_seg['건수별평균이용금액_카드론_R6M'] = np.where(\n",
        "    (sales_with_seg['이용건수_카드론_R6M'] == 0) | (sales_with_seg['이용금액_카드론_R6M'] == 0), 0,\n",
        "    sales_with_seg['이용금액_카드론_R6M'] / sales_with_seg['이용건수_카드론_R6M'].abs()\n",
        ")"
      ],
      "metadata": {
        "id": "oLEFo8cwZJPp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 이용월평균이용금액 변수 생성 (R6M 기준)\n",
        "sales_with_seg['이용월평균이용금액_신용_R6M'] = np.where(\n",
        "    sales_with_seg['이용개월수_신용_R6M'] == 0, 0,\n",
        "    sales_with_seg['이용금액_신용_R6M'] / sales_with_seg['이용개월수_신용_R6M']\n",
        ")\n",
        "\n",
        "sales_with_seg['이용월평균이용금액_신판_R6M'] = np.where(\n",
        "    sales_with_seg['이용개월수_신판_R6M'] == 0, 0,\n",
        "    sales_with_seg['이용금액_신판_R6M'] / sales_with_seg['이용개월수_신판_R6M']\n",
        ")\n",
        "\n",
        "sales_with_seg['이용월평균이용금액_일시불_R6M'] = np.where(\n",
        "    sales_with_seg['이용개월수_일시불_R6M'] == 0, 0,\n",
        "    sales_with_seg['이용금액_일시불_R6M'] / sales_with_seg['이용개월수_일시불_R6M']\n",
        ")\n",
        "\n",
        "sales_with_seg['이용월평균이용금액_할부_R6M'] = np.where(\n",
        "    sales_with_seg['이용개월수_할부_R6M'] == 0, 0,\n",
        "    sales_with_seg['이용금액_할부_R6M'] / sales_with_seg['이용개월수_할부_R6M']\n",
        ")\n",
        "\n",
        "sales_with_seg['이용월평균이용금액_할부_유이자_R6M'] = np.where(\n",
        "    sales_with_seg['이용개월수_할부_유이자_R6M'] == 0, 0,\n",
        "    sales_with_seg['이용금액_할부_유이자_R6M'] / sales_with_seg['이용개월수_할부_유이자_R6M']\n",
        ")\n",
        "\n",
        "sales_with_seg['이용월평균이용금액_할부_무이자_R6M'] = np.where(\n",
        "    sales_with_seg['이용개월수_할부_무이자_R6M'] == 0, 0,\n",
        "    sales_with_seg['이용금액_할부_무이자_R6M'] / sales_with_seg['이용개월수_할부_무이자_R6M']\n",
        ")\n",
        "\n",
        "sales_with_seg['이용월평균이용금액_부분무이자_R6M'] = np.where(\n",
        "    sales_with_seg['이용개월수_부분무이자_R6M'] == 0, 0,\n",
        "    sales_with_seg['이용금액_부분무이자_R6M'] / sales_with_seg['이용개월수_부분무이자_R6M']\n",
        ")\n",
        "\n",
        "sales_with_seg['이용월평균이용금액_CA_R6M'] = np.where(\n",
        "    sales_with_seg['이용개월수_CA_R6M'] == 0, 0,\n",
        "    sales_with_seg['이용금액_CA_R6M'] / sales_with_seg['이용개월수_CA_R6M']\n",
        ")\n",
        "\n",
        "sales_with_seg['이용월평균이용금액_체크_R6M'] = np.where(\n",
        "    sales_with_seg['이용개월수_체크_R6M'] == 0, 0,\n",
        "    sales_with_seg['이용금액_체크_R6M'] / sales_with_seg['이용개월수_체크_R6M']\n",
        ")\n",
        "\n",
        "sales_with_seg['이용월평균이용금액_카드론_R6M'] = np.where(\n",
        "    sales_with_seg['이용개월수_카드론_R6M'] == 0, 0,\n",
        "    sales_with_seg['이용금액_카드론_R6M'] / sales_with_seg['이용개월수_카드론_R6M']\n",
        ")"
      ],
      "metadata": {
        "id": "ncIyFht_ZJRQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 이용월평균이용건수 변수 생성 (R6M 기준)\n",
        "sales_with_seg['이용월평균이용건수_신용_R6M'] = np.where(\n",
        "    sales_with_seg['이용개월수_신용_R6M'] == 0, 0,\n",
        "    sales_with_seg['이용건수_신용_R6M'] / sales_with_seg['이용개월수_신용_R6M']\n",
        ")\n",
        "\n",
        "sales_with_seg['이용월평균이용건수_신판_R6M'] = np.where(\n",
        "    sales_with_seg['이용개월수_신판_R6M'] == 0, 0,\n",
        "    sales_with_seg['이용건수_신판_R6M'] / sales_with_seg['이용개월수_신판_R6M']\n",
        ")\n",
        "\n",
        "sales_with_seg['이용월평균이용건수_일시불_R6M'] = np.where(\n",
        "    sales_with_seg['이용개월수_일시불_R6M'] == 0, 0,\n",
        "    sales_with_seg['이용건수_일시불_R6M'] / sales_with_seg['이용개월수_일시불_R6M']\n",
        ")\n",
        "\n",
        "sales_with_seg['이용월평균이용건수_할부_R6M'] = np.where(\n",
        "    sales_with_seg['이용개월수_할부_R6M'] == 0, 0,\n",
        "    sales_with_seg['이용건수_할부_R6M'] / sales_with_seg['이용개월수_할부_R6M']\n",
        ")\n",
        "\n",
        "sales_with_seg['이용월평균이용건수_할부_유이자_R6M'] = np.where(\n",
        "    sales_with_seg['이용개월수_할부_유이자_R6M'] == 0, 0,\n",
        "    sales_with_seg['이용건수_할부_유이자_R6M'] / sales_with_seg['이용개월수_할부_유이자_R6M']\n",
        ")\n",
        "\n",
        "sales_with_seg['이용월평균이용건수_할부_무이자_R6M'] = np.where(\n",
        "    sales_with_seg['이용개월수_할부_무이자_R6M'] == 0, 0,\n",
        "    sales_with_seg['이용건수_할부_무이자_R6M'] / sales_with_seg['이용개월수_할부_무이자_R6M']\n",
        ")\n",
        "\n",
        "sales_with_seg['이용월평균이용건수_부분무이자_R6M'] = np.where(\n",
        "    sales_with_seg['이용개월수_부분무이자_R6M'] == 0, 0,\n",
        "    sales_with_seg['이용건수_부분무이자_R6M'] / sales_with_seg['이용개월수_부분무이자_R6M']\n",
        ")\n",
        "\n",
        "sales_with_seg['이용월평균이용건수_CA_R6M'] = np.where(\n",
        "    sales_with_seg['이용개월수_CA_R6M'] == 0, 0,\n",
        "    sales_with_seg['이용건수_CA_R6M'] / sales_with_seg['이용개월수_CA_R6M']\n",
        ")\n",
        "\n",
        "sales_with_seg['이용월평균이용건수_체크_R6M'] = np.where(\n",
        "    sales_with_seg['이용개월수_체크_R6M'] == 0, 0,\n",
        "    sales_with_seg['이용건수_체크_R6M'] / sales_with_seg['이용개월수_체크_R6M']\n",
        ")\n",
        "\n",
        "sales_with_seg['이용월평균이용건수_카드론_R6M'] = np.where(\n",
        "    sales_with_seg['이용개월수_카드론_R6M'] == 0, 0,\n",
        "    sales_with_seg['이용건수_카드론_R6M'] / sales_with_seg['이용개월수_카드론_R6M']\n",
        ")"
      ],
      "metadata": {
        "id": "M1EvVyr5ZJUO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "03587768-eb2c-4e57-9520-52f76a5cc1fa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-26-14d78e973320>:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  sales_with_seg['이용월평균이용건수_할부_유이자_R6M'] = np.where(\n",
            "<ipython-input-26-14d78e973320>:27: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  sales_with_seg['이용월평균이용건수_할부_무이자_R6M'] = np.where(\n",
            "<ipython-input-26-14d78e973320>:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  sales_with_seg['이용월평균이용건수_부분무이자_R6M'] = np.where(\n",
            "<ipython-input-26-14d78e973320>:37: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  sales_with_seg['이용월평균이용건수_CA_R6M'] = np.where(\n",
            "<ipython-input-26-14d78e973320>:42: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  sales_with_seg['이용월평균이용건수_체크_R6M'] = np.where(\n",
            "<ipython-input-26-14d78e973320>:47: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  sales_with_seg['이용월평균이용건수_카드론_R6M'] = np.where(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- R3M 변수"
      ],
      "metadata": {
        "id": "9w0xabuMlBYj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "##### 이용건수 #####\n",
        "\n",
        "# '이용건수_신용_R3M' 변수 값 보정\n",
        "sales_with_seg['이용건수_신용_R3M'] = sales_with_seg['이용건수_신용_R3M'] + sales_with_seg['이용건수_카드론_R3M']\n",
        "\n",
        "\n",
        "##### 이용금액 #####\n",
        "\n",
        "# '이용금액_신용_R3M', '이용금액_신판_R3M' 변수 생성\n",
        "sales_with_seg['이용금액_신용_R3M'] = sales_with_seg['이용금액_일시불_R3M'] + sales_with_seg['이용금액_할부_R3M'] + sales_with_seg['이용금액_CA_R3M'] + sales_with_seg['이용금액_카드론_R3M']\n",
        "sales_with_seg['이용금액_신판_R3M'] = sales_with_seg['이용금액_일시불_R3M'] + sales_with_seg['이용금액_할부_R3M']\n"
      ],
      "metadata": {
        "id": "EQPAukzMgV4k",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9b69f4cc-37d5-4b86-e99b-606b064d8505"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-27-4d9390fc2cd0>:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  sales_with_seg['이용금액_신용_R3M'] = sales_with_seg['이용금액_일시불_R3M'] + sales_with_seg['이용금액_할부_R3M'] + sales_with_seg['이용금액_CA_R3M'] + sales_with_seg['이용금액_카드론_R3M']\n",
            "<ipython-input-27-4d9390fc2cd0>:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  sales_with_seg['이용금액_신판_R3M'] = sales_with_seg['이용금액_일시불_R3M'] + sales_with_seg['이용금액_할부_R3M']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 건수별평균이용금액 변수 생성 (R3M 기준)\n",
        "sales_with_seg['건수별평균이용금액_신용_R3M'] = np.where(\n",
        "    (sales_with_seg['이용건수_신용_R3M'] == 0) | (sales_with_seg['이용금액_신용_R3M'] == 0), 0,\n",
        "    sales_with_seg['이용금액_신용_R3M'] / sales_with_seg['이용건수_신용_R3M'].abs()\n",
        ")\n",
        "\n",
        "sales_with_seg['건수별평균이용금액_신판_R3M'] = np.where(\n",
        "    (sales_with_seg['이용건수_신판_R3M'] == 0) | (sales_with_seg['이용금액_신판_R3M'] == 0), 0,\n",
        "    sales_with_seg['이용금액_신판_R3M'] / sales_with_seg['이용건수_신판_R3M'].abs()\n",
        ")\n",
        "\n",
        "sales_with_seg['건수별평균이용금액_일시불_R3M'] = np.where(\n",
        "    (sales_with_seg['이용건수_일시불_R3M'] == 0) | (sales_with_seg['이용금액_일시불_R3M'] == 0), 0,\n",
        "    sales_with_seg['이용금액_일시불_R3M'] / sales_with_seg['이용건수_일시불_R3M'].abs()\n",
        ")\n",
        "\n",
        "sales_with_seg['건수별평균이용금액_할부_R3M'] = np.where(\n",
        "    (sales_with_seg['이용건수_할부_R3M'] == 0) | (sales_with_seg['이용금액_할부_R3M'] == 0), 0,\n",
        "    sales_with_seg['이용금액_할부_R3M'] / sales_with_seg['이용건수_할부_R3M'].abs()\n",
        ")\n",
        "\n",
        "sales_with_seg['건수별평균이용금액_할부_유이자_R3M'] = np.where(\n",
        "    (sales_with_seg['이용건수_할부_유이자_R3M'] == 0) | (sales_with_seg['이용금액_할부_유이자_R3M'] == 0), 0,\n",
        "    sales_with_seg['이용금액_할부_유이자_R3M'] / sales_with_seg['이용건수_할부_유이자_R3M'].abs()\n",
        ")\n",
        "\n",
        "sales_with_seg['건수별평균이용금액_할부_무이자_R3M'] = np.where(\n",
        "    (sales_with_seg['이용건수_할부_무이자_R3M'] == 0) | (sales_with_seg['이용금액_할부_무이자_R3M'] == 0), 0,\n",
        "    sales_with_seg['이용금액_할부_무이자_R3M'] / sales_with_seg['이용건수_할부_무이자_R3M'].abs()\n",
        ")\n",
        "\n",
        "sales_with_seg['건수별평균이용금액_부분무이자_R3M'] = np.where(\n",
        "    (sales_with_seg['이용건수_부분무이자_R3M'] == 0) | (sales_with_seg['이용금액_부분무이자_R3M'] == 0), 0,\n",
        "    sales_with_seg['이용금액_부분무이자_R3M'] / sales_with_seg['이용건수_부분무이자_R3M'].abs()\n",
        ")\n",
        "\n",
        "sales_with_seg['건수별평균이용금액_CA_R3M'] = np.where(\n",
        "    (sales_with_seg['이용건수_CA_R3M'] == 0) | (sales_with_seg['이용금액_CA_R3M'] == 0), 0,\n",
        "    sales_with_seg['이용금액_CA_R3M'] / sales_with_seg['이용건수_CA_R3M'].abs()\n",
        ")\n",
        "\n",
        "sales_with_seg['건수별평균이용금액_체크_R3M'] = np.where(\n",
        "    (sales_with_seg['이용건수_체크_R3M'] == 0) | (sales_with_seg['이용금액_체크_R3M'] == 0), 0,\n",
        "    sales_with_seg['이용금액_체크_R3M'] / sales_with_seg['이용건수_체크_R3M'].abs()\n",
        ")\n",
        "\n",
        "sales_with_seg['건수별평균이용금액_카드론_R3M'] = np.where(\n",
        "    (sales_with_seg['이용건수_카드론_R3M'] == 0) | (sales_with_seg['이용금액_카드론_R3M'] == 0), 0,\n",
        "    sales_with_seg['이용금액_카드론_R3M'] / sales_with_seg['이용건수_카드론_R3M'].abs()\n",
        ")"
      ],
      "metadata": {
        "id": "mDvLDHmclDLs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "913fd73d-842f-416b-a214-82e2ebc6122e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-28-8a8fe6265eaa>:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  sales_with_seg['건수별평균이용금액_신용_R3M'] = np.where(\n",
            "<ipython-input-28-8a8fe6265eaa>:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  sales_with_seg['건수별평균이용금액_신판_R3M'] = np.where(\n",
            "<ipython-input-28-8a8fe6265eaa>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  sales_with_seg['건수별평균이용금액_일시불_R3M'] = np.where(\n",
            "<ipython-input-28-8a8fe6265eaa>:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  sales_with_seg['건수별평균이용금액_할부_R3M'] = np.where(\n",
            "<ipython-input-28-8a8fe6265eaa>:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  sales_with_seg['건수별평균이용금액_할부_유이자_R3M'] = np.where(\n",
            "<ipython-input-28-8a8fe6265eaa>:27: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  sales_with_seg['건수별평균이용금액_할부_무이자_R3M'] = np.where(\n",
            "<ipython-input-28-8a8fe6265eaa>:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  sales_with_seg['건수별평균이용금액_부분무이자_R3M'] = np.where(\n",
            "<ipython-input-28-8a8fe6265eaa>:37: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  sales_with_seg['건수별평균이용금액_CA_R3M'] = np.where(\n",
            "<ipython-input-28-8a8fe6265eaa>:42: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  sales_with_seg['건수별평균이용금액_체크_R3M'] = np.where(\n",
            "<ipython-input-28-8a8fe6265eaa>:47: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  sales_with_seg['건수별평균이용금액_카드론_R3M'] = np.where(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 이용월평균이용금액 변수 생성 (R3M 기준)\n",
        "sales_with_seg['이용월평균이용금액_신용_R3M'] = np.where(\n",
        "    sales_with_seg['이용개월수_신용_R3M'] == 0, 0,\n",
        "    sales_with_seg['이용금액_신용_R3M'] / sales_with_seg['이용개월수_신용_R3M']\n",
        ")\n",
        "\n",
        "sales_with_seg['이용월평균이용금액_신판_R3M'] = np.where(\n",
        "    sales_with_seg['이용개월수_신판_R3M'] == 0, 0,\n",
        "    sales_with_seg['이용금액_신판_R3M'] / sales_with_seg['이용개월수_신판_R3M']\n",
        ")\n",
        "\n",
        "sales_with_seg['이용월평균이용금액_일시불_R3M'] = np.where(\n",
        "    sales_with_seg['이용개월수_일시불_R3M'] == 0, 0,\n",
        "    sales_with_seg['이용금액_일시불_R3M'] / sales_with_seg['이용개월수_일시불_R3M']\n",
        ")\n",
        "\n",
        "sales_with_seg['이용월평균이용금액_할부_R3M'] = np.where(\n",
        "    sales_with_seg['이용개월수_할부_R3M'] == 0, 0,\n",
        "    sales_with_seg['이용금액_할부_R3M'] / sales_with_seg['이용개월수_할부_R3M']\n",
        ")\n",
        "\n",
        "sales_with_seg['이용월평균이용금액_할부_유이자_R3M'] = np.where(\n",
        "    sales_with_seg['이용개월수_할부_유이자_R3M'] == 0, 0,\n",
        "    sales_with_seg['이용금액_할부_유이자_R3M'] / sales_with_seg['이용개월수_할부_유이자_R3M']\n",
        ")\n",
        "\n",
        "sales_with_seg['이용월평균이용금액_할부_무이자_R3M'] = np.where(\n",
        "    sales_with_seg['이용개월수_할부_무이자_R3M'] == 0, 0,\n",
        "    sales_with_seg['이용금액_할부_무이자_R3M'] / sales_with_seg['이용개월수_할부_무이자_R3M']\n",
        ")\n",
        "\n",
        "sales_with_seg['이용월평균이용금액_부분무이자_R3M'] = np.where(\n",
        "    sales_with_seg['이용개월수_부분무이자_R3M'] == 0, 0,\n",
        "    sales_with_seg['이용금액_부분무이자_R3M'] / sales_with_seg['이용개월수_부분무이자_R3M']\n",
        ")\n",
        "\n",
        "sales_with_seg['이용월평균이용금액_CA_R3M'] = np.where(\n",
        "    sales_with_seg['이용개월수_CA_R3M'] == 0, 0,\n",
        "    sales_with_seg['이용금액_CA_R3M'] / sales_with_seg['이용개월수_CA_R3M']\n",
        ")\n",
        "\n",
        "sales_with_seg['이용월평균이용금액_체크_R3M'] = np.where(\n",
        "    sales_with_seg['이용개월수_체크_R3M'] == 0, 0,\n",
        "    sales_with_seg['이용금액_체크_R3M'] / sales_with_seg['이용개월수_체크_R3M']\n",
        ")\n",
        "\n",
        "sales_with_seg['이용월평균이용금액_카드론_R3M'] = np.where(\n",
        "    sales_with_seg['이용개월수_카드론_R3M'] == 0, 0,\n",
        "    sales_with_seg['이용금액_카드론_R3M'] / sales_with_seg['이용개월수_카드론_R3M']\n",
        ")"
      ],
      "metadata": {
        "id": "w3nXyqBslDNo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b8708e11-0ff8-48b7-ab1e-ee9abb3b0b02"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-29-c32a9b21fcfa>:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  sales_with_seg['이용월평균이용금액_신용_R3M'] = np.where(\n",
            "<ipython-input-29-c32a9b21fcfa>:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  sales_with_seg['이용월평균이용금액_신판_R3M'] = np.where(\n",
            "<ipython-input-29-c32a9b21fcfa>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  sales_with_seg['이용월평균이용금액_일시불_R3M'] = np.where(\n",
            "<ipython-input-29-c32a9b21fcfa>:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  sales_with_seg['이용월평균이용금액_할부_R3M'] = np.where(\n",
            "<ipython-input-29-c32a9b21fcfa>:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  sales_with_seg['이용월평균이용금액_할부_유이자_R3M'] = np.where(\n",
            "<ipython-input-29-c32a9b21fcfa>:27: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  sales_with_seg['이용월평균이용금액_할부_무이자_R3M'] = np.where(\n",
            "<ipython-input-29-c32a9b21fcfa>:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  sales_with_seg['이용월평균이용금액_부분무이자_R3M'] = np.where(\n",
            "<ipython-input-29-c32a9b21fcfa>:37: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  sales_with_seg['이용월평균이용금액_CA_R3M'] = np.where(\n",
            "<ipython-input-29-c32a9b21fcfa>:42: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  sales_with_seg['이용월평균이용금액_체크_R3M'] = np.where(\n",
            "<ipython-input-29-c32a9b21fcfa>:47: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  sales_with_seg['이용월평균이용금액_카드론_R3M'] = np.where(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 이용월평균이용건수 변수 생성 (R3M 기준)\n",
        "sales_with_seg['이용월평균이용건수_신용_R3M'] = np.where(\n",
        "    sales_with_seg['이용개월수_신용_R3M'] == 0, 0,\n",
        "    sales_with_seg['이용건수_신용_R3M'] / sales_with_seg['이용개월수_신용_R3M']\n",
        ")\n",
        "\n",
        "sales_with_seg['이용월평균이용건수_신판_R3M'] = np.where(\n",
        "    sales_with_seg['이용개월수_신판_R3M'] == 0, 0,\n",
        "    sales_with_seg['이용건수_신판_R3M'] / sales_with_seg['이용개월수_신판_R3M']\n",
        ")\n",
        "\n",
        "sales_with_seg['이용월평균이용건수_일시불_R3M'] = np.where(\n",
        "    sales_with_seg['이용개월수_일시불_R3M'] == 0, 0,\n",
        "    sales_with_seg['이용건수_일시불_R3M'] / sales_with_seg['이용개월수_일시불_R3M']\n",
        ")\n",
        "\n",
        "sales_with_seg['이용월평균이용건수_할부_R3M'] = np.where(\n",
        "    sales_with_seg['이용개월수_할부_R3M'] == 0, 0,\n",
        "    sales_with_seg['이용건수_할부_R3M'] / sales_with_seg['이용개월수_할부_R3M']\n",
        ")\n",
        "\n",
        "sales_with_seg['이용월평균이용건수_할부_유이자_R3M'] = np.where(\n",
        "    sales_with_seg['이용개월수_할부_유이자_R3M'] == 0, 0,\n",
        "    sales_with_seg['이용건수_할부_유이자_R3M'] / sales_with_seg['이용개월수_할부_유이자_R3M']\n",
        ")\n",
        "\n",
        "sales_with_seg['이용월평균이용건수_할부_무이자_R3M'] = np.where(\n",
        "    sales_with_seg['이용개월수_할부_무이자_R3M'] == 0, 0,\n",
        "    sales_with_seg['이용건수_할부_무이자_R3M'] / sales_with_seg['이용개월수_할부_무이자_R3M']\n",
        ")\n",
        "\n",
        "sales_with_seg['이용월평균이용건수_부분무이자_R3M'] = np.where(\n",
        "    sales_with_seg['이용개월수_부분무이자_R3M'] == 0, 0,\n",
        "    sales_with_seg['이용건수_부분무이자_R3M'] / sales_with_seg['이용개월수_부분무이자_R3M']\n",
        ")\n",
        "\n",
        "sales_with_seg['이용월평균이용건수_CA_R3M'] = np.where(\n",
        "    sales_with_seg['이용개월수_CA_R3M'] == 0, 0,\n",
        "    sales_with_seg['이용건수_CA_R3M'] / sales_with_seg['이용개월수_CA_R3M']\n",
        ")\n",
        "\n",
        "sales_with_seg['이용월평균이용건수_체크_R3M'] = np.where(\n",
        "    sales_with_seg['이용개월수_체크_R3M'] == 0, 0,\n",
        "    sales_with_seg['이용건수_체크_R3M'] / sales_with_seg['이용개월수_체크_R3M']\n",
        ")\n",
        "\n",
        "sales_with_seg['이용월평균이용건수_카드론_R3M'] = np.where(\n",
        "    sales_with_seg['이용개월수_카드론_R3M'] == 0, 0,\n",
        "    sales_with_seg['이용건수_카드론_R3M'] / sales_with_seg['이용개월수_카드론_R3M']\n",
        ")\n"
      ],
      "metadata": {
        "id": "XOD9jQmJlDPZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "11029d80-e1dd-4fef-d1a1-ad1f48b58d3e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-30-cb1d1abb0035>:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  sales_with_seg['이용월평균이용건수_신용_R3M'] = np.where(\n",
            "<ipython-input-30-cb1d1abb0035>:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  sales_with_seg['이용월평균이용건수_신판_R3M'] = np.where(\n",
            "<ipython-input-30-cb1d1abb0035>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  sales_with_seg['이용월평균이용건수_일시불_R3M'] = np.where(\n",
            "<ipython-input-30-cb1d1abb0035>:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  sales_with_seg['이용월평균이용건수_할부_R3M'] = np.where(\n",
            "<ipython-input-30-cb1d1abb0035>:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  sales_with_seg['이용월평균이용건수_할부_유이자_R3M'] = np.where(\n",
            "<ipython-input-30-cb1d1abb0035>:27: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  sales_with_seg['이용월평균이용건수_할부_무이자_R3M'] = np.where(\n",
            "<ipython-input-30-cb1d1abb0035>:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  sales_with_seg['이용월평균이용건수_부분무이자_R3M'] = np.where(\n",
            "<ipython-input-30-cb1d1abb0035>:37: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  sales_with_seg['이용월평균이용건수_CA_R3M'] = np.where(\n",
            "<ipython-input-30-cb1d1abb0035>:42: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  sales_with_seg['이용월평균이용건수_체크_R3M'] = np.where(\n",
            "<ipython-input-30-cb1d1abb0035>:47: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  sales_with_seg['이용월평균이용건수_카드론_R3M'] = np.where(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 쇼핑/교통/여유/납부"
      ],
      "metadata": {
        "id": "JA1U7uGhnt5r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# '쇼핑_총이용금액' 변수 생성\n",
        "shopping_columns = ['쇼핑_도소매_이용금액',\n",
        "                    '쇼핑_백화점_이용금액',\n",
        "                    '쇼핑_마트_이용금액',\n",
        "                    '쇼핑_슈퍼마켓_이용금액',\n",
        "                    '쇼핑_편의점_이용금액',\n",
        "                    '쇼핑_아울렛_이용금액',\n",
        "                    '쇼핑_온라인_이용금액',\n",
        "                    '쇼핑_기타_이용금액']\n",
        "sales_with_seg['쇼핑_총이용금액'] = sales_with_seg[shopping_columns].sum(axis=1)\n",
        "\n",
        "# '교통_총이용금액' 변수 생성\n",
        "shopping_columns = ['교통_주유이용금액',\n",
        "                    '교통_정비이용금액',\n",
        "                    '교통_통행료이용금액',\n",
        "                    '교통_버스지하철이용금액',\n",
        "                    '교통_택시이용금액',\n",
        "                    '교통_철도버스이용금액']\n",
        "sales_with_seg['교통_총이용금액'] = sales_with_seg[shopping_columns].sum(axis=1)\n",
        "\n",
        "# '여유_총이용금액' 변수 생성\n",
        "shopping_columns = ['여유_운동이용금액',\n",
        "                    '여유_Pet이용금액',\n",
        "                    '여유_공연이용금액',\n",
        "                    '여유_공원이용금액',\n",
        "                    '여유_숙박이용금액',\n",
        "                    '여유_항공이용금액',\n",
        "                    '여유_기타이용금액']\n",
        "sales_with_seg['여유_총이용금액'] = sales_with_seg[shopping_columns].sum(axis=1)\n",
        "\n",
        "# '납부_총이용금액' 변수 생성\n",
        "shopping_columns = ['납부_통신비이용금액',\n",
        "                    '납부_관리비이용금액',\n",
        "                    '납부_가스전기료이용금액',\n",
        "                    '납부_보험료이용금액',\n",
        "                    '납부_기타이용금액']\n",
        "sales_with_seg['납부_총이용금액'] = sales_with_seg[shopping_columns].sum(axis=1)"
      ],
      "metadata": {
        "id": "rdLxQfb_lDRT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "646c0b3f-1e3c-46d9-df46-5c0194cfd72c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-31-406ff2616aa4>:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  sales_with_seg['쇼핑_총이용금액'] = sales_with_seg[shopping_columns].sum(axis=1)\n",
            "<ipython-input-31-406ff2616aa4>:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  sales_with_seg['교통_총이용금액'] = sales_with_seg[shopping_columns].sum(axis=1)\n",
            "<ipython-input-31-406ff2616aa4>:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  sales_with_seg['여유_총이용금액'] = sales_with_seg[shopping_columns].sum(axis=1)\n",
            "<ipython-input-31-406ff2616aa4>:37: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  sales_with_seg['납부_총이용금액'] = sales_with_seg[shopping_columns].sum(axis=1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 상관계수 절댓값 0.3 넘는 변수 5개만 합치기\n",
        "shopping_columns = ['쇼핑_도소매_이용금액',\n",
        "                    '쇼핑_마트_이용금액',\n",
        "                    '쇼핑_온라인_이용금액',\n",
        "                    '교통_주유이용금액',\n",
        "                    '납부_기타이용금액']\n",
        "sales_with_seg['0.3이상_총이용금액'] = sales_with_seg[shopping_columns].sum(axis=1)"
      ],
      "metadata": {
        "id": "U8p1WuNSD3Yi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f7172377-38b7-42fc-d3e5-28a3625dce08"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-32-b7ebe65e3d8d>:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  sales_with_seg['0.3이상_총이용금액'] = sales_with_seg[shopping_columns].sum(axis=1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 쇼핑/교통/여유/납부 다 합치기\n",
        "columns = ['쇼핑_총이용금액',\n",
        "          '교통_총이용금액',\n",
        "          '여유_총이용금액',\n",
        "          '납부_총이용금액']\n",
        "sales_with_seg['총이용금액_쇼핑교통여유납부'] = sales_with_seg[columns].sum(axis=1)"
      ],
      "metadata": {
        "id": "IbT_POdhBXNe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1a39d7f2-9f61-471a-c210-f74a14adeee4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-33-22bf84db1bde>:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  sales_with_seg['총이용금액_쇼핑교통여유납부'] = sales_with_seg[columns].sum(axis=1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 기존 변수 다 삭제\n",
        "columns_to_drop = [\n",
        "    '쇼핑_도소매_이용금액', '쇼핑_백화점_이용금액', '쇼핑_마트_이용금액',\n",
        "    '쇼핑_슈퍼마켓_이용금액', '쇼핑_편의점_이용금액', '쇼핑_아울렛_이용금액',\n",
        "    '쇼핑_온라인_이용금액', '쇼핑_기타_이용금액',\n",
        "\n",
        "    '교통_주유이용금액', '교통_정비이용금액', '교통_통행료이용금액',\n",
        "    '교통_버스지하철이용금액', '교통_택시이용금액', '교통_철도버스이용금액',\n",
        "\n",
        "    '여유_운동이용금액', '여유_Pet이용금액', '여유_공연이용금액',\n",
        "    '여유_공원이용금액', '여유_숙박이용금액', '여유_여행이용금액',\n",
        "    '여유_항공이용금액', '여유_기타이용금액',\n",
        "\n",
        "    '납부_통신비이용금액', '납부_관리비이용금액', '납부_렌탈료이용금액',\n",
        "    '납부_가스전기료이용금액', '납부_보험료이용금액', '납부_유선방송이용금액',\n",
        "    '납부_건강연금이용금액', '납부_기타이용금액'\n",
        "]\n",
        "\n",
        "# 변수 삭제\n",
        "sales_with_seg.drop(columns=columns_to_drop, inplace=True)"
      ],
      "metadata": {
        "id": "cBEuN_rLBXPO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "-  R12M 할부건수/할부금액"
      ],
      "metadata": {
        "id": "VQajVJgfH68v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터 동일한 변수 4개 삭제\n",
        "columns_drop = [\n",
        "    '할부건수_부분_3M_R12M',\n",
        "    '할부건수_부분_6M_R12M',\n",
        "    '할부건수_부분_14M_R12M',\n",
        "    '할부금액_부분_3M_R12M'\n",
        "    ]\n",
        "sales_with_seg.drop(columns=columns_drop, inplace=True)"
      ],
      "metadata": {
        "id": "7c4zwZc7BXQ8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 최근 1년치 총합 변수 7개 생성 (할부건수/할부금액)\n",
        "\n",
        "# 1. 할부\n",
        "sales_with_seg['할부건수총합_R12M'] = (\n",
        "    sales_with_seg['할부건수_3M_R12M'] +\n",
        "    sales_with_seg['할부건수_6M_R12M'] +\n",
        "    sales_with_seg['할부건수_12M_R12M']\n",
        ")\n",
        "\n",
        "sales_with_seg['할부금액총합_R12M'] = (\n",
        "    sales_with_seg['할부금액_3M_R12M'] +\n",
        "    sales_with_seg['할부금액_6M_R12M'] +\n",
        "    sales_with_seg['할부금액_12M_R12M']\n",
        ")\n",
        "\n",
        "# 2. 유이자 할부\n",
        "sales_with_seg['할부건수총합_유이자_R12M'] = (\n",
        "    sales_with_seg['할부건수_유이자_3M_R12M'] +\n",
        "    sales_with_seg['할부건수_유이자_6M_R12M'] +\n",
        "    sales_with_seg['할부건수_유이자_12M_R12M']\n",
        ")\n",
        "\n",
        "sales_with_seg['할부금액총합_유이자_R12M'] = (\n",
        "    sales_with_seg['할부금액_유이자_3M_R12M'] +\n",
        "    sales_with_seg['할부금액_유이자_6M_R12M'] +\n",
        "    sales_with_seg['할부금액_유이자_12M_R12M']\n",
        ")\n",
        "\n",
        "# 3. 무이자 할부\n",
        "sales_with_seg['할부건수총합_무이자_R12M'] = (\n",
        "    sales_with_seg['할부건수_무이자_3M_R12M'] +\n",
        "    sales_with_seg['할부건수_무이자_6M_R12M'] +\n",
        "    sales_with_seg['할부건수_무이자_12M_R12M']\n",
        ")\n",
        "\n",
        "sales_with_seg['할부금액총합_무이자_R12M'] = (\n",
        "    sales_with_seg['할부금액_무이자_3M_R12M'] +\n",
        "    sales_with_seg['할부금액_무이자_6M_R12M'] +\n",
        "    sales_with_seg['할부금액_무이자_12M_R12M']\n",
        ")\n",
        "\n",
        "# 3. 부분 할부\n",
        "# '할부건수_부분_3M_R12M', '할부건수_부분_6M_R12M'가 다 0이라서 '할부건수_부분_12M_R12M'가 1년치 총합과 동일함\n",
        "sales_with_seg['할부금액총합_부분_R12M'] = (\n",
        "    sales_with_seg['할부금액_부분_6M_R12M'] +\n",
        "    sales_with_seg['할부금액_부분_12M_R12M']\n",
        ")"
      ],
      "metadata": {
        "id": "SZ0MOHT5BXVl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9dee8a59-8539-43a6-c22f-eab8eca9b81a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-36-a57ce0275030>:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  sales_with_seg['할부건수총합_R12M'] = (\n",
            "<ipython-input-36-a57ce0275030>:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  sales_with_seg['할부금액총합_R12M'] = (\n",
            "<ipython-input-36-a57ce0275030>:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  sales_with_seg['할부건수총합_유이자_R12M'] = (\n",
            "<ipython-input-36-a57ce0275030>:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  sales_with_seg['할부금액총합_유이자_R12M'] = (\n",
            "<ipython-input-36-a57ce0275030>:30: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  sales_with_seg['할부건수총합_무이자_R12M'] = (\n",
            "<ipython-input-36-a57ce0275030>:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  sales_with_seg['할부금액총합_무이자_R12M'] = (\n",
            "<ipython-input-36-a57ce0275030>:44: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  sales_with_seg['할부금액총합_부분_R12M'] = (\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 할부 건수 별 금액 변수 4개 생성\n",
        "#  - 3M 기준이 제일 상관계수가 좋음\n",
        "#  - 부분 무이자 할부는 할부건수가 12M 밖에 없어서 12M 기준으로 계산\n",
        "\n",
        "# 1. 할부\n",
        "sales_with_seg['건수별할부금액_3M'] = np.where(\n",
        "    (sales_with_seg['할부금액_3M_R12M'] == 0) | (sales_with_seg['할부건수_3M_R12M'] == 0),\n",
        "    0,\n",
        "    sales_with_seg['할부금액_3M_R12M'] / sales_with_seg['할부건수_3M_R12M']\n",
        ")\n",
        "\n",
        "# 2. 유이자 할부\n",
        "sales_with_seg['건수별할부금액_유이자_3M'] = np.where(\n",
        "    (sales_with_seg['할부금액_유이자_3M_R12M'] == 0) | (sales_with_seg['할부건수_유이자_3M_R12M'] == 0),\n",
        "    0,\n",
        "    sales_with_seg['할부금액_유이자_3M_R12M'] / sales_with_seg['할부건수_유이자_3M_R12M']\n",
        ")\n",
        "\n",
        "# 3. 무이자 할부\n",
        "sales_with_seg['건수별할부금액_무이자_3M'] = np.where(\n",
        "    (sales_with_seg['할부금액_무이자_3M_R12M'] == 0) | (sales_with_seg['할부건수_무이자_3M_R12M'] == 0),\n",
        "    0,\n",
        "    sales_with_seg['할부금액_무이자_3M_R12M'] / sales_with_seg['할부건수_무이자_3M_R12M']\n",
        ")\n",
        "\n",
        "# 4. 부분 무이자 할부\n",
        "sales_with_seg['건수별할부금액_부분_12M'] = np.where(\n",
        "    (sales_with_seg['할부금액_부분_12M_R12M'] == 0) | (sales_with_seg['할부건수_부분_12M_R12M'] == 0),\n",
        "    0,\n",
        "    sales_with_seg['할부금액_부분_12M_R12M'] / sales_with_seg['할부건수_부분_12M_R12M']\n",
        ")"
      ],
      "metadata": {
        "id": "YH6EpzTZBXXW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "93331fa2-fbf5-4724-978b-790d516aa3b6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-37-fbf2bfb45a75>:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  sales_with_seg['건수별할부금액_3M'] = np.where(\n",
            "<ipython-input-37-fbf2bfb45a75>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  sales_with_seg['건수별할부금액_유이자_3M'] = np.where(\n",
            "<ipython-input-37-fbf2bfb45a75>:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  sales_with_seg['건수별할부금액_무이자_3M'] = np.where(\n",
            "<ipython-input-37-fbf2bfb45a75>:27: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  sales_with_seg['건수별할부금액_부분_12M'] = np.where(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- RP 관련 변수들"
      ],
      "metadata": {
        "id": "dgxSBLzxwSMb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터 동일한 변수 6개 삭제\n",
        "columns_drop = ['RP건수_유선방송_B0M',\n",
        "                'RP건수_건강_B0M',\n",
        "                'RP후경과월_유선방송',\n",
        "                'RP후경과월_건강',\n",
        "                '증감_RP건수_유선방송_전월',\n",
        "                '증감_RP건수_건강_전월']\n",
        "sales_with_seg.drop(columns=columns_drop, inplace=True)\n",
        "\n",
        "# '최근3개월이용여부_RP' 변수 생성\n",
        "sales_with_seg['최근3개월이용여부_RP'] = (sales_with_seg['RP후경과월'] <= 3).astype(int)\n",
        "\n",
        "# 'RP_이용확대여부' 변수 생성\n",
        "delta_cols = [col for col in sales_with_seg.columns if col.startswith('증감_RP건수_')]\n",
        "sales_with_seg['RP건수_증감총합'] = sales_with_seg[delta_cols].sum(axis=1)\n",
        "sales_with_seg['RP_이용확대여부'] = (sales_with_seg['RP건수_증감총합'] > 0).astype(int) # 방향성: 양수면 확장, 음수면 축소\n",
        "sales_with_seg.drop(columns=['RP건수_증감총합'], inplace=True)"
      ],
      "metadata": {
        "id": "85VT8Kb8BXYv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "76708043-772c-4691-8a6c-768e30171066"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-38-071d93968994>:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  sales_with_seg['최근3개월이용여부_RP'] = (sales_with_seg['RP후경과월'] <= 3).astype(int)\n",
            "<ipython-input-38-071d93968994>:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  sales_with_seg['RP건수_증감총합'] = sales_with_seg[delta_cols].sum(axis=1)\n",
            "<ipython-input-38-071d93968994>:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  sales_with_seg['RP_이용확대여부'] = (sales_with_seg['RP건수_증감총합'] > 0).astype(int) # 방향성: 양수면 확장, 음수면 축소\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 'RP활성업종수' 변수 생성\n",
        "rp_cols = [\n",
        "    'RP건수_통신_B0M', 'RP건수_아파트_B0M', 'RP건수_제휴사서비스직접판매_B0M',\n",
        "    'RP건수_렌탈_B0M', 'RP건수_가스_B0M', 'RP건수_전기_B0M', 'RP건수_보험_B0M',\n",
        "    'RP건수_학습비_B0M', 'RP건수_교통_B0M'\n",
        "]\n",
        "sales_with_seg['RP활성업종수'] = sales_with_seg[rp_cols].gt(0).sum(axis=1)"
      ],
      "metadata": {
        "id": "WpQf2SsiqNVi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "746f0d4f-ea14-42d7-87d0-b75b8150d013"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-39-a8a35245fb88>:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  sales_with_seg['RP활성업종수'] = sales_with_seg[rp_cols].gt(0).sum(axis=1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 카드론 관련 변수들"
      ],
      "metadata": {
        "id": "NMp4RSeDPrKg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# '카드론이용여부' 변수 생성\n",
        "sales_with_seg['카드론이용여부'] = (\n",
        "    (sales_with_seg['최초카드론이용경과월'] != 999) &\n",
        "    (sales_with_seg['최종카드론이용경과월'] != 999)\n",
        ").astype(int)"
      ],
      "metadata": {
        "id": "lhofBST_BXaf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4705c3bf-44c6-428d-c36d-4df951ea1c7c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-40-781516af5b95>:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  sales_with_seg['카드론이용여부'] = (\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 이용개월수/이용금액/이용건수 - 온라인/오프라인"
      ],
      "metadata": {
        "id": "tnUAwKncWeFL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 건수별평균금액 변수 6개 생성\n",
        "\n",
        "# R6M(최근 6개월)\n",
        "sales_with_seg['건수별평균이용금액_온라인_R6M'] = np.where(\n",
        "    (sales_with_seg['이용금액_온라인_R6M'] == 0) | (sales_with_seg['이용건수_온라인_R6M'] == 0),\n",
        "    0,\n",
        "    sales_with_seg['이용금액_온라인_R6M'] / sales_with_seg['이용건수_온라인_R6M'].abs()\n",
        ")\n",
        "\n",
        "sales_with_seg['건수별평균이용금액_오프라인_R6M'] = np.where(\n",
        "    (sales_with_seg['이용금액_오프라인_R6M'] == 0) | (sales_with_seg['이용건수_오프라인_R6M'] == 0),\n",
        "    0,\n",
        "    sales_with_seg['이용금액_오프라인_R6M'] / sales_with_seg['이용건수_오프라인_R6M'].abs()\n",
        ")\n",
        "\n",
        "# R3M(최근 3개월)\n",
        "sales_with_seg['건수별평균이용금액_온라인_R3M'] = np.where(\n",
        "    (sales_with_seg['이용금액_온라인_R3M'] == 0) | (sales_with_seg['이용건수_온라인_R3M'] == 0),\n",
        "    0,\n",
        "    sales_with_seg['이용금액_온라인_R3M'] / sales_with_seg['이용건수_온라인_R3M'].abs()\n",
        ")\n",
        "\n",
        "sales_with_seg['건수별평균이용금액_오프라인_R3M'] = np.where(\n",
        "    (sales_with_seg['이용금액_오프라인_R3M'] == 0) | (sales_with_seg['이용건수_오프라인_R3M'] == 0),\n",
        "    0,\n",
        "    sales_with_seg['이용금액_오프라인_R3M'] / sales_with_seg['이용건수_오프라인_R3M'].abs()\n",
        ")\n",
        "\n",
        "\n",
        "# B0M(당월)\n",
        "sales_with_seg['건수별평균이용금액_온라인_B0M'] = np.where(\n",
        "    (sales_with_seg['이용금액_온라인_B0M'] == 0) | (sales_with_seg['이용건수_온라인_B0M'] == 0),\n",
        "    0,\n",
        "    sales_with_seg['이용금액_온라인_B0M'] / sales_with_seg['이용건수_온라인_B0M'].abs()\n",
        ")\n",
        "\n",
        "sales_with_seg['건수별평균이용금액_오프라인_B0M'] = np.where(\n",
        "    (sales_with_seg['이용금액_오프라인_B0M'] == 0) | (sales_with_seg['이용건수_오프라인_B0M'] == 0),\n",
        "    0,\n",
        "    sales_with_seg['이용금액_오프라인_B0M'] / sales_with_seg['이용건수_오프라인_B0M'].abs()\n",
        ")"
      ],
      "metadata": {
        "id": "Tw1OMNUFBXb4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5ed17062-7d25-496f-ce4c-1eb64f88cb69"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-41-9fcf63bd8b3f>:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  sales_with_seg['건수별평균이용금액_온라인_R6M'] = np.where(\n",
            "<ipython-input-41-9fcf63bd8b3f>:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  sales_with_seg['건수별평균이용금액_오프라인_R6M'] = np.where(\n",
            "<ipython-input-41-9fcf63bd8b3f>:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  sales_with_seg['건수별평균이용금액_온라인_R3M'] = np.where(\n",
            "<ipython-input-41-9fcf63bd8b3f>:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  sales_with_seg['건수별평균이용금액_오프라인_R3M'] = np.where(\n",
            "<ipython-input-41-9fcf63bd8b3f>:31: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  sales_with_seg['건수별평균이용금액_온라인_B0M'] = np.where(\n",
            "<ipython-input-41-9fcf63bd8b3f>:37: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  sales_with_seg['건수별평균이용금액_오프라인_B0M'] = np.where(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 이용개월수/이용금액/이용건수 - 페이_온라인/오프라인"
      ],
      "metadata": {
        "id": "BbfizfpQXelE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 건수별평균이용금액 변수 생성\n",
        "\n",
        "# R6M (최근 6개월)\n",
        "sales_with_seg['건수별평균이용금액_페이_온라인_R6M'] = np.where(\n",
        "    (sales_with_seg['이용금액_페이_온라인_R6M'] == 0) | (sales_with_seg['이용건수_페이_온라인_R6M'] == 0),\n",
        "    0,\n",
        "    sales_with_seg['이용금액_페이_온라인_R6M'] / sales_with_seg['이용건수_페이_온라인_R6M'].abs()\n",
        ")\n",
        "\n",
        "sales_with_seg['건수별평균이용금액_페이_오프라인_R6M'] = np.where(\n",
        "    (sales_with_seg['이용금액_페이_오프라인_R6M'] == 0) | (sales_with_seg['이용건수_페이_오프라인_R6M'] == 0),\n",
        "    0,\n",
        "    sales_with_seg['이용금액_페이_오프라인_R6M'] / sales_with_seg['이용건수_페이_오프라인_R6M'].abs()\n",
        ")\n",
        "\n",
        "# R3M (최근 3개월)\n",
        "sales_with_seg['건수별평균이용금액_페이_온라인_R3M'] = np.where(\n",
        "    (sales_with_seg['이용금액_페이_온라인_R3M'] == 0) | (sales_with_seg['이용건수_페이_온라인_R3M'] == 0),\n",
        "    0,\n",
        "    sales_with_seg['이용금액_페이_온라인_R3M'] / sales_with_seg['이용건수_페이_온라인_R3M'].abs()\n",
        ")\n",
        "\n",
        "sales_with_seg['건수별평균이용금액_페이_오프라인_R3M'] = np.where(\n",
        "    (sales_with_seg['이용금액_페이_오프라인_R3M'] == 0) | (sales_with_seg['이용건수_페이_오프라인_R3M'] == 0),\n",
        "    0,\n",
        "    sales_with_seg['이용금액_페이_오프라인_R3M'] / sales_with_seg['이용건수_페이_오프라인_R3M'].abs()\n",
        ")\n",
        "\n",
        "# B0M (당월)\n",
        "sales_with_seg['건수별평균이용금액_페이_온라인_B0M'] = np.where(\n",
        "    (sales_with_seg['이용금액_페이_온라인_B0M'] == 0) | (sales_with_seg['이용건수_페이_온라인_B0M'] == 0),\n",
        "    0,\n",
        "    sales_with_seg['이용금액_페이_온라인_B0M'] / sales_with_seg['이용건수_페이_온라인_B0M'].abs()\n",
        ")\n",
        "\n",
        "sales_with_seg['건수별평균이용금액_페이_오프라인_B0M'] = np.where(\n",
        "    (sales_with_seg['이용금액_페이_오프라인_B0M'] == 0) | (sales_with_seg['이용건수_페이_오프라인_B0M'] == 0),\n",
        "    0,\n",
        "    sales_with_seg['이용금액_페이_오프라인_B0M'] / sales_with_seg['이용건수_페이_오프라인_B0M'].abs()\n",
        ")"
      ],
      "metadata": {
        "id": "aXOdR2E4BXdp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "04068269-1634-4988-c12c-a35cac710fcb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-42-1b4362d6e054>:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  sales_with_seg['건수별평균이용금액_페이_온라인_R6M'] = np.where(\n",
            "<ipython-input-42-1b4362d6e054>:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  sales_with_seg['건수별평균이용금액_페이_오프라인_R6M'] = np.where(\n",
            "<ipython-input-42-1b4362d6e054>:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  sales_with_seg['건수별평균이용금액_페이_온라인_R3M'] = np.where(\n",
            "<ipython-input-42-1b4362d6e054>:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  sales_with_seg['건수별평균이용금액_페이_오프라인_R3M'] = np.where(\n",
            "<ipython-input-42-1b4362d6e054>:30: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  sales_with_seg['건수별평균이용금액_페이_온라인_B0M'] = np.where(\n",
            "<ipython-input-42-1b4362d6e054>:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  sales_with_seg['건수별평균이용금액_페이_오프라인_B0M'] = np.where(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 이용개월수/이용금액/이용건수 -  간편결제/당사페이/당사기타/A,B,C,D페이"
      ],
      "metadata": {
        "id": "mNbao3-OYYXw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- R6M"
      ],
      "metadata": {
        "id": "5uCKDBXJZ9dl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터 동일한 변수 5개 삭제\n",
        "columns_drop = ['이용개월수_당사페이_R6M',\n",
        "                '이용금액_당사페이_R6M',\n",
        "                '이용금액_당사기타_R6M',\n",
        "                '이용건수_당사페이_R6M',\n",
        "                '이용건수_당사기타_R6M']\n",
        "sales_with_seg.drop(columns=columns_drop, inplace=True)"
      ],
      "metadata": {
        "id": "P6brX_sMBcN5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 건수별평균이용금액 변수 5개 생성 (R6M 기준)\n",
        "\n",
        "# 간편결제\n",
        "sales_with_seg['건수별평균이용금액_간편결제_R6M'] = np.where(\n",
        "    (sales_with_seg['이용금액_간편결제_R6M'] == 0) | (sales_with_seg['이용건수_간편결제_R6M'] == 0),\n",
        "    0,\n",
        "    sales_with_seg['이용금액_간편결제_R6M'] / sales_with_seg['이용건수_간편결제_R6M'].abs()\n",
        ")\n",
        "\n",
        "# A페이\n",
        "sales_with_seg['건수별평균이용금액_A페이_R6M'] = np.where(\n",
        "    (sales_with_seg['이용금액_A페이_R6M'] == 0) | (sales_with_seg['이용건수_A페이_R6M'] == 0),\n",
        "    0,\n",
        "    sales_with_seg['이용금액_A페이_R6M'] / sales_with_seg['이용건수_A페이_R6M'].abs()\n",
        ")\n",
        "\n",
        "# B페이\n",
        "sales_with_seg['건수별평균이용금액_B페이_R6M'] = np.where(\n",
        "    (sales_with_seg['이용금액_B페이_R6M'] == 0) | (sales_with_seg['이용건수_B페이_R6M'] == 0),\n",
        "    0,\n",
        "    sales_with_seg['이용금액_B페이_R6M'] / sales_with_seg['이용건수_B페이_R6M'].abs()\n",
        ")\n",
        "\n",
        "# C페이\n",
        "sales_with_seg['건수별평균이용금액_C페이_R6M'] = np.where(\n",
        "    (sales_with_seg['이용금액_C페이_R6M'] == 0) | (sales_with_seg['이용건수_C페이_R6M'] == 0),\n",
        "    0,\n",
        "    sales_with_seg['이용금액_C페이_R6M'] / sales_with_seg['이용건수_C페이_R6M'].abs()\n",
        ")\n",
        "\n",
        "# D페이\n",
        "sales_with_seg['건수별평균이용금액_D페이_R6M'] = np.where(\n",
        "    (sales_with_seg['이용금액_D페이_R6M'] == 0) | (sales_with_seg['이용건수_D페이_R6M'] == 0),\n",
        "    0,\n",
        "    sales_with_seg['이용금액_D페이_R6M'] / sales_with_seg['이용건수_D페이_R6M'].abs()\n",
        ")"
      ],
      "metadata": {
        "id": "kcszdYMFBXfl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b4f6a049-6e50-4d12-d840-55c1d6f309e2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-44-154095dbc84a>:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  sales_with_seg['건수별평균이용금액_간편결제_R6M'] = np.where(\n",
            "<ipython-input-44-154095dbc84a>:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  sales_with_seg['건수별평균이용금액_A페이_R6M'] = np.where(\n",
            "<ipython-input-44-154095dbc84a>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  sales_with_seg['건수별평균이용금액_B페이_R6M'] = np.where(\n",
            "<ipython-input-44-154095dbc84a>:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  sales_with_seg['건수별평균이용금액_C페이_R6M'] = np.where(\n",
            "<ipython-input-44-154095dbc84a>:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  sales_with_seg['건수별평균이용금액_D페이_R6M'] = np.where(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- R3M"
      ],
      "metadata": {
        "id": "jpTbVpATZ_J8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터 동일한 변수 4개 삭제\n",
        "columns_drop = ['이용금액_당사페이_R3M',\n",
        "                '이용금액_당사기타_R3M',\n",
        "                '이용건수_당사페이_R3M',\n",
        "                '이용건수_당사기타_R3M']\n",
        "sales_with_seg.drop(columns=columns_drop, inplace=True)"
      ],
      "metadata": {
        "id": "Ciyvoa13aAZz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 건수별평균이용금액 변수 5개 생성 (R3M 기준)\n",
        "\n",
        "# 간편결제\n",
        "sales_with_seg['건수별평균이용금액_간편결제_R3M'] = np.where(\n",
        "    (sales_with_seg['이용금액_간편결제_R3M'] == 0) | (sales_with_seg['이용건수_간편결제_R3M'] == 0),\n",
        "    0,\n",
        "    sales_with_seg['이용금액_간편결제_R3M'] / sales_with_seg['이용건수_간편결제_R3M'].abs()\n",
        ")\n",
        "\n",
        "# A페이\n",
        "sales_with_seg['건수별평균이용금액_A페이_R3M'] = np.where(\n",
        "    (sales_with_seg['이용금액_A페이_R3M'] == 0) | (sales_with_seg['이용건수_A페이_R3M'] == 0),\n",
        "    0,\n",
        "    sales_with_seg['이용금액_A페이_R3M'] / sales_with_seg['이용건수_A페이_R3M'].abs()\n",
        ")\n",
        "\n",
        "# B페이\n",
        "sales_with_seg['건수별평균이용금액_B페이_R3M'] = np.where(\n",
        "    (sales_with_seg['이용금액_B페이_R3M'] == 0) | (sales_with_seg['이용건수_B페이_R3M'] == 0),\n",
        "    0,\n",
        "    sales_with_seg['이용금액_B페이_R3M'] / sales_with_seg['이용건수_B페이_R3M'].abs()\n",
        ")\n",
        "\n",
        "# C페이\n",
        "sales_with_seg['건수별평균이용금액_C페이_R3M'] = np.where(\n",
        "    (sales_with_seg['이용금액_C페이_R3M'] == 0) | (sales_with_seg['이용건수_C페이_R3M'] == 0),\n",
        "    0,\n",
        "    sales_with_seg['이용금액_C페이_R3M'] / sales_with_seg['이용건수_C페이_R3M'].abs()\n",
        ")\n",
        "\n",
        "# D페이\n",
        "sales_with_seg['건수별평균이용금액_D페이_R3M'] = np.where(\n",
        "    (sales_with_seg['이용금액_D페이_R3M'] == 0) | (sales_with_seg['이용건수_D페이_R3M'] == 0),\n",
        "    0,\n",
        "    sales_with_seg['이용금액_D페이_R3M'] / sales_with_seg['이용건수_D페이_R3M'].abs()\n",
        ")"
      ],
      "metadata": {
        "id": "XGsNrmVeaNNk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a115f9eb-d1fd-423d-b0b1-cba1714d3b9f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-46-c3a97c739420>:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  sales_with_seg['건수별평균이용금액_간편결제_R3M'] = np.where(\n",
            "<ipython-input-46-c3a97c739420>:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  sales_with_seg['건수별평균이용금액_A페이_R3M'] = np.where(\n",
            "<ipython-input-46-c3a97c739420>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  sales_with_seg['건수별평균이용금액_B페이_R3M'] = np.where(\n",
            "<ipython-input-46-c3a97c739420>:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  sales_with_seg['건수별평균이용금액_C페이_R3M'] = np.where(\n",
            "<ipython-input-46-c3a97c739420>:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  sales_with_seg['건수별평균이용금액_D페이_R3M'] = np.where(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- B0M"
      ],
      "metadata": {
        "id": "gKJlU1K3aAdT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터 동일한 변수 4개 삭제\n",
        "columns_drop = ['이용금액_당사페이_B0M',\n",
        "                '이용금액_당사기타_B0M',\n",
        "                '이용건수_당사페이_B0M',\n",
        "                '이용건수_당사기타_B0M']\n",
        "sales_with_seg.drop(columns=columns_drop, inplace=True)"
      ],
      "metadata": {
        "id": "7-Djn2zZaAiz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 건수별평균이용금액 변수 5개 생성 (B0M 기준)\n",
        "\n",
        "# 간편결제\n",
        "sales_with_seg['건수별평균이용금액_간편결제_B0M'] = np.where(\n",
        "    (sales_with_seg['이용금액_간편결제_B0M'] == 0) | (sales_with_seg['이용건수_간편결제_B0M'] == 0),\n",
        "    0,\n",
        "    sales_with_seg['이용금액_간편결제_B0M'] / sales_with_seg['이용건수_간편결제_B0M'].abs()\n",
        ")\n",
        "\n",
        "# A페이\n",
        "sales_with_seg['건수별평균이용금액_A페이_B0M'] = np.where(\n",
        "    (sales_with_seg['이용금액_A페이_B0M'] == 0) | (sales_with_seg['이용건수_A페이_B0M'] == 0),\n",
        "    0,\n",
        "    sales_with_seg['이용금액_A페이_B0M'] / sales_with_seg['이용건수_A페이_B0M'].abs()\n",
        ")\n",
        "\n",
        "# B페이\n",
        "sales_with_seg['건수별평균이용금액_B페이_B0M'] = np.where(\n",
        "    (sales_with_seg['이용금액_B페이_B0M'] == 0) | (sales_with_seg['이용건수_B페이_B0M'] == 0),\n",
        "    0,\n",
        "    sales_with_seg['이용금액_B페이_B0M'] / sales_with_seg['이용건수_B페이_B0M'].abs()\n",
        ")\n",
        "\n",
        "# C페이\n",
        "sales_with_seg['건수별평균이용금액_C페이_B0M'] = np.where(\n",
        "    (sales_with_seg['이용금액_C페이_B0M'] == 0) | (sales_with_seg['이용건수_C페이_B0M'] == 0),\n",
        "    0,\n",
        "    sales_with_seg['이용금액_C페이_B0M'] / sales_with_seg['이용건수_C페이_B0M'].abs()\n",
        ")\n",
        "\n",
        "# D페이\n",
        "sales_with_seg['건수별평균이용금액_D페이_B0M'] = np.where(\n",
        "    (sales_with_seg['이용금액_D페이_B0M'] == 0) | (sales_with_seg['이용건수_D페이_B0M'] == 0),\n",
        "    0,\n",
        "    sales_with_seg['이용금액_D페이_B0M'] / sales_with_seg['이용건수_D페이_B0M'].abs()\n",
        ")"
      ],
      "metadata": {
        "id": "Lde88MIdbR1k",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ae053d52-8dca-42d0-d05a-f82bb945cc14"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-48-51b69cc8c592>:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  sales_with_seg['건수별평균이용금액_간편결제_B0M'] = np.where(\n",
            "<ipython-input-48-51b69cc8c592>:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  sales_with_seg['건수별평균이용금액_A페이_B0M'] = np.where(\n",
            "<ipython-input-48-51b69cc8c592>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  sales_with_seg['건수별평균이용금액_B페이_B0M'] = np.where(\n",
            "<ipython-input-48-51b69cc8c592>:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  sales_with_seg['건수별평균이용금액_C페이_B0M'] = np.where(\n",
            "<ipython-input-48-51b69cc8c592>:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  sales_with_seg['건수별평균이용금액_D페이_B0M'] = np.where(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 선결제"
      ],
      "metadata": {
        "id": "fYMEXBW2ZIdT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 횟수별/건수별 평균이용금액\n",
        "\n",
        "# R6M\n",
        "sales_with_seg['횟수별평균이용금액_선결제_R6M'] = np.where(\n",
        "    (sales_with_seg['이용금액_선결제_R6M'] == 0) | (sales_with_seg['이용횟수_선결제_R6M'] == 0),\n",
        "    0,\n",
        "    sales_with_seg['이용금액_선결제_R6M'] / sales_with_seg['이용횟수_선결제_R6M'].abs()\n",
        ")\n",
        "\n",
        "sales_with_seg['건수별평균이용금액_선결제_R6M'] = np.where(\n",
        "    (sales_with_seg['이용금액_선결제_R6M'] == 0) | (sales_with_seg['이용건수_선결제_R6M'] == 0),\n",
        "    0,\n",
        "    sales_with_seg['이용금액_선결제_R6M'] / sales_with_seg['이용건수_선결제_R6M'].abs()\n",
        ")\n",
        "\n",
        "# R3M\n",
        "sales_with_seg['횟수별평균이용금액_선결제_R3M'] = np.where(\n",
        "    (sales_with_seg['이용금액_선결제_R3M'] == 0) | (sales_with_seg['이용횟수_선결제_R3M'] == 0),\n",
        "    0,\n",
        "    sales_with_seg['이용금액_선결제_R3M'] / sales_with_seg['이용횟수_선결제_R3M'].abs()\n",
        ")\n",
        "\n",
        "sales_with_seg['건수별평균이용금액_선결제_R3M'] = np.where(\n",
        "    (sales_with_seg['이용금액_선결제_R3M'] == 0) | (sales_with_seg['이용건수_선결제_R3M'] == 0),\n",
        "    0,\n",
        "    sales_with_seg['이용금액_선결제_R3M'] / sales_with_seg['이용건수_선결제_R3M'].abs()\n",
        ")\n",
        "\n",
        "# B0M\n",
        "sales_with_seg['횟수별평균이용금액_선결제_B0M'] = np.where(\n",
        "    (sales_with_seg['이용금액_선결제_B0M'] == 0) | (sales_with_seg['이용횟수_선결제_B0M'] == 0),\n",
        "    0,\n",
        "    sales_with_seg['이용금액_선결제_B0M'] / sales_with_seg['이용횟수_선결제_B0M'].abs()\n",
        ")\n",
        "\n",
        "sales_with_seg['건수별평균이용금액_선결제_B0M'] = np.where(\n",
        "    (sales_with_seg['이용금액_선결제_B0M'] == 0) | (sales_with_seg['이용건수_선결제_B0M'] == 0),\n",
        "    0,\n",
        "    sales_with_seg['이용금액_선결제_B0M'] / sales_with_seg['이용건수_선결제_B0M'].abs()\n",
        ")"
      ],
      "metadata": {
        "id": "iPk_aoAsBXg3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "60b68f67-d8bd-40cc-a8b6-3b95c71f1cac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-49-f74a7dbb1d59>:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  sales_with_seg['횟수별평균이용금액_선결제_R6M'] = np.where(\n",
            "<ipython-input-49-f74a7dbb1d59>:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  sales_with_seg['건수별평균이용금액_선결제_R6M'] = np.where(\n",
            "<ipython-input-49-f74a7dbb1d59>:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  sales_with_seg['횟수별평균이용금액_선결제_R3M'] = np.where(\n",
            "<ipython-input-49-f74a7dbb1d59>:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  sales_with_seg['건수별평균이용금액_선결제_R3M'] = np.where(\n",
            "<ipython-input-49-f74a7dbb1d59>:30: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  sales_with_seg['횟수별평균이용금액_선결제_B0M'] = np.where(\n",
            "<ipython-input-49-f74a7dbb1d59>:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  sales_with_seg['건수별평균이용금액_선결제_B0M'] = np.where(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 연체"
      ],
      "metadata": {
        "id": "yI2kPN98dnVh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 횟수별평균이용금액 변수 생성\n",
        "\n",
        "# R6M\n",
        "sales_with_seg['횟수별평균이용금액_연체_R6M'] = np.where(\n",
        "    (sales_with_seg['이용금액_연체_R6M'] == 0) | (sales_with_seg['이용횟수_연체_R6M'] == 0),\n",
        "    0,\n",
        "    sales_with_seg['이용금액_연체_R6M'] / sales_with_seg['이용횟수_연체_R6M'].abs()\n",
        ")\n",
        "\n",
        "# R3M\n",
        "sales_with_seg['횟수별평균이용금액_연체_R3M'] = np.where(\n",
        "    (sales_with_seg['이용금액_연체_R3M'] == 0) | (sales_with_seg['이용횟수_연체_R3M'] == 0),\n",
        "    0,\n",
        "    sales_with_seg['이용금액_연체_R3M'] / sales_with_seg['이용횟수_연체_R3M'].abs()\n",
        ")\n",
        "\n",
        "# B0M\n",
        "sales_with_seg['횟수별평균이용금액_연체_B0M'] = np.where(\n",
        "    (sales_with_seg['이용금액_연체_B0M'] == 0) | (sales_with_seg['이용횟수_연체_B0M'] == 0),\n",
        "    0,\n",
        "    sales_with_seg['이용금액_연체_B0M'] / sales_with_seg['이용횟수_연체_B0M'].abs()\n",
        ")"
      ],
      "metadata": {
        "id": "txLz4SuulDSt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ef95ae1a-399a-4641-bc69-fff353aba22c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-50-d7558ba4bb37>:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  sales_with_seg['횟수별평균이용금액_연체_R6M'] = np.where(\n",
            "<ipython-input-50-d7558ba4bb37>:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  sales_with_seg['횟수별평균이용금액_연체_R3M'] = np.where(\n",
            "<ipython-input-50-d7558ba4bb37>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  sales_with_seg['횟수별평균이용금액_연체_B0M'] = np.where(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 입금원금 관련 변수"
      ],
      "metadata": {
        "id": "qzlyPVBofcpN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 총납부금 변수 및 납부비율 변수 생성\n",
        "for month in ['B0M', 'B2M', 'B5M']:\n",
        "    sales_with_seg[f'총납부금_{month}'] = (\n",
        "        sales_with_seg[f'선입금원금_{month}'] +\n",
        "        sales_with_seg[f'정상입금원금_{month}'] +\n",
        "        sales_with_seg[f'연체입금원금_{month}']\n",
        "    )\n",
        "\n",
        "    sales_with_seg[f'납부비율_{month}'] = np.where(\n",
        "        sales_with_seg[f'정상청구원금_{month}'] == 0,\n",
        "        0,\n",
        "        sales_with_seg[f'총납부금_{month}'] / sales_with_seg[f'정상청구원금_{month}']\n",
        "    )"
      ],
      "metadata": {
        "id": "F8kB8ToLlDU_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2ab162c0-6ea5-4be1-aeca-19d779d49a94"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-51-a792eb1a16b8>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  sales_with_seg[f'총납부금_{month}'] = (\n",
            "<ipython-input-51-a792eb1a16b8>:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  sales_with_seg[f'납부비율_{month}'] = np.where(\n",
            "<ipython-input-51-a792eb1a16b8>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  sales_with_seg[f'총납부금_{month}'] = (\n",
            "<ipython-input-51-a792eb1a16b8>:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  sales_with_seg[f'납부비율_{month}'] = np.where(\n",
            "<ipython-input-51-a792eb1a16b8>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  sales_with_seg[f'총납부금_{month}'] = (\n",
            "<ipython-input-51-a792eb1a16b8>:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  sales_with_seg[f'납부비율_{month}'] = np.where(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 정시납부금 및 정시납부비율 변수 생성\n",
        "for month in ['B0M', 'B2M', 'B5M']:\n",
        "    sales_with_seg[f'정시납부금_{month}'] = (\n",
        "        sales_with_seg[f'선입금원금_{month}'] +\n",
        "        sales_with_seg[f'정상입금원금_{month}']\n",
        "    )\n",
        "\n",
        "    sales_with_seg[f'정시납부비율_{month}'] = np.where(\n",
        "        sales_with_seg[f'정상청구원금_{month}'] == 0,\n",
        "        0,\n",
        "        sales_with_seg[f'정시납부금_{month}'] / sales_with_seg[f'정상청구원금_{month}']\n",
        "    )"
      ],
      "metadata": {
        "id": "8UmWaDSqkBr2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e2388df1-3e5c-4ff6-db4b-93c53d2aa24c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-52-d151c7f70dda>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  sales_with_seg[f'정시납부금_{month}'] = (\n",
            "<ipython-input-52-d151c7f70dda>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  sales_with_seg[f'정시납부비율_{month}'] = np.where(\n",
            "<ipython-input-52-d151c7f70dda>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  sales_with_seg[f'정시납부금_{month}'] = (\n",
            "<ipython-input-52-d151c7f70dda>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  sales_with_seg[f'정시납부비율_{month}'] = np.where(\n",
            "<ipython-input-52-d151c7f70dda>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  sales_with_seg[f'정시납부금_{month}'] = (\n",
            "<ipython-input-52-d151c7f70dda>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  sales_with_seg[f'정시납부비율_{month}'] = np.where(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 건수 관련 변수 등"
      ],
      "metadata": {
        "id": "L-XSn50BiBmT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 건수별평균금액 변수 만들기\n",
        "# R6M\n",
        "sales_with_seg['건수별평균금액_할부전환_R6M'] = np.where(\n",
        "    (sales_with_seg['금액_할부전환_R6M'] == 0) | (sales_with_seg['건수_할부전환_R6M'] == 0),\n",
        "    0,\n",
        "    sales_with_seg['금액_할부전환_R6M'] / sales_with_seg['건수_할부전환_R6M'].abs()\n",
        ")\n",
        "\n",
        "# R3M\n",
        "sales_with_seg['건수별평균금액_할부전환_R3M'] = np.where(\n",
        "    (sales_with_seg['금액_할부전환_R3M'] == 0) | (sales_with_seg['건수_할부전환_R3M'] == 0),\n",
        "    0,\n",
        "    sales_with_seg['금액_할부전환_R3M'] / sales_with_seg['건수_할부전환_R3M'].abs()\n",
        ")"
      ],
      "metadata": {
        "id": "OoxAmapwlUvr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0d7bb6df-b18c-4a67-8eb0-b534d53b198a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-53-a4a144698f85>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  sales_with_seg['건수별평균금액_할부전환_R6M'] = np.where(\n",
            "<ipython-input-53-a4a144698f85>:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  sales_with_seg['건수별평균금액_할부전환_R3M'] = np.where(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 파일 저장: sales_train_cleaned (2400000, 523)"
      ],
      "metadata": {
        "id": "G8ldgatYnigV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# int64 -> int32로 변경 (메모리 줄이기 위함)\n",
        "for col in sales_with_seg.select_dtypes(include='int64').columns:\n",
        "    if sales_with_seg[col].max() < 2_147_483_647:\n",
        "        sales_with_seg[col] = sales_with_seg[col].astype('int32')\n",
        "\n",
        "# float64 -> float 32로 변경 (메모리 줄이기 위함)\n",
        "for col in sales_with_seg.select_dtypes(include='float64').columns:\n",
        "    sales_with_seg[col] = sales_with_seg[col].astype('float32')\n",
        "\n",
        "sales_with_seg = sales_with_seg.drop(columns=['Segment'])\n",
        "sales_with_seg.to_parquet(\"/content/drive/MyDrive/Dacon/sales_train_cleaned.parquet\")"
      ],
      "metadata": {
        "id": "_iytdINXnjqn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 청구입금정보 (billing)"
      ],
      "metadata": {
        "id": "63EOZW4VDsha"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Google Drive에 있는 데이터 경로\n",
        "base_dir = '/content/drive/MyDrive/Data'\n",
        "\n",
        "# 데이터 분할(폴더) 구분\n",
        "data_splits = [\"train\"] # train 만!\n",
        "\n",
        "# 각 데이터 유형별 폴더명, 파일 접미사, 변수 접두어 설정\n",
        "data_categories = {\n",
        "    \"청구정보\": {\"folder\": \"4.청구입금정보\", \"suffix\": \"청구정보\", \"var_prefix\": \"billing\"}\n",
        "}\n",
        "\n",
        "# 2018년 7월부터 12월까지의 월 리스트\n",
        "months = ['07', '08', '09', '10', '11', '12']\n",
        "\n",
        "for split in data_splits:\n",
        "    for category, info in data_categories.items():\n",
        "        folder = info[\"folder\"]\n",
        "        suffix = info[\"suffix\"]\n",
        "        var_prefix = info[\"var_prefix\"]\n",
        "\n",
        "        for month in months:\n",
        "            # 파일명 형식: 2018{month}_{split}_{suffix}.parquet\n",
        "            file_path = f\"{base_dir}/{split}/{folder}/2018{month}_{split}_{suffix}.parquet\"\n",
        "            # 변수명 형식: {var_prefix}_{split}_{month}\n",
        "            variable_name = f\"{var_prefix}_{split}_{month}\"\n",
        "            globals()[variable_name] = pd.read_parquet(file_path)\n",
        "            print(f\"{variable_name} is loaded from {file_path}\")\n",
        "\n",
        "gc.collect()"
      ],
      "metadata": {
        "id": "2bHfyZxZGY1T",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a35b666a-8419-438c-a706-d6a92955e62c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "billing_train_07 is loaded from /content/drive/MyDrive/Data/train/4.청구입금정보/201807_train_청구정보.parquet\n",
            "billing_train_08 is loaded from /content/drive/MyDrive/Data/train/4.청구입금정보/201808_train_청구정보.parquet\n",
            "billing_train_09 is loaded from /content/drive/MyDrive/Data/train/4.청구입금정보/201809_train_청구정보.parquet\n",
            "billing_train_10 is loaded from /content/drive/MyDrive/Data/train/4.청구입금정보/201810_train_청구정보.parquet\n",
            "billing_train_11 is loaded from /content/drive/MyDrive/Data/train/4.청구입금정보/201811_train_청구정보.parquet\n",
            "billing_train_12 is loaded from /content/drive/MyDrive/Data/train/4.청구입금정보/201812_train_청구정보.parquet\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터 유형별 설정\n",
        "info_categories = [\"billing\"]\n",
        "\n",
        "# 월 설정\n",
        "months = ['07', '08', '09', '10', '11', '12']\n",
        "\n",
        "# 각 유형별로 월별 데이터를 합쳐서 새로운 변수에 저장\n",
        "train_dfs = {}\n",
        "\n",
        "for prefix in info_categories:\n",
        "    # globals()에서 동적 변수명으로 데이터프레임들을 가져와 리스트에 저장\n",
        "    df_list = [globals()[f\"{prefix}_train_{month}\"] for month in months]\n",
        "    train_dfs[f\"{prefix}_train_df\"] = pd.concat(df_list, axis=0)\n",
        "    gc.collect()\n",
        "    print(f\"{prefix}_train_df is created with shape: {train_dfs[f'{prefix}_train_df'].shape}\")\n",
        "\n",
        "billing_train_df  = train_dfs[\"billing_train_df\"]\n",
        "\n",
        "gc.collect()"
      ],
      "metadata": {
        "id": "4JdzrqpqGqYl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bfe5947a-97bc-4bba-8d3a-59a2f655a272"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "billing_train_df is created with shape: (2400000, 46)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 전처리"
      ],
      "metadata": {
        "id": "GFHD2K6ZHFBn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 대표결제일이 10인 경우: D, E만 있다 -> 대표결제일 10 여부 변수 추가\n",
        "billing_train_df['대표결제일_10여부'] = np.where(billing_train_df['대표결제일'] == 10, 1, 0)\n",
        "\n",
        "# 대표결제일이 21인 경우: C, D, E만 있다 -> 대표결제일 21 여부 변수 추가\n",
        "billing_train_df['대표결제일_21여부'] = np.where(billing_train_df['대표결제일'] == 21, 1, 0)\n",
        "\n",
        "billing_train_df = billing_train_df.drop(['대표결제일'], axis=1) #원래 대표결제일 변수 삭제\n",
        "\n",
        "# 청구서수령방법이 당사멤버십인 고객: C, D, E만 있다 -> 청구서수령방법 당사멤버십 여부 변수 추가\n",
        "billing_train_df['청구서수령방법_당사멤버십여부'] = np.where(billing_train_df['청구서수령방법'] == '당사멤버십', 1, 0)\n",
        "billing_train_df = billing_train_df.drop(['청구서수령방법'], axis=1) # 원래 청구서수령방법 변수 삭제\n",
        "\n",
        "# 대표결제방법코드: 모두 '자동이체'로 동일 -> 삭제\n",
        "# 대표청구서수령지구분코드, 대표청구지고객주소구분코드: 청구서수령방법에 대해 세분화한 것 -> 삭제\n",
        "# 청구서발송여부_B0, 청구서발송여부_R3M, 청구서발송여부_R6M: 0,1로 구성되어있으며 청구금액이 0이면 미발송 -> 청구금액 변수와 겹치므로 삭제\n",
        "billing_train_df = billing_train_df.drop(['대표결제방법코드', '대표청구서수령지구분코드', '대표청구지고객주소구분코드', '청구서발송여부_B0',\n",
        "                                          '청구서발송여부_R3M', '청구서발송여부_R6M'], axis=1)\n",
        "\n",
        "# 문자열 인코딩\n",
        "billing_train_df['할인건수_R3M'] = billing_train_df['할인건수_R3M'].map({'1회 이상': 0, '10회 이상': 1, '20회 이상': 2,'30회 이상': 3, '40회 이상': 4})\n",
        "billing_train_df['할인건수_B0M'] = billing_train_df['할인건수_B0M'].map({'1회 이상': 0, '10회 이상': 1})"
      ],
      "metadata": {
        "id": "fU6T3nz8HMCl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# int64 -> int32로 변경 (메모리 줄이기 위함)\n",
        "for col in billing_train_df.select_dtypes(include='int64').columns:\n",
        "    if billing_train_df[col].max() < 2_147_483_647:\n",
        "        billing_train_df[col] = billing_train_df[col].astype('int32')\n",
        "\n",
        "# float64 -> float 32로 변경 (메모리 줄이기 위함)\n",
        "for col in billing_train_df.select_dtypes(include='float64').columns:\n",
        "    billing_train_df[col] = billing_train_df[col].astype('float32')\n",
        "\n",
        "billing_train_df.to_parquet(\"/content/drive/MyDrive/Dacon/billing_train_cleaned.parquet\")"
      ],
      "metadata": {
        "id": "lxx7XrEdd1of"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 잔액정보 (balance)"
      ],
      "metadata": {
        "id": "VlxYszFKDsjv"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CoD3AzgEIitB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "854d36cc-5dcd-496f-fb61-1dcd3121e536"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "balance_train_07 is loaded from /content/drive/MyDrive/Data/train/5.잔액정보/201807_train_잔액정보.parquet\n",
            "balance_train_08 is loaded from /content/drive/MyDrive/Data/train/5.잔액정보/201808_train_잔액정보.parquet\n",
            "balance_train_09 is loaded from /content/drive/MyDrive/Data/train/5.잔액정보/201809_train_잔액정보.parquet\n",
            "balance_train_10 is loaded from /content/drive/MyDrive/Data/train/5.잔액정보/201810_train_잔액정보.parquet\n",
            "balance_train_11 is loaded from /content/drive/MyDrive/Data/train/5.잔액정보/201811_train_잔액정보.parquet\n",
            "balance_train_12 is loaded from /content/drive/MyDrive/Data/train/5.잔액정보/201812_train_잔액정보.parquet\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ],
      "source": [
        "# Google Drive에 있는 데이터 경로\n",
        "base_dir = \"/content/drive/MyDrive/Data\"\n",
        "\n",
        "# 데이터 분할(폴더) 구분\n",
        "data_splits = [\"train\"]\n",
        "\n",
        "# 각 데이터 유형별 폴더명, 파일 접미사, 변수 접두어 설정\n",
        "data_categories = {\n",
        "    \"잔액정보\": {\"folder\": \"5.잔액정보\", \"suffix\": \"잔액정보\", \"var_prefix\": \"balance\"}\n",
        "}\n",
        "\n",
        "# 2018년 7월부터 12월까지의 월 리스트\n",
        "months = ['07', '08', '09', '10', '11', '12']\n",
        "\n",
        "for split in data_splits:\n",
        "    for category, info in data_categories.items():\n",
        "        folder = info[\"folder\"]\n",
        "        suffix = info[\"suffix\"]\n",
        "        var_prefix = info[\"var_prefix\"]\n",
        "\n",
        "        for month in months:\n",
        "            # 파일명 형식: 2018{month}_{split}_{suffix}.parquet\n",
        "            file_path = f\"{base_dir}/{split}/{folder}/2018{month}_{split}_{suffix}.parquet\"\n",
        "            # 변수명 형식: {var_prefix}_{split}_{month}\n",
        "            variable_name = f\"{var_prefix}_{split}_{month}\"\n",
        "            globals()[variable_name] = pd.read_parquet(file_path)\n",
        "            print(f\"{variable_name} is loaded from {file_path}\")\n",
        "\n",
        "gc.collect()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "outputId": "b13b91e0-d567-422b-f304-a7c3230d9a67",
        "id": "8O9sX8v6IitB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "balance_train_df is created with shape: (2400000, 82)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ],
      "source": [
        "# 데이터 유형별 설정\n",
        "info_categories = [\"balance\"]\n",
        "\n",
        "# 월 설정\n",
        "months = ['07', '08', '09', '10', '11', '12']\n",
        "\n",
        "# 각 유형별로 월별 데이터를 합쳐서 새로운 변수에 저장\n",
        "train_dfs = {}\n",
        "\n",
        "for prefix in info_categories:\n",
        "    # globals()에서 동적 변수명으로 데이터프레임들을 가져와 리스트에 저장\n",
        "    df_list = [globals()[f\"{prefix}_train_{month}\"] for month in months]\n",
        "    train_dfs[f\"{prefix}_train_df\"] = pd.concat(df_list, axis=0)\n",
        "    gc.collect()\n",
        "    print(f\"{prefix}_train_df is created with shape: {train_dfs[f'{prefix}_train_df'].shape}\")\n",
        "\n",
        "balance_train_df  = train_dfs[\"balance_train_df\"]\n",
        "gc.collect()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 연체일자_B0M: 99.7%가 결측값 -> 연체일수 변수도 있기 때문에 삭제\n",
        "# 카드론잔액_최종경과월, 최종연체개월수_R15M, RV잔액이월횟수_R6M, RV잔액이월횟수_R3M, 연체잔액_일시불_해외_B0M, 연체잔액_RV일시불_해외_B0M, 연체잔액_할부_해외_B0M, 연체잔액_CA_해외_B0M : 모두 0 → 삭제\n",
        "balance_train_df = balance_train_df.drop(['연체일자_B0M', '카드론잔액_최종경과월', '최종연체개월수_R15M', 'RV잔액이월횟수_R6M',\n",
        "                                          'RV잔액이월횟수_R3M', '연체잔액_일시불_해외_B0M', '연체잔액_RV일시불_해외_B0M', '연체잔액_할부_해외_B0M',\n",
        "                                          '연체잔액_CA_해외_B0M'], axis=1)\n",
        "\n",
        "#최종연체회차: -99, 0으로 구성됨 -> 0,1로 바꿔서 인코딩\n",
        "balance_train_df['최종연체회차'] = balance_train_df['최종연체회차'].map({-99: 0, 0: 1})\n",
        "\n",
        "# 연체일수_B1M, 연체일수_B2M, 연체일수_최근: -999999, 0, 1로 구성됨, 연체일수 1은 C,D,E뿐 -> 연체일수 1이면 1, 아니면 0으로 인코딩\n",
        "balance_train_df['연체일수_B1M'] = np.where(balance_train_df['연체일수_B1M'] == 1, 1, 0)\n",
        "balance_train_df['연체일수_B2M'] = np.where(balance_train_df['연체일수_B2M'] == 1, 1, 0)\n",
        "balance_train_df['연체일수_최근'] = np.where(balance_train_df['연체일수_최근'] == 1, 1, 0)"
      ],
      "metadata": {
        "id": "heTJBO8tI_Hn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# int64 -> int32로 변경 (메모리 줄이기 위함)\n",
        "for col in balance_train_df.select_dtypes(include='int64').columns:\n",
        "    if balance_train_df[col].max() < 2_147_483_647:\n",
        "        balance_train_df[col] = balance_train_df[col].astype('int32')\n",
        "\n",
        "# float64 -> float 32로 변경 (메모리 줄이기 위함)\n",
        "for col in balance_train_df.select_dtypes(include='float64').columns:\n",
        "    balance_train_df[col] = balance_train_df[col].astype('float32')\n",
        "\n",
        "balance_train_df.to_parquet(\"/content/drive/MyDrive/Dacon/balance_train_cleaned.parquet\")"
      ],
      "metadata": {
        "id": "GLBqfc_GeMQ3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 채널정보 (channel)"
      ],
      "metadata": {
        "id": "4K4YLvcTDsl8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Google Drive에 있는 데이터 경로\n",
        "base_dir = \"/content/drive/MyDrive/Data\"\n",
        "\n",
        "# 데이터 분할(폴더) 구분\n",
        "data_splits = [\"train\"]\n",
        "\n",
        "# 각 데이터 유형별 폴더명, 파일 접미사, 변수 접두어 설정\n",
        "data_categories = {\n",
        "    \"채널정보\": {\"folder\": \"6.채널정보\", \"suffix\": \"채널정보\", \"var_prefix\": \"channel\"}\n",
        "}\n",
        "\n",
        "# 2018년 7월부터 12월까지의 월 리스트\n",
        "months = ['07', '08', '09', '10', '11', '12']\n",
        "\n",
        "for split in data_splits:\n",
        "    for category, info in data_categories.items():\n",
        "        folder = info[\"folder\"]\n",
        "        suffix = info[\"suffix\"]\n",
        "        var_prefix = info[\"var_prefix\"]\n",
        "\n",
        "        for month in months:\n",
        "            # 파일명 형식: 2018{month}_{split}_{suffix}.parquet\n",
        "            file_path = f\"{base_dir}/{split}/{folder}/2018{month}_{split}_{suffix}.parquet\"\n",
        "            # 변수명 형식: {var_prefix}_{split}_{month}\n",
        "            variable_name = f\"{var_prefix}_{split}_{month}\"\n",
        "            globals()[variable_name] = pd.read_parquet(file_path)\n",
        "            print(f\"{variable_name} is loaded from {file_path}\")\n",
        "\n",
        "gc.collect()"
      ],
      "metadata": {
        "id": "APYcBJTuShgG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "69194fe8-3f84-4a13-bb68-80f172f6d7af"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "channel_train_07 is loaded from /content/drive/MyDrive/Data/train/6.채널정보/201807_train_채널정보.parquet\n",
            "channel_train_08 is loaded from /content/drive/MyDrive/Data/train/6.채널정보/201808_train_채널정보.parquet\n",
            "channel_train_09 is loaded from /content/drive/MyDrive/Data/train/6.채널정보/201809_train_채널정보.parquet\n",
            "channel_train_10 is loaded from /content/drive/MyDrive/Data/train/6.채널정보/201810_train_채널정보.parquet\n",
            "channel_train_11 is loaded from /content/drive/MyDrive/Data/train/6.채널정보/201811_train_채널정보.parquet\n",
            "channel_train_12 is loaded from /content/drive/MyDrive/Data/train/6.채널정보/201812_train_채널정보.parquet\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "outputId": "a1e08f8d-25f1-4a1a-e438-b069a371d874",
        "id": "s4aJkpi3IkCe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "channel_train_df is created with shape: (2400000, 105)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ],
      "source": [
        "# 데이터 유형별 설정\n",
        "info_categories = [\"channel\"]\n",
        "\n",
        "# 월 설정\n",
        "months = ['07', '08', '09', '10', '11', '12']\n",
        "\n",
        "# 각 유형별로 월별 데이터를 합쳐서 새로운 변수에 저장\n",
        "train_dfs = {}\n",
        "\n",
        "for prefix in info_categories:\n",
        "    # globals()에서 동적 변수명으로 데이터프레임들을 가져와 리스트에 저장\n",
        "    df_list = [globals()[f\"{prefix}_train_{month}\"] for month in months]\n",
        "    train_dfs[f\"{prefix}_train_df\"] = pd.concat(df_list, axis=0)\n",
        "    gc.collect()\n",
        "    print(f\"{prefix}_train_df is created with shape: {train_dfs[f'{prefix}_train_df'].shape}\")\n",
        "\n",
        "channel_train_df  = train_dfs[\"channel_train_df\"]\n",
        "\n",
        "gc.collect()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 인입횟수~당사PAY 방문월수: 모두 0 -> 삭제\n",
        "# 인입불만후경과월_IB_R6M: 모두 6 -> 삭제\n",
        "# OS구분코드: Android, OS로 구성되어 있으나 결측치가 많음 -> 삭제\n",
        "channel_train_df = channel_train_df.drop(['인입횟수_금융_IB_R6M', '인입불만횟수_IB_R6M', '인입불만일수_IB_R6M', '인입불만월수_IB_R6M',\n",
        "                                          '인입불만횟수_IB_B0M', '인입불만일수_IB_B0M', 'IB문의건수_한도_B0M', 'IB문의건수_결제_B0M',\n",
        "                                          'IB문의건수_할부_B0M', 'IB문의건수_정보변경_B0M', 'IB문의건수_결제일변경_B0M', 'IB문의건수_명세서_B0M',\n",
        "                                          'IB문의건수_비밀번호_B0M', 'IB문의건수_SMS_B0M', 'IB문의건수_APP_B0M', 'IB문의건수_부대서비스_B0M',\n",
        "                                          'IB문의건수_포인트_B0M', 'IB문의건수_BL_B0M', 'IB문의건수_분실도난_B0M', 'IB문의건수_CA_B0M',\n",
        "                                          'IB상담건수_VOC_B0M', 'IB상담건수_VOC민원_B0M', 'IB상담건수_VOC불만_B0M', 'IB상담건수_금감원_B0M',\n",
        "                                          'IB문의건수_명세서_R6M', 'IB문의건수_APP_R6M', 'IB상담건수_VOC_R6M', 'IB상담건수_VOC민원_R6M',\n",
        "                                          'IB상담건수_VOC불만_R6M', 'IB상담건수_금감원_R6M', '불만제기건수_B0M', '불만제기건수_R12M',\n",
        "                                          '당사PAY_방문횟수_B0M', '당사PAY_방문횟수_R6M', '당사PAY_방문월수_R6M','인입불만후경과월_IB_R6M',\n",
        "                                          'OS구분코드'], axis=1)\n",
        "# 문자열 인코딩\n",
        "channel_train_df['인입횟수_ARS_R6M'] = channel_train_df['인입횟수_ARS_R6M'].map({'1회 이상': 0, '10회 이상': 1})\n",
        "channel_train_df['이용메뉴건수_ARS_R6M'] = channel_train_df['이용메뉴건수_ARS_R6M'].map({'1회 이상': 0, '10회 이상': 1, '20회 이상': 2, '30회 이상': 3})\n",
        "channel_train_df['방문횟수_PC_R6M'] = channel_train_df['방문횟수_PC_R6M'].map({'1회 이상': 0, '10회 이상': 1, '20회 이상': 2, '30회 이상': 3, '40회 이상': 4})\n",
        "channel_train_df['방문일수_PC_R6M'] = channel_train_df['방문일수_PC_R6M'].map({'1회 이상': 0, '10회 이상': 1, '20회 이상': 2, '30회 이상': 3})\n",
        "channel_train_df['방문횟수_앱_R6M'] = channel_train_df['방문횟수_앱_R6M'].map({'1회 이상': 0, '10회 이상': 1, '20회 이상': 2, '30회 이상': 3, '40회 이상': 4,\n",
        "                                                                     '50회 이상': 5, '60회 이상': 6, '70회 이상': 7, '80회 이상': 8})"
      ],
      "metadata": {
        "id": "wPQwC4bqJGPZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# int64 -> int32로 변경 (메모리 줄이기 위함)\n",
        "for col in channel_train_df.select_dtypes(include='int64').columns:\n",
        "    if channel_train_df[col].max() < 2_147_483_647:\n",
        "        channel_train_df[col] = channel_train_df[col].astype('int32')\n",
        "\n",
        "# float64 -> float 32로 변경 (메모리 줄이기 위함)\n",
        "for col in channel_train_df.select_dtypes(include='float64').columns:\n",
        "    channel_train_df[col] = channel_train_df[col].astype('float32')\n",
        "\n",
        "channel_train_df.to_parquet(\"/content/drive/MyDrive/Dacon/channel_train_cleaned.parquet\")"
      ],
      "metadata": {
        "id": "hCAuMR4OenjO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 마케팅정보 (marketing)"
      ],
      "metadata": {
        "id": "ocJRgnz7DsoQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Google Drive에 있는 데이터 경로\n",
        "base_dir = \"/content/drive/MyDrive/Data\"\n",
        "\n",
        "# 데이터 분할(폴더) 구분\n",
        "data_splits = [\"train\"]\n",
        "\n",
        "# 각 데이터 유형별 폴더명, 파일 접미사, 변수 접두어 설정\n",
        "data_categories = {\n",
        "    \"마케팅정보\": {\"folder\": \"7.마케팅정보\", \"suffix\": \"마케팅정보\", \"var_prefix\": \"marketing\"}\n",
        "}\n",
        "\n",
        "# 2018년 7월부터 12월까지의 월 리스트\n",
        "months = ['07', '08', '09', '10', '11', '12']\n",
        "\n",
        "for split in data_splits:\n",
        "    for category, info in data_categories.items():\n",
        "        folder = info[\"folder\"]\n",
        "        suffix = info[\"suffix\"]\n",
        "        var_prefix = info[\"var_prefix\"]\n",
        "\n",
        "        for month in months:\n",
        "            # 파일명 형식: 2018{month}_{split}_{suffix}.parquet\n",
        "            file_path = f\"{base_dir}/{split}/{folder}/2018{month}_{split}_{suffix}.parquet\"\n",
        "            # 변수명 형식: {var_prefix}_{split}_{month}\n",
        "            variable_name = f\"{var_prefix}_{split}_{month}\"\n",
        "            globals()[variable_name] = pd.read_parquet(file_path)\n",
        "            print(f\"{variable_name} is loaded from {file_path}\")\n",
        "\n",
        "gc.collect()"
      ],
      "metadata": {
        "id": "h09etwAPTiIC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "06658332-0622-4a13-838d-ed8c8a2ed460"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "marketing_train_07 is loaded from /content/drive/MyDrive/Data/train/7.마케팅정보/201807_train_마케팅정보.parquet\n",
            "marketing_train_08 is loaded from /content/drive/MyDrive/Data/train/7.마케팅정보/201808_train_마케팅정보.parquet\n",
            "marketing_train_09 is loaded from /content/drive/MyDrive/Data/train/7.마케팅정보/201809_train_마케팅정보.parquet\n",
            "marketing_train_10 is loaded from /content/drive/MyDrive/Data/train/7.마케팅정보/201810_train_마케팅정보.parquet\n",
            "marketing_train_11 is loaded from /content/drive/MyDrive/Data/train/7.마케팅정보/201811_train_마케팅정보.parquet\n",
            "marketing_train_12 is loaded from /content/drive/MyDrive/Data/train/7.마케팅정보/201812_train_마케팅정보.parquet\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "outputId": "960c3b33-1d33-468a-8be7-fbd8171904d8",
        "id": "dHREnL3aIk0Y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "marketing_train_df is created with shape: (2400000, 64)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ],
      "source": [
        "# 데이터 유형별 설정\n",
        "info_categories = [\"marketing\"]\n",
        "\n",
        "# 월 설정\n",
        "months = ['07', '08', '09', '10', '11', '12']\n",
        "\n",
        "# 각 유형별로 월별 데이터를 합쳐서 새로운 변수에 저장\n",
        "train_dfs = {}\n",
        "\n",
        "for prefix in info_categories:\n",
        "    # globals()에서 동적 변수명으로 데이터프레임들을 가져와 리스트에 저장\n",
        "    df_list = [globals()[f\"{prefix}_train_{month}\"] for month in months]\n",
        "    train_dfs[f\"{prefix}_train_df\"] = pd.concat(df_list, axis=0)\n",
        "    gc.collect()\n",
        "    print(f\"{prefix}_train_df is created with shape: {train_dfs[f'{prefix}_train_df'].shape}\")\n",
        "\n",
        "marketing_train_df= train_dfs[\"marketing_train_df\"]\n",
        "\n",
        "gc.collect()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 문자열 인코딩\n",
        "marketing_train_df['캠페인접촉건수_R12M'] = marketing_train_df['캠페인접촉건수_R12M'].map({'1회 이상': 0, '5회 이상': 1,\n",
        "                                                                             '10회 이상': 2,'15회 이상': 3, '20회 이상': 4, '25회 이상': 5})\n",
        "marketing_train_df['캠페인접촉일수_R12M'] = marketing_train_df['캠페인접촉일수_R12M'].map({'1일 이상': 0, '5일 이상': 1, '10일 이상': 2,\n",
        "                                                                             '15일 이상': 3, '20일 이상': 4})\n",
        "# 모두 0이므로 삭제\n",
        "marketing_train_df = marketing_train_df.drop(['컨택건수_CA_TM_B0M', '컨택건수_포인트소진_TM_B0M', '컨택건수_CA_EM_B0M', '컨택건수_리볼빙_EM_B0M',\n",
        "                                              '컨택건수_리볼빙_청구서_B0M', '컨택건수_카드론_인터넷_B0M', '컨택건수_CA_인터넷_B0M', '컨택건수_리볼빙_인터넷_B0M',\n",
        "                                              '컨택건수_카드론_당사앱_B0M', '컨택건수_CA_당사앱_B0M', '컨택건수_리볼빙_당사앱_B0M', '컨택건수_CA_EM_R6M',\n",
        "                                              '컨택건수_리볼빙_EM_R6M', '컨택건수_리볼빙_청구서_R6M', '컨택건수_카드론_인터넷_R6M', '컨택건수_CA_인터넷_R6M',\n",
        "                                              '컨택건수_리볼빙_인터넷_R6M', '컨택건수_카드론_당사앱_R6M', '컨택건수_CA_당사앱_R6M', '컨택건수_리볼빙_당사앱_R6M',\n",
        "                                              '컨택건수_FDS_B0M', '컨택건수_FDS_R6M'], axis=1)"
      ],
      "metadata": {
        "id": "H66z3JYMJPu3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# int64 -> int32로 변경 (메모리 줄이기 위함)\n",
        "for col in marketing_train_df.select_dtypes(include='int64').columns:\n",
        "    if marketing_train_df[col].max() < 2_147_483_647:\n",
        "        marketing_train_df[col] = marketing_train_df[col].astype('int32')\n",
        "\n",
        "# float64 -> float 32로 변경 (메모리 줄이기 위함)\n",
        "for col in marketing_train_df.select_dtypes(include='float64').columns:\n",
        "    marketing_train_df[col] = marketing_train_df[col].astype('float32')\n",
        "\n",
        "marketing_train_df.to_parquet(\"/content/drive/MyDrive/Dacon/marketing_train_cleaned.parquet\")"
      ],
      "metadata": {
        "id": "ux8es8a4e-EC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 성과정보 (performance)"
      ],
      "metadata": {
        "id": "Bj70Da6rEumg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Google Drive에 있는 데이터 경로\n",
        "base_dir = \"/content/drive/MyDrive/Data\"\n",
        "\n",
        "# 데이터 분할(폴더) 구분\n",
        "data_splits = [\"train\"]\n",
        "\n",
        "# 각 데이터 유형별 폴더명, 파일 접미사, 변수 접두어 설정\n",
        "data_categories = {\n",
        "    \"성과정보\": {\"folder\": \"8.성과정보\", \"suffix\": \"성과정보\", \"var_prefix\": \"performance\"}\n",
        "}\n",
        "\n",
        "# 2018년 7월부터 12월까지의 월 리스트\n",
        "months = ['07', '08', '09', '10', '11', '12']\n",
        "\n",
        "for split in data_splits:\n",
        "    for category, info in data_categories.items():\n",
        "        folder = info[\"folder\"]\n",
        "        suffix = info[\"suffix\"]\n",
        "        var_prefix = info[\"var_prefix\"]\n",
        "\n",
        "        for month in months:\n",
        "            # 파일명 형식: 2018{month}_{split}_{suffix}.parquet\n",
        "            file_path = f\"{base_dir}/{split}/{folder}/2018{month}_{split}_{suffix}.parquet\"\n",
        "            # 변수명 형식: {var_prefix}_{split}_{month}\n",
        "            variable_name = f\"{var_prefix}_{split}_{month}\"\n",
        "            globals()[variable_name] = pd.read_parquet(file_path)\n",
        "            print(f\"{variable_name} is loaded from {file_path}\")\n",
        "\n",
        "gc.collect()"
      ],
      "metadata": {
        "id": "gTjCG6b7TykY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4fd4be86-8974-49cf-cfe3-72ee7ce17e77"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "performance_train_07 is loaded from /content/drive/MyDrive/Data/train/8.성과정보/201807_train_성과정보.parquet\n",
            "performance_train_08 is loaded from /content/drive/MyDrive/Data/train/8.성과정보/201808_train_성과정보.parquet\n",
            "performance_train_09 is loaded from /content/drive/MyDrive/Data/train/8.성과정보/201809_train_성과정보.parquet\n",
            "performance_train_10 is loaded from /content/drive/MyDrive/Data/train/8.성과정보/201810_train_성과정보.parquet\n",
            "performance_train_11 is loaded from /content/drive/MyDrive/Data/train/8.성과정보/201811_train_성과정보.parquet\n",
            "performance_train_12 is loaded from /content/drive/MyDrive/Data/train/8.성과정보/201812_train_성과정보.parquet\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "outputId": "6380d721-f1cf-43ec-c8bb-2a42cbe37f3c",
        "id": "RDlk-c3kIllj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "performance_train_df is created with shape: (2400000, 49)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ],
      "source": [
        "# 데이터 유형별 설정\n",
        "info_categories = [\"performance\"]\n",
        "\n",
        "# 월 설정\n",
        "months = ['07', '08', '09', '10', '11', '12']\n",
        "\n",
        "# 각 유형별로 월별 데이터를 합쳐서 새로운 변수에 저장\n",
        "train_dfs = {}\n",
        "\n",
        "for prefix in info_categories:\n",
        "    # globals()에서 동적 변수명으로 데이터프레임들을 가져와 리스트에 저장\n",
        "    df_list = [globals()[f\"{prefix}_train_{month}\"] for month in months]\n",
        "    train_dfs[f\"{prefix}_train_df\"] = pd.concat(df_list, axis=0)\n",
        "    gc.collect()\n",
        "    print(f\"{prefix}_train_df is created with shape: {train_dfs[f'{prefix}_train_df'].shape}\")\n",
        "\n",
        "\n",
        "performance_train_df = train_dfs[\"performance_train_df\"]\n",
        "\n",
        "gc.collect()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 결측치를 중앙값으로 대체\n",
        "performance_train_df[\"혜택수혜율_B0M\"] = performance_train_df[\"혜택수혜율_B0M\"].fillna(performance_train_df[\"혜택수혜율_B0M\"].median())\n",
        "performance_train_df[\"혜택수혜율_R3M\"] = performance_train_df[\"혜택수혜율_R3M\"].fillna(performance_train_df[\"혜택수혜율_R3M\"].median())"
      ],
      "metadata": {
        "id": "DV3u1bdJJWNJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# int64 -> int32로 변경 (메모리 줄이기 위함)\n",
        "for col in performance_train_df.select_dtypes(include='int64').columns:\n",
        "    if performance_train_df[col].max() < 2_147_483_647:\n",
        "        performance_train_df[col] = performance_train_df[col].astype('int32')\n",
        "\n",
        "# float64 -> float 32로 변경 (메모리 줄이기 위함)\n",
        "for col in performance_train_df.select_dtypes(include='float64').columns:\n",
        "    performance_train_df[col] = performance_train_df[col].astype('float32')\n",
        "\n",
        "performance_train_df.to_parquet(\"/content/drive/MyDrive/Dacon/performance_train_cleaned.parquet\")"
      ],
      "metadata": {
        "id": "xvnGF6qPft-_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data load & Preprocessing (2) - test data"
      ],
      "metadata": {
        "id": "lKkiV1RDHdi4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 회원정보 (customer)"
      ],
      "metadata": {
        "id": "z10FeYofoAYU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "customer_test_df 생성"
      ],
      "metadata": {
        "id": "18Zgt121o3ys"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Google Drive에 있는 데이터 경로\n",
        "base_dir = \"/content/drive/MyDrive/Data\"\n",
        "\n",
        "# 데이터 분할(폴더) 구분\n",
        "data_splits = [\"test\"] # test 만!\n",
        "\n",
        "# 각 데이터 유형별 폴더명, 파일 접미사, 변수 접두어 설정\n",
        "data_categories = {\n",
        "    \"회원정보\": {\"folder\": \"1.회원정보\", \"suffix\": \"회원정보\", \"var_prefix\": \"customer\"}\n",
        "}\n",
        "\n",
        "# 2018년 7월부터 12월까지의 월 리스트\n",
        "months = ['07', '08', '09', '10', '11', '12']\n",
        "\n",
        "for split in data_splits:\n",
        "    for category, info in data_categories.items():\n",
        "        folder = info[\"folder\"]\n",
        "        suffix = info[\"suffix\"]\n",
        "        var_prefix = info[\"var_prefix\"]\n",
        "\n",
        "        for month in months:\n",
        "            # 파일명 형식: 2018{month}_{split}_{suffix}.parquet\n",
        "            #file_path = f\"./{split}/{folder}/2018{month}_{split}_{suffix}.parquet\"\n",
        "            file_path = f\"{base_dir}/{split}/{folder}/2018{month}_{split}_{suffix}.parquet\"\n",
        "\n",
        "            # 변수명 형식: {var_prefix}_{split}_{month}\n",
        "            variable_name = f\"{var_prefix}_{split}_{month}\"\n",
        "\n",
        "            globals()[variable_name] = pd.read_parquet(file_path)\n",
        "            print(f\"{variable_name} is loaded from {file_path}\")\n",
        "\n",
        "gc.collect()"
      ],
      "metadata": {
        "id": "t9mtZr97HMu0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "82c7ffbb-a495-4407-dea3-f25057bc1e48"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "customer_test_07 is loaded from /content/drive/MyDrive/Data/test/1.회원정보/201807_test_회원정보.parquet\n",
            "customer_test_08 is loaded from /content/drive/MyDrive/Data/test/1.회원정보/201808_test_회원정보.parquet\n",
            "customer_test_09 is loaded from /content/drive/MyDrive/Data/test/1.회원정보/201809_test_회원정보.parquet\n",
            "customer_test_10 is loaded from /content/drive/MyDrive/Data/test/1.회원정보/201810_test_회원정보.parquet\n",
            "customer_test_11 is loaded from /content/drive/MyDrive/Data/test/1.회원정보/201811_test_회원정보.parquet\n",
            "customer_test_12 is loaded from /content/drive/MyDrive/Data/test/1.회원정보/201812_test_회원정보.parquet\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터 유형별 설정\n",
        "info_categories = [\"customer\"]\n",
        "\n",
        "# 월 설정\n",
        "months = ['07', '08', '09', '10', '11', '12']\n",
        "\n",
        "# 각 유형별로 월별 데이터를 합쳐서 새로운 변수에 저장\n",
        "test_dfs = {}\n",
        "\n",
        "for prefix in info_categories:\n",
        "    # globals()에서 동적 변수명으로 데이터프레임들을 가져와 리스트에 저장\n",
        "    df_list = [globals()[f\"{prefix}_test_{month}\"] for month in months]\n",
        "    test_dfs[f\"{prefix}_test_df\"] = pd.concat(df_list, axis=0)\n",
        "    gc.collect()\n",
        "    print(f\"{prefix}_test_df is created with shape: {test_dfs[f'{prefix}_test_df'].shape}\")\n",
        "    # (600000, 77)\n",
        "\n",
        "customer_test_df = test_dfs[\"customer_test_df\"]\n",
        "\n",
        "gc.collect()"
      ],
      "metadata": {
        "id": "5BBpuiJ9o6Vq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c5729b43-b02b-48ba-9f3c-763328789b80"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "customer_test_df is created with shape: (600000, 77)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "전처리"
      ],
      "metadata": {
        "id": "yyAlddREpQaG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "##### 1. 결측치 처리\n",
        "# '_1순위신용체크구분', '_2순위신용체크구분’\n",
        "#    → 결측치 '기타'로 채우기\n",
        "#    → '_1순위신용체크구분_인코딩', '_2순위신용체크구분_인코딩’\n",
        "customer_test_df['_1순위신용체크구분'] = customer_test_df['_1순위신용체크구분'].fillna('기타')\n",
        "customer_test_df['_2순위신용체크구분'] = customer_test_df['_2순위신용체크구분'].fillna('기타')\n",
        "mapping = {'신용': 1, '체크': 0, '기타': -1}\n",
        "customer_test_df['1순위신용체크구분_인코딩'] = customer_test_df['_1순위신용체크구분'].map(mapping)\n",
        "customer_test_df['2순위신용체크구분_인코딩'] = customer_test_df['_2순위신용체크구분'].map(mapping)\n",
        "customer_test_df.drop(columns=['_1순위신용체크구분','_2순위신용체크구분'], inplace=True)\n",
        "\n",
        "# 가입통신회사코드 → 가입통신회사_S사여부\n",
        "customer_test_df['가입통신회사_S사여부'] = (customer_test_df['가입통신회사코드'] == 'S사').astype(int)\n",
        "customer_test_df = customer_test_df.drop(columns=['가입통신회사코드'])\n",
        "\n",
        "# 직장시도명 → 직장_수도권여부\n",
        "customer_test_df['직장_수도권여부'] = customer_test_df['직장시도명'].isin(['서울', '경기']).astype(int)\n",
        "customer_test_df = customer_test_df.drop(columns=['직장시도명'])\n",
        "\n",
        "# 결측치 많은 변수 삭제\n",
        "customer_test_df = customer_test_df.drop(columns=['최종카드발급일자', '최종유효년월_신용_이용가능', '최종유효년월_신용_이용'])\n",
        "\n",
        "\n",
        "##### 2. 자료형 변환\n",
        "# 거주시도명 → 거주지_수도권여부\n",
        "customer_test_df['거주지_수도권여부'] = customer_test_df['거주시도명'].isin(['서울', '경기']).astype(int)\n",
        "customer_test_df = customer_test_df.drop(columns=['거주시도명'])\n",
        "\n",
        "# 연회비발생카드수_B0M → 연회비발생카드수_B0M_이진\n",
        "customer_test_df['연회비발생카드수_B0M_이진'] = customer_test_df['연회비발생카드수_B0M'].isin(['1개이상']).astype(int)\n",
        "customer_test_df = customer_test_df.drop(columns=['연회비발생카드수_B0M'])\n",
        "\n",
        "# 데이터 다 동일한 변수 4개 삭제!\n",
        "columns_drop = ['상품관련면제카드수_B0M','임직원면제카드수_B0M', '우수회원면제카드수_B0M', '기타면제카드수_B0M']\n",
        "customer_test_df = customer_test_df.drop(columns=columns_drop)\n",
        "\n",
        "# Life_Stage: 파생변수(Life_Stage_자녀성장_여부) 생성 후 변수 삭제\n",
        "customer_test_df['Life_Stage_자녀성장_여부'] = customer_test_df['Life_Stage'].isin(['자녀성장(1)', '자녀성장(2)']).astype(int)\n",
        "customer_test_df = customer_test_df.drop(columns=['Life_Stage'])\n",
        "\n",
        "# 연령에서 숫자만 추출 후 int형으로 변환\n",
        "customer_test_df['연령'] = customer_test_df['연령'].str.extract(r'(\\d+)').astype(float).astype('Int64')\n",
        "\n",
        "\n",
        "##### 3. 상관관계 분석\n",
        "# 데이터 다 동일한 변수 4개 삭제\n",
        "columns_drop = ['이용금액_R3M_체크_가족','연회비할인카드수_B0M','할인금액_기본연회비_B0M','할인금액_제휴연회비_B0M']\n",
        "customer_test_df = customer_test_df.drop(columns=columns_drop)\n",
        "\n",
        "\n",
        "##### 4. 변수 별로 확인\n",
        "# 총 4개의 변수 삭제\n",
        "# '입회일자_신용' 삭제 (입회경과개월수_신용 있음)\n",
        "# 데이터 다 동일한 변수 '이용카드수_체크_가족' 삭제!\n",
        "# '청구금액_기본연회비_B0M','청구금액_제휴연회비_B0M’삭제 (의미 같은 변수 있음)\n",
        "columns_drop = ['입회일자_신용','이용카드수_체크_가족','청구금액_기본연회비_B0M','청구금액_제휴연회비_B0M']\n",
        "customer_test_df = customer_test_df.drop(columns=columns_drop)"
      ],
      "metadata": {
        "id": "vLjcReSho6b3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "customer_test_df.to_parquet(\"/content/drive/MyDrive/Dacon/customer_test_cleaned.parquet\")"
      ],
      "metadata": {
        "id": "5Ea66N6Co6eo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 신용정보 (credit)"
      ],
      "metadata": {
        "id": "a9ZwexQ7oDqY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "credit_test_df 생성"
      ],
      "metadata": {
        "id": "5_2I8oSVpURF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Google Drive에 있는 데이터 경로\n",
        "base_dir = \"/content/drive/MyDrive/Data\"\n",
        "\n",
        "# 데이터 분할(폴더) 구분\n",
        "data_splits = [\"test\"] # test 만!\n",
        "\n",
        "# 각 데이터 유형별 폴더명, 파일 접미사, 변수 접두어 설정\n",
        "data_categories = {\n",
        "    \"신용정보\": {\"folder\": \"2.신용정보\", \"suffix\": \"신용정보\", \"var_prefix\": \"credit\"}\n",
        "}\n",
        "\n",
        "# 2018년 7월부터 12월까지의 월 리스트\n",
        "months = ['07', '08', '09', '10', '11', '12']\n",
        "\n",
        "for split in data_splits:\n",
        "    for category, info in data_categories.items():\n",
        "        folder = info[\"folder\"]\n",
        "        suffix = info[\"suffix\"]\n",
        "        var_prefix = info[\"var_prefix\"]\n",
        "\n",
        "        for month in months:\n",
        "            # 파일명 형식: 2018{month}_{split}_{suffix}.parquet\n",
        "            #file_path = f\"./{split}/{folder}/2018{month}_{split}_{suffix}.parquet\"\n",
        "            file_path = f\"{base_dir}/{split}/{folder}/2018{month}_{split}_{suffix}.parquet\"\n",
        "\n",
        "            # 변수명 형식: {var_prefix}_{split}_{month}\n",
        "            variable_name = f\"{var_prefix}_{split}_{month}\"\n",
        "\n",
        "            globals()[variable_name] = pd.read_parquet(file_path)\n",
        "            print(f\"{variable_name} is loaded from {file_path}\")\n",
        "\n",
        "gc.collect()"
      ],
      "metadata": {
        "id": "He8FQ06EHQaq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "79cb3fa1-6721-4db5-947a-3c7adb65dd35"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "credit_test_07 is loaded from /content/drive/MyDrive/Data/test/2.신용정보/201807_test_신용정보.parquet\n",
            "credit_test_08 is loaded from /content/drive/MyDrive/Data/test/2.신용정보/201808_test_신용정보.parquet\n",
            "credit_test_09 is loaded from /content/drive/MyDrive/Data/test/2.신용정보/201809_test_신용정보.parquet\n",
            "credit_test_10 is loaded from /content/drive/MyDrive/Data/test/2.신용정보/201810_test_신용정보.parquet\n",
            "credit_test_11 is loaded from /content/drive/MyDrive/Data/test/2.신용정보/201811_test_신용정보.parquet\n",
            "credit_test_12 is loaded from /content/drive/MyDrive/Data/test/2.신용정보/201812_test_신용정보.parquet\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "18"
            ]
          },
          "metadata": {},
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터 유형별 설정\n",
        "info_categories = [\"credit\"]\n",
        "\n",
        "# 월 설정\n",
        "months = ['07', '08', '09', '10', '11', '12']\n",
        "\n",
        "# 각 유형별로 월별 데이터를 합쳐서 새로운 변수에 저장\n",
        "test_dfs = {}\n",
        "\n",
        "for prefix in info_categories:\n",
        "    # globals()에서 동적 변수명으로 데이터프레임들을 가져와 리스트에 저장\n",
        "    df_list = [globals()[f\"{prefix}_test_{month}\"] for month in months]\n",
        "    test_dfs[f\"{prefix}_test_df\"] = pd.concat(df_list, axis=0)\n",
        "    gc.collect()\n",
        "    print(f\"{prefix}_test_df is created with shape: {test_dfs[f'{prefix}_test_df'].shape}\")\n",
        "    # (600000, 42)\n",
        "\n",
        "credit_with_seg = test_dfs[\"credit_test_df\"]\n",
        "\n",
        "gc.collect()"
      ],
      "metadata": {
        "id": "qHjvxr5LpW21",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f512932d-7e1f-481f-d507-58323a7aeec9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "credit_test_df is created with shape: (600000, 42)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "전처리"
      ],
      "metadata": {
        "id": "npNt415kqsXP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "##### 1. 결측치 처리\n",
        "# 'RV신청일자' 변수 삭제\n",
        "credit_with_seg = credit_with_seg.drop(columns=['RV신청일자'])\n",
        "\n",
        "# 'RV전환가능여부' → 'RV전환불가능여부'\n",
        "credit_with_seg['RV_전환가능여부_이진'] = (credit_with_seg['RV전환가능여부'] == 'N').astype(int)\n",
        "credit_with_seg = credit_with_seg.drop(columns='RV전환가능여부')\n",
        "\n",
        "\n",
        "\n",
        "##### 2. 자료형 변환\n",
        "# 자발한도감액횟수_R12M\n",
        "# '0회' → 0, '1회' → 1, '2회' → 2\n",
        "credit_with_seg['자발한도감액횟수_R12M'] = (\n",
        "    credit_with_seg['자발한도감액횟수_R12M']\n",
        "    .str.replace('회', '', regex=False)  # '회' 제거\n",
        "    .astype(int)  # 바로 int로 변환!\n",
        ")\n",
        "\n",
        "#‘한도증액횟수_R12M’ → '한도증액_R12M_여부'\n",
        "# '0회' → 0, '1회이상' → 1\n",
        "credit_with_seg['한도증액_R12M_여부'] = credit_with_seg['한도증액횟수_R12M'].map({\n",
        "    '0회': 0,\n",
        "    '1회이상': 1\n",
        "    }).astype(int)\n",
        "credit_with_seg.drop(columns=['한도증액횟수_R12M'], inplace=True)\n",
        "\n",
        "#‘카드론동의여부’\n",
        "# 'Y' → 1, 'N' → 0\n",
        "credit_with_seg['카드론동의여부'] = credit_with_seg['카드론동의여부'].map({\n",
        "    'Y': 1,\n",
        "    'N': 0\n",
        "    }).astype(int)\n",
        "\n",
        "#‘한도심사요청건수’ → ‘한도심사요청여부’\n",
        "# '0회' → 0, '1회이상' → 1\n",
        "credit_with_seg['한도심사요청여부'] = credit_with_seg['한도심사요청건수'].map({\n",
        "    '0회': 0,\n",
        "    '1회이상': 1\n",
        "    }).astype(int)\n",
        "credit_with_seg.drop(columns=['한도심사요청건수'], inplace=True)\n",
        "\n",
        "\n",
        "\n",
        "##### 3. 상관관계 분석\n",
        "# 데이터 모두 동일한 변수 1개 삭제\n",
        "credit_with_seg = credit_with_seg.drop(columns=['시장연체상환여부_R3M'])\n",
        "\n",
        "\n",
        "\n",
        "##### 4. 변수 별로 데이터 살펴보기\n",
        "# 'RV실사용여부' 변수 추가\n",
        "credit_with_seg['RV실사용여부'] = (credit_with_seg['RV약정청구율'] > 0).astype(int)\n",
        "\n",
        "# '강제한도감액횟수_2회이상여부' 변수 추가\n",
        "credit_with_seg['강제한도감액횟수_2회이상여부'] = (credit_with_seg['강제한도감액횟수_R12M'] > 1).astype(int)\n",
        "\n",
        "# '강제한도감액금액_R12M_3이상여부' 변수 추가\n",
        "credit_with_seg['강제한도감액금액_R12M_3이상여부'] = (credit_with_seg['강제한도감액금액_R12M'] > 2).astype(int)\n",
        "\n",
        "# '상향가능CA한도금액_1여부' 변수 추가\n",
        "credit_with_seg['상향가능CA한도금액_1여부'] = (credit_with_seg['상향가능CA한도금액'] == 1).astype(int)\n",
        "\n",
        "# '카드이용한도금액_A수준복합' 변수 추가\n",
        "def classify_dual_limit(row):\n",
        "    b1 = row['카드이용한도금액_B1M'] >= 170344\n",
        "    b2 = row['카드이용한도금액_B2M'] >= 170344\n",
        "    if b1 and b2:\n",
        "        return 2     # 둘 다 170,344 이상\n",
        "    elif b1 or b2:\n",
        "        return 1     # 하나만 170,344 이상\n",
        "    else:\n",
        "        return 0    # 둘 다 170,344 미만\n",
        "\n",
        "credit_with_seg['카드이용한도금액_A수준복합'] = credit_with_seg.apply(classify_dual_limit, axis=1)"
      ],
      "metadata": {
        "id": "L-4tDMCIqtLw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "credit_with_seg.to_parquet(\"/content/drive/MyDrive/Dacon/credit_test_cleaned.parquet\")"
      ],
      "metadata": {
        "id": "jcT66hLKpW6r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 승인매출정보 (sales)"
      ],
      "metadata": {
        "id": "4DODECiKoGXB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "sales_test_df 생성"
      ],
      "metadata": {
        "id": "uHSloz7OpmBL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Google Drive에 있는 데이터 경로\n",
        "base_dir = \"/content/drive/MyDrive/Data\"\n",
        "\n",
        "# 데이터 분할(폴더) 구분\n",
        "data_splits = [\"test\"] # test 만!\n",
        "\n",
        "# 각 데이터 유형별 폴더명, 파일 접미사, 변수 접두어 설정\n",
        "data_categories = {\n",
        "    \"승인매출정보\": {\"folder\": \"3.승인매출정보\", \"suffix\": \"승인매출정보\", \"var_prefix\": \"sales\"}\n",
        "}\n",
        "\n",
        "# 2018년 7월부터 12월까지의 월 리스트\n",
        "months = ['07', '08', '09', '10', '11', '12']\n",
        "\n",
        "for split in data_splits:\n",
        "    for category, info in data_categories.items():\n",
        "        folder = info[\"folder\"]\n",
        "        suffix = info[\"suffix\"]\n",
        "        var_prefix = info[\"var_prefix\"]\n",
        "\n",
        "        for month in months:\n",
        "            # 파일명 형식: 2018{month}_{split}_{suffix}.parquet\n",
        "            #file_path = f\"./{split}/{folder}/2018{month}_{split}_{suffix}.parquet\"\n",
        "            file_path = f\"{base_dir}/{split}/{folder}/2018{month}_{split}_{suffix}.parquet\"\n",
        "\n",
        "            # 변수명 형식: {var_prefix}_{split}_{month}\n",
        "            variable_name = f\"{var_prefix}_{split}_{month}\"\n",
        "\n",
        "            globals()[variable_name] = pd.read_parquet(file_path)\n",
        "            print(f\"{variable_name} is loaded from {file_path}\")\n",
        "\n",
        "gc.collect()"
      ],
      "metadata": {
        "id": "dEyE_gWopnut",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ae87818e-cf24-4bf2-c95b-88634452f1a8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sales_test_07 is loaded from /content/drive/MyDrive/Data/test/3.승인매출정보/201807_test_승인매출정보.parquet\n",
            "sales_test_08 is loaded from /content/drive/MyDrive/Data/test/3.승인매출정보/201808_test_승인매출정보.parquet\n",
            "sales_test_09 is loaded from /content/drive/MyDrive/Data/test/3.승인매출정보/201809_test_승인매출정보.parquet\n",
            "sales_test_10 is loaded from /content/drive/MyDrive/Data/test/3.승인매출정보/201810_test_승인매출정보.parquet\n",
            "sales_test_11 is loaded from /content/drive/MyDrive/Data/test/3.승인매출정보/201811_test_승인매출정보.parquet\n",
            "sales_test_12 is loaded from /content/drive/MyDrive/Data/test/3.승인매출정보/201812_test_승인매출정보.parquet\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터 유형별 설정\n",
        "info_categories = [\"sales\"]\n",
        "\n",
        "# 월 설정\n",
        "months = ['07', '08', '09', '10', '11', '12']\n",
        "\n",
        "# 각 유형별로 월별 데이터를 합쳐서 새로운 변수에 저장\n",
        "test_dfs = {}\n",
        "\n",
        "for prefix in info_categories:\n",
        "    # globals()에서 동적 변수명으로 데이터프레임들을 가져와 리스트에 저장\n",
        "    df_list = [globals()[f\"{prefix}_test_{month}\"] for month in months]\n",
        "    test_dfs[f\"{prefix}_test_df\"] = pd.concat(df_list, axis=0)\n",
        "    gc.collect()\n",
        "    print(f\"{prefix}_test_df is created with shape: {test_dfs[f'{prefix}_test_df'].shape}\")\n",
        "    # (600000, 406)\n",
        "\n",
        "sales_with_seg = test_dfs[\"sales_test_df\"]\n",
        "\n",
        "gc.collect()"
      ],
      "metadata": {
        "id": "sjUKsliApnyL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "55c03f4d-17b1-4ebc-9c7e-62c2d1926317"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sales_test_df is created with shape: (600000, 406)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "전처리"
      ],
      "metadata": {
        "id": "YjInxO_ouO0K"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 결측치 처리"
      ],
      "metadata": {
        "id": "IJUMMGV-dpwg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- '_n순위@@업종' 변수 - AB"
      ],
      "metadata": {
        "id": "00pI0YHddtIg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# '_n순위@@업종' 변수(총 15개 변수) 결측치는 '없음'으로 채우기\n",
        "upjong_cols = [\n",
        "    '_1순위업종','_2순위업종','_3순위업종',\n",
        "    '_1순위쇼핑업종','_2순위쇼핑업종','_3순위쇼핑업종',\n",
        "    '_1순위교통업종','_2순위교통업종','_3순위교통업종',\n",
        "    '_1순위여유업종','_2순위여유업종','_3순위여유업종',\n",
        "    '_1순위납부업종','_2순위납부업종','_3순위납부업종'\n",
        "]\n",
        "\n",
        "sales_with_seg[upjong_cols] = sales_with_seg[upjong_cols].fillna('없음')"
      ],
      "metadata": {
        "id": "fsUjIOSAcyd4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# '_n순위업종_AB' 변수 추가 (상관계수 -0.3030)\n",
        "\n",
        "'''\n",
        "- 1순위 업종이 쇼핑\t+1\n",
        "- 2순위 업종이 사교활동\t+1\n",
        "- 2순위 업종이 교육\t+0.5\n",
        "- 2순위 업종이 의료\t+1.5 (A, B에서 더 강하게 나타나므로)\n",
        "- 3순위 업종이 사교활동\t+1\n",
        "- 3순위 업종이 의료\t+1.5 (A, B에서 더 강하게 나타나므로)\n",
        "\n",
        "- 2순위 업종이 없음 -1\n",
        "- 3순위 업종이 없음 -1\n",
        "- 2순위 업종이 교통 -0.5\n",
        "- 2순위 업종이 납부 -0.5\n",
        "'''\n",
        "\n",
        "def compute_ab_score(row):\n",
        "    score = 0\n",
        "    # 가점 조건\n",
        "    if row['_1순위업종'] == '쇼핑':\n",
        "        score += 1\n",
        "    if row['_2순위업종'] == '사교활동':\n",
        "        score += 1\n",
        "    if row['_2순위업종'] == '교육':\n",
        "        score += 0.5\n",
        "    if row['_2순위업종'] == '의료':\n",
        "        score += 1\n",
        "    if row['_3순위업종'] == '사교활동':\n",
        "        score += 1\n",
        "    if row['_3순위업종'] == '의료':\n",
        "        score += 1\n",
        "\n",
        "    # 감점 조건\n",
        "    if row['_2순위업종'] == '없음':\n",
        "        score -= 1\n",
        "    if row['_3순위업종'] == '없음':\n",
        "        score -= 1\n",
        "    if row['_2순위업종'] == '교통':\n",
        "        score -= 0.5\n",
        "    if row['_2순위업종'] == '납부':\n",
        "        score -= 0.5\n",
        "\n",
        "    return score\n",
        "\n",
        "sales_with_seg['_n순위업종_AB'] = sales_with_seg.apply(compute_ab_score, axis=1)"
      ],
      "metadata": {
        "id": "67ieVjwhPOGY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# '_n순위쇼핑업종_AB' 변수 추가 (상관계수 -0.3304)\n",
        "\n",
        "'''\n",
        "- 1순위 쇼핑업종이 온라인 +1\n",
        "- 2순위 쇼핑업종이 도소매 +1\n",
        "- 3순위 쇼핑업종이 마트 +1\n",
        "\n",
        "- 1순위 쇼핑업종이 없음 -1\n",
        "- 2순위 쇼핑업종이 슈퍼마켓 -0.5\n",
        "- 2순위 쇼핑업종이 없음 -0.5\n",
        "- 3순위 쇼핑업종이 없음 -1\n",
        "'''\n",
        "\n",
        "def compute_ab_score(row):\n",
        "    score = 0\n",
        "    # 가점 조건\n",
        "    if row['_1순위쇼핑업종'] == '온라인':\n",
        "        score += 1\n",
        "    if row['_2순위쇼핑업종'] == '도소매':\n",
        "        score += 1\n",
        "    if row['_3순위쇼핑업종'] == '마트':\n",
        "        score += 1\n",
        "\n",
        "    # 감점 조건\n",
        "    if row['_1순위쇼핑업종'] == '없음':\n",
        "        score -= 1\n",
        "    if row['_2순위쇼핑업종'] == '슈퍼마켓':\n",
        "        score -= 0.5\n",
        "    if row['_2순위쇼핑업종'] == '없음':\n",
        "        score -= 0.5\n",
        "    if row['_3순위쇼핑업종'] == '없음':\n",
        "        score -= 1\n",
        "\n",
        "    return score\n",
        "\n",
        "sales_with_seg['_n순위쇼핑업종_AB'] = sales_with_seg.apply(compute_ab_score, axis=1)"
      ],
      "metadata": {
        "id": "aZB1dwzfPOJL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# '_n순위교통업종_AB' 변수 추가 (상관계수 -0.34514)\n",
        "\n",
        "'''\n",
        "- 1순위 교통업종이 주유 +1\n",
        "- 2순위 교통업종이 정비 +1\n",
        "- 3순위 교통업종이 택시 +0.5\n",
        "- 3순위 교통업종이 정비 +0.5\n",
        "- 3순위 교통업종이 철도버스 +0.5\n",
        "\n",
        "- 1순위 교통업종이 없음 -1\n",
        "- 2순위 교통업종이 없음 -1\n",
        "'''\n",
        "\n",
        "def compute_ab_score(row):\n",
        "    score = 0\n",
        "    # 가점 조건\n",
        "    if row['_1순위교통업종'] == '주유':\n",
        "        score += 1\n",
        "    if row['_2순위교통업종'] == '정비':\n",
        "        score += 1\n",
        "    if row['_3순위교통업종'] == '택시':\n",
        "        score += 0.5\n",
        "    if row['_3순위교통업종'] == '정비':\n",
        "        score += 0.5\n",
        "    if row['_3순위교통업종'] == '철도버스':\n",
        "        score += 0.5\n",
        "\n",
        "    # 감점 조건\n",
        "    if row['_1순위교통업종'] == '없음':\n",
        "        score -= 1\n",
        "    if row['_2순위교통업종'] == '없음':\n",
        "        score -= 1\n",
        "\n",
        "    return score\n",
        "\n",
        "sales_with_seg['_n순위교통업종_AB'] = sales_with_seg.apply(compute_ab_score, axis=1)"
      ],
      "metadata": {
        "id": "Vicnk2yrT--s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# '_n순위여유업종_AB' 변수 추가 (상관계수 -0.26628)\n",
        "\n",
        "'''\n",
        "- 1순위 여유업종이 운동 +1\n",
        "- 1순위 여유업종이 항공 +1\n",
        "- 2순위 여유업종이 숙박 +1\n",
        "- 2순위 여유업종이 공연 +1\n",
        "- 3순위 여유업종이 숙박 +1\n",
        "- 3순위 여유업종이 공연 +1\n",
        "- 3순위 여유업종이 여유기타 +1\n",
        "\n",
        "- 1순위 여유업종이 없음 -0.5\n",
        "- 2순위 여유업종이 없음 -0.5\n",
        "- 3순위 여유업종이 없음 -0.5\n",
        "'''\n",
        "\n",
        "def compute_ab_score(row):\n",
        "    score = 0\n",
        "    # 가점 조건\n",
        "    if row['_1순위여유업종'] == '운동':\n",
        "        score += 1\n",
        "    if row['_1순위여유업종'] == '항공':\n",
        "        score += 1\n",
        "    if row['_2순위여유업종'] == '숙박':\n",
        "        score += 1\n",
        "    if row['_2순위여유업종'] == '공연':\n",
        "        score += 1\n",
        "    if row['_3순위여유업종'] == '숙박':\n",
        "        score += 1\n",
        "    if row['_3순위여유업종'] == '공연':\n",
        "        score += 1\n",
        "    if row['_3순위여유업종'] == '여유기타':\n",
        "        score += 1\n",
        "\n",
        "    # 감점 조건\n",
        "    if row['_1순위여유업종'] == '없음':\n",
        "        score -= 0.5\n",
        "    if row['_2순위여유업종'] == '없음':\n",
        "        score -= 0.5\n",
        "    if row['_3순위여유업종'] == '없음':\n",
        "        score -= 0.5\n",
        "\n",
        "    return score\n",
        "\n",
        "sales_with_seg['_n순위여유업종_AB'] = sales_with_seg.apply(compute_ab_score, axis=1)"
      ],
      "metadata": {
        "id": "ow77FBSYT_Az"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# '_n순위납부업종_AB' 변수 추가 (상관계수 -0.2579)\n",
        "\n",
        "'''\n",
        "- 1순위 납부업종이 납부기타 +0.5\n",
        "- 1순위 납부업종이 보험료 +0.5\n",
        "- 1순위 납부업종이 통신비 +0.5\n",
        "- 2순위 납부업종이 납부기타 +0.5\n",
        "- 2순위 납부업종이 보험료 +0.5\n",
        "- 2순위 납부업종이 통신비 +0.5\n",
        "- 3순위 납부업종이 납부기타 +0.5\n",
        "\n",
        "- 1순위 납부업종이 없음 -0.5\n",
        "- 2순위 납부업종이 없음 -0.5\n",
        "- 3순위 납부업종이 없음 -0.5\n",
        "'''\n",
        "\n",
        "def compute_ab_score(row):\n",
        "    score = 0\n",
        "    # 가점 조건\n",
        "    if row['_1순위납부업종'] == '납부기타':\n",
        "        score += 0.5\n",
        "    if row['_1순위납부업종'] == '보험료':\n",
        "        score += 0.5\n",
        "    if row['_1순위납부업종'] == '통신비':\n",
        "        score += 0.5\n",
        "    if row['_2순위납부업종'] == '납부기타':\n",
        "        score += 0.5\n",
        "    if row['_2순위납부업종'] == '보험료':\n",
        "        score += 0.5\n",
        "    if row['_2순위납부업종'] == '통신비':\n",
        "        score += 0.5\n",
        "    if row['_3순위납부업종'] == '납부기타':\n",
        "        score += 0.5\n",
        "\n",
        "    # 감점 조건\n",
        "    if row['_1순위납부업종'] == '없음':\n",
        "        score -= 0.5\n",
        "    if row['_2순위납부업종'] == '없음':\n",
        "        score -= 0.5\n",
        "    if row['_3순위납부업종'] == '없음':\n",
        "        score -= 0.5\n",
        "\n",
        "    return score\n",
        "\n",
        "sales_with_seg['_n순위납부업종_AB'] = sales_with_seg.apply(compute_ab_score, axis=1)"
      ],
      "metadata": {
        "id": "TgFVbUKfT_Cs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# '_n순위@@업종_AB' 5개 변수 합친 변수 '_n순위업종_AB_총합' 추가 (상관계수 -0.3927)\n",
        "sales_with_seg['_n순위업종_AB_총합'] = (\n",
        "    sales_with_seg['_n순위업종_AB'] +\n",
        "    sales_with_seg['_n순위쇼핑업종_AB'] +\n",
        "    sales_with_seg['_n순위교통업종_AB'] +\n",
        "    sales_with_seg['_n순위여유업종_AB'] +\n",
        "    sales_with_seg['_n순위납부업종_AB']\n",
        ")"
      ],
      "metadata": {
        "id": "7-HF_vsNT_EU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# '_n순위@@업종' 변수 삭제\n",
        "cols_to_drop = [\n",
        "    '_1순위업종','_2순위업종','_3순위업종',\n",
        "    '_1순위쇼핑업종','_2순위쇼핑업종','_3순위쇼핑업종',\n",
        "    '_1순위교통업종','_2순위교통업종','_3순위교통업종',\n",
        "    '_1순위여유업종','_2순위여유업종','_3순위여유업종',\n",
        "    '_1순위납부업종','_2순위납부업종','_3순위납부업종'\n",
        "]\n",
        "\n",
        "sales_with_seg.drop(columns=cols_to_drop, inplace=True)"
      ],
      "metadata": {
        "id": "5-2jb1G2c-Lv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 결측치 80% 이상인 최종카드론 관련 변수들"
      ],
      "metadata": {
        "id": "fo18981BiVkw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 변수 삭제\n",
        "cols_to_drop = ['최종카드론_대출일자','최종카드론_신청경로코드','최종카드론_금융상환방식코드']\n",
        "sales_with_seg = sales_with_seg.drop(columns=cols_to_drop)"
      ],
      "metadata": {
        "id": "0tB54dM9c-OI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 자료형 변환"
      ],
      "metadata": {
        "id": "RLWsEdJa4N6U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# '이용금액대_점수' 변수 생성 (상관계수 -0.6026)\n",
        "amount_mapping = {\n",
        "    '01.100만원+': 18,\n",
        "    '02.50만원+': 5,\n",
        "    '03.30만원+': 2,\n",
        "    '04.10만원+': 2,\n",
        "    '05.10만원-': 1,\n",
        "    '09.미사용': 1\n",
        "}\n",
        "\n",
        "sales_with_seg['이용금액대_점수'] = sales_with_seg['이용금액대'].map(amount_mapping)"
      ],
      "metadata": {
        "id": "gZ9cU-lEc-Qo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 원래 변수 '이용금액대' 삭제\n",
        "sales_with_seg = sales_with_seg.drop(columns=['이용금액대'])"
      ],
      "metadata": {
        "id": "eCPaFuYu5TVM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 상관관계 분석"
      ],
      "metadata": {
        "id": "ukQqa7FE-HSD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터 값이 모두 같은 변수 2개 제거\n",
        "sales_with_seg = sales_with_seg.drop(columns=['승인거절건수_입력오류_B0M','승인거절건수_기타_B0M'])"
      ],
      "metadata": {
        "id": "bxQZx53U-GvK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 변수 별로 데이터 살펴보기"
      ],
      "metadata": {
        "id": "YiJ-H-qDuVfD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# '이용여부_@@' 변수 생성\n",
        "sales_with_seg['이용여부_기본']   = (sales_with_seg['최종이용일자_기본'] != 10101).astype(int)\n",
        "sales_with_seg['이용여부_신판']   = (sales_with_seg['최종이용일자_신판'] != 10101).astype(int)\n",
        "sales_with_seg['이용여부_CA']    = (sales_with_seg['최종이용일자_CA'] != 10101).astype(int)\n",
        "sales_with_seg['이용여부_카드론'] = (sales_with_seg['최종이용일자_카드론'] != 10101).astype(int)\n",
        "sales_with_seg['이용여부_체크']   = (sales_with_seg['최종이용일자_체크'] != 10101).astype(int)\n",
        "sales_with_seg['이용여부_일시불'] = (sales_with_seg['최종이용일자_일시불'] != 10101).astype(int)\n",
        "sales_with_seg['이용여부_할부']   = (sales_with_seg['최종이용일자_할부'] != 10101).astype(int)\n",
        "\n",
        "# 원래 '최종이용일자_@@' 변수 삭제\n",
        "for i in ['최종이용일자_기본','최종이용일자_신판','최종이용일자_CA','최종이용일자_카드론','최종이용일자_체크','최종이용일자_일시불','최종이용일자_할부']:\n",
        "  sales_with_seg = sales_with_seg.drop(columns=[i])"
      ],
      "metadata": {
        "id": "FfG2QaduuVfD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- BOM 변수"
      ],
      "metadata": {
        "id": "sC-fsJBsuVfD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "##### 이용건수 #####\n",
        "\n",
        "# 데이터 값이 모두 같은 변수 제거\n",
        "sales_with_seg = sales_with_seg.drop(columns=['이용건수_부분무이자_B0M'])\n",
        "\n",
        "# '이용건수_신용_B0M' 변수 값 보정\n",
        "sales_with_seg['이용건수_신용_B0M'] = sales_with_seg['이용건수_신용_B0M'] + sales_with_seg['이용건수_카드론_B0M']\n",
        "\n",
        "\n",
        "\n",
        "##### 이용금액 #####\n",
        "\n",
        "# 데이터 값이 모두 같은 변수 제거\n",
        "sales_with_seg = sales_with_seg.drop(columns=['이용금액_부분무이자_B0M'])\n",
        "\n",
        "# '이용금액_신용_B0M', '이용금액_신판_B0M' 변수 생성\n",
        "sales_with_seg['이용금액_신용_B0M'] = sales_with_seg['이용금액_일시불_B0M'] + sales_with_seg['이용금액_할부_B0M'] + sales_with_seg['이용금액_CA_B0M'] + sales_with_seg['이용금액_카드론_B0M']\n",
        "sales_with_seg['이용금액_신판_B0M'] = sales_with_seg['이용금액_일시불_B0M'] + sales_with_seg['이용금액_할부_B0M']"
      ],
      "metadata": {
        "id": "FYlhbsQguVfD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 건수별평균이용금액 변수 생성\n",
        "sales_with_seg['건수별평균이용금액_신용_B0M'] = np.where(\n",
        "    (sales_with_seg['이용건수_신용_B0M'] == 0) | (sales_with_seg['이용금액_신용_B0M'] == 0), 0,\n",
        "    sales_with_seg['이용금액_신용_B0M'] / sales_with_seg['이용건수_신용_B0M'].abs()\n",
        ")\n",
        "\n",
        "sales_with_seg['건수별평균이용금액_신판_B0M'] = np.where(\n",
        "    (sales_with_seg['이용건수_신판_B0M'] == 0) | (sales_with_seg['이용금액_신판_B0M'] == 0), 0,\n",
        "    sales_with_seg['이용금액_신판_B0M'] / sales_with_seg['이용건수_신판_B0M'].abs()\n",
        ")\n",
        "\n",
        "sales_with_seg['건수별평균이용금액_일시불_B0M'] = np.where(\n",
        "    (sales_with_seg['이용건수_일시불_B0M'] == 0) | (sales_with_seg['이용금액_일시불_B0M'] == 0), 0,\n",
        "    sales_with_seg['이용금액_일시불_B0M'] / sales_with_seg['이용건수_일시불_B0M'].abs()\n",
        ")\n",
        "\n",
        "sales_with_seg['건수별평균이용금액_할부_B0M'] = np.where(\n",
        "    (sales_with_seg['이용건수_할부_B0M'] == 0) | (sales_with_seg['이용금액_할부_B0M'] == 0), 0,\n",
        "    sales_with_seg['이용금액_할부_B0M'] / sales_with_seg['이용건수_할부_B0M'].abs()\n",
        ")\n",
        "\n",
        "sales_with_seg['건수별평균이용금액_할부_유이자_B0M'] = np.where(\n",
        "    (sales_with_seg['이용건수_할부_유이자_B0M'] == 0) | (sales_with_seg['이용금액_할부_유이자_B0M'] == 0), 0,\n",
        "    sales_with_seg['이용금액_할부_유이자_B0M'] / sales_with_seg['이용건수_할부_유이자_B0M'].abs()\n",
        ")\n",
        "\n",
        "sales_with_seg['건수별평균이용금액_할부_무이자_B0M'] = np.where(\n",
        "    (sales_with_seg['이용건수_할부_무이자_B0M'] == 0) | (sales_with_seg['이용금액_할부_무이자_B0M'] == 0), 0,\n",
        "    sales_with_seg['이용금액_할부_무이자_B0M'] / sales_with_seg['이용건수_할부_무이자_B0M'].abs()\n",
        ")\n",
        "\n",
        "sales_with_seg['건수별평균이용금액_CA_B0M'] = np.where(\n",
        "    (sales_with_seg['이용건수_CA_B0M'] == 0) | (sales_with_seg['이용금액_CA_B0M'] == 0), 0,\n",
        "    sales_with_seg['이용금액_CA_B0M'] / sales_with_seg['이용건수_CA_B0M'].abs()\n",
        ")\n",
        "\n",
        "sales_with_seg['건수별평균이용금액_체크_B0M'] = np.where(\n",
        "    (sales_with_seg['이용건수_체크_B0M'] == 0) | (sales_with_seg['이용금액_체크_B0M'] == 0), 0,\n",
        "    sales_with_seg['이용금액_체크_B0M'] / sales_with_seg['이용건수_체크_B0M'].abs()\n",
        ")\n",
        "\n",
        "sales_with_seg['건수별평균이용금액_카드론_B0M'] = np.where(\n",
        "    (sales_with_seg['이용건수_카드론_B0M'] == 0) | (sales_with_seg['이용금액_카드론_B0M'] == 0), 0,\n",
        "    sales_with_seg['이용금액_카드론_B0M'] / sales_with_seg['이용건수_카드론_B0M'].abs()\n",
        ")"
      ],
      "metadata": {
        "id": "0bjRokj3uVfD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 최근3개월이용여부 변수 생성\n",
        "sales_with_seg['최근3개월이용여부_신용'] = (sales_with_seg['이용후경과월_신용'] <= 3).astype(int)\n",
        "sales_with_seg['최근3개월이용여부_신판'] = (sales_with_seg['이용후경과월_신판'] <= 3).astype(int)\n",
        "sales_with_seg['최근3개월이용여부_일시불'] = (sales_with_seg['이용후경과월_일시불'] <= 3).astype(int)\n",
        "sales_with_seg['최근3개월이용여부_할부'] = (sales_with_seg['이용후경과월_할부'] <= 3).astype(int)\n",
        "sales_with_seg['최근3개월이용여부_할부_유이자'] = (sales_with_seg['이용후경과월_할부_유이자'] <= 3).astype(int)\n",
        "sales_with_seg['최근3개월이용여부_할부_무이자'] = (sales_with_seg['이용후경과월_할부_무이자'] <= 3).astype(int)\n",
        "sales_with_seg['최근3개월이용여부_CA'] = (sales_with_seg['이용후경과월_CA'] <= 3).astype(int)\n",
        "sales_with_seg['최근3개월이용여부_체크'] = (sales_with_seg['이용후경과월_체크'] <= 3).astype(int)\n",
        "sales_with_seg['최근3개월이용여부_카드론'] = (sales_with_seg['이용후경과월_카드론'] <= 3).astype(int)"
      ],
      "metadata": {
        "id": "4Qee0H9DuVfE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- R12M 변수"
      ],
      "metadata": {
        "id": "P37aFW-8uVfE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "##### 이용건수 #####\n",
        "\n",
        "# '이용건수_신용_R12M' 변수 값 보정\n",
        "sales_with_seg['이용건수_신용_R12M'] = sales_with_seg['이용건수_신용_R12M'] + sales_with_seg['이용건수_카드론_R12M']\n",
        "\n",
        "\n",
        "##### 이용금액 #####\n",
        "\n",
        "# '이용금액_신용_R12M', '이용금액_신판_R12M' 변수 생성\n",
        "sales_with_seg['이용금액_신용_R12M'] = sales_with_seg['이용금액_일시불_R12M'] + sales_with_seg['이용금액_할부_R12M'] + sales_with_seg['이용금액_CA_R12M'] + sales_with_seg['이용금액_카드론_R12M']\n",
        "sales_with_seg['이용금액_신판_R12M'] = sales_with_seg['이용금액_일시불_R12M'] + sales_with_seg['이용금액_할부_R12M']\n"
      ],
      "metadata": {
        "id": "VHrSDtx1uVfE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 건수별평균이용금액 변수 생성 (R12M 기준)\n",
        "sales_with_seg['건수별평균이용금액_신용_R12M'] = np.where(\n",
        "    (sales_with_seg['이용건수_신용_R12M'] == 0) | (sales_with_seg['이용금액_신용_R12M'] == 0), 0,\n",
        "    sales_with_seg['이용금액_신용_R12M'] / sales_with_seg['이용건수_신용_R12M'].abs()\n",
        ")\n",
        "\n",
        "sales_with_seg['건수별평균이용금액_신판_R12M'] = np.where(\n",
        "    (sales_with_seg['이용건수_신판_R12M'] == 0) | (sales_with_seg['이용금액_신판_R12M'] == 0), 0,\n",
        "    sales_with_seg['이용금액_신판_R12M'] / sales_with_seg['이용건수_신판_R12M'].abs()\n",
        ")\n",
        "\n",
        "sales_with_seg['건수별평균이용금액_일시불_R12M'] = np.where(\n",
        "    (sales_with_seg['이용건수_일시불_R12M'] == 0) | (sales_with_seg['이용금액_일시불_R12M'] == 0), 0,\n",
        "    sales_with_seg['이용금액_일시불_R12M'] / sales_with_seg['이용건수_일시불_R12M'].abs()\n",
        ")\n",
        "\n",
        "sales_with_seg['건수별평균이용금액_할부_R12M'] = np.where(\n",
        "    (sales_with_seg['이용건수_할부_R12M'] == 0) | (sales_with_seg['이용금액_할부_R12M'] == 0), 0,\n",
        "    sales_with_seg['이용금액_할부_R12M'] / sales_with_seg['이용건수_할부_R12M'].abs()\n",
        ")\n",
        "\n",
        "sales_with_seg['건수별평균이용금액_할부_유이자_R12M'] = np.where(\n",
        "    (sales_with_seg['이용건수_할부_유이자_R12M'] == 0) | (sales_with_seg['이용금액_할부_유이자_R12M'] == 0), 0,\n",
        "    sales_with_seg['이용금액_할부_유이자_R12M'] / sales_with_seg['이용건수_할부_유이자_R12M'].abs()\n",
        ")\n",
        "\n",
        "sales_with_seg['건수별평균이용금액_할부_무이자_R12M'] = np.where(\n",
        "    (sales_with_seg['이용건수_할부_무이자_R12M'] == 0) | (sales_with_seg['이용금액_할부_무이자_R12M'] == 0), 0,\n",
        "    sales_with_seg['이용금액_할부_무이자_R12M'] / sales_with_seg['이용건수_할부_무이자_R12M'].abs()\n",
        ")\n",
        "\n",
        "sales_with_seg['건수별평균이용금액_CA_R12M'] = np.where(\n",
        "    (sales_with_seg['이용건수_CA_R12M'] == 0) | (sales_with_seg['이용금액_CA_R12M'] == 0), 0,\n",
        "    sales_with_seg['이용금액_CA_R12M'] / sales_with_seg['이용건수_CA_R12M'].abs()\n",
        ")\n",
        "\n",
        "sales_with_seg['건수별평균이용금액_체크_R12M'] = np.where(\n",
        "    (sales_with_seg['이용건수_체크_R12M'] == 0) | (sales_with_seg['이용금액_체크_R12M'] == 0), 0,\n",
        "    sales_with_seg['이용금액_체크_R12M'] / sales_with_seg['이용건수_체크_R12M'].abs()\n",
        ")\n",
        "\n",
        "sales_with_seg['건수별평균이용금액_카드론_R12M'] = np.where(\n",
        "    (sales_with_seg['이용건수_카드론_R12M'] == 0) | (sales_with_seg['이용금액_카드론_R12M'] == 0), 0,\n",
        "    sales_with_seg['이용금액_카드론_R12M'] / sales_with_seg['이용건수_카드론_R12M'].abs()\n",
        ")"
      ],
      "metadata": {
        "id": "wDgH4aA9uVfE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 이용월평균이용금액 변수 생성 (R12M 기)\n",
        "sales_with_seg['이용월평균이용금액_신용_R12M'] = np.where(\n",
        "    sales_with_seg['이용개월수_신용_R12M'] == 0, 0,\n",
        "    sales_with_seg['이용금액_신용_R12M'] / sales_with_seg['이용개월수_신용_R12M']\n",
        ")\n",
        "\n",
        "sales_with_seg['이용월평균이용금액_신판_R12M'] = np.where(\n",
        "    sales_with_seg['이용개월수_신판_R12M'] == 0, 0,\n",
        "    sales_with_seg['이용금액_신판_R12M'] / sales_with_seg['이용개월수_신판_R12M']\n",
        ")\n",
        "\n",
        "sales_with_seg['이용월평균이용금액_일시불_R12M'] = np.where(\n",
        "    sales_with_seg['이용개월수_일시불_R12M'] == 0, 0,\n",
        "    sales_with_seg['이용금액_일시불_R12M'] / sales_with_seg['이용개월수_일시불_R12M']\n",
        ")\n",
        "\n",
        "sales_with_seg['이용월평균이용금액_할부_R12M'] = np.where(\n",
        "    sales_with_seg['이용개월수_할부_R12M'] == 0, 0,\n",
        "    sales_with_seg['이용금액_할부_R12M'] / sales_with_seg['이용개월수_할부_R12M']\n",
        ")\n",
        "\n",
        "sales_with_seg['이용월평균이용금액_할부_유이자_R12M'] = np.where(\n",
        "    sales_with_seg['이용개월수_할부_유이자_R12M'] == 0, 0,\n",
        "    sales_with_seg['이용금액_할부_유이자_R12M'] / sales_with_seg['이용개월수_할부_유이자_R12M']\n",
        ")\n",
        "\n",
        "sales_with_seg['이용월평균이용금액_할부_무이자_R12M'] = np.where(\n",
        "    sales_with_seg['이용개월수_할부_무이자_R12M'] == 0, 0,\n",
        "    sales_with_seg['이용금액_할부_무이자_R12M'] / sales_with_seg['이용개월수_할부_무이자_R12M']\n",
        ")\n",
        "\n",
        "sales_with_seg['이용월평균이용금액_부분무이자_R12M'] = np.where(\n",
        "    sales_with_seg['이용개월수_부분무이자_R12M'] == 0, 0,\n",
        "    sales_with_seg['이용금액_부분무이자_R12M'] / sales_with_seg['이용개월수_부분무이자_R12M']\n",
        ")\n",
        "\n",
        "sales_with_seg['이용월평균이용금액_CA_R12M'] = np.where(\n",
        "    sales_with_seg['이용개월수_CA_R12M'] == 0, 0,\n",
        "    sales_with_seg['이용금액_CA_R12M'] / sales_with_seg['이용개월수_CA_R12M']\n",
        ")\n",
        "\n",
        "sales_with_seg['이용월평균이용금액_체크_R12M'] = np.where(\n",
        "    sales_with_seg['이용개월수_체크_R12M'] == 0, 0,\n",
        "    sales_with_seg['이용금액_체크_R12M'] / sales_with_seg['이용개월수_체크_R12M']\n",
        ")\n",
        "\n",
        "sales_with_seg['이용월평균이용금액_카드론_R12M'] = np.where(\n",
        "    sales_with_seg['이용개월수_카드론_R12M'] == 0, 0,\n",
        "    sales_with_seg['이용금액_카드론_R12M'] / sales_with_seg['이용개월수_카드론_R12M']\n",
        ")"
      ],
      "metadata": {
        "id": "Qwx_XXCbuVfE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 이용월평균이용건수 변수 생성 (R12M 기준)\n",
        "sales_with_seg['이용월평균이용건수_신용_R12M'] = np.where(\n",
        "    sales_with_seg['이용개월수_신용_R12M'] == 0, 0,\n",
        "    sales_with_seg['이용건수_신용_R12M'] / sales_with_seg['이용개월수_신용_R12M']\n",
        ")\n",
        "\n",
        "sales_with_seg['이용월평균이용건수_신판_R12M'] = np.where(\n",
        "    sales_with_seg['이용개월수_신판_R12M'] == 0, 0,\n",
        "    sales_with_seg['이용건수_신판_R12M'] / sales_with_seg['이용개월수_신판_R12M']\n",
        ")\n",
        "\n",
        "sales_with_seg['이용월평균이용건수_일시불_R12M'] = np.where(\n",
        "    sales_with_seg['이용개월수_일시불_R12M'] == 0, 0,\n",
        "    sales_with_seg['이용건수_일시불_R12M'] / sales_with_seg['이용개월수_일시불_R12M']\n",
        ")\n",
        "\n",
        "sales_with_seg['이용월평균이용건수_할부_R12M'] = np.where(\n",
        "    sales_with_seg['이용개월수_할부_R12M'] == 0, 0,\n",
        "    sales_with_seg['이용건수_할부_R12M'] / sales_with_seg['이용개월수_할부_R12M']\n",
        ")\n",
        "\n",
        "sales_with_seg['이용월평균이용건수_할부_유이자_R12M'] = np.where(\n",
        "    sales_with_seg['이용개월수_할부_유이자_R12M'] == 0, 0,\n",
        "    sales_with_seg['이용건수_할부_유이자_R12M'] / sales_with_seg['이용개월수_할부_유이자_R12M']\n",
        ")\n",
        "\n",
        "sales_with_seg['이용월평균이용건수_할부_무이자_R12M'] = np.where(\n",
        "    sales_with_seg['이용개월수_할부_무이자_R12M'] == 0, 0,\n",
        "    sales_with_seg['이용건수_할부_무이자_R12M'] / sales_with_seg['이용개월수_할부_무이자_R12M']\n",
        ")\n",
        "\n",
        "sales_with_seg['이용월평균이용건수_부분무이자_R12M'] = np.where(\n",
        "    sales_with_seg['이용개월수_부분무이자_R12M'] == 0, 0,\n",
        "    sales_with_seg['이용건수_부분무이자_R12M'] / sales_with_seg['이용개월수_부분무이자_R12M']\n",
        ")\n",
        "\n",
        "sales_with_seg['이용월평균이용건수_CA_R12M'] = np.where(\n",
        "    sales_with_seg['이용개월수_CA_R12M'] == 0, 0,\n",
        "    sales_with_seg['이용건수_CA_R12M'] / sales_with_seg['이용개월수_CA_R12M']\n",
        ")\n",
        "\n",
        "sales_with_seg['이용월평균이용건수_체크_R12M'] = np.where(\n",
        "    sales_with_seg['이용개월수_체크_R12M'] == 0, 0,\n",
        "    sales_with_seg['이용건수_체크_R12M'] / sales_with_seg['이용개월수_체크_R12M']\n",
        ")\n",
        "\n",
        "sales_with_seg['이용월평균이용건수_카드론_R12M'] = np.where(\n",
        "    sales_with_seg['이용개월수_카드론_R12M'] == 0, 0,\n",
        "    sales_with_seg['이용건수_카드론_R12M'] / sales_with_seg['이용개월수_카드론_R12M']\n",
        ")"
      ],
      "metadata": {
        "id": "ymd5snhOuVfE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- R6M 변수"
      ],
      "metadata": {
        "id": "8wLpfd5ouVfF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "##### 이용건수 #####\n",
        "\n",
        "# '이용건수_신용_R6M' 변수 값 보정\n",
        "sales_with_seg['이용건수_신용_R6M'] = sales_with_seg['이용건수_신용_R6M'] + sales_with_seg['이용건수_카드론_R6M']\n",
        "\n",
        "\n",
        "##### 이용금액 #####\n",
        "\n",
        "# '이용금액_신용_R6M', '이용금액_신판_R6M' 변수 생성\n",
        "sales_with_seg['이용금액_신용_R6M'] = sales_with_seg['이용금액_일시불_R6M'] + sales_with_seg['이용금액_할부_R6M'] + sales_with_seg['이용금액_CA_R6M'] + sales_with_seg['이용금액_카드론_R6M']\n",
        "sales_with_seg['이용금액_신판_R6M'] = sales_with_seg['이용금액_일시불_R6M'] + sales_with_seg['이용금액_할부_R6M']"
      ],
      "metadata": {
        "id": "5rEq0rU6uVfF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 건수별평균이용금액 변수 생성 (R6M 기준)\n",
        "sales_with_seg['건수별평균이용금액_신용_R6M'] = np.where(\n",
        "    (sales_with_seg['이용건수_신용_R6M'] == 0) | (sales_with_seg['이용금액_신용_R6M'] == 0), 0,\n",
        "    sales_with_seg['이용금액_신용_R6M'] / sales_with_seg['이용건수_신용_R6M'].abs()\n",
        ")\n",
        "\n",
        "sales_with_seg['건수별평균이용금액_신판_R6M'] = np.where(\n",
        "    (sales_with_seg['이용건수_신판_R6M'] == 0) | (sales_with_seg['이용금액_신판_R6M'] == 0), 0,\n",
        "    sales_with_seg['이용금액_신판_R6M'] / sales_with_seg['이용건수_신판_R6M'].abs()\n",
        ")\n",
        "\n",
        "sales_with_seg['건수별평균이용금액_일시불_R6M'] = np.where(\n",
        "    (sales_with_seg['이용건수_일시불_R6M'] == 0) | (sales_with_seg['이용금액_일시불_R6M'] == 0), 0,\n",
        "    sales_with_seg['이용금액_일시불_R6M'] / sales_with_seg['이용건수_일시불_R6M'].abs()\n",
        ")\n",
        "\n",
        "sales_with_seg['건수별평균이용금액_할부_R6M'] = np.where(\n",
        "    (sales_with_seg['이용건수_할부_R6M'] == 0) | (sales_with_seg['이용금액_할부_R6M'] == 0), 0,\n",
        "    sales_with_seg['이용금액_할부_R6M'] / sales_with_seg['이용건수_할부_R6M'].abs()\n",
        ")\n",
        "\n",
        "sales_with_seg['건수별평균이용금액_할부_유이자_R6M'] = np.where(\n",
        "    (sales_with_seg['이용건수_할부_유이자_R6M'] == 0) | (sales_with_seg['이용금액_할부_유이자_R6M'] == 0), 0,\n",
        "    sales_with_seg['이용금액_할부_유이자_R6M'] / sales_with_seg['이용건수_할부_유이자_R6M'].abs()\n",
        ")\n",
        "\n",
        "sales_with_seg['건수별평균이용금액_할부_무이자_R6M'] = np.where(\n",
        "    (sales_with_seg['이용건수_할부_무이자_R6M'] == 0) | (sales_with_seg['이용금액_할부_무이자_R6M'] == 0), 0,\n",
        "    sales_with_seg['이용금액_할부_무이자_R6M'] / sales_with_seg['이용건수_할부_무이자_R6M'].abs()\n",
        ")\n",
        "\n",
        "sales_with_seg['건수별평균이용금액_부분무이자_R6M'] = np.where(\n",
        "    (sales_with_seg['이용건수_부분무이자_R6M'] == 0) | (sales_with_seg['이용금액_부분무이자_R6M'] == 0), 0,\n",
        "    sales_with_seg['이용금액_부분무이자_R6M'] / sales_with_seg['이용건수_부분무이자_R6M'].abs()\n",
        ")\n",
        "\n",
        "sales_with_seg['건수별평균이용금액_CA_R6M'] = np.where(\n",
        "    (sales_with_seg['이용건수_CA_R6M'] == 0) | (sales_with_seg['이용금액_CA_R6M'] == 0), 0,\n",
        "    sales_with_seg['이용금액_CA_R6M'] / sales_with_seg['이용건수_CA_R6M'].abs()\n",
        ")\n",
        "\n",
        "sales_with_seg['건수별평균이용금액_체크_R6M'] = np.where(\n",
        "    (sales_with_seg['이용건수_체크_R6M'] == 0) | (sales_with_seg['이용금액_체크_R6M'] == 0), 0,\n",
        "    sales_with_seg['이용금액_체크_R6M'] / sales_with_seg['이용건수_체크_R6M'].abs()\n",
        ")\n",
        "\n",
        "sales_with_seg['건수별평균이용금액_카드론_R6M'] = np.where(\n",
        "    (sales_with_seg['이용건수_카드론_R6M'] == 0) | (sales_with_seg['이용금액_카드론_R6M'] == 0), 0,\n",
        "    sales_with_seg['이용금액_카드론_R6M'] / sales_with_seg['이용건수_카드론_R6M'].abs()\n",
        ")"
      ],
      "metadata": {
        "id": "d_B-4-HruVfF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9a74bc01-ea5e-4fe8-e12b-9438a0237bc6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-106-f2f64e88dced>:42: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  sales_with_seg['건수별평균이용금액_체크_R6M'] = np.where(\n",
            "<ipython-input-106-f2f64e88dced>:47: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  sales_with_seg['건수별평균이용금액_카드론_R6M'] = np.where(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 이용월평균이용금액 변수 생성 (R6M 기준)\n",
        "sales_with_seg['이용월평균이용금액_신용_R6M'] = np.where(\n",
        "    sales_with_seg['이용개월수_신용_R6M'] == 0, 0,\n",
        "    sales_with_seg['이용금액_신용_R6M'] / sales_with_seg['이용개월수_신용_R6M']\n",
        ")\n",
        "\n",
        "sales_with_seg['이용월평균이용금액_신판_R6M'] = np.where(\n",
        "    sales_with_seg['이용개월수_신판_R6M'] == 0, 0,\n",
        "    sales_with_seg['이용금액_신판_R6M'] / sales_with_seg['이용개월수_신판_R6M']\n",
        ")\n",
        "\n",
        "sales_with_seg['이용월평균이용금액_일시불_R6M'] = np.where(\n",
        "    sales_with_seg['이용개월수_일시불_R6M'] == 0, 0,\n",
        "    sales_with_seg['이용금액_일시불_R6M'] / sales_with_seg['이용개월수_일시불_R6M']\n",
        ")\n",
        "\n",
        "sales_with_seg['이용월평균이용금액_할부_R6M'] = np.where(\n",
        "    sales_with_seg['이용개월수_할부_R6M'] == 0, 0,\n",
        "    sales_with_seg['이용금액_할부_R6M'] / sales_with_seg['이용개월수_할부_R6M']\n",
        ")\n",
        "\n",
        "sales_with_seg['이용월평균이용금액_할부_유이자_R6M'] = np.where(\n",
        "    sales_with_seg['이용개월수_할부_유이자_R6M'] == 0, 0,\n",
        "    sales_with_seg['이용금액_할부_유이자_R6M'] / sales_with_seg['이용개월수_할부_유이자_R6M']\n",
        ")\n",
        "\n",
        "sales_with_seg['이용월평균이용금액_할부_무이자_R6M'] = np.where(\n",
        "    sales_with_seg['이용개월수_할부_무이자_R6M'] == 0, 0,\n",
        "    sales_with_seg['이용금액_할부_무이자_R6M'] / sales_with_seg['이용개월수_할부_무이자_R6M']\n",
        ")\n",
        "\n",
        "sales_with_seg['이용월평균이용금액_부분무이자_R6M'] = np.where(\n",
        "    sales_with_seg['이용개월수_부분무이자_R6M'] == 0, 0,\n",
        "    sales_with_seg['이용금액_부분무이자_R6M'] / sales_with_seg['이용개월수_부분무이자_R6M']\n",
        ")\n",
        "\n",
        "sales_with_seg['이용월평균이용금액_CA_R6M'] = np.where(\n",
        "    sales_with_seg['이용개월수_CA_R6M'] == 0, 0,\n",
        "    sales_with_seg['이용금액_CA_R6M'] / sales_with_seg['이용개월수_CA_R6M']\n",
        ")\n",
        "\n",
        "sales_with_seg['이용월평균이용금액_체크_R6M'] = np.where(\n",
        "    sales_with_seg['이용개월수_체크_R6M'] == 0, 0,\n",
        "    sales_with_seg['이용금액_체크_R6M'] / sales_with_seg['이용개월수_체크_R6M']\n",
        ")\n",
        "\n",
        "sales_with_seg['이용월평균이용금액_카드론_R6M'] = np.where(\n",
        "    sales_with_seg['이용개월수_카드론_R6M'] == 0, 0,\n",
        "    sales_with_seg['이용금액_카드론_R6M'] / sales_with_seg['이용개월수_카드론_R6M']\n",
        ")"
      ],
      "metadata": {
        "id": "u8ii_RAauVfF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3595d85d-acae-4e95-8c5c-e4586bab93e9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-107-aaa73e740e06>:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  sales_with_seg['이용월평균이용금액_신용_R6M'] = np.where(\n",
            "<ipython-input-107-aaa73e740e06>:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  sales_with_seg['이용월평균이용금액_신판_R6M'] = np.where(\n",
            "<ipython-input-107-aaa73e740e06>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  sales_with_seg['이용월평균이용금액_일시불_R6M'] = np.where(\n",
            "<ipython-input-107-aaa73e740e06>:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  sales_with_seg['이용월평균이용금액_할부_R6M'] = np.where(\n",
            "<ipython-input-107-aaa73e740e06>:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  sales_with_seg['이용월평균이용금액_할부_유이자_R6M'] = np.where(\n",
            "<ipython-input-107-aaa73e740e06>:27: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  sales_with_seg['이용월평균이용금액_할부_무이자_R6M'] = np.where(\n",
            "<ipython-input-107-aaa73e740e06>:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  sales_with_seg['이용월평균이용금액_부분무이자_R6M'] = np.where(\n",
            "<ipython-input-107-aaa73e740e06>:37: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  sales_with_seg['이용월평균이용금액_CA_R6M'] = np.where(\n",
            "<ipython-input-107-aaa73e740e06>:42: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  sales_with_seg['이용월평균이용금액_체크_R6M'] = np.where(\n",
            "<ipython-input-107-aaa73e740e06>:47: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  sales_with_seg['이용월평균이용금액_카드론_R6M'] = np.where(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 이용월평균이용건수 변수 생성 (R6M 기준)\n",
        "sales_with_seg['이용월평균이용건수_신용_R6M'] = np.where(\n",
        "    sales_with_seg['이용개월수_신용_R6M'] == 0, 0,\n",
        "    sales_with_seg['이용건수_신용_R6M'] / sales_with_seg['이용개월수_신용_R6M']\n",
        ")\n",
        "\n",
        "sales_with_seg['이용월평균이용건수_신판_R6M'] = np.where(\n",
        "    sales_with_seg['이용개월수_신판_R6M'] == 0, 0,\n",
        "    sales_with_seg['이용건수_신판_R6M'] / sales_with_seg['이용개월수_신판_R6M']\n",
        ")\n",
        "\n",
        "sales_with_seg['이용월평균이용건수_일시불_R6M'] = np.where(\n",
        "    sales_with_seg['이용개월수_일시불_R6M'] == 0, 0,\n",
        "    sales_with_seg['이용건수_일시불_R6M'] / sales_with_seg['이용개월수_일시불_R6M']\n",
        ")\n",
        "\n",
        "sales_with_seg['이용월평균이용건수_할부_R6M'] = np.where(\n",
        "    sales_with_seg['이용개월수_할부_R6M'] == 0, 0,\n",
        "    sales_with_seg['이용건수_할부_R6M'] / sales_with_seg['이용개월수_할부_R6M']\n",
        ")\n",
        "\n",
        "sales_with_seg['이용월평균이용건수_할부_유이자_R6M'] = np.where(\n",
        "    sales_with_seg['이용개월수_할부_유이자_R6M'] == 0, 0,\n",
        "    sales_with_seg['이용건수_할부_유이자_R6M'] / sales_with_seg['이용개월수_할부_유이자_R6M']\n",
        ")\n",
        "\n",
        "sales_with_seg['이용월평균이용건수_할부_무이자_R6M'] = np.where(\n",
        "    sales_with_seg['이용개월수_할부_무이자_R6M'] == 0, 0,\n",
        "    sales_with_seg['이용건수_할부_무이자_R6M'] / sales_with_seg['이용개월수_할부_무이자_R6M']\n",
        ")\n",
        "\n",
        "sales_with_seg['이용월평균이용건수_부분무이자_R6M'] = np.where(\n",
        "    sales_with_seg['이용개월수_부분무이자_R6M'] == 0, 0,\n",
        "    sales_with_seg['이용건수_부분무이자_R6M'] / sales_with_seg['이용개월수_부분무이자_R6M']\n",
        ")\n",
        "\n",
        "sales_with_seg['이용월평균이용건수_CA_R6M'] = np.where(\n",
        "    sales_with_seg['이용개월수_CA_R6M'] == 0, 0,\n",
        "    sales_with_seg['이용건수_CA_R6M'] / sales_with_seg['이용개월수_CA_R6M']\n",
        ")\n",
        "\n",
        "sales_with_seg['이용월평균이용건수_체크_R6M'] = np.where(\n",
        "    sales_with_seg['이용개월수_체크_R6M'] == 0, 0,\n",
        "    sales_with_seg['이용건수_체크_R6M'] / sales_with_seg['이용개월수_체크_R6M']\n",
        ")\n",
        "\n",
        "sales_with_seg['이용월평균이용건수_카드론_R6M'] = np.where(\n",
        "    sales_with_seg['이용개월수_카드론_R6M'] == 0, 0,\n",
        "    sales_with_seg['이용건수_카드론_R6M'] / sales_with_seg['이용개월수_카드론_R6M']\n",
        ")"
      ],
      "metadata": {
        "id": "TjG6myupuVfF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b8dba775-f7fd-4a97-f244-e2ad80f35d40"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-108-14d78e973320>:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  sales_with_seg['이용월평균이용건수_신용_R6M'] = np.where(\n",
            "<ipython-input-108-14d78e973320>:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  sales_with_seg['이용월평균이용건수_신판_R6M'] = np.where(\n",
            "<ipython-input-108-14d78e973320>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  sales_with_seg['이용월평균이용건수_일시불_R6M'] = np.where(\n",
            "<ipython-input-108-14d78e973320>:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  sales_with_seg['이용월평균이용건수_할부_R6M'] = np.where(\n",
            "<ipython-input-108-14d78e973320>:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  sales_with_seg['이용월평균이용건수_할부_유이자_R6M'] = np.where(\n",
            "<ipython-input-108-14d78e973320>:27: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  sales_with_seg['이용월평균이용건수_할부_무이자_R6M'] = np.where(\n",
            "<ipython-input-108-14d78e973320>:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  sales_with_seg['이용월평균이용건수_부분무이자_R6M'] = np.where(\n",
            "<ipython-input-108-14d78e973320>:37: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  sales_with_seg['이용월평균이용건수_CA_R6M'] = np.where(\n",
            "<ipython-input-108-14d78e973320>:42: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  sales_with_seg['이용월평균이용건수_체크_R6M'] = np.where(\n",
            "<ipython-input-108-14d78e973320>:47: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  sales_with_seg['이용월평균이용건수_카드론_R6M'] = np.where(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- R3M 변수"
      ],
      "metadata": {
        "id": "fOupkddLuVfG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "##### 이용건수 #####\n",
        "\n",
        "# '이용건수_신용_R3M' 변수 값 보정\n",
        "sales_with_seg['이용건수_신용_R3M'] = sales_with_seg['이용건수_신용_R3M'] + sales_with_seg['이용건수_카드론_R3M']\n",
        "\n",
        "\n",
        "##### 이용금액 #####\n",
        "\n",
        "# '이용금액_신용_R3M', '이용금액_신판_R3M' 변수 생성\n",
        "sales_with_seg['이용금액_신용_R3M'] = sales_with_seg['이용금액_일시불_R3M'] + sales_with_seg['이용금액_할부_R3M'] + sales_with_seg['이용금액_CA_R3M'] + sales_with_seg['이용금액_카드론_R3M']\n",
        "sales_with_seg['이용금액_신판_R3M'] = sales_with_seg['이용금액_일시불_R3M'] + sales_with_seg['이용금액_할부_R3M']\n"
      ],
      "metadata": {
        "id": "lDw4QmmUuVfG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cd5c74f9-c865-4b77-e219-2d25aed66e12"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-109-4d9390fc2cd0>:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  sales_with_seg['이용금액_신용_R3M'] = sales_with_seg['이용금액_일시불_R3M'] + sales_with_seg['이용금액_할부_R3M'] + sales_with_seg['이용금액_CA_R3M'] + sales_with_seg['이용금액_카드론_R3M']\n",
            "<ipython-input-109-4d9390fc2cd0>:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  sales_with_seg['이용금액_신판_R3M'] = sales_with_seg['이용금액_일시불_R3M'] + sales_with_seg['이용금액_할부_R3M']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 건수별평균이용금액 변수 생성 (R3M 기준)\n",
        "sales_with_seg['건수별평균이용금액_신용_R3M'] = np.where(\n",
        "    (sales_with_seg['이용건수_신용_R3M'] == 0) | (sales_with_seg['이용금액_신용_R3M'] == 0), 0,\n",
        "    sales_with_seg['이용금액_신용_R3M'] / sales_with_seg['이용건수_신용_R3M'].abs()\n",
        ")\n",
        "\n",
        "sales_with_seg['건수별평균이용금액_신판_R3M'] = np.where(\n",
        "    (sales_with_seg['이용건수_신판_R3M'] == 0) | (sales_with_seg['이용금액_신판_R3M'] == 0), 0,\n",
        "    sales_with_seg['이용금액_신판_R3M'] / sales_with_seg['이용건수_신판_R3M'].abs()\n",
        ")\n",
        "\n",
        "sales_with_seg['건수별평균이용금액_일시불_R3M'] = np.where(\n",
        "    (sales_with_seg['이용건수_일시불_R3M'] == 0) | (sales_with_seg['이용금액_일시불_R3M'] == 0), 0,\n",
        "    sales_with_seg['이용금액_일시불_R3M'] / sales_with_seg['이용건수_일시불_R3M'].abs()\n",
        ")\n",
        "\n",
        "sales_with_seg['건수별평균이용금액_할부_R3M'] = np.where(\n",
        "    (sales_with_seg['이용건수_할부_R3M'] == 0) | (sales_with_seg['이용금액_할부_R3M'] == 0), 0,\n",
        "    sales_with_seg['이용금액_할부_R3M'] / sales_with_seg['이용건수_할부_R3M'].abs()\n",
        ")\n",
        "\n",
        "sales_with_seg['건수별평균이용금액_할부_유이자_R3M'] = np.where(\n",
        "    (sales_with_seg['이용건수_할부_유이자_R3M'] == 0) | (sales_with_seg['이용금액_할부_유이자_R3M'] == 0), 0,\n",
        "    sales_with_seg['이용금액_할부_유이자_R3M'] / sales_with_seg['이용건수_할부_유이자_R3M'].abs()\n",
        ")\n",
        "\n",
        "sales_with_seg['건수별평균이용금액_할부_무이자_R3M'] = np.where(\n",
        "    (sales_with_seg['이용건수_할부_무이자_R3M'] == 0) | (sales_with_seg['이용금액_할부_무이자_R3M'] == 0), 0,\n",
        "    sales_with_seg['이용금액_할부_무이자_R3M'] / sales_with_seg['이용건수_할부_무이자_R3M'].abs()\n",
        ")\n",
        "\n",
        "sales_with_seg['건수별평균이용금액_부분무이자_R3M'] = np.where(\n",
        "    (sales_with_seg['이용건수_부분무이자_R3M'] == 0) | (sales_with_seg['이용금액_부분무이자_R3M'] == 0), 0,\n",
        "    sales_with_seg['이용금액_부분무이자_R3M'] / sales_with_seg['이용건수_부분무이자_R3M'].abs()\n",
        ")\n",
        "\n",
        "sales_with_seg['건수별평균이용금액_CA_R3M'] = np.where(\n",
        "    (sales_with_seg['이용건수_CA_R3M'] == 0) | (sales_with_seg['이용금액_CA_R3M'] == 0), 0,\n",
        "    sales_with_seg['이용금액_CA_R3M'] / sales_with_seg['이용건수_CA_R3M'].abs()\n",
        ")\n",
        "\n",
        "sales_with_seg['건수별평균이용금액_체크_R3M'] = np.where(\n",
        "    (sales_with_seg['이용건수_체크_R3M'] == 0) | (sales_with_seg['이용금액_체크_R3M'] == 0), 0,\n",
        "    sales_with_seg['이용금액_체크_R3M'] / sales_with_seg['이용건수_체크_R3M'].abs()\n",
        ")\n",
        "\n",
        "sales_with_seg['건수별평균이용금액_카드론_R3M'] = np.where(\n",
        "    (sales_with_seg['이용건수_카드론_R3M'] == 0) | (sales_with_seg['이용금액_카드론_R3M'] == 0), 0,\n",
        "    sales_with_seg['이용금액_카드론_R3M'] / sales_with_seg['이용건수_카드론_R3M'].abs()\n",
        ")"
      ],
      "metadata": {
        "id": "bR3jlpAGuVfG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f8872e8d-2c83-49a7-9612-b3cae09eb766"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-110-8a8fe6265eaa>:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  sales_with_seg['건수별평균이용금액_신용_R3M'] = np.where(\n",
            "<ipython-input-110-8a8fe6265eaa>:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  sales_with_seg['건수별평균이용금액_신판_R3M'] = np.where(\n",
            "<ipython-input-110-8a8fe6265eaa>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  sales_with_seg['건수별평균이용금액_일시불_R3M'] = np.where(\n",
            "<ipython-input-110-8a8fe6265eaa>:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  sales_with_seg['건수별평균이용금액_할부_R3M'] = np.where(\n",
            "<ipython-input-110-8a8fe6265eaa>:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  sales_with_seg['건수별평균이용금액_할부_유이자_R3M'] = np.where(\n",
            "<ipython-input-110-8a8fe6265eaa>:27: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  sales_with_seg['건수별평균이용금액_할부_무이자_R3M'] = np.where(\n",
            "<ipython-input-110-8a8fe6265eaa>:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  sales_with_seg['건수별평균이용금액_부분무이자_R3M'] = np.where(\n",
            "<ipython-input-110-8a8fe6265eaa>:37: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  sales_with_seg['건수별평균이용금액_CA_R3M'] = np.where(\n",
            "<ipython-input-110-8a8fe6265eaa>:42: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  sales_with_seg['건수별평균이용금액_체크_R3M'] = np.where(\n",
            "<ipython-input-110-8a8fe6265eaa>:47: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  sales_with_seg['건수별평균이용금액_카드론_R3M'] = np.where(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 이용월평균이용금액 변수 생성 (R3M 기준)\n",
        "sales_with_seg['이용월평균이용금액_신용_R3M'] = np.where(\n",
        "    sales_with_seg['이용개월수_신용_R3M'] == 0, 0,\n",
        "    sales_with_seg['이용금액_신용_R3M'] / sales_with_seg['이용개월수_신용_R3M']\n",
        ")\n",
        "\n",
        "sales_with_seg['이용월평균이용금액_신판_R3M'] = np.where(\n",
        "    sales_with_seg['이용개월수_신판_R3M'] == 0, 0,\n",
        "    sales_with_seg['이용금액_신판_R3M'] / sales_with_seg['이용개월수_신판_R3M']\n",
        ")\n",
        "\n",
        "sales_with_seg['이용월평균이용금액_일시불_R3M'] = np.where(\n",
        "    sales_with_seg['이용개월수_일시불_R3M'] == 0, 0,\n",
        "    sales_with_seg['이용금액_일시불_R3M'] / sales_with_seg['이용개월수_일시불_R3M']\n",
        ")\n",
        "\n",
        "sales_with_seg['이용월평균이용금액_할부_R3M'] = np.where(\n",
        "    sales_with_seg['이용개월수_할부_R3M'] == 0, 0,\n",
        "    sales_with_seg['이용금액_할부_R3M'] / sales_with_seg['이용개월수_할부_R3M']\n",
        ")\n",
        "\n",
        "sales_with_seg['이용월평균이용금액_할부_유이자_R3M'] = np.where(\n",
        "    sales_with_seg['이용개월수_할부_유이자_R3M'] == 0, 0,\n",
        "    sales_with_seg['이용금액_할부_유이자_R3M'] / sales_with_seg['이용개월수_할부_유이자_R3M']\n",
        ")\n",
        "\n",
        "sales_with_seg['이용월평균이용금액_할부_무이자_R3M'] = np.where(\n",
        "    sales_with_seg['이용개월수_할부_무이자_R3M'] == 0, 0,\n",
        "    sales_with_seg['이용금액_할부_무이자_R3M'] / sales_with_seg['이용개월수_할부_무이자_R3M']\n",
        ")\n",
        "\n",
        "sales_with_seg['이용월평균이용금액_부분무이자_R3M'] = np.where(\n",
        "    sales_with_seg['이용개월수_부분무이자_R3M'] == 0, 0,\n",
        "    sales_with_seg['이용금액_부분무이자_R3M'] / sales_with_seg['이용개월수_부분무이자_R3M']\n",
        ")\n",
        "\n",
        "sales_with_seg['이용월평균이용금액_CA_R3M'] = np.where(\n",
        "    sales_with_seg['이용개월수_CA_R3M'] == 0, 0,\n",
        "    sales_with_seg['이용금액_CA_R3M'] / sales_with_seg['이용개월수_CA_R3M']\n",
        ")\n",
        "\n",
        "sales_with_seg['이용월평균이용금액_체크_R3M'] = np.where(\n",
        "    sales_with_seg['이용개월수_체크_R3M'] == 0, 0,\n",
        "    sales_with_seg['이용금액_체크_R3M'] / sales_with_seg['이용개월수_체크_R3M']\n",
        ")\n",
        "\n",
        "sales_with_seg['이용월평균이용금액_카드론_R3M'] = np.where(\n",
        "    sales_with_seg['이용개월수_카드론_R3M'] == 0, 0,\n",
        "    sales_with_seg['이용금액_카드론_R3M'] / sales_with_seg['이용개월수_카드론_R3M']\n",
        ")"
      ],
      "metadata": {
        "id": "CA4MW7WruVfG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2a6ec118-366c-4634-b6ca-d252a1ce3bcb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-111-c32a9b21fcfa>:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  sales_with_seg['이용월평균이용금액_신용_R3M'] = np.where(\n",
            "<ipython-input-111-c32a9b21fcfa>:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  sales_with_seg['이용월평균이용금액_신판_R3M'] = np.where(\n",
            "<ipython-input-111-c32a9b21fcfa>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  sales_with_seg['이용월평균이용금액_일시불_R3M'] = np.where(\n",
            "<ipython-input-111-c32a9b21fcfa>:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  sales_with_seg['이용월평균이용금액_할부_R3M'] = np.where(\n",
            "<ipython-input-111-c32a9b21fcfa>:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  sales_with_seg['이용월평균이용금액_할부_유이자_R3M'] = np.where(\n",
            "<ipython-input-111-c32a9b21fcfa>:27: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  sales_with_seg['이용월평균이용금액_할부_무이자_R3M'] = np.where(\n",
            "<ipython-input-111-c32a9b21fcfa>:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  sales_with_seg['이용월평균이용금액_부분무이자_R3M'] = np.where(\n",
            "<ipython-input-111-c32a9b21fcfa>:37: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  sales_with_seg['이용월평균이용금액_CA_R3M'] = np.where(\n",
            "<ipython-input-111-c32a9b21fcfa>:42: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  sales_with_seg['이용월평균이용금액_체크_R3M'] = np.where(\n",
            "<ipython-input-111-c32a9b21fcfa>:47: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  sales_with_seg['이용월평균이용금액_카드론_R3M'] = np.where(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 이용월평균이용건수 변수 생성 (R3M 기준)\n",
        "sales_with_seg['이용월평균이용건수_신용_R3M'] = np.where(\n",
        "    sales_with_seg['이용개월수_신용_R3M'] == 0, 0,\n",
        "    sales_with_seg['이용건수_신용_R3M'] / sales_with_seg['이용개월수_신용_R3M']\n",
        ")\n",
        "\n",
        "sales_with_seg['이용월평균이용건수_신판_R3M'] = np.where(\n",
        "    sales_with_seg['이용개월수_신판_R3M'] == 0, 0,\n",
        "    sales_with_seg['이용건수_신판_R3M'] / sales_with_seg['이용개월수_신판_R3M']\n",
        ")\n",
        "\n",
        "sales_with_seg['이용월평균이용건수_일시불_R3M'] = np.where(\n",
        "    sales_with_seg['이용개월수_일시불_R3M'] == 0, 0,\n",
        "    sales_with_seg['이용건수_일시불_R3M'] / sales_with_seg['이용개월수_일시불_R3M']\n",
        ")\n",
        "\n",
        "sales_with_seg['이용월평균이용건수_할부_R3M'] = np.where(\n",
        "    sales_with_seg['이용개월수_할부_R3M'] == 0, 0,\n",
        "    sales_with_seg['이용건수_할부_R3M'] / sales_with_seg['이용개월수_할부_R3M']\n",
        ")\n",
        "\n",
        "sales_with_seg['이용월평균이용건수_할부_유이자_R3M'] = np.where(\n",
        "    sales_with_seg['이용개월수_할부_유이자_R3M'] == 0, 0,\n",
        "    sales_with_seg['이용건수_할부_유이자_R3M'] / sales_with_seg['이용개월수_할부_유이자_R3M']\n",
        ")\n",
        "\n",
        "sales_with_seg['이용월평균이용건수_할부_무이자_R3M'] = np.where(\n",
        "    sales_with_seg['이용개월수_할부_무이자_R3M'] == 0, 0,\n",
        "    sales_with_seg['이용건수_할부_무이자_R3M'] / sales_with_seg['이용개월수_할부_무이자_R3M']\n",
        ")\n",
        "\n",
        "sales_with_seg['이용월평균이용건수_부분무이자_R3M'] = np.where(\n",
        "    sales_with_seg['이용개월수_부분무이자_R3M'] == 0, 0,\n",
        "    sales_with_seg['이용건수_부분무이자_R3M'] / sales_with_seg['이용개월수_부분무이자_R3M']\n",
        ")\n",
        "\n",
        "sales_with_seg['이용월평균이용건수_CA_R3M'] = np.where(\n",
        "    sales_with_seg['이용개월수_CA_R3M'] == 0, 0,\n",
        "    sales_with_seg['이용건수_CA_R3M'] / sales_with_seg['이용개월수_CA_R3M']\n",
        ")\n",
        "\n",
        "sales_with_seg['이용월평균이용건수_체크_R3M'] = np.where(\n",
        "    sales_with_seg['이용개월수_체크_R3M'] == 0, 0,\n",
        "    sales_with_seg['이용건수_체크_R3M'] / sales_with_seg['이용개월수_체크_R3M']\n",
        ")\n",
        "\n",
        "sales_with_seg['이용월평균이용건수_카드론_R3M'] = np.where(\n",
        "    sales_with_seg['이용개월수_카드론_R3M'] == 0, 0,\n",
        "    sales_with_seg['이용건수_카드론_R3M'] / sales_with_seg['이용개월수_카드론_R3M']\n",
        ")\n"
      ],
      "metadata": {
        "id": "j4d-uSoLuVfG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "299850aa-a373-4575-9802-dcee3d06e66a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-112-cb1d1abb0035>:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  sales_with_seg['이용월평균이용건수_신용_R3M'] = np.where(\n",
            "<ipython-input-112-cb1d1abb0035>:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  sales_with_seg['이용월평균이용건수_신판_R3M'] = np.where(\n",
            "<ipython-input-112-cb1d1abb0035>:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  sales_with_seg['이용월평균이용건수_일시불_R3M'] = np.where(\n",
            "<ipython-input-112-cb1d1abb0035>:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  sales_with_seg['이용월평균이용건수_할부_R3M'] = np.where(\n",
            "<ipython-input-112-cb1d1abb0035>:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  sales_with_seg['이용월평균이용건수_할부_유이자_R3M'] = np.where(\n",
            "<ipython-input-112-cb1d1abb0035>:27: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  sales_with_seg['이용월평균이용건수_할부_무이자_R3M'] = np.where(\n",
            "<ipython-input-112-cb1d1abb0035>:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  sales_with_seg['이용월평균이용건수_부분무이자_R3M'] = np.where(\n",
            "<ipython-input-112-cb1d1abb0035>:37: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  sales_with_seg['이용월평균이용건수_CA_R3M'] = np.where(\n",
            "<ipython-input-112-cb1d1abb0035>:42: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  sales_with_seg['이용월평균이용건수_체크_R3M'] = np.where(\n",
            "<ipython-input-112-cb1d1abb0035>:47: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  sales_with_seg['이용월평균이용건수_카드론_R3M'] = np.where(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 쇼핑/교통/여유/납부"
      ],
      "metadata": {
        "id": "bl7JWdmbuVfH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# '쇼핑_총이용금액' 변수 생성\n",
        "shopping_columns = ['쇼핑_도소매_이용금액',\n",
        "                    '쇼핑_백화점_이용금액',\n",
        "                    '쇼핑_마트_이용금액',\n",
        "                    '쇼핑_슈퍼마켓_이용금액',\n",
        "                    '쇼핑_편의점_이용금액',\n",
        "                    '쇼핑_아울렛_이용금액',\n",
        "                    '쇼핑_온라인_이용금액',\n",
        "                    '쇼핑_기타_이용금액']\n",
        "sales_with_seg['쇼핑_총이용금액'] = sales_with_seg[shopping_columns].sum(axis=1)\n",
        "\n",
        "# '교통_총이용금액' 변수 생성\n",
        "shopping_columns = ['교통_주유이용금액',\n",
        "                    '교통_정비이용금액',\n",
        "                    '교통_통행료이용금액',\n",
        "                    '교통_버스지하철이용금액',\n",
        "                    '교통_택시이용금액',\n",
        "                    '교통_철도버스이용금액']\n",
        "sales_with_seg['교통_총이용금액'] = sales_with_seg[shopping_columns].sum(axis=1)\n",
        "\n",
        "# '여유_총이용금액' 변수 생성\n",
        "shopping_columns = ['여유_운동이용금액',\n",
        "                    '여유_Pet이용금액',\n",
        "                    '여유_공연이용금액',\n",
        "                    '여유_공원이용금액',\n",
        "                    '여유_숙박이용금액',\n",
        "                    '여유_항공이용금액',\n",
        "                    '여유_기타이용금액']\n",
        "sales_with_seg['여유_총이용금액'] = sales_with_seg[shopping_columns].sum(axis=1)\n",
        "\n",
        "# '납부_총이용금액' 변수 생성\n",
        "shopping_columns = ['납부_통신비이용금액',\n",
        "                    '납부_관리비이용금액',\n",
        "                    '납부_가스전기료이용금액',\n",
        "                    '납부_보험료이용금액',\n",
        "                    '납부_기타이용금액']\n",
        "sales_with_seg['납부_총이용금액'] = sales_with_seg[shopping_columns].sum(axis=1)"
      ],
      "metadata": {
        "id": "rFoF0GkGuVfH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e825be67-e2d8-4c51-d56e-f63033d52d48"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-113-406ff2616aa4>:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  sales_with_seg['쇼핑_총이용금액'] = sales_with_seg[shopping_columns].sum(axis=1)\n",
            "<ipython-input-113-406ff2616aa4>:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  sales_with_seg['교통_총이용금액'] = sales_with_seg[shopping_columns].sum(axis=1)\n",
            "<ipython-input-113-406ff2616aa4>:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  sales_with_seg['여유_총이용금액'] = sales_with_seg[shopping_columns].sum(axis=1)\n",
            "<ipython-input-113-406ff2616aa4>:37: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  sales_with_seg['납부_총이용금액'] = sales_with_seg[shopping_columns].sum(axis=1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 상관계수 절댓값 0.3 넘는 변수 5개만 합치기\n",
        "shopping_columns = ['쇼핑_도소매_이용금액',\n",
        "                    '쇼핑_마트_이용금액',\n",
        "                    '쇼핑_온라인_이용금액',\n",
        "                    '교통_주유이용금액',\n",
        "                    '납부_기타이용금액']\n",
        "sales_with_seg['0.3이상_총이용금액'] = sales_with_seg[shopping_columns].sum(axis=1)"
      ],
      "metadata": {
        "id": "fAAtHL3auVfH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e79ca22a-57ef-456f-9c4d-696e6e1c3d47"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-114-b7ebe65e3d8d>:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  sales_with_seg['0.3이상_총이용금액'] = sales_with_seg[shopping_columns].sum(axis=1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 쇼핑/교통/여유/납부 다 합치기\n",
        "columns = ['쇼핑_총이용금액',\n",
        "          '교통_총이용금액',\n",
        "          '여유_총이용금액',\n",
        "          '납부_총이용금액']\n",
        "sales_with_seg['총이용금액_쇼핑교통여유납부'] = sales_with_seg[columns].sum(axis=1)"
      ],
      "metadata": {
        "id": "CwU2Yj7_uVfH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "343a7cb7-0963-46e8-f601-ff39881f2b7e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-115-22bf84db1bde>:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  sales_with_seg['총이용금액_쇼핑교통여유납부'] = sales_with_seg[columns].sum(axis=1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 기존 변수 다 삭제\n",
        "columns_to_drop = [\n",
        "    '쇼핑_도소매_이용금액', '쇼핑_백화점_이용금액', '쇼핑_마트_이용금액',\n",
        "    '쇼핑_슈퍼마켓_이용금액', '쇼핑_편의점_이용금액', '쇼핑_아울렛_이용금액',\n",
        "    '쇼핑_온라인_이용금액', '쇼핑_기타_이용금액',\n",
        "\n",
        "    '교통_주유이용금액', '교통_정비이용금액', '교통_통행료이용금액',\n",
        "    '교통_버스지하철이용금액', '교통_택시이용금액', '교통_철도버스이용금액',\n",
        "\n",
        "    '여유_운동이용금액', '여유_Pet이용금액', '여유_공연이용금액',\n",
        "    '여유_공원이용금액', '여유_숙박이용금액', '여유_여행이용금액',\n",
        "    '여유_항공이용금액', '여유_기타이용금액',\n",
        "\n",
        "    '납부_통신비이용금액', '납부_관리비이용금액', '납부_렌탈료이용금액',\n",
        "    '납부_가스전기료이용금액', '납부_보험료이용금액', '납부_유선방송이용금액',\n",
        "    '납부_건강연금이용금액', '납부_기타이용금액'\n",
        "]\n",
        "\n",
        "# 변수 삭제\n",
        "sales_with_seg.drop(columns=columns_to_drop, inplace=True)"
      ],
      "metadata": {
        "id": "iWy39XKMuVfH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "-  R12M 할부건수/할부금액"
      ],
      "metadata": {
        "id": "l-cn2QbVuVfH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터 동일한 변수 4개 삭제\n",
        "columns_drop = [\n",
        "    '할부건수_부분_3M_R12M',\n",
        "    '할부건수_부분_6M_R12M',\n",
        "    '할부건수_부분_14M_R12M',\n",
        "    '할부금액_부분_3M_R12M'\n",
        "    ]\n",
        "sales_with_seg.drop(columns=columns_drop, inplace=True)"
      ],
      "metadata": {
        "id": "GLOk0pEBuVfH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 최근 1년치 총합 변수 7개 생성 (할부건수/할부금액)\n",
        "\n",
        "# 1. 할부\n",
        "sales_with_seg['할부건수총합_R12M'] = (\n",
        "    sales_with_seg['할부건수_3M_R12M'] +\n",
        "    sales_with_seg['할부건수_6M_R12M'] +\n",
        "    sales_with_seg['할부건수_12M_R12M']\n",
        ")\n",
        "\n",
        "sales_with_seg['할부금액총합_R12M'] = (\n",
        "    sales_with_seg['할부금액_3M_R12M'] +\n",
        "    sales_with_seg['할부금액_6M_R12M'] +\n",
        "    sales_with_seg['할부금액_12M_R12M']\n",
        ")\n",
        "\n",
        "# 2. 유이자 할부\n",
        "sales_with_seg['할부건수총합_유이자_R12M'] = (\n",
        "    sales_with_seg['할부건수_유이자_3M_R12M'] +\n",
        "    sales_with_seg['할부건수_유이자_6M_R12M'] +\n",
        "    sales_with_seg['할부건수_유이자_12M_R12M']\n",
        ")\n",
        "\n",
        "sales_with_seg['할부금액총합_유이자_R12M'] = (\n",
        "    sales_with_seg['할부금액_유이자_3M_R12M'] +\n",
        "    sales_with_seg['할부금액_유이자_6M_R12M'] +\n",
        "    sales_with_seg['할부금액_유이자_12M_R12M']\n",
        ")\n",
        "\n",
        "# 3. 무이자 할부\n",
        "sales_with_seg['할부건수총합_무이자_R12M'] = (\n",
        "    sales_with_seg['할부건수_무이자_3M_R12M'] +\n",
        "    sales_with_seg['할부건수_무이자_6M_R12M'] +\n",
        "    sales_with_seg['할부건수_무이자_12M_R12M']\n",
        ")\n",
        "\n",
        "sales_with_seg['할부금액총합_무이자_R12M'] = (\n",
        "    sales_with_seg['할부금액_무이자_3M_R12M'] +\n",
        "    sales_with_seg['할부금액_무이자_6M_R12M'] +\n",
        "    sales_with_seg['할부금액_무이자_12M_R12M']\n",
        ")\n",
        "\n",
        "# 3. 부분 할부\n",
        "# '할부건수_부분_3M_R12M', '할부건수_부분_6M_R12M'가 다 0이라서 '할부건수_부분_12M_R12M'가 1년치 총합과 동일함\n",
        "sales_with_seg['할부금액총합_부분_R12M'] = (\n",
        "    sales_with_seg['할부금액_부분_6M_R12M'] +\n",
        "    sales_with_seg['할부금액_부분_12M_R12M']\n",
        ")"
      ],
      "metadata": {
        "id": "JHIj9MDguVfH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "56fbe5bc-63aa-49ec-8b39-6c6aed99ee98"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-118-a57ce0275030>:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  sales_with_seg['할부건수총합_R12M'] = (\n",
            "<ipython-input-118-a57ce0275030>:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  sales_with_seg['할부금액총합_R12M'] = (\n",
            "<ipython-input-118-a57ce0275030>:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  sales_with_seg['할부건수총합_유이자_R12M'] = (\n",
            "<ipython-input-118-a57ce0275030>:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  sales_with_seg['할부금액총합_유이자_R12M'] = (\n",
            "<ipython-input-118-a57ce0275030>:30: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  sales_with_seg['할부건수총합_무이자_R12M'] = (\n",
            "<ipython-input-118-a57ce0275030>:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  sales_with_seg['할부금액총합_무이자_R12M'] = (\n",
            "<ipython-input-118-a57ce0275030>:44: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  sales_with_seg['할부금액총합_부분_R12M'] = (\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 할부 건수 별 금액 변수 4개 생성\n",
        "#  - 3M 기준이 제일 상관계수가 좋음\n",
        "#  - 부분 무이자 할부는 할부건수가 12M 밖에 없어서 12M 기준으로 계산\n",
        "\n",
        "# 1. 할부\n",
        "sales_with_seg['건수별할부금액_3M'] = np.where(\n",
        "    (sales_with_seg['할부금액_3M_R12M'] == 0) | (sales_with_seg['할부건수_3M_R12M'] == 0),\n",
        "    0,\n",
        "    sales_with_seg['할부금액_3M_R12M'] / sales_with_seg['할부건수_3M_R12M']\n",
        ")\n",
        "\n",
        "# 2. 유이자 할부\n",
        "sales_with_seg['건수별할부금액_유이자_3M'] = np.where(\n",
        "    (sales_with_seg['할부금액_유이자_3M_R12M'] == 0) | (sales_with_seg['할부건수_유이자_3M_R12M'] == 0),\n",
        "    0,\n",
        "    sales_with_seg['할부금액_유이자_3M_R12M'] / sales_with_seg['할부건수_유이자_3M_R12M']\n",
        ")\n",
        "\n",
        "# 3. 무이자 할부\n",
        "sales_with_seg['건수별할부금액_무이자_3M'] = np.where(\n",
        "    (sales_with_seg['할부금액_무이자_3M_R12M'] == 0) | (sales_with_seg['할부건수_무이자_3M_R12M'] == 0),\n",
        "    0,\n",
        "    sales_with_seg['할부금액_무이자_3M_R12M'] / sales_with_seg['할부건수_무이자_3M_R12M']\n",
        ")\n",
        "\n",
        "# 4. 부분 무이자 할부\n",
        "sales_with_seg['건수별할부금액_부분_12M'] = np.where(\n",
        "    (sales_with_seg['할부금액_부분_12M_R12M'] == 0) | (sales_with_seg['할부건수_부분_12M_R12M'] == 0),\n",
        "    0,\n",
        "    sales_with_seg['할부금액_부분_12M_R12M'] / sales_with_seg['할부건수_부분_12M_R12M']\n",
        ")"
      ],
      "metadata": {
        "id": "SkySu6c3uVfI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bc047d6a-1ef2-4685-dbd5-9e08939bc48a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-119-fbf2bfb45a75>:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  sales_with_seg['건수별할부금액_3M'] = np.where(\n",
            "<ipython-input-119-fbf2bfb45a75>:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  sales_with_seg['건수별할부금액_유이자_3M'] = np.where(\n",
            "<ipython-input-119-fbf2bfb45a75>:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  sales_with_seg['건수별할부금액_무이자_3M'] = np.where(\n",
            "<ipython-input-119-fbf2bfb45a75>:27: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  sales_with_seg['건수별할부금액_부분_12M'] = np.where(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- RP 관련 변수들"
      ],
      "metadata": {
        "id": "XIPaAjGFuVfI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터 동일한 변수 6개 삭제\n",
        "columns_drop = ['RP건수_유선방송_B0M',\n",
        "                'RP건수_건강_B0M',\n",
        "                'RP후경과월_유선방송',\n",
        "                'RP후경과월_건강',\n",
        "                '증감_RP건수_유선방송_전월',\n",
        "                '증감_RP건수_건강_전월']\n",
        "sales_with_seg.drop(columns=columns_drop, inplace=True)\n",
        "\n",
        "# '최근3개월이용여부_RP' 변수 생성\n",
        "sales_with_seg['최근3개월이용여부_RP'] = (sales_with_seg['RP후경과월'] <= 3).astype(int)\n",
        "\n",
        "# 'RP_이용확대여부' 변수 생성\n",
        "delta_cols = [col for col in sales_with_seg.columns if col.startswith('증감_RP건수_')]\n",
        "sales_with_seg['RP건수_증감총합'] = sales_with_seg[delta_cols].sum(axis=1)\n",
        "sales_with_seg['RP_이용확대여부'] = (sales_with_seg['RP건수_증감총합'] > 0).astype(int) # 방향성: 양수면 확장, 음수면 축소\n",
        "sales_with_seg.drop(columns=['RP건수_증감총합'], inplace=True)"
      ],
      "metadata": {
        "id": "agsBHbu6uVfI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8380fa24-9ec8-4c9e-b433-add12a0334a9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-120-071d93968994>:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  sales_with_seg['최근3개월이용여부_RP'] = (sales_with_seg['RP후경과월'] <= 3).astype(int)\n",
            "<ipython-input-120-071d93968994>:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  sales_with_seg['RP건수_증감총합'] = sales_with_seg[delta_cols].sum(axis=1)\n",
            "<ipython-input-120-071d93968994>:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  sales_with_seg['RP_이용확대여부'] = (sales_with_seg['RP건수_증감총합'] > 0).astype(int) # 방향성: 양수면 확장, 음수면 축소\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 'RP활성업종수' 변수 생성\n",
        "rp_cols = [\n",
        "    'RP건수_통신_B0M', 'RP건수_아파트_B0M', 'RP건수_제휴사서비스직접판매_B0M',\n",
        "    'RP건수_렌탈_B0M', 'RP건수_가스_B0M', 'RP건수_전기_B0M', 'RP건수_보험_B0M',\n",
        "    'RP건수_학습비_B0M', 'RP건수_교통_B0M'\n",
        "]\n",
        "sales_with_seg['RP활성업종수'] = sales_with_seg[rp_cols].gt(0).sum(axis=1)"
      ],
      "metadata": {
        "id": "fNKy-oODuVfI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b2901189-0121-4be6-94af-16519f280f11"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-121-a8a35245fb88>:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  sales_with_seg['RP활성업종수'] = sales_with_seg[rp_cols].gt(0).sum(axis=1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 카드론 관련 변수들"
      ],
      "metadata": {
        "id": "xg9V4u07uVfI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# '카드론이용여부' 변수 생성\n",
        "sales_with_seg['카드론이용여부'] = (\n",
        "    (sales_with_seg['최초카드론이용경과월'] != 999) &\n",
        "    (sales_with_seg['최종카드론이용경과월'] != 999)\n",
        ").astype(int)"
      ],
      "metadata": {
        "id": "4vkq5HCGuVfI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "048ebb80-0509-411a-b9fd-c7f5d6964702"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-122-781516af5b95>:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  sales_with_seg['카드론이용여부'] = (\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 이용개월수/이용금액/이용건수-  온라인/오프라인"
      ],
      "metadata": {
        "id": "3hBR2GRWuVfJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 건수별평균금액 변수 6개 생성\n",
        "\n",
        "# R6M(최근 6개월)\n",
        "sales_with_seg['건수별평균이용금액_온라인_R6M'] = np.where(\n",
        "    (sales_with_seg['이용금액_온라인_R6M'] == 0) | (sales_with_seg['이용건수_온라인_R6M'] == 0),\n",
        "    0,\n",
        "    sales_with_seg['이용금액_온라인_R6M'] / sales_with_seg['이용건수_온라인_R6M'].abs()\n",
        ")\n",
        "\n",
        "sales_with_seg['건수별평균이용금액_오프라인_R6M'] = np.where(\n",
        "    (sales_with_seg['이용금액_오프라인_R6M'] == 0) | (sales_with_seg['이용건수_오프라인_R6M'] == 0),\n",
        "    0,\n",
        "    sales_with_seg['이용금액_오프라인_R6M'] / sales_with_seg['이용건수_오프라인_R6M'].abs()\n",
        ")\n",
        "\n",
        "# R3M(최근 3개월)\n",
        "sales_with_seg['건수별평균이용금액_온라인_R3M'] = np.where(\n",
        "    (sales_with_seg['이용금액_온라인_R3M'] == 0) | (sales_with_seg['이용건수_온라인_R3M'] == 0),\n",
        "    0,\n",
        "    sales_with_seg['이용금액_온라인_R3M'] / sales_with_seg['이용건수_온라인_R3M'].abs()\n",
        ")\n",
        "\n",
        "sales_with_seg['건수별평균이용금액_오프라인_R3M'] = np.where(\n",
        "    (sales_with_seg['이용금액_오프라인_R3M'] == 0) | (sales_with_seg['이용건수_오프라인_R3M'] == 0),\n",
        "    0,\n",
        "    sales_with_seg['이용금액_오프라인_R3M'] / sales_with_seg['이용건수_오프라인_R3M'].abs()\n",
        ")\n",
        "\n",
        "\n",
        "# B0M(당월)\n",
        "sales_with_seg['건수별평균이용금액_온라인_B0M'] = np.where(\n",
        "    (sales_with_seg['이용금액_온라인_B0M'] == 0) | (sales_with_seg['이용건수_온라인_B0M'] == 0),\n",
        "    0,\n",
        "    sales_with_seg['이용금액_온라인_B0M'] / sales_with_seg['이용건수_온라인_B0M'].abs()\n",
        ")\n",
        "\n",
        "sales_with_seg['건수별평균이용금액_오프라인_B0M'] = np.where(\n",
        "    (sales_with_seg['이용금액_오프라인_B0M'] == 0) | (sales_with_seg['이용건수_오프라인_B0M'] == 0),\n",
        "    0,\n",
        "    sales_with_seg['이용금액_오프라인_B0M'] / sales_with_seg['이용건수_오프라인_B0M'].abs()\n",
        ")"
      ],
      "metadata": {
        "id": "0JBSH7wVuVfJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e224a076-6854-4d5a-b147-9b9f013fd2c4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-123-9fcf63bd8b3f>:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  sales_with_seg['건수별평균이용금액_온라인_R6M'] = np.where(\n",
            "<ipython-input-123-9fcf63bd8b3f>:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  sales_with_seg['건수별평균이용금액_오프라인_R6M'] = np.where(\n",
            "<ipython-input-123-9fcf63bd8b3f>:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  sales_with_seg['건수별평균이용금액_온라인_R3M'] = np.where(\n",
            "<ipython-input-123-9fcf63bd8b3f>:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  sales_with_seg['건수별평균이용금액_오프라인_R3M'] = np.where(\n",
            "<ipython-input-123-9fcf63bd8b3f>:31: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  sales_with_seg['건수별평균이용금액_온라인_B0M'] = np.where(\n",
            "<ipython-input-123-9fcf63bd8b3f>:37: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  sales_with_seg['건수별평균이용금액_오프라인_B0M'] = np.where(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 이용개월수/이용금액/이용건수 - 페이_온라인/오프라인"
      ],
      "metadata": {
        "id": "Ek_cum-euVfJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 건수별평균이용금액 변수 생성\n",
        "\n",
        "# R6M (최근 6개월)\n",
        "sales_with_seg['건수별평균이용금액_페이_온라인_R6M'] = np.where(\n",
        "    (sales_with_seg['이용금액_페이_온라인_R6M'] == 0) | (sales_with_seg['이용건수_페이_온라인_R6M'] == 0),\n",
        "    0,\n",
        "    sales_with_seg['이용금액_페이_온라인_R6M'] / sales_with_seg['이용건수_페이_온라인_R6M'].abs()\n",
        ")\n",
        "\n",
        "sales_with_seg['건수별평균이용금액_페이_오프라인_R6M'] = np.where(\n",
        "    (sales_with_seg['이용금액_페이_오프라인_R6M'] == 0) | (sales_with_seg['이용건수_페이_오프라인_R6M'] == 0),\n",
        "    0,\n",
        "    sales_with_seg['이용금액_페이_오프라인_R6M'] / sales_with_seg['이용건수_페이_오프라인_R6M'].abs()\n",
        ")\n",
        "\n",
        "# R3M (최근 3개월)\n",
        "sales_with_seg['건수별평균이용금액_페이_온라인_R3M'] = np.where(\n",
        "    (sales_with_seg['이용금액_페이_온라인_R3M'] == 0) | (sales_with_seg['이용건수_페이_온라인_R3M'] == 0),\n",
        "    0,\n",
        "    sales_with_seg['이용금액_페이_온라인_R3M'] / sales_with_seg['이용건수_페이_온라인_R3M'].abs()\n",
        ")\n",
        "\n",
        "sales_with_seg['건수별평균이용금액_페이_오프라인_R3M'] = np.where(\n",
        "    (sales_with_seg['이용금액_페이_오프라인_R3M'] == 0) | (sales_with_seg['이용건수_페이_오프라인_R3M'] == 0),\n",
        "    0,\n",
        "    sales_with_seg['이용금액_페이_오프라인_R3M'] / sales_with_seg['이용건수_페이_오프라인_R3M'].abs()\n",
        ")\n",
        "\n",
        "# B0M (당월)\n",
        "sales_with_seg['건수별평균이용금액_페이_온라인_B0M'] = np.where(\n",
        "    (sales_with_seg['이용금액_페이_온라인_B0M'] == 0) | (sales_with_seg['이용건수_페이_온라인_B0M'] == 0),\n",
        "    0,\n",
        "    sales_with_seg['이용금액_페이_온라인_B0M'] / sales_with_seg['이용건수_페이_온라인_B0M'].abs()\n",
        ")\n",
        "\n",
        "sales_with_seg['건수별평균이용금액_페이_오프라인_B0M'] = np.where(\n",
        "    (sales_with_seg['이용금액_페이_오프라인_B0M'] == 0) | (sales_with_seg['이용건수_페이_오프라인_B0M'] == 0),\n",
        "    0,\n",
        "    sales_with_seg['이용금액_페이_오프라인_B0M'] / sales_with_seg['이용건수_페이_오프라인_B0M'].abs()\n",
        ")"
      ],
      "metadata": {
        "id": "cWhBrw4TuVfJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d241a5dd-ba9b-4f52-8e35-c0d15f0ccaf1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-124-1b4362d6e054>:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  sales_with_seg['건수별평균이용금액_페이_온라인_R6M'] = np.where(\n",
            "<ipython-input-124-1b4362d6e054>:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  sales_with_seg['건수별평균이용금액_페이_오프라인_R6M'] = np.where(\n",
            "<ipython-input-124-1b4362d6e054>:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  sales_with_seg['건수별평균이용금액_페이_온라인_R3M'] = np.where(\n",
            "<ipython-input-124-1b4362d6e054>:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  sales_with_seg['건수별평균이용금액_페이_오프라인_R3M'] = np.where(\n",
            "<ipython-input-124-1b4362d6e054>:30: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  sales_with_seg['건수별평균이용금액_페이_온라인_B0M'] = np.where(\n",
            "<ipython-input-124-1b4362d6e054>:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  sales_with_seg['건수별평균이용금액_페이_오프라인_B0M'] = np.where(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 이용개월수/이용금액/이용건수 - 간편결제/당사페이/당사기타/A,B,C,D페이"
      ],
      "metadata": {
        "id": "FgFgPakauVfJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- R6M"
      ],
      "metadata": {
        "id": "z_W9Ld_9uVfK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터 동일한 변수 5개 삭제\n",
        "columns_drop = ['이용개월수_당사페이_R6M',\n",
        "                '이용금액_당사페이_R6M',\n",
        "                '이용금액_당사기타_R6M',\n",
        "                '이용건수_당사페이_R6M',\n",
        "                '이용건수_당사기타_R6M']\n",
        "sales_with_seg.drop(columns=columns_drop, inplace=True)"
      ],
      "metadata": {
        "id": "YGAcQH7auVfK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 건수별평균이용금액 변수 5개 생성 (R6M 기준)\n",
        "\n",
        "# 간편결제\n",
        "sales_with_seg['건수별평균이용금액_간편결제_R6M'] = np.where(\n",
        "    (sales_with_seg['이용금액_간편결제_R6M'] == 0) | (sales_with_seg['이용건수_간편결제_R6M'] == 0),\n",
        "    0,\n",
        "    sales_with_seg['이용금액_간편결제_R6M'] / sales_with_seg['이용건수_간편결제_R6M'].abs()\n",
        ")\n",
        "\n",
        "# A페이\n",
        "sales_with_seg['건수별평균이용금액_A페이_R6M'] = np.where(\n",
        "    (sales_with_seg['이용금액_A페이_R6M'] == 0) | (sales_with_seg['이용건수_A페이_R6M'] == 0),\n",
        "    0,\n",
        "    sales_with_seg['이용금액_A페이_R6M'] / sales_with_seg['이용건수_A페이_R6M'].abs()\n",
        ")\n",
        "\n",
        "# B페이\n",
        "sales_with_seg['건수별평균이용금액_B페이_R6M'] = np.where(\n",
        "    (sales_with_seg['이용금액_B페이_R6M'] == 0) | (sales_with_seg['이용건수_B페이_R6M'] == 0),\n",
        "    0,\n",
        "    sales_with_seg['이용금액_B페이_R6M'] / sales_with_seg['이용건수_B페이_R6M'].abs()\n",
        ")\n",
        "\n",
        "# C페이\n",
        "sales_with_seg['건수별평균이용금액_C페이_R6M'] = np.where(\n",
        "    (sales_with_seg['이용금액_C페이_R6M'] == 0) | (sales_with_seg['이용건수_C페이_R6M'] == 0),\n",
        "    0,\n",
        "    sales_with_seg['이용금액_C페이_R6M'] / sales_with_seg['이용건수_C페이_R6M'].abs()\n",
        ")\n",
        "\n",
        "# D페이\n",
        "sales_with_seg['건수별평균이용금액_D페이_R6M'] = np.where(\n",
        "    (sales_with_seg['이용금액_D페이_R6M'] == 0) | (sales_with_seg['이용건수_D페이_R6M'] == 0),\n",
        "    0,\n",
        "    sales_with_seg['이용금액_D페이_R6M'] / sales_with_seg['이용건수_D페이_R6M'].abs()\n",
        ")"
      ],
      "metadata": {
        "id": "dgxtnPq5uVfK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7dc4ed71-c367-428f-9bff-f202901f5154"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-126-154095dbc84a>:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  sales_with_seg['건수별평균이용금액_간편결제_R6M'] = np.where(\n",
            "<ipython-input-126-154095dbc84a>:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  sales_with_seg['건수별평균이용금액_A페이_R6M'] = np.where(\n",
            "<ipython-input-126-154095dbc84a>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  sales_with_seg['건수별평균이용금액_B페이_R6M'] = np.where(\n",
            "<ipython-input-126-154095dbc84a>:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  sales_with_seg['건수별평균이용금액_C페이_R6M'] = np.where(\n",
            "<ipython-input-126-154095dbc84a>:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  sales_with_seg['건수별평균이용금액_D페이_R6M'] = np.where(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- R3M"
      ],
      "metadata": {
        "id": "mKpoOr1OuVfK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터 동일한 변수 4개 삭제\n",
        "columns_drop = ['이용금액_당사페이_R3M',\n",
        "                '이용금액_당사기타_R3M',\n",
        "                '이용건수_당사페이_R3M',\n",
        "                '이용건수_당사기타_R3M']\n",
        "sales_with_seg.drop(columns=columns_drop, inplace=True)"
      ],
      "metadata": {
        "id": "CeDlbYpFuVfK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 건수별평균이용금액 변수 5개 생성 (R3M 기준)\n",
        "\n",
        "# 간편결제\n",
        "sales_with_seg['건수별평균이용금액_간편결제_R3M'] = np.where(\n",
        "    (sales_with_seg['이용금액_간편결제_R3M'] == 0) | (sales_with_seg['이용건수_간편결제_R3M'] == 0),\n",
        "    0,\n",
        "    sales_with_seg['이용금액_간편결제_R3M'] / sales_with_seg['이용건수_간편결제_R3M'].abs()\n",
        ")\n",
        "\n",
        "# A페이\n",
        "sales_with_seg['건수별평균이용금액_A페이_R3M'] = np.where(\n",
        "    (sales_with_seg['이용금액_A페이_R3M'] == 0) | (sales_with_seg['이용건수_A페이_R3M'] == 0),\n",
        "    0,\n",
        "    sales_with_seg['이용금액_A페이_R3M'] / sales_with_seg['이용건수_A페이_R3M'].abs()\n",
        ")\n",
        "\n",
        "# B페이\n",
        "sales_with_seg['건수별평균이용금액_B페이_R3M'] = np.where(\n",
        "    (sales_with_seg['이용금액_B페이_R3M'] == 0) | (sales_with_seg['이용건수_B페이_R3M'] == 0),\n",
        "    0,\n",
        "    sales_with_seg['이용금액_B페이_R3M'] / sales_with_seg['이용건수_B페이_R3M'].abs()\n",
        ")\n",
        "\n",
        "# C페이\n",
        "sales_with_seg['건수별평균이용금액_C페이_R3M'] = np.where(\n",
        "    (sales_with_seg['이용금액_C페이_R3M'] == 0) | (sales_with_seg['이용건수_C페이_R3M'] == 0),\n",
        "    0,\n",
        "    sales_with_seg['이용금액_C페이_R3M'] / sales_with_seg['이용건수_C페이_R3M'].abs()\n",
        ")\n",
        "\n",
        "# D페이\n",
        "sales_with_seg['건수별평균이용금액_D페이_R3M'] = np.where(\n",
        "    (sales_with_seg['이용금액_D페이_R3M'] == 0) | (sales_with_seg['이용건수_D페이_R3M'] == 0),\n",
        "    0,\n",
        "    sales_with_seg['이용금액_D페이_R3M'] / sales_with_seg['이용건수_D페이_R3M'].abs()\n",
        ")"
      ],
      "metadata": {
        "id": "EGFVKlbFuVfK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "db47bcd0-116f-42a7-ac6e-47567d104d14"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-128-c3a97c739420>:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  sales_with_seg['건수별평균이용금액_간편결제_R3M'] = np.where(\n",
            "<ipython-input-128-c3a97c739420>:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  sales_with_seg['건수별평균이용금액_A페이_R3M'] = np.where(\n",
            "<ipython-input-128-c3a97c739420>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  sales_with_seg['건수별평균이용금액_B페이_R3M'] = np.where(\n",
            "<ipython-input-128-c3a97c739420>:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  sales_with_seg['건수별평균이용금액_C페이_R3M'] = np.where(\n",
            "<ipython-input-128-c3a97c739420>:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  sales_with_seg['건수별평균이용금액_D페이_R3M'] = np.where(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- B0M"
      ],
      "metadata": {
        "id": "W1Gh9kFmuVfK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터 동일한 변수 4개 삭제\n",
        "columns_drop = ['이용금액_당사페이_B0M',\n",
        "                '이용금액_당사기타_B0M',\n",
        "                '이용건수_당사페이_B0M',\n",
        "                '이용건수_당사기타_B0M']\n",
        "sales_with_seg.drop(columns=columns_drop, inplace=True)"
      ],
      "metadata": {
        "id": "OWtCY706uVfL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 건수별평균이용금액 변수 5개 생성 (B0M 기준)\n",
        "\n",
        "# 간편결제\n",
        "sales_with_seg['건수별평균이용금액_간편결제_B0M'] = np.where(\n",
        "    (sales_with_seg['이용금액_간편결제_B0M'] == 0) | (sales_with_seg['이용건수_간편결제_B0M'] == 0),\n",
        "    0,\n",
        "    sales_with_seg['이용금액_간편결제_B0M'] / sales_with_seg['이용건수_간편결제_B0M'].abs()\n",
        ")\n",
        "\n",
        "# A페이\n",
        "sales_with_seg['건수별평균이용금액_A페이_B0M'] = np.where(\n",
        "    (sales_with_seg['이용금액_A페이_B0M'] == 0) | (sales_with_seg['이용건수_A페이_B0M'] == 0),\n",
        "    0,\n",
        "    sales_with_seg['이용금액_A페이_B0M'] / sales_with_seg['이용건수_A페이_B0M'].abs()\n",
        ")\n",
        "\n",
        "# B페이\n",
        "sales_with_seg['건수별평균이용금액_B페이_B0M'] = np.where(\n",
        "    (sales_with_seg['이용금액_B페이_B0M'] == 0) | (sales_with_seg['이용건수_B페이_B0M'] == 0),\n",
        "    0,\n",
        "    sales_with_seg['이용금액_B페이_B0M'] / sales_with_seg['이용건수_B페이_B0M'].abs()\n",
        ")\n",
        "\n",
        "# C페이\n",
        "sales_with_seg['건수별평균이용금액_C페이_B0M'] = np.where(\n",
        "    (sales_with_seg['이용금액_C페이_B0M'] == 0) | (sales_with_seg['이용건수_C페이_B0M'] == 0),\n",
        "    0,\n",
        "    sales_with_seg['이용금액_C페이_B0M'] / sales_with_seg['이용건수_C페이_B0M'].abs()\n",
        ")\n",
        "\n",
        "# D페이\n",
        "sales_with_seg['건수별평균이용금액_D페이_B0M'] = np.where(\n",
        "    (sales_with_seg['이용금액_D페이_B0M'] == 0) | (sales_with_seg['이용건수_D페이_B0M'] == 0),\n",
        "    0,\n",
        "    sales_with_seg['이용금액_D페이_B0M'] / sales_with_seg['이용건수_D페이_B0M'].abs()\n",
        ")"
      ],
      "metadata": {
        "id": "nXBvlsoHuVfL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "27f94d76-cfe5-466c-9066-47dadfcf1dd9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-130-51b69cc8c592>:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  sales_with_seg['건수별평균이용금액_간편결제_B0M'] = np.where(\n",
            "<ipython-input-130-51b69cc8c592>:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  sales_with_seg['건수별평균이용금액_A페이_B0M'] = np.where(\n",
            "<ipython-input-130-51b69cc8c592>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  sales_with_seg['건수별평균이용금액_B페이_B0M'] = np.where(\n",
            "<ipython-input-130-51b69cc8c592>:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  sales_with_seg['건수별평균이용금액_C페이_B0M'] = np.where(\n",
            "<ipython-input-130-51b69cc8c592>:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  sales_with_seg['건수별평균이용금액_D페이_B0M'] = np.where(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 선결제"
      ],
      "metadata": {
        "id": "Ql9jWbuXuVfL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 횟수별/건수별 평균이용금액\n",
        "\n",
        "# R6M\n",
        "sales_with_seg['횟수별평균이용금액_선결제_R6M'] = np.where(\n",
        "    (sales_with_seg['이용금액_선결제_R6M'] == 0) | (sales_with_seg['이용횟수_선결제_R6M'] == 0),\n",
        "    0,\n",
        "    sales_with_seg['이용금액_선결제_R6M'] / sales_with_seg['이용횟수_선결제_R6M'].abs()\n",
        ")\n",
        "\n",
        "sales_with_seg['건수별평균이용금액_선결제_R6M'] = np.where(\n",
        "    (sales_with_seg['이용금액_선결제_R6M'] == 0) | (sales_with_seg['이용건수_선결제_R6M'] == 0),\n",
        "    0,\n",
        "    sales_with_seg['이용금액_선결제_R6M'] / sales_with_seg['이용건수_선결제_R6M'].abs()\n",
        ")\n",
        "\n",
        "# R3M\n",
        "sales_with_seg['횟수별평균이용금액_선결제_R3M'] = np.where(\n",
        "    (sales_with_seg['이용금액_선결제_R3M'] == 0) | (sales_with_seg['이용횟수_선결제_R3M'] == 0),\n",
        "    0,\n",
        "    sales_with_seg['이용금액_선결제_R3M'] / sales_with_seg['이용횟수_선결제_R3M'].abs()\n",
        ")\n",
        "\n",
        "sales_with_seg['건수별평균이용금액_선결제_R3M'] = np.where(\n",
        "    (sales_with_seg['이용금액_선결제_R3M'] == 0) | (sales_with_seg['이용건수_선결제_R3M'] == 0),\n",
        "    0,\n",
        "    sales_with_seg['이용금액_선결제_R3M'] / sales_with_seg['이용건수_선결제_R3M'].abs()\n",
        ")\n",
        "\n",
        "# B0M\n",
        "sales_with_seg['횟수별평균이용금액_선결제_B0M'] = np.where(\n",
        "    (sales_with_seg['이용금액_선결제_B0M'] == 0) | (sales_with_seg['이용횟수_선결제_B0M'] == 0),\n",
        "    0,\n",
        "    sales_with_seg['이용금액_선결제_B0M'] / sales_with_seg['이용횟수_선결제_B0M'].abs()\n",
        ")\n",
        "\n",
        "sales_with_seg['건수별평균이용금액_선결제_B0M'] = np.where(\n",
        "    (sales_with_seg['이용금액_선결제_B0M'] == 0) | (sales_with_seg['이용건수_선결제_B0M'] == 0),\n",
        "    0,\n",
        "    sales_with_seg['이용금액_선결제_B0M'] / sales_with_seg['이용건수_선결제_B0M'].abs()\n",
        ")"
      ],
      "metadata": {
        "id": "7CM6DdquuVfL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "238dc383-4690-4f2d-a955-a6857af4cd70"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-131-f74a7dbb1d59>:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  sales_with_seg['횟수별평균이용금액_선결제_R6M'] = np.where(\n",
            "<ipython-input-131-f74a7dbb1d59>:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  sales_with_seg['건수별평균이용금액_선결제_R6M'] = np.where(\n",
            "<ipython-input-131-f74a7dbb1d59>:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  sales_with_seg['횟수별평균이용금액_선결제_R3M'] = np.where(\n",
            "<ipython-input-131-f74a7dbb1d59>:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  sales_with_seg['건수별평균이용금액_선결제_R3M'] = np.where(\n",
            "<ipython-input-131-f74a7dbb1d59>:30: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  sales_with_seg['횟수별평균이용금액_선결제_B0M'] = np.where(\n",
            "<ipython-input-131-f74a7dbb1d59>:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  sales_with_seg['건수별평균이용금액_선결제_B0M'] = np.where(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 연체"
      ],
      "metadata": {
        "id": "zrXqWCX-uVfL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 횟수별평균이용금액 변수 생성\n",
        "\n",
        "# R6M\n",
        "sales_with_seg['횟수별평균이용금액_연체_R6M'] = np.where(\n",
        "    (sales_with_seg['이용금액_연체_R6M'] == 0) | (sales_with_seg['이용횟수_연체_R6M'] == 0),\n",
        "    0,\n",
        "    sales_with_seg['이용금액_연체_R6M'] / sales_with_seg['이용횟수_연체_R6M'].abs()\n",
        ")\n",
        "\n",
        "# R3M\n",
        "sales_with_seg['횟수별평균이용금액_연체_R3M'] = np.where(\n",
        "    (sales_with_seg['이용금액_연체_R3M'] == 0) | (sales_with_seg['이용횟수_연체_R3M'] == 0),\n",
        "    0,\n",
        "    sales_with_seg['이용금액_연체_R3M'] / sales_with_seg['이용횟수_연체_R3M'].abs()\n",
        ")\n",
        "\n",
        "# B0M\n",
        "sales_with_seg['횟수별평균이용금액_연체_B0M'] = np.where(\n",
        "    (sales_with_seg['이용금액_연체_B0M'] == 0) | (sales_with_seg['이용횟수_연체_B0M'] == 0),\n",
        "    0,\n",
        "    sales_with_seg['이용금액_연체_B0M'] / sales_with_seg['이용횟수_연체_B0M'].abs()\n",
        ")"
      ],
      "metadata": {
        "id": "YnA7hjbRuVfL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "57a40c44-cbac-4044-e448-08bda61664d6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-132-d7558ba4bb37>:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  sales_with_seg['횟수별평균이용금액_연체_R6M'] = np.where(\n",
            "<ipython-input-132-d7558ba4bb37>:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  sales_with_seg['횟수별평균이용금액_연체_R3M'] = np.where(\n",
            "<ipython-input-132-d7558ba4bb37>:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  sales_with_seg['횟수별평균이용금액_연체_B0M'] = np.where(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 입금원금 관련 변수"
      ],
      "metadata": {
        "id": "e73QzOQ-uVfL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 총납부금 변수 및 납부비율 변수 생성\n",
        "for month in ['B0M', 'B2M', 'B5M']:\n",
        "    sales_with_seg[f'총납부금_{month}'] = (\n",
        "        sales_with_seg[f'선입금원금_{month}'] +\n",
        "        sales_with_seg[f'정상입금원금_{month}'] +\n",
        "        sales_with_seg[f'연체입금원금_{month}']\n",
        "    )\n",
        "\n",
        "    sales_with_seg[f'납부비율_{month}'] = np.where(\n",
        "        sales_with_seg[f'정상청구원금_{month}'] == 0,\n",
        "        0,\n",
        "        sales_with_seg[f'총납부금_{month}'] / sales_with_seg[f'정상청구원금_{month}']\n",
        "    )"
      ],
      "metadata": {
        "id": "wF6uAJOouVfM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2e5b019f-41a2-4065-8780-67ede31ca5de"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-133-a792eb1a16b8>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  sales_with_seg[f'총납부금_{month}'] = (\n",
            "<ipython-input-133-a792eb1a16b8>:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  sales_with_seg[f'납부비율_{month}'] = np.where(\n",
            "<ipython-input-133-a792eb1a16b8>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  sales_with_seg[f'총납부금_{month}'] = (\n",
            "<ipython-input-133-a792eb1a16b8>:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  sales_with_seg[f'납부비율_{month}'] = np.where(\n",
            "<ipython-input-133-a792eb1a16b8>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  sales_with_seg[f'총납부금_{month}'] = (\n",
            "<ipython-input-133-a792eb1a16b8>:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  sales_with_seg[f'납부비율_{month}'] = np.where(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 정시납부금 및 정시납부비율 변수 생성\n",
        "for month in ['B0M', 'B2M', 'B5M']:\n",
        "    sales_with_seg[f'정시납부금_{month}'] = (\n",
        "        sales_with_seg[f'선입금원금_{month}'] +\n",
        "        sales_with_seg[f'정상입금원금_{month}']\n",
        "    )\n",
        "\n",
        "    sales_with_seg[f'정시납부비율_{month}'] = np.where(\n",
        "        sales_with_seg[f'정상청구원금_{month}'] == 0,\n",
        "        0,\n",
        "        sales_with_seg[f'정시납부금_{month}'] / sales_with_seg[f'정상청구원금_{month}']\n",
        "    )"
      ],
      "metadata": {
        "id": "sgubg_EvuVfM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ddefb159-17fd-471a-c597-41d562d87cab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-134-d151c7f70dda>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  sales_with_seg[f'정시납부금_{month}'] = (\n",
            "<ipython-input-134-d151c7f70dda>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  sales_with_seg[f'정시납부비율_{month}'] = np.where(\n",
            "<ipython-input-134-d151c7f70dda>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  sales_with_seg[f'정시납부금_{month}'] = (\n",
            "<ipython-input-134-d151c7f70dda>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  sales_with_seg[f'정시납부비율_{month}'] = np.where(\n",
            "<ipython-input-134-d151c7f70dda>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  sales_with_seg[f'정시납부금_{month}'] = (\n",
            "<ipython-input-134-d151c7f70dda>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  sales_with_seg[f'정시납부비율_{month}'] = np.where(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 건수 관련 변수 등"
      ],
      "metadata": {
        "id": "yTpPh1PbuVfM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 건수별평균금액 변수 만들기\n",
        "# R6M\n",
        "sales_with_seg['건수별평균금액_할부전환_R6M'] = np.where(\n",
        "    (sales_with_seg['금액_할부전환_R6M'] == 0) | (sales_with_seg['건수_할부전환_R6M'] == 0),\n",
        "    0,\n",
        "    sales_with_seg['금액_할부전환_R6M'] / sales_with_seg['건수_할부전환_R6M'].abs()\n",
        ")\n",
        "\n",
        "# R3M\n",
        "sales_with_seg['건수별평균금액_할부전환_R3M'] = np.where(\n",
        "    (sales_with_seg['금액_할부전환_R3M'] == 0) | (sales_with_seg['건수_할부전환_R3M'] == 0),\n",
        "    0,\n",
        "    sales_with_seg['금액_할부전환_R3M'] / sales_with_seg['건수_할부전환_R3M'].abs()\n",
        ")"
      ],
      "metadata": {
        "id": "QtMV5OVOuVfM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8b9a278c-9c78-486e-f42b-a5d5807f93e1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-135-a4a144698f85>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  sales_with_seg['건수별평균금액_할부전환_R6M'] = np.where(\n",
            "<ipython-input-135-a4a144698f85>:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  sales_with_seg['건수별평균금액_할부전환_R3M'] = np.where(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 파일 저장: sales_test_cleaned (600000, 523)"
      ],
      "metadata": {
        "id": "NSXdcHrlufL-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sales_with_seg.to_parquet(\"/content/drive/MyDrive/Dacon/sales_test_cleaned.parquet\")"
      ],
      "metadata": {
        "id": "2cy06CAvmcaI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 청구입금정보 (billing)"
      ],
      "metadata": {
        "id": "lGSTmyKLIAKS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Google Drive에 있는 데이터 경로\n",
        "base_dir = \"/content/drive/MyDrive/Data\"\n",
        "\n",
        "# 데이터 분할(폴더) 구분\n",
        "data_splits = [\"test\"]\n",
        "\n",
        "# 각 데이터 유형별 폴더명, 파일 접미사, 변수 접두어 설정\n",
        "data_categories = {\n",
        "    \"청구정보\": {\"folder\": \"4.청구입금정보\", \"suffix\": \"청구정보\", \"var_prefix\": \"billing\"}\n",
        "}\n",
        "\n",
        "# 2018년 7월부터 12월까지의 월 리스트\n",
        "months = ['07', '08', '09', '10', '11', '12']\n",
        "\n",
        "for split in data_splits:\n",
        "    for category, info in data_categories.items():\n",
        "        folder = info[\"folder\"]\n",
        "        suffix = info[\"suffix\"]\n",
        "        var_prefix = info[\"var_prefix\"]\n",
        "\n",
        "        for month in months:\n",
        "            # 파일명 형식: 2018{month}_{split}_{suffix}.parquet\n",
        "            file_path = f\"{base_dir}/{split}/{folder}/2018{month}_{split}_{suffix}.parquet\"\n",
        "            # 변수명 형식: {var_prefix}_{split}_{month}\n",
        "            variable_name = f\"{var_prefix}_{split}_{month}\"\n",
        "            globals()[variable_name] = pd.read_parquet(file_path)\n",
        "            print(f\"{variable_name} is loaded from {file_path}\")\n",
        "\n",
        "gc.collect()"
      ],
      "metadata": {
        "id": "EJvIxh_1UD9U",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "83dbd375-78c0-41d5-a823-c7c128cbe6b1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "billing_test_07 is loaded from /content/drive/MyDrive/Data/test/4.청구입금정보/201807_test_청구정보.parquet\n",
            "billing_test_08 is loaded from /content/drive/MyDrive/Data/test/4.청구입금정보/201808_test_청구정보.parquet\n",
            "billing_test_09 is loaded from /content/drive/MyDrive/Data/test/4.청구입금정보/201809_test_청구정보.parquet\n",
            "billing_test_10 is loaded from /content/drive/MyDrive/Data/test/4.청구입금정보/201810_test_청구정보.parquet\n",
            "billing_test_11 is loaded from /content/drive/MyDrive/Data/test/4.청구입금정보/201811_test_청구정보.parquet\n",
            "billing_test_12 is loaded from /content/drive/MyDrive/Data/test/4.청구입금정보/201812_test_청구정보.parquet\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 137
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "outputId": "964112d9-dceb-4804-e9b9-7d6f69f23321",
        "id": "m_4OY7WAIrhh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "billing_test_df is created with shape: (600000, 46)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 138
        }
      ],
      "source": [
        "# 데이터 유형별 설정\n",
        "info_categories = [\"billing\"]\n",
        "\n",
        "# 월 설정\n",
        "months = ['07', '08', '09', '10', '11', '12']\n",
        "\n",
        "# test 데이터에 대해 train과 동일한 방법 적용\n",
        "test_dfs = {}\n",
        "\n",
        "for prefix in info_categories:\n",
        "    df_list = [globals()[f\"{prefix}_test_{month}\"] for month in months]\n",
        "    test_dfs[f\"{prefix}_test_df\"] = pd.concat(df_list, axis=0)\n",
        "    gc.collect()\n",
        "    print(f\"{prefix}_test_df is created with shape: {test_dfs[f'{prefix}_test_df'].shape}\")\n",
        "\n",
        "billing_test_df  = test_dfs[\"billing_test_df\"]\n",
        "\n",
        "gc.collect()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# test 데이터에 대해 train과 동일한 방법 적용\n",
        "billing_test_df['대표결제일_10여부'] = np.where(billing_test_df['대표결제일'] == 10, 1, 0)\n",
        "billing_test_df['대표결제일_21여부'] = np.where(billing_test_df['대표결제일'] == 21, 1, 0)\n",
        "billing_test_df = billing_test_df.drop(['대표결제일'], axis=1)\n",
        "billing_test_df['청구서수령방법_당사멤버십여부'] = np.where(billing_test_df['청구서수령방법'] == '당사멤버십', 1, 0)\n",
        "billing_test_df = billing_test_df.drop(['청구서수령방법'], axis=1)\n",
        "billing_test_df = billing_test_df.drop(['대표결제방법코드', '대표청구서수령지구분코드', '대표청구지고객주소구분코드', '청구서발송여부_B0',\n",
        "                                        '청구서발송여부_R3M', '청구서발송여부_R6M'], axis=1)\n",
        "billing_test_df['할인건수_R3M'] = billing_test_df['할인건수_R3M'].map({'1회 이상': 0, '10회 이상': 1, '20회 이상': 2,'30회 이상': 3, '40회 이상': 4})\n",
        "billing_test_df['할인건수_B0M'] = billing_test_df['할인건수_B0M'].map({'1회 이상': 0, '10회 이상': 1})"
      ],
      "metadata": {
        "id": "P8MKTL6LI3Or"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "billing_test_df.to_parquet(\"/content/drive/MyDrive/Dacon/billing_test_cleaned.parquet\")"
      ],
      "metadata": {
        "id": "VypChtcxmtU9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 잔액정보 (balance)"
      ],
      "metadata": {
        "id": "KGFGRkYlIEhP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Google Drive에 있는 데이터 경로\n",
        "base_dir = \"/content/drive/MyDrive/Data\"\n",
        "\n",
        "# 데이터 분할(폴더) 구분\n",
        "data_splits = [\"test\"]\n",
        "\n",
        "# 각 데이터 유형별 폴더명, 파일 접미사, 변수 접두어 설정\n",
        "data_categories = {\n",
        "    \"잔액정보\": {\"folder\": \"5.잔액정보\", \"suffix\": \"잔액정보\", \"var_prefix\": \"balance\"}\n",
        "    }\n",
        "\n",
        "# 2018년 7월부터 12월까지의 월 리스트\n",
        "months = ['07', '08', '09', '10', '11', '12']\n",
        "\n",
        "for split in data_splits:\n",
        "    for category, info in data_categories.items():\n",
        "        folder = info[\"folder\"]\n",
        "        suffix = info[\"suffix\"]\n",
        "        var_prefix = info[\"var_prefix\"]\n",
        "\n",
        "        for month in months:\n",
        "            # 파일명 형식: 2018{month}_{split}_{suffix}.parquet\n",
        "            file_path = f\"{base_dir}/{split}/{folder}/2018{month}_{split}_{suffix}.parquet\"\n",
        "            # 변수명 형식: {var_prefix}_{split}_{month}\n",
        "            variable_name = f\"{var_prefix}_{split}_{month}\"\n",
        "            globals()[variable_name] = pd.read_parquet(file_path)\n",
        "            print(f\"{variable_name} is loaded from {file_path}\")\n",
        "\n",
        "gc.collect()"
      ],
      "metadata": {
        "id": "Om9kv2QYUPJZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f898d8b7-467a-454c-d767-453c7d806987"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "balance_test_07 is loaded from /content/drive/MyDrive/Data/test/5.잔액정보/201807_test_잔액정보.parquet\n",
            "balance_test_08 is loaded from /content/drive/MyDrive/Data/test/5.잔액정보/201808_test_잔액정보.parquet\n",
            "balance_test_09 is loaded from /content/drive/MyDrive/Data/test/5.잔액정보/201809_test_잔액정보.parquet\n",
            "balance_test_10 is loaded from /content/drive/MyDrive/Data/test/5.잔액정보/201810_test_잔액정보.parquet\n",
            "balance_test_11 is loaded from /content/drive/MyDrive/Data/test/5.잔액정보/201811_test_잔액정보.parquet\n",
            "balance_test_12 is loaded from /content/drive/MyDrive/Data/test/5.잔액정보/201812_test_잔액정보.parquet\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 141
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "outputId": "0edcb66b-9868-4d4b-bd80-00fa66b5d49f",
        "id": "GyD8x9Z2IsZB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "balance_test_df is created with shape: (600000, 82)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 142
        }
      ],
      "source": [
        "# 데이터 유형별 설정\n",
        "info_categories = [\"balance\"]\n",
        "\n",
        "# 월 설정\n",
        "months = ['07', '08', '09', '10', '11', '12']\n",
        "\n",
        "# test 데이터에 대해 train과 동일한 방법 적용\n",
        "test_dfs = {}\n",
        "\n",
        "for prefix in info_categories:\n",
        "    df_list = [globals()[f\"{prefix}_test_{month}\"] for month in months]\n",
        "    test_dfs[f\"{prefix}_test_df\"] = pd.concat(df_list, axis=0)\n",
        "    gc.collect()\n",
        "    print(f\"{prefix}_test_df is created with shape: {test_dfs[f'{prefix}_test_df'].shape}\")\n",
        "\n",
        "balance_test_df  = test_dfs[\"balance_test_df\"]\n",
        "\n",
        "gc.collect()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# test 데이터에 대해 train과 동일한 방법 적용\n",
        "balance_test_df = balance_test_df.drop(['연체일자_B0M', '카드론잔액_최종경과월', '최종연체개월수_R15M', 'RV잔액이월횟수_R6M',\n",
        "                                        'RV잔액이월횟수_R3M', '연체잔액_일시불_해외_B0M', '연체잔액_RV일시불_해외_B0M', '연체잔액_할부_해외_B0M',\n",
        "                                        '연체잔액_CA_해외_B0M'], axis=1)\n",
        "balance_test_df['최종연체회차'] = balance_test_df['최종연체회차'].map({-99: 0, 0: 1})\n",
        "balance_test_df['연체일수_B1M'] = np.where(balance_test_df['연체일수_B1M'] == 1, 1, 0)\n",
        "balance_test_df['연체일수_B2M'] = np.where(balance_test_df['연체일수_B2M'] == 1, 1, 0)\n",
        "balance_test_df['연체일수_최근'] = np.where(balance_test_df['연체일수_최근'] == 1, 1, 0)"
      ],
      "metadata": {
        "id": "H1bpyS7eJCGE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "balance_test_df.to_parquet(\"/content/drive/MyDrive/Dacon/balance_test_cleaned.parquet\")"
      ],
      "metadata": {
        "id": "kJYedmsGm7GL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 채널정보 (channel)"
      ],
      "metadata": {
        "id": "MLU53AxJIHbl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Google Drive에 있는 데이터 경로\n",
        "base_dir = \"/content/drive/MyDrive/Data\"\n",
        "\n",
        "# 데이터 분할(폴더) 구분\n",
        "data_splits = [\"test\"]\n",
        "\n",
        "# 각 데이터 유형별 폴더명, 파일 접미사, 변수 접두어 설정\n",
        "data_categories = {\n",
        "    \"채널정보\": {\"folder\": \"6.채널정보\", \"suffix\": \"채널정보\", \"var_prefix\": \"channel\"}\n",
        "}\n",
        "\n",
        "# 2018년 7월부터 12월까지의 월 리스트\n",
        "months = ['07', '08', '09', '10', '11', '12']\n",
        "\n",
        "for split in data_splits:\n",
        "    for category, info in data_categories.items():\n",
        "        folder = info[\"folder\"]\n",
        "        suffix = info[\"suffix\"]\n",
        "        var_prefix = info[\"var_prefix\"]\n",
        "\n",
        "        for month in months:\n",
        "            # 파일명 형식: 2018{month}_{split}_{suffix}.parquet\n",
        "            file_path = f\"{base_dir}/{split}/{folder}/2018{month}_{split}_{suffix}.parquet\"\n",
        "            # 변수명 형식: {var_prefix}_{split}_{month}\n",
        "            variable_name = f\"{var_prefix}_{split}_{month}\"\n",
        "            globals()[variable_name] = pd.read_parquet(file_path)\n",
        "            print(f\"{variable_name} is loaded from {file_path}\")\n",
        "\n",
        "gc.collect()"
      ],
      "metadata": {
        "id": "BFxahYiuUY2E",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8e22c1da-b146-464f-a730-18f2fc4b00ed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "channel_test_07 is loaded from /content/drive/MyDrive/Data/test/6.채널정보/201807_test_채널정보.parquet\n",
            "channel_test_08 is loaded from /content/drive/MyDrive/Data/test/6.채널정보/201808_test_채널정보.parquet\n",
            "channel_test_09 is loaded from /content/drive/MyDrive/Data/test/6.채널정보/201809_test_채널정보.parquet\n",
            "channel_test_10 is loaded from /content/drive/MyDrive/Data/test/6.채널정보/201810_test_채널정보.parquet\n",
            "channel_test_11 is loaded from /content/drive/MyDrive/Data/test/6.채널정보/201811_test_채널정보.parquet\n",
            "channel_test_12 is loaded from /content/drive/MyDrive/Data/test/6.채널정보/201812_test_채널정보.parquet\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 145
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "outputId": "f49122b6-3c0e-4342-8bfa-ad367db85c6e",
        "id": "suIvVS3pItVV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "channel_test_df is created with shape: (600000, 105)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 146
        }
      ],
      "source": [
        "# 데이터 유형별 설정\n",
        "info_categories = [\"channel\"]\n",
        "\n",
        "# 월 설정\n",
        "months = ['07', '08', '09', '10', '11', '12']\n",
        "\n",
        "# test 데이터에 대해 train과 동일한 방법 적용\n",
        "test_dfs = {}\n",
        "\n",
        "for prefix in info_categories:\n",
        "    df_list = [globals()[f\"{prefix}_test_{month}\"] for month in months]\n",
        "    test_dfs[f\"{prefix}_test_df\"] = pd.concat(df_list, axis=0)\n",
        "    gc.collect()\n",
        "    print(f\"{prefix}_test_df is created with shape: {test_dfs[f'{prefix}_test_df'].shape}\")\n",
        "\n",
        "channel_test_df  = test_dfs[\"channel_test_df\"]\n",
        "\n",
        "gc.collect()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# test 데이터에 대해 train과 동일한 방법 적용\n",
        "channel_test_df = channel_test_df.drop(['인입횟수_금융_IB_R6M', '인입불만횟수_IB_R6M', '인입불만일수_IB_R6M', '인입불만월수_IB_R6M',\n",
        "                                        '인입불만횟수_IB_B0M', '인입불만일수_IB_B0M', 'IB문의건수_한도_B0M', 'IB문의건수_결제_B0M',\n",
        "                                        'IB문의건수_할부_B0M', 'IB문의건수_정보변경_B0M', 'IB문의건수_결제일변경_B0M', 'IB문의건수_명세서_B0M',\n",
        "                                        'IB문의건수_비밀번호_B0M', 'IB문의건수_SMS_B0M', 'IB문의건수_APP_B0M', 'IB문의건수_부대서비스_B0M',\n",
        "                                        'IB문의건수_포인트_B0M', 'IB문의건수_BL_B0M', 'IB문의건수_분실도난_B0M', 'IB문의건수_CA_B0M',\n",
        "                                        'IB상담건수_VOC_B0M', 'IB상담건수_VOC민원_B0M', 'IB상담건수_VOC불만_B0M', 'IB상담건수_금감원_B0M',\n",
        "                                        'IB문의건수_명세서_R6M', 'IB문의건수_APP_R6M', 'IB상담건수_VOC_R6M', 'IB상담건수_VOC민원_R6M',\n",
        "                                        'IB상담건수_VOC불만_R6M', 'IB상담건수_금감원_R6M', '불만제기건수_B0M', '불만제기건수_R12M',\n",
        "                                        '당사PAY_방문횟수_B0M', '당사PAY_방문횟수_R6M', '당사PAY_방문월수_R6M','인입불만후경과월_IB_R6M',\n",
        "                                        'OS구분코드'], axis=1)\n",
        "channel_test_df['인입횟수_ARS_R6M'] = channel_test_df['인입횟수_ARS_R6M'].map({'1회 이상': 0, '10회 이상': 1})\n",
        "channel_test_df['이용메뉴건수_ARS_R6M'] = channel_test_df['이용메뉴건수_ARS_R6M'].map({'1회 이상': 0, '10회 이상': 1, '20회 이상': 2, '30회 이상': 3})\n",
        "channel_test_df['방문횟수_PC_R6M'] = channel_test_df['방문횟수_PC_R6M'].map({'1회 이상': 0, '10회 이상': 1, '20회 이상': 2, '30회 이상': 3, '40회 이상': 4})\n",
        "channel_test_df['방문일수_PC_R6M'] = channel_test_df['방문일수_PC_R6M'].map({'1회 이상': 0, '10회 이상': 1, '20회 이상': 2, '30회 이상': 3})\n",
        "channel_test_df['방문횟수_앱_R6M'] = channel_test_df['방문횟수_앱_R6M'].map({'1회 이상': 0, '10회 이상': 1, '20회 이상': 2, '30회 이상': 3, '40회 이상': 4,\n",
        "                                                                   '50회 이상': 5, '60회 이상': 6, '70회 이상': 7, '80회 이상': 8})"
      ],
      "metadata": {
        "id": "w7ZSfcDAJKm0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "channel_test_df.to_parquet(\"/content/drive/MyDrive/Dacon/channel_test_cleaned.parquet\")"
      ],
      "metadata": {
        "id": "Cr96XeoTnbOJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 마케팅정보 (marketing)"
      ],
      "metadata": {
        "id": "Zp_J2JZcIagp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Google Drive에 있는 데이터 경로\n",
        "base_dir = \"/content/drive/MyDrive/Data\"\n",
        "\n",
        "# 데이터 분할(폴더) 구분\n",
        "data_splits = [\"test\"]\n",
        "\n",
        "# 각 데이터 유형별 폴더명, 파일 접미사, 변수 접두어 설정\n",
        "data_categories = {\n",
        "    \"마케팅정보\": {\"folder\": \"7.마케팅정보\", \"suffix\": \"마케팅정보\", \"var_prefix\": \"marketing\"}\n",
        "}\n",
        "\n",
        "# 2018년 7월부터 12월까지의 월 리스트\n",
        "months = ['07', '08', '09', '10', '11', '12']\n",
        "\n",
        "for split in data_splits:\n",
        "    for category, info in data_categories.items():\n",
        "        folder = info[\"folder\"]\n",
        "        suffix = info[\"suffix\"]\n",
        "        var_prefix = info[\"var_prefix\"]\n",
        "\n",
        "        for month in months:\n",
        "            # 파일명 형식: 2018{month}_{split}_{suffix}.parquet\n",
        "            file_path = f\"{base_dir}/{split}/{folder}/2018{month}_{split}_{suffix}.parquet\"\n",
        "            # 변수명 형식: {var_prefix}_{split}_{month}\n",
        "            variable_name = f\"{var_prefix}_{split}_{month}\"\n",
        "            globals()[variable_name] = pd.read_parquet(file_path)\n",
        "            print(f\"{variable_name} is loaded from {file_path}\")\n",
        "\n",
        "gc.collect()"
      ],
      "metadata": {
        "id": "QuROMTW2UlxP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ea95983c-910e-4d05-ede4-53a83e5b6d54"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "marketing_test_07 is loaded from /content/drive/MyDrive/Data/test/7.마케팅정보/201807_test_마케팅정보.parquet\n",
            "marketing_test_08 is loaded from /content/drive/MyDrive/Data/test/7.마케팅정보/201808_test_마케팅정보.parquet\n",
            "marketing_test_09 is loaded from /content/drive/MyDrive/Data/test/7.마케팅정보/201809_test_마케팅정보.parquet\n",
            "marketing_test_10 is loaded from /content/drive/MyDrive/Data/test/7.마케팅정보/201810_test_마케팅정보.parquet\n",
            "marketing_test_11 is loaded from /content/drive/MyDrive/Data/test/7.마케팅정보/201811_test_마케팅정보.parquet\n",
            "marketing_test_12 is loaded from /content/drive/MyDrive/Data/test/7.마케팅정보/201812_test_마케팅정보.parquet\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 149
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "outputId": "009db4c6-11a3-427f-f559-caf60cabae2e",
        "id": "YWry7cgeIuMw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "marketing_test_df is created with shape: (600000, 64)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 150
        }
      ],
      "source": [
        "# 데이터 유형별 설정\n",
        "info_categories = [\"marketing\"]\n",
        "\n",
        "# 월 설정\n",
        "months = ['07', '08', '09', '10', '11', '12']\n",
        "\n",
        "# test 데이터에 대해 train과 동일한 방법 적용\n",
        "test_dfs = {}\n",
        "\n",
        "for prefix in info_categories:\n",
        "    df_list = [globals()[f\"{prefix}_test_{month}\"] for month in months]\n",
        "    test_dfs[f\"{prefix}_test_df\"] = pd.concat(df_list, axis=0)\n",
        "    gc.collect()\n",
        "    print(f\"{prefix}_test_df is created with shape: {test_dfs[f'{prefix}_test_df'].shape}\")\n",
        "\n",
        "\n",
        "marketing_test_df= test_dfs[\"marketing_test_df\"]\n",
        "\n",
        "gc.collect()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# test 데이터에 대해 train과 동일한 방법 적용\n",
        "marketing_test_df['캠페인접촉건수_R12M'] = marketing_test_df['캠페인접촉건수_R12M'].map({'1회 이상': 0, '5회 이상': 1,\n",
        "                                                                           '10회 이상': 2,'15회 이상': 3, '20회 이상': 4, '25회 이상': 5})\n",
        "marketing_test_df['캠페인접촉일수_R12M'] = marketing_test_df['캠페인접촉일수_R12M'].map({'1일 이상': 0, '5일 이상': 1, '10일 이상': 2,\n",
        "                                                                           '15일 이상': 3, '20일 이상': 4})\n",
        "marketing_test_df = marketing_test_df.drop(['컨택건수_CA_TM_B0M', '컨택건수_포인트소진_TM_B0M', '컨택건수_CA_EM_B0M', '컨택건수_리볼빙_EM_B0M',\n",
        "                                            '컨택건수_리볼빙_청구서_B0M', '컨택건수_카드론_인터넷_B0M', '컨택건수_CA_인터넷_B0M', '컨택건수_리볼빙_인터넷_B0M',\n",
        "                                            '컨택건수_카드론_당사앱_B0M', '컨택건수_CA_당사앱_B0M', '컨택건수_리볼빙_당사앱_B0M', '컨택건수_CA_EM_R6M',\n",
        "                                            '컨택건수_리볼빙_EM_R6M', '컨택건수_리볼빙_청구서_R6M', '컨택건수_카드론_인터넷_R6M', '컨택건수_CA_인터넷_R6M',\n",
        "                                            '컨택건수_리볼빙_인터넷_R6M', '컨택건수_카드론_당사앱_R6M', '컨택건수_CA_당사앱_R6M', '컨택건수_리볼빙_당사앱_R6M',\n",
        "                                            '컨택건수_FDS_B0M', '컨택건수_FDS_R6M'], axis=1)"
      ],
      "metadata": {
        "id": "rLE9MFx-JR97"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "marketing_test_df.to_parquet(\"/content/drive/MyDrive/Dacon/marketing_test_cleaned.parquet\")"
      ],
      "metadata": {
        "id": "ISGlFe1JnpBY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 성과정보 (performance)"
      ],
      "metadata": {
        "id": "Suv5QAKMIagq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Google Drive에 있는 데이터 경로\n",
        "base_dir = \"/content/drive/MyDrive/Data\"\n",
        "\n",
        "# 데이터 분할(폴더) 구분\n",
        "data_splits = [\"test\"]\n",
        "\n",
        "# 각 데이터 유형별 폴더명, 파일 접미사, 변수 접두어 설정\n",
        "data_categories = {\n",
        "    \"성과정보\": {\"folder\": \"8.성과정보\", \"suffix\": \"성과정보\", \"var_prefix\": \"performance\"}\n",
        "}\n",
        "\n",
        "# 2018년 7월부터 12월까지의 월 리스트\n",
        "months = ['07', '08', '09', '10', '11', '12']\n",
        "\n",
        "for split in data_splits:\n",
        "    for category, info in data_categories.items():\n",
        "        folder = info[\"folder\"]\n",
        "        suffix = info[\"suffix\"]\n",
        "        var_prefix = info[\"var_prefix\"]\n",
        "\n",
        "        for month in months:\n",
        "            # 파일명 형식: 2018{month}_{split}_{suffix}.parquet\n",
        "            file_path = f\"{base_dir}/{split}/{folder}/2018{month}_{split}_{suffix}.parquet\"\n",
        "            # 변수명 형식: {var_prefix}_{split}_{month}\n",
        "            variable_name = f\"{var_prefix}_{split}_{month}\"\n",
        "            globals()[variable_name] = pd.read_parquet(file_path)\n",
        "            print(f\"{variable_name} is loaded from {file_path}\")\n",
        "\n",
        "gc.collect()"
      ],
      "metadata": {
        "id": "ffgQEg2WU5ue",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8542d652-6eb1-4b3c-9b89-ed0ce3115928"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "performance_test_07 is loaded from /content/drive/MyDrive/Data/test/8.성과정보/201807_test_성과정보.parquet\n",
            "performance_test_08 is loaded from /content/drive/MyDrive/Data/test/8.성과정보/201808_test_성과정보.parquet\n",
            "performance_test_09 is loaded from /content/drive/MyDrive/Data/test/8.성과정보/201809_test_성과정보.parquet\n",
            "performance_test_10 is loaded from /content/drive/MyDrive/Data/test/8.성과정보/201810_test_성과정보.parquet\n",
            "performance_test_11 is loaded from /content/drive/MyDrive/Data/test/8.성과정보/201811_test_성과정보.parquet\n",
            "performance_test_12 is loaded from /content/drive/MyDrive/Data/test/8.성과정보/201812_test_성과정보.parquet\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 153
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "outputId": "9035205f-95a6-4e70-fba2-a0772e68c858",
        "id": "ToA9u3MKIvOB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "performance_test_df is created with shape: (600000, 49)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 154
        }
      ],
      "source": [
        "# 데이터 유형별 설정\n",
        "info_categories = [\"performance\"]\n",
        "\n",
        "# 월 설정\n",
        "months = ['07', '08', '09', '10', '11', '12']\n",
        "\n",
        "# test 데이터에 대해 train과 동일한 방법 적용\n",
        "test_dfs = {}\n",
        "\n",
        "for prefix in info_categories:\n",
        "    df_list = [globals()[f\"{prefix}_test_{month}\"] for month in months]\n",
        "    test_dfs[f\"{prefix}_test_df\"] = pd.concat(df_list, axis=0)\n",
        "    gc.collect()\n",
        "    print(f\"{prefix}_test_df is created with shape: {test_dfs[f'{prefix}_test_df'].shape}\")\n",
        "\n",
        "performance_test_df = test_dfs[\"performance_test_df\"]\n",
        "\n",
        "gc.collect()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# test 데이터에 대해 train과 동일한 방법 적용\n",
        "performance_test_df[\"혜택수혜율_B0M\"] = performance_test_df[\"혜택수혜율_B0M\"].fillna(performance_test_df[\"혜택수혜율_B0M\"].median())\n",
        "performance_test_df[\"혜택수혜율_R3M\"] = performance_test_df[\"혜택수혜율_R3M\"].fillna(performance_test_df[\"혜택수혜율_R3M\"].median())"
      ],
      "metadata": {
        "id": "zDxV2fDcJYoj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "performance_test_df.to_parquet(\"/content/drive/MyDrive/Dacon/performance_test_cleaned.parquet\")"
      ],
      "metadata": {
        "id": "3lKG4gShoJ-A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Preprocessing(3) - concat & merge"
      ],
      "metadata": {
        "id": "w983dFctU8Yy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import gc\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "lBtBSrsssqUW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5e9468ba-5fa4-43cf-ad99-c3db249e571c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# train data\n",
        "customer_train_df = pd.read_parquet(\"/content/drive/MyDrive/Dacon/customer_train_cleaned.parquet\")\n",
        "credit_train_df = pd.read_parquet(\"/content/drive/MyDrive/Dacon/credit_train_cleaned.parquet\")\n",
        "sales_train_df = pd.read_parquet(\"/content/drive/MyDrive/Dacon/sales_train_cleaned.parquet\")\n",
        "billing_train_df = pd.read_parquet(\"/content/drive/MyDrive/Dacon/billing_train_cleaned.parquet\")\n",
        "balance_train_df = pd.read_parquet(\"/content/drive/MyDrive/Dacon/balance_train_cleaned.parquet\")\n",
        "channel_train_df = pd.read_parquet(\"/content/drive/MyDrive/Dacon/channel_train_cleaned.parquet\")\n",
        "marketing_train_df = pd.read_parquet(\"/content/drive/MyDrive/Dacon/marketing_train_cleaned.parquet\")\n",
        "performance_train_df = pd.read_parquet(\"/content/drive/MyDrive/Dacon/performance_train_cleaned.parquet\")"
      ],
      "metadata": {
        "id": "5ZT2VLT9VNiB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df = customer_train_df.merge(credit_train_df, on=['기준년월', 'ID'], how='left')\n",
        "train_df = train_df.merge(sales_train_df, on=['기준년월', 'ID'], how='left')\n",
        "train_df = train_df.merge(billing_train_df, on=['기준년월', 'ID'], how='left')\n",
        "train_df = train_df.merge(balance_train_df, on=['기준년월', 'ID'], how='left')\n",
        "train_df = train_df.merge(channel_train_df, on=['기준년월', 'ID'], how='left')\n",
        "train_df = train_df.merge(marketing_train_df, on=['기준년월', 'ID'], how='left')\n",
        "train_df = train_df.merge(performance_train_df, on=['기준년월', 'ID'], how='left')"
      ],
      "metadata": {
        "id": "JfmP7kCTGfNq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for col in train_df.select_dtypes(include='int64').columns:\n",
        "    if train_df[col].max() < 2_147_483_647:\n",
        "        train_df[col] = train_df[col].astype('int32') # 메모리 줄이기 위해 int64 ->int32"
      ],
      "metadata": {
        "id": "r-7Q0fILvR97"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df.to_parquet('/content/drive/MyDrive/Data/train_df_cleaned.parquet')"
      ],
      "metadata": {
        "id": "mMz7guH3qxg_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# test data\n",
        "customer_test_df = pd.read_parquet(\"/content/drive/MyDrive/Dacon/customer_test_cleaned.parquet\")\n",
        "credit_test_df = pd.read_parquet(\"/content/drive/MyDrive/Dacon/credit_test_cleaned.parquet\")\n",
        "sales_test_df = pd.read_parquet(\"/content/drive/MyDrive/Dacon/sales_test_cleaned.parquet\")\n",
        "billing_test_df = pd.read_parquet(\"/content/drive/MyDrive/Dacon/billing_test_cleaned.parquet\")\n",
        "balance_test_df = pd.read_parquet(\"/content/drive/MyDrive/Dacon/balance_test_cleaned.parquet\")\n",
        "channel_test_df = pd.read_parquet(\"/content/drive/MyDrive/Dacon/channel_test_cleaned.parquet\")\n",
        "marketing_test_df = pd.read_parquet(\"/content/drive/MyDrive/Dacon/marketing_test_cleaned.parquet\")\n",
        "performance_test_df = pd.read_parquet(\"/content/drive/MyDrive/Dacon/performance_test_cleaned.parquet\")"
      ],
      "metadata": {
        "id": "PEIfSR8JVQ7r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_df = customer_test_df.merge(credit_test_df, on=['기준년월', 'ID'], how='left')\n",
        "test_df = test_df.merge(sales_test_df, on=['기준년월', 'ID'], how='left')\n",
        "test_df = test_df.merge(billing_test_df, on=['기준년월', 'ID'], how='left')\n",
        "test_df = test_df.merge(balance_test_df, on=['기준년월', 'ID'], how='left')\n",
        "test_df = test_df.merge(channel_test_df, on=['기준년월', 'ID'], how='left')\n",
        "test_df = test_df.merge(marketing_test_df, on=['기준년월', 'ID'], how='left')\n",
        "test_df = test_df.merge(performance_test_df, on=['기준년월', 'ID'], how='left')\n",
        "\n",
        "for col in test_df.select_dtypes(include='int64').columns:\n",
        "    if test_df[col].max() < 2_147_483_647:\n",
        "        test_df[col] = test_df[col].astype('int32')\n",
        "\n",
        "for col in test_df.select_dtypes(include='float64').columns:\n",
        "    test_df[col] = test_df[col].astype('float32')"
      ],
      "metadata": {
        "id": "Rk2JeEVVHFJH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_df.to_parquet('/content/drive/MyDrive/Data/test_df_cleaned.parquet')"
      ],
      "metadata": {
        "id": "4vvTx5uCIRTi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Modeling(1) - feature importance"
      ],
      "metadata": {
        "id": "HbgzqQ5oUVWk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import gc\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import sklearn\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "import imblearn\n",
        "from imblearn.over_sampling import SMOTE\n",
        "import xgboost as xgb\n",
        "from xgboost import XGBClassifier"
      ],
      "metadata": {
        "id": "_lX32hBWsHcw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fcd28ecb-6387-49df-fe1a-d4faa641b459"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_df = pd.read_parquet('/content/drive/MyDrive/Data/train_df_cleaned.parquet')\n",
        "\n",
        "feature_cols = [col for col in train_df.columns if col not in [\"ID\", \"Segment\"]]\n",
        "X = train_df[feature_cols].copy()\n",
        "y = train_df[\"Segment\"].copy()\n",
        "y = y.map({'A':0, 'B':1,'C':2,'D':3,'E':4})\n",
        "\n",
        "del train_df\n",
        "gc.collect()\n",
        "\n",
        "# 클래스 weight 계산\n",
        "classes = np.unique(y)\n",
        "weights = compute_class_weight(class_weight='balanced', classes=classes, y=y)\n",
        "class_weights = dict(zip(classes, weights))\n",
        "\n",
        "# 각 샘플에 대해 weight 매핑\n",
        "w_train = pd.Series(y).map(class_weights)\n",
        "\n",
        "# 전체 feature로 XGBoost 학습 (변수 중요도 추출용)\n",
        "temp_model = xgb.XGBClassifier(\n",
        "    objective='multi:softprob',\n",
        "    num_class=5,\n",
        "    eval_metric='mlogloss',\n",
        "    n_estimators=700,\n",
        "    tree_method='hist',\n",
        "    device='cuda',\n",
        "    random_state=42\n",
        "    )\n",
        "\n",
        "temp_model.fit(X, y, sample_weight = w_train, verbose=False)"
      ],
      "metadata": {
        "id": "SYqU8BQ_wcS-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 253
        },
        "outputId": "178ab86b-8c78-4b5e-e2e6-0ddb025f96ed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
              "              colsample_bylevel=None, colsample_bynode=None,\n",
              "              colsample_bytree=None, device='cuda', early_stopping_rounds=None,\n",
              "              enable_categorical=False, eval_metric='mlogloss',\n",
              "              feature_types=None, gamma=None, grow_policy=None,\n",
              "              importance_type=None, interaction_constraints=None,\n",
              "              learning_rate=None, max_bin=None, max_cat_threshold=None,\n",
              "              max_cat_to_onehot=None, max_delta_step=None, max_depth=None,\n",
              "              max_leaves=None, min_child_weight=None, missing=nan,\n",
              "              monotone_constraints=None, multi_strategy=None, n_estimators=700,\n",
              "              n_jobs=None, num_class=5, num_parallel_tree=None, ...)"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {\n",
              "  /* Definition of color scheme common for light and dark mode */\n",
              "  --sklearn-color-text: #000;\n",
              "  --sklearn-color-text-muted: #666;\n",
              "  --sklearn-color-line: gray;\n",
              "  /* Definition of color scheme for unfitted estimators */\n",
              "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
              "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
              "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
              "  --sklearn-color-unfitted-level-3: chocolate;\n",
              "  /* Definition of color scheme for fitted estimators */\n",
              "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
              "  --sklearn-color-fitted-level-1: #d4ebff;\n",
              "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
              "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
              "\n",
              "  /* Specific color for light theme */\n",
              "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
              "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-icon: #696969;\n",
              "\n",
              "  @media (prefers-color-scheme: dark) {\n",
              "    /* Redefinition of color scheme for dark theme */\n",
              "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
              "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-icon: #878787;\n",
              "  }\n",
              "}\n",
              "\n",
              "#sk-container-id-1 {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 pre {\n",
              "  padding: 0;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-hidden--visually {\n",
              "  border: 0;\n",
              "  clip: rect(1px 1px 1px 1px);\n",
              "  clip: rect(1px, 1px, 1px, 1px);\n",
              "  height: 1px;\n",
              "  margin: -1px;\n",
              "  overflow: hidden;\n",
              "  padding: 0;\n",
              "  position: absolute;\n",
              "  width: 1px;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-dashed-wrapped {\n",
              "  border: 1px dashed var(--sklearn-color-line);\n",
              "  margin: 0 0.4em 0.5em 0.4em;\n",
              "  box-sizing: border-box;\n",
              "  padding-bottom: 0.4em;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-container {\n",
              "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
              "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
              "     so we also need the `!important` here to be able to override the\n",
              "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
              "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
              "  display: inline-block !important;\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-text-repr-fallback {\n",
              "  display: none;\n",
              "}\n",
              "\n",
              "div.sk-parallel-item,\n",
              "div.sk-serial,\n",
              "div.sk-item {\n",
              "  /* draw centered vertical line to link estimators */\n",
              "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
              "  background-size: 2px 100%;\n",
              "  background-repeat: no-repeat;\n",
              "  background-position: center center;\n",
              "}\n",
              "\n",
              "/* Parallel-specific style estimator block */\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item::after {\n",
              "  content: \"\";\n",
              "  width: 100%;\n",
              "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
              "  flex-grow: 1;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel {\n",
              "  display: flex;\n",
              "  align-items: stretch;\n",
              "  justify-content: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
              "  align-self: flex-end;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
              "  align-self: flex-start;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
              "  width: 0;\n",
              "}\n",
              "\n",
              "/* Serial-specific style estimator block */\n",
              "\n",
              "#sk-container-id-1 div.sk-serial {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "  align-items: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  padding-right: 1em;\n",
              "  padding-left: 1em;\n",
              "}\n",
              "\n",
              "\n",
              "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
              "clickable and can be expanded/collapsed.\n",
              "- Pipeline and ColumnTransformer use this feature and define the default style\n",
              "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
              "*/\n",
              "\n",
              "/* Pipeline and ColumnTransformer style (default) */\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable {\n",
              "  /* Default theme specific background. It is overwritten whether we have a\n",
              "  specific estimator or a Pipeline/ColumnTransformer */\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "/* Toggleable label */\n",
              "#sk-container-id-1 label.sk-toggleable__label {\n",
              "  cursor: pointer;\n",
              "  display: flex;\n",
              "  width: 100%;\n",
              "  margin-bottom: 0;\n",
              "  padding: 0.5em;\n",
              "  box-sizing: border-box;\n",
              "  text-align: center;\n",
              "  align-items: start;\n",
              "  justify-content: space-between;\n",
              "  gap: 0.5em;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 label.sk-toggleable__label .caption {\n",
              "  font-size: 0.6rem;\n",
              "  font-weight: lighter;\n",
              "  color: var(--sklearn-color-text-muted);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
              "  /* Arrow on the left of the label */\n",
              "  content: \"▸\";\n",
              "  float: left;\n",
              "  margin-right: 0.25em;\n",
              "  color: var(--sklearn-color-icon);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "/* Toggleable content - dropdown */\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content {\n",
              "  max-height: 0;\n",
              "  max-width: 0;\n",
              "  overflow: hidden;\n",
              "  text-align: left;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content pre {\n",
              "  margin: 0.2em;\n",
              "  border-radius: 0.25em;\n",
              "  color: var(--sklearn-color-text);\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
              "  /* Expand drop-down */\n",
              "  max-height: 200px;\n",
              "  max-width: 100%;\n",
              "  overflow: auto;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
              "  content: \"▾\";\n",
              "}\n",
              "\n",
              "/* Pipeline/ColumnTransformer-specific style */\n",
              "\n",
              "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator-specific style */\n",
              "\n",
              "/* Colorize estimator box */\n",
              "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
              "#sk-container-id-1 div.sk-label label {\n",
              "  /* The background is the default theme color */\n",
              "  color: var(--sklearn-color-text-on-default-background);\n",
              "}\n",
              "\n",
              "/* On hover, darken the color of the background */\n",
              "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "/* Label box, darken color on hover, fitted */\n",
              "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator label */\n",
              "\n",
              "#sk-container-id-1 div.sk-label label {\n",
              "  font-family: monospace;\n",
              "  font-weight: bold;\n",
              "  display: inline-block;\n",
              "  line-height: 1.2em;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label-container {\n",
              "  text-align: center;\n",
              "}\n",
              "\n",
              "/* Estimator-specific */\n",
              "#sk-container-id-1 div.sk-estimator {\n",
              "  font-family: monospace;\n",
              "  border: 1px dotted var(--sklearn-color-border-box);\n",
              "  border-radius: 0.25em;\n",
              "  box-sizing: border-box;\n",
              "  margin-bottom: 0.5em;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "/* on hover */\n",
              "#sk-container-id-1 div.sk-estimator:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
              "\n",
              "/* Common style for \"i\" and \"?\" */\n",
              "\n",
              ".sk-estimator-doc-link,\n",
              "a:link.sk-estimator-doc-link,\n",
              "a:visited.sk-estimator-doc-link {\n",
              "  float: right;\n",
              "  font-size: smaller;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1em;\n",
              "  height: 1em;\n",
              "  width: 1em;\n",
              "  text-decoration: none !important;\n",
              "  margin-left: 0.5em;\n",
              "  text-align: center;\n",
              "  /* unfitted */\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted,\n",
              "a:link.sk-estimator-doc-link.fitted,\n",
              "a:visited.sk-estimator-doc-link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "/* Span, style for the box shown on hovering the info icon */\n",
              ".sk-estimator-doc-link span {\n",
              "  display: none;\n",
              "  z-index: 9999;\n",
              "  position: relative;\n",
              "  font-weight: normal;\n",
              "  right: .2ex;\n",
              "  padding: .5ex;\n",
              "  margin: .5ex;\n",
              "  width: min-content;\n",
              "  min-width: 20ex;\n",
              "  max-width: 50ex;\n",
              "  color: var(--sklearn-color-text);\n",
              "  box-shadow: 2pt 2pt 4pt #999;\n",
              "  /* unfitted */\n",
              "  background: var(--sklearn-color-unfitted-level-0);\n",
              "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted span {\n",
              "  /* fitted */\n",
              "  background: var(--sklearn-color-fitted-level-0);\n",
              "  border: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link:hover span {\n",
              "  display: block;\n",
              "}\n",
              "\n",
              "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link {\n",
              "  float: right;\n",
              "  font-size: 1rem;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1rem;\n",
              "  height: 1rem;\n",
              "  width: 1rem;\n",
              "  text-decoration: none;\n",
              "  /* unfitted */\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "#sk-container-id-1 a.estimator_doc_link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
              "              colsample_bylevel=None, colsample_bynode=None,\n",
              "              colsample_bytree=None, device=&#x27;cuda&#x27;, early_stopping_rounds=None,\n",
              "              enable_categorical=False, eval_metric=&#x27;mlogloss&#x27;,\n",
              "              feature_types=None, gamma=None, grow_policy=None,\n",
              "              importance_type=None, interaction_constraints=None,\n",
              "              learning_rate=None, max_bin=None, max_cat_threshold=None,\n",
              "              max_cat_to_onehot=None, max_delta_step=None, max_depth=None,\n",
              "              max_leaves=None, min_child_weight=None, missing=nan,\n",
              "              monotone_constraints=None, multi_strategy=None, n_estimators=700,\n",
              "              n_jobs=None, num_class=5, num_parallel_tree=None, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>XGBClassifier</div></div><div><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
              "              colsample_bylevel=None, colsample_bynode=None,\n",
              "              colsample_bytree=None, device=&#x27;cuda&#x27;, early_stopping_rounds=None,\n",
              "              enable_categorical=False, eval_metric=&#x27;mlogloss&#x27;,\n",
              "              feature_types=None, gamma=None, grow_policy=None,\n",
              "              importance_type=None, interaction_constraints=None,\n",
              "              learning_rate=None, max_bin=None, max_cat_threshold=None,\n",
              "              max_cat_to_onehot=None, max_delta_step=None, max_depth=None,\n",
              "              max_leaves=None, min_child_weight=None, missing=nan,\n",
              "              monotone_constraints=None, multi_strategy=None, n_estimators=700,\n",
              "              n_jobs=None, num_class=5, num_parallel_tree=None, ...)</pre></div> </div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# XGBoost 기준 중요도 상위 300개 변수 추출\n",
        "importance_df = pd.DataFrame({\n",
        "    'feature': X.columns,\n",
        "    'importance': temp_model.feature_importances_\n",
        "}).sort_values(by='importance', ascending=False)\n",
        "\n",
        "top300_features = importance_df.head(300)['feature'].tolist()\n",
        "\n",
        "print(top300_features)\n",
        "\n",
        "top300_df = pd.DataFrame({'feature': top300_features})\n",
        "top300_df.to_csv(\n",
        "    \"/content/drive/MyDrive/Dacon/top300_features_XGB_balanced.csv\",\n",
        "    index=False,\n",
        "    encoding=\"utf-8-sig\"\n",
        ")"
      ],
      "metadata": {
        "id": "kNGzXvpCAfhm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3126b8a4-9c59-4d04-c08b-e8d75cbe2029"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['카드이용한도금액_A수준복합', '평잔_CA_해외_3M', '이용금액_선결제_B0M', '할부금액_무이자_3M_R12M', '정상청구원금_B5M', '이용금액_신용_R12M', '정상청구원금_B0M', '이용금액_체크_B0M', '이용월평균이용금액_체크_R3M', '할인금액_청구서_B0M', '카드이용한도금액_B1M', '총납부금_B5M', 'CA한도금액', '잔액_리볼빙CA이월_B0M', '이용월평균이용금액_체크_R12M', '카드이용한도금액_B2M', '할부금액총합_무이자_R12M', 'RP건수_학습비_B0M', '이용개월수_카드론_R6M', '평잔_CA_해외_6M', '총납부금_B2M', '탈회횟수_발급1년이내', '방문일수_앱_B0M', '연체입금원금_B5M', '월중평잔_할부_B0M', '건수별평균이용금액_CA_R6M', '이용월평균이용금액_할부_유이자_R6M', 'RP후경과월_아파트', 'RP건수_아파트_B0M', '이용금액_체크_R12M', '이용금액_할부_무이자_B0M', '이용개월수_체크_R3M', 'rv최초시작후경과일', '이용여부_CA', '건수별평균이용금액_체크_R3M', '건수별평균이용금액_신용_R12M', '정상청구원금_B2M', '이용금액_해외', '이용개월수_할부_무이자_R12M', '이용금액_신용_B0M', '최대이용금액_체크_R12M', '이용금액_오프라인_B0M', '입회경과개월수_신용', '정시납부금_B2M', '월중평잔_CA_B0M', '이용금액_신판_R12M', '할인금액_청구서_R3M', '최종카드론_대출이율', '연속유실적개월수_기본_24M_카드', '이용금액_체크_R6M', '카드이용한도금액', '포인트_마일리지_건별_R3M', '증감_RP건수_전기_전월', '이용건수_카드론_R12M', '건수별평균이용금액_체크_R6M', '여유_총이용금액', '총납부금_B0M', '이용금액_할부_R12M', '이용월평균이용금액_신용_R12M', '포인트_마일리지_건별_B0M', '이용개월수_결제일_R6M', 'CA이자율_할인전', '잔액_카드론_B2M', '평잔_CA_3M', '이용금액_카드론_R6M', '최대이용금액_할부_R12M', '평잔_RV일시불_3M', '최초한도금액', '이용개월수_CA_R6M', '증감_RP건수_전월', '이용건수_신용_R12M', '건수별평균금액_할부전환_R6M', '이용월평균이용금액_카드론_R12M', '포인트_마일리지_월적립_B0M', '이용금액_일시불_B0M', '이용개월수_할부_R12M', '최대이용금액_할부_무이자_R12M', '이용후경과월_신용', 'RP건수_B0M', '증감_RP건수_렌탈_전월', '이용금액대_점수', '소지카드수_유효_신용', '최대이용금액_CA_R12M', '_1순위여유업종_이용금액', '쇼핑_총이용금액', '이용카드수_신용체크', '건수별평균이용금액_카드론_R12M', '포인트_이용포인트_R3M', '잔액_카드론_B3M', '변동률_RVCA평잔', '이용개월수_카드론_R12M', '건수별평균이용금액_A페이_R3M', '이용금액_카드론_R12M', '이용가능카드수_신용체크', '이용후경과월_신판', '이용금액_신용_R3M', '정시납부비율_B5M', '마일_잔여포인트_B0M', '최대이용금액_일시불_R12M', '이용개월수_체크_R12M', '이용개월수_할부_무이자_R6M', '카드론이용월수_누적', '이용금액_R3M_신용체크', '컨택건수_이용유도_인터넷_R6M', '이용건수_B페이_R6M', '건수별평균이용금액_간편결제_B0M', '한도증액_R12M_여부', '이용금액_할부_무이자_R6M', '월중평잔_할부', 'IB문의건수_CA_R6M', '이용금액_신용_R6M', '연체입금원금_B0M', '강제한도감액횟수_R12M', '이용월평균이용금액_신판_R12M', '유효카드수_신용체크', 'RV현금서비스이자율_할인전', '강제한도감액금액_R12M', '상향가능CA한도금액_1여부', '이용카드수_체크', '건수별평균이용금액_CA_B0M', '월상환론한도금액', '건수별평균이용금액_신용_R6M', '유효카드수_신용', '_1순위카드이용금액', '연체입금원금_B2M', '방문월수_모바일웹_R6M', '일시상환론한도금액', '건수별평균이용금액_신판_B0M', '건수별평균이용금액_일시불_R12M', '이용개월수_페이_오프라인_R6M', '평잔_일시불_6M', '이용금액_신판_R6M', '이용금액_할부_무이자_R3M', '할부금액_6M_R12M', '이용건수_일시불_R6M', '이용월평균이용금액_신용_R6M', '할부건수_무이자_3M_R12M', '이용건수_페이_온라인_R6M', '할부금액_14M_R12M', 'RP후경과월_렌탈', '자발한도감액금액_R12M', '평잔_할부_3M', '증감율_이용금액_일시불_분기', '건수별평균이용금액_신판_R12M', '이용월평균이용금액_일시불_R12M', '선결제건수_R6M', '이용개월수_할부_유이자_R12M', '이용여부_할부', '이용월평균이용건수_신판_R12M', '기준년월', '포인트_마일리지_월적립_R3M', '소지카드수_이용가능_신용', '한도증액후경과월', '방문일수_앱_R6M', '_2순위카드이용건수', '증감율_이용금액_신판_분기', '이용개월수_신용_R12M', '자발한도감액횟수_R12M', '잔액_신판ca평균한도소진율_r3m', '이용월평균이용건수_신판_R6M', '이용금액_일시불_R12M', '최종카드론이용경과월', '_1순위카드이용건수', '수신거부여부_TM', '수신거부여부_메일', '증감율_이용금액_신용_분기', '연속무실적개월수_기본_24M_카드', '잔액_카드론_B5M', '증감율_이용금액_신용_전월', '당사멤버쉽_방문월수_R6M', '건수별평균이용금액_체크_B0M', '잔액_할부_무이자_B0M', '잔액_현금서비스_B0M', '_2순위카드이용금액', '이용개월수_CA_R12M', '할부금액_유이자_3M_R12M', '마일_적립포인트_R12M', '이용월평균이용금액_할부_무이자_R12M', 'RP후경과월_보험', 'IB문의건수_CL_RV_R6M', '할부금액_무이자_12M_R12M', '잔액_현금서비스_B1M', 'RP건수_제휴사서비스직접판매_B0M', '최종카드론_대출금액', '이용금액_오프라인_R3M', '평잔_할부_6M', '마케팅동의여부', '건수별평균이용금액_할부_무이자_R12M', '이용가능카드수_신용_가족', '당사멤버쉽_방문횟수_B0M', '평잔_6M', '이용건수_선결제_R3M', '건수별평균이용금액_일시불_B0M', '컨택건수_이용유도_LMS_B0M', 'RV_최대잔액_R12M', '이용건수_CA_R12M', '이용월평균이용건수_일시불_R6M', '최종카드발급경과월', '포인트_적립포인트_R12M', '잔액_신판ca최대한도소진율_r6m', '변동률_카드론평잔', '홈페이지_선결제건수_R6M', '컨택건수_이용유도_청구서_B0M', '잔액_할부_B0M', '건수별평균이용금액_신판_R6M', '한도증액금액_R12M', '포인트_마일리지_환산_B0M', '건수별할부금액_3M', '이용월평균이용건수_신용_R12M', '보유여부_해외겸용_본인', '연체건수_R3M', '이용건수_D페이_B0M', '건수별평균이용금액_CA_R3M', '평잔_카드론_6M', '평잔_일시불_해외_6M', '상환개월수_결제일_R6M', '건수별평균이용금액_할부_유이자_R12M', 'RV_평균잔액_R12M', '이용금액_오프라인_R6M', 'RV_최대잔액_R6M', '이용금액_CA_R12M', '방문월수_PC_R6M', '_n순위여유업종_AB', '할인건수_R3M', '이용월평균이용건수_일시불_R12M', '포인트_포인트_월적립_R3M', '건수별평균이용금액_일시불_R6M', '회원여부_이용가능_카드론', '이용금액_일시불_R3M', '방문횟수_앱_B0M', 'IB문의건수_선결제_B0M', '이용월평균이용건수_CA_R6M', '할인금액_R3M', '이용금액_CA_R6M', '이용건수_신판_R12M', '이용월평균이용금액_체크_R6M', '이용건수_일시불_R12M', '이용후경과월_할부_유이자', '컨택건수_이용유도_청구서_R6M', '상담건수_R6M', '이용건수_간편결제_R6M', '포인트_이용포인트_R12M', '홈페이지_금융건수_R6M', '이용개월수_신판_R12M', '이용건수_신판_R6M', '증감율_이용건수_할부_분기', '청구금액_R6M', '이용금액_체크_R3M', '혜택수혜금액_R3M', '정상입금원금_B0M', '이용금액_신판_B0M', '이용개월수_할부_유이자_R6M', '컨택건수_이용유도_EM_B0M', '이용개월수_간편결제_R6M', '월중평잔_일시불_B0M', '이용금액_일시불_R6M', '건수별평균이용금액_오프라인_B0M', '할부건수_6M_R12M', '건수별평균이용금액_CA_R12M', '회원여부_이용가능_CA', '당사멤버쉽_방문횟수_R6M', '_2순위여유업종_이용금액', '할인금액_B0M', '건수별할부금액_무이자_3M', '이용월평균이용금액_신판_R6M', '할부금액총합_유이자_R12M', 'CL이자율_할인전', '선입금원금_B5M', '변동률_일시불평잔', '이용금액_R3M_체크', '이용개월수_선결제_R6M', '이용금액_CA_B0M', '이용후경과월_체크', '증감율_이용금액_체크_분기', 'RP후경과월_전기', '잔액_리볼빙일시불이월_B0M', '_2순위쇼핑업종_이용금액', '불만제기후경과월_R12M', '잔액_현금서비스_B2M', '평잔_카드론_3M', '최대이용금액_할부_유이자_R12M', '수신거부여부_DM', 'IB문의건수_선결제_R6M', '이용개월수_할부_R6M', '할부건수총합_R12M', '_1순위쇼핑업종_이용금액', '이용월평균이용금액_신용_R3M', '가맹점매출금액_B2M', 'RP후경과월', '월중평잔_일시불', '횟수별평균이용금액_연체_B0M', '포인트_포인트_건별_R3M', '동의여부_한도증액안내', '컨택건수_리볼빙_LMS_R6M', '이용금액_할부_B0M', '카드신청건수', '_n순위교통업종_AB', '잔액_신판평균한도소진율_r6m', 'RV일시불이자율_할인전', 'IB문의건수_카드발급_R6M']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Modeling(2) - final model train"
      ],
      "metadata": {
        "id": "FUCOBrIjLFgL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## XGBoost 모델 학습"
      ],
      "metadata": {
        "id": "bUFu4-MXoJu-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import gc\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import sklearn\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "import imblearn\n",
        "from imblearn.over_sampling import SMOTE\n",
        "import xgboost as xgb\n",
        "from xgboost import XGBClassifier"
      ],
      "metadata": {
        "id": "D1wx4Wi2sVhR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "689df930-7d98-468e-df3d-fef0fde21717"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_df = pd.read_parquet('/content/drive/MyDrive/Data/train_df_cleaned.parquet')\n",
        "\n",
        "feature_cols = [col for col in train_df.columns if col not in [\"ID\", \"Segment\"]]\n",
        "X = train_df[feature_cols].copy()\n",
        "y = train_df[\"Segment\"].copy()\n",
        "y = y.map({'A':0, 'B':1,'C':2,'D':3,'E':4})\n",
        "inverse_label_map = {0: 'A', 1: 'B', 2: 'C', 3: 'D', 4: 'E'}\n",
        "\n",
        "# 변수 300개 사용\n",
        "top300_df = pd.read_csv(\"/content/drive/MyDrive/Dacon/top300_features_XGB_balanced.csv\")\n",
        "top300_features = top300_df['feature'].tolist()\n",
        "X_top300 = X[top300_features]\n",
        "\n",
        "# 오버샘플링\n",
        "smote = SMOTE(sampling_strategy={0: 30000, 1: 30000, 2: 250000}, random_state=42)\n",
        "X_resampled, y_resampled = smote.fit_resample(X_top300, y)\n",
        "\n",
        "# 클래스별 weight 계산\n",
        "classes = np.unique(y_resampled)\n",
        "weights = compute_class_weight(class_weight='balanced', classes=classes, y=y_resampled)\n",
        "class_weights = dict(zip(classes, weights))\n",
        "sample_weights = pd.Series(y_resampled).map(class_weights)\n",
        "\n",
        "for cls in sorted(class_weights):\n",
        "    print(f\"클래스 {cls}: weight = {class_weights[cls]:.2f}\")"
      ],
      "metadata": {
        "id": "ASSGZyHswV-h",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "db899bfd-50d8-4020-ae7b-bbe49e4504ad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "클래스 0: weight = 17.21\n",
            "클래스 1: weight = 17.21\n",
            "클래스 2: weight = 2.07\n",
            "클래스 3: weight = 1.48\n",
            "클래스 4: weight = 0.27\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "xgb_model = xgb.XGBClassifier(\n",
        "    objective='multi:softprob',\n",
        "    num_class=5,\n",
        "    eval_metric='mlogloss',\n",
        "    n_estimators=5000,\n",
        "    tree_method='hist',\n",
        "    device='cuda',\n",
        "    random_state=42\n",
        "    )\n",
        "\n",
        "# 모델 학습 (검증 없이 전체 데이터 사용)\n",
        "xgb_model.fit(\n",
        "    X_resampled, y_resampled,\n",
        "    sample_weight=sample_weights,\n",
        "    verbose=False\n",
        ")"
      ],
      "metadata": {
        "id": "S21LdA9UoOgA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 253
        },
        "outputId": "3395e7b1-2c32-4780-922a-85b156539b1b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
              "              colsample_bylevel=None, colsample_bynode=None,\n",
              "              colsample_bytree=None, device='cuda', early_stopping_rounds=None,\n",
              "              enable_categorical=False, eval_metric='mlogloss',\n",
              "              feature_types=None, gamma=None, grow_policy=None,\n",
              "              importance_type=None, interaction_constraints=None,\n",
              "              learning_rate=None, max_bin=None, max_cat_threshold=None,\n",
              "              max_cat_to_onehot=None, max_delta_step=None, max_depth=None,\n",
              "              max_leaves=None, min_child_weight=None, missing=nan,\n",
              "              monotone_constraints=None, multi_strategy=None, n_estimators=5000,\n",
              "              n_jobs=None, num_class=5, num_parallel_tree=None, ...)"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {\n",
              "  /* Definition of color scheme common for light and dark mode */\n",
              "  --sklearn-color-text: #000;\n",
              "  --sklearn-color-text-muted: #666;\n",
              "  --sklearn-color-line: gray;\n",
              "  /* Definition of color scheme for unfitted estimators */\n",
              "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
              "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
              "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
              "  --sklearn-color-unfitted-level-3: chocolate;\n",
              "  /* Definition of color scheme for fitted estimators */\n",
              "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
              "  --sklearn-color-fitted-level-1: #d4ebff;\n",
              "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
              "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
              "\n",
              "  /* Specific color for light theme */\n",
              "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
              "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-icon: #696969;\n",
              "\n",
              "  @media (prefers-color-scheme: dark) {\n",
              "    /* Redefinition of color scheme for dark theme */\n",
              "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
              "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-icon: #878787;\n",
              "  }\n",
              "}\n",
              "\n",
              "#sk-container-id-1 {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 pre {\n",
              "  padding: 0;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-hidden--visually {\n",
              "  border: 0;\n",
              "  clip: rect(1px 1px 1px 1px);\n",
              "  clip: rect(1px, 1px, 1px, 1px);\n",
              "  height: 1px;\n",
              "  margin: -1px;\n",
              "  overflow: hidden;\n",
              "  padding: 0;\n",
              "  position: absolute;\n",
              "  width: 1px;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-dashed-wrapped {\n",
              "  border: 1px dashed var(--sklearn-color-line);\n",
              "  margin: 0 0.4em 0.5em 0.4em;\n",
              "  box-sizing: border-box;\n",
              "  padding-bottom: 0.4em;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-container {\n",
              "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
              "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
              "     so we also need the `!important` here to be able to override the\n",
              "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
              "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
              "  display: inline-block !important;\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-text-repr-fallback {\n",
              "  display: none;\n",
              "}\n",
              "\n",
              "div.sk-parallel-item,\n",
              "div.sk-serial,\n",
              "div.sk-item {\n",
              "  /* draw centered vertical line to link estimators */\n",
              "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
              "  background-size: 2px 100%;\n",
              "  background-repeat: no-repeat;\n",
              "  background-position: center center;\n",
              "}\n",
              "\n",
              "/* Parallel-specific style estimator block */\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item::after {\n",
              "  content: \"\";\n",
              "  width: 100%;\n",
              "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
              "  flex-grow: 1;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel {\n",
              "  display: flex;\n",
              "  align-items: stretch;\n",
              "  justify-content: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
              "  align-self: flex-end;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
              "  align-self: flex-start;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
              "  width: 0;\n",
              "}\n",
              "\n",
              "/* Serial-specific style estimator block */\n",
              "\n",
              "#sk-container-id-1 div.sk-serial {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "  align-items: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  padding-right: 1em;\n",
              "  padding-left: 1em;\n",
              "}\n",
              "\n",
              "\n",
              "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
              "clickable and can be expanded/collapsed.\n",
              "- Pipeline and ColumnTransformer use this feature and define the default style\n",
              "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
              "*/\n",
              "\n",
              "/* Pipeline and ColumnTransformer style (default) */\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable {\n",
              "  /* Default theme specific background. It is overwritten whether we have a\n",
              "  specific estimator or a Pipeline/ColumnTransformer */\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "/* Toggleable label */\n",
              "#sk-container-id-1 label.sk-toggleable__label {\n",
              "  cursor: pointer;\n",
              "  display: flex;\n",
              "  width: 100%;\n",
              "  margin-bottom: 0;\n",
              "  padding: 0.5em;\n",
              "  box-sizing: border-box;\n",
              "  text-align: center;\n",
              "  align-items: start;\n",
              "  justify-content: space-between;\n",
              "  gap: 0.5em;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 label.sk-toggleable__label .caption {\n",
              "  font-size: 0.6rem;\n",
              "  font-weight: lighter;\n",
              "  color: var(--sklearn-color-text-muted);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
              "  /* Arrow on the left of the label */\n",
              "  content: \"▸\";\n",
              "  float: left;\n",
              "  margin-right: 0.25em;\n",
              "  color: var(--sklearn-color-icon);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "/* Toggleable content - dropdown */\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content {\n",
              "  max-height: 0;\n",
              "  max-width: 0;\n",
              "  overflow: hidden;\n",
              "  text-align: left;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content pre {\n",
              "  margin: 0.2em;\n",
              "  border-radius: 0.25em;\n",
              "  color: var(--sklearn-color-text);\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
              "  /* Expand drop-down */\n",
              "  max-height: 200px;\n",
              "  max-width: 100%;\n",
              "  overflow: auto;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
              "  content: \"▾\";\n",
              "}\n",
              "\n",
              "/* Pipeline/ColumnTransformer-specific style */\n",
              "\n",
              "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator-specific style */\n",
              "\n",
              "/* Colorize estimator box */\n",
              "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
              "#sk-container-id-1 div.sk-label label {\n",
              "  /* The background is the default theme color */\n",
              "  color: var(--sklearn-color-text-on-default-background);\n",
              "}\n",
              "\n",
              "/* On hover, darken the color of the background */\n",
              "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "/* Label box, darken color on hover, fitted */\n",
              "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator label */\n",
              "\n",
              "#sk-container-id-1 div.sk-label label {\n",
              "  font-family: monospace;\n",
              "  font-weight: bold;\n",
              "  display: inline-block;\n",
              "  line-height: 1.2em;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label-container {\n",
              "  text-align: center;\n",
              "}\n",
              "\n",
              "/* Estimator-specific */\n",
              "#sk-container-id-1 div.sk-estimator {\n",
              "  font-family: monospace;\n",
              "  border: 1px dotted var(--sklearn-color-border-box);\n",
              "  border-radius: 0.25em;\n",
              "  box-sizing: border-box;\n",
              "  margin-bottom: 0.5em;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "/* on hover */\n",
              "#sk-container-id-1 div.sk-estimator:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
              "\n",
              "/* Common style for \"i\" and \"?\" */\n",
              "\n",
              ".sk-estimator-doc-link,\n",
              "a:link.sk-estimator-doc-link,\n",
              "a:visited.sk-estimator-doc-link {\n",
              "  float: right;\n",
              "  font-size: smaller;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1em;\n",
              "  height: 1em;\n",
              "  width: 1em;\n",
              "  text-decoration: none !important;\n",
              "  margin-left: 0.5em;\n",
              "  text-align: center;\n",
              "  /* unfitted */\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted,\n",
              "a:link.sk-estimator-doc-link.fitted,\n",
              "a:visited.sk-estimator-doc-link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "/* Span, style for the box shown on hovering the info icon */\n",
              ".sk-estimator-doc-link span {\n",
              "  display: none;\n",
              "  z-index: 9999;\n",
              "  position: relative;\n",
              "  font-weight: normal;\n",
              "  right: .2ex;\n",
              "  padding: .5ex;\n",
              "  margin: .5ex;\n",
              "  width: min-content;\n",
              "  min-width: 20ex;\n",
              "  max-width: 50ex;\n",
              "  color: var(--sklearn-color-text);\n",
              "  box-shadow: 2pt 2pt 4pt #999;\n",
              "  /* unfitted */\n",
              "  background: var(--sklearn-color-unfitted-level-0);\n",
              "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted span {\n",
              "  /* fitted */\n",
              "  background: var(--sklearn-color-fitted-level-0);\n",
              "  border: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link:hover span {\n",
              "  display: block;\n",
              "}\n",
              "\n",
              "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link {\n",
              "  float: right;\n",
              "  font-size: 1rem;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1rem;\n",
              "  height: 1rem;\n",
              "  width: 1rem;\n",
              "  text-decoration: none;\n",
              "  /* unfitted */\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "#sk-container-id-1 a.estimator_doc_link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
              "              colsample_bylevel=None, colsample_bynode=None,\n",
              "              colsample_bytree=None, device=&#x27;cuda&#x27;, early_stopping_rounds=None,\n",
              "              enable_categorical=False, eval_metric=&#x27;mlogloss&#x27;,\n",
              "              feature_types=None, gamma=None, grow_policy=None,\n",
              "              importance_type=None, interaction_constraints=None,\n",
              "              learning_rate=None, max_bin=None, max_cat_threshold=None,\n",
              "              max_cat_to_onehot=None, max_delta_step=None, max_depth=None,\n",
              "              max_leaves=None, min_child_weight=None, missing=nan,\n",
              "              monotone_constraints=None, multi_strategy=None, n_estimators=5000,\n",
              "              n_jobs=None, num_class=5, num_parallel_tree=None, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>XGBClassifier</div></div><div><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
              "              colsample_bylevel=None, colsample_bynode=None,\n",
              "              colsample_bytree=None, device=&#x27;cuda&#x27;, early_stopping_rounds=None,\n",
              "              enable_categorical=False, eval_metric=&#x27;mlogloss&#x27;,\n",
              "              feature_types=None, gamma=None, grow_policy=None,\n",
              "              importance_type=None, interaction_constraints=None,\n",
              "              learning_rate=None, max_bin=None, max_cat_threshold=None,\n",
              "              max_cat_to_onehot=None, max_delta_step=None, max_depth=None,\n",
              "              max_leaves=None, min_child_weight=None, missing=nan,\n",
              "              monotone_constraints=None, multi_strategy=None, n_estimators=5000,\n",
              "              n_jobs=None, num_class=5, num_parallel_tree=None, ...)</pre></div> </div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "xgb_model.save_model('/content/drive/MyDrive/Dacon/softvoting_xgb_xgb변수_3_3_25.json')"
      ],
      "metadata": {
        "id": "bz2xLMvVwi6a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## LightGBM 모델 학습"
      ],
      "metadata": {
        "id": "mFBetY0UoO7I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import gc\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# LightGBM을 위한 GPU driver 설치 코드\n",
        "!mkdir -p /etc/OpenCL/vendors && echo \"libnvidia-opencl.so.1\" > /etc/OpenCL/vendors/nvidia.icd\n",
        "!sudo apt install nvidia-driver-460 nvidia-cuda-toolkit clinfo\n",
        "!apt-get update --fix-missing\n",
        "!pip install -q  lightgbm==4.1.0 \\\n",
        "  --config-settings=cmake.define.USE_GPU=ON \\\n",
        "  --config-settings=cmake.define.OpenCL_INCLUDE_DIR=\"/usr/local/cuda/include/\" \\\n",
        "  --config-settings=cmake.define.OpenCL_LIBRARY=\"/usr/local/cuda/lib64/libOpenCL.so\"\n",
        "\n",
        "import sklearn\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "import imblearn\n",
        "from imblearn.over_sampling import SMOTE\n",
        "import lightgbm as lgb\n",
        "from lightgbm import early_stopping, log_evaluation, LGBMClassifier"
      ],
      "metadata": {
        "id": "OILBAPaRsbm4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f98482e0-f244-436c-ac82-a05c3903d17e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "clinfo is already the newest version (3.0.21.02.21-1).\n",
            "Some packages could not be installed. This may mean that you have\n",
            "requested an impossible situation or if you are using the unstable\n",
            "distribution that some required packages have not yet been created\n",
            "or been moved out of Incoming.\n",
            "The following information may help to resolve the situation:\n",
            "\n",
            "The following packages have unmet dependencies:\n",
            " libnvidia-compute-510 : Depends: libnvidia-compute-535 but it is not installable\n",
            " nvidia-cuda-dev : Breaks: libcuda1 (< 495)\n",
            "                   Recommends: libnvcuvid1 but it is not installable\n",
            "\u001b[1;31mE: \u001b[0mUnable to correct problems, you have held broken packages.\u001b[0m\n",
            "Hit:1 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n",
            "Hit:2 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease\n",
            "Hit:3 http://security.ubuntu.com/ubuntu jammy-security InRelease\n",
            "Hit:4 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Hit:5 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Hit:6 http://archive.ubuntu.com/ubuntu jammy-updates InRelease\n",
            "Hit:7 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:8 http://archive.ubuntu.com/ubuntu jammy-backports InRelease\n",
            "Hit:9 https://r2u.stat.illinois.edu/ubuntu jammy InRelease\n",
            "Hit:10 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Reading package lists... Done\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_df = pd.read_parquet('/content/drive/MyDrive/Data/train_df_cleaned.parquet')\n",
        "\n",
        "feature_cols = [col for col in train_df.columns if col not in [\"ID\", \"Segment\"]]\n",
        "X = train_df[feature_cols].copy()\n",
        "y = train_df[\"Segment\"].copy()\n",
        "y = y.map({'A':0, 'B':1,'C':2,'D':3,'E':4})\n",
        "inverse_label_map = {0: 'A', 1: 'B', 2: 'C', 3: 'D', 4: 'E'}\n",
        "\n",
        "# 변수 300개 사용\n",
        "top300_df = pd.read_csv(\"/content/drive/MyDrive/Dacon/top300_features_XGB_balanced.csv\")\n",
        "top300_features = top300_df['feature'].tolist()\n",
        "X_top300 = X[top300_features]\n",
        "\n",
        "# 오버샘플링\n",
        "smote = SMOTE(sampling_strategy={0: 30000, 1: 30000, 2: 250000}, random_state=42)\n",
        "X_resampled, y_resampled = smote.fit_resample(X_top300, y)\n",
        "\n",
        "# 클래스별 weight 계산\n",
        "classes = np.unique(y_resampled)\n",
        "weights = compute_class_weight(class_weight='balanced', classes=classes, y=y_resampled)\n",
        "class_weights = dict(zip(classes, weights))\n",
        "sample_weights = pd.Series(y_resampled).map(class_weights)\n",
        "\n",
        "for cls in sorted(class_weights):\n",
        "    print(f\"클래스 {cls}: weight = {class_weights[cls]:.2f}\")"
      ],
      "metadata": {
        "id": "-JLhwhpqoQY3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4d7605b0-d061-4d8a-f275-fc9555177aa7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "클래스 0: weight = 17.21\n",
            "클래스 1: weight = 17.21\n",
            "클래스 2: weight = 2.07\n",
            "클래스 3: weight = 1.48\n",
            "클래스 4: weight = 0.27\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lgb_model = LGBMClassifier(\n",
        "    objective='multiclass',\n",
        "    boosting_type = 'gbdt',\n",
        "    metric = 'multi_logloss',\n",
        "    verbosity = -1,\n",
        "    random_state = 42,\n",
        "    device = 'gpu',\n",
        "    num_class = 5,\n",
        "    gpu_platform_id = 0,\n",
        "    gpu_device_id = 0,\n",
        "\n",
        "    num_boost_round = 3348, # n_estimators\n",
        "    learning_rate = 0.16304239034369372,\n",
        "    num_leaves = 260,\n",
        "    max_depth = 6,\n",
        "    min_data_in_leaf = 1200,\n",
        "    bagging_fraction = 0.8999999999999999,\n",
        "    bagging_freq = 4,\n",
        "    feature_fraction = 0.8,\n",
        "    lambda_l1 = 4.4610495762623494e-05,\n",
        "    lambda_l2 = 0.6898684039866835,\n",
        "    min_gain_to_split = 0.3944497642389666\n",
        "    )\n",
        "\n",
        "# 모델 학습 (검증 없이 전체 데이터 사용)\n",
        "lgb_model.fit(\n",
        "    X_resampled, y_resampled,\n",
        "    sample_weight=sample_weights,\n",
        "    callbacks=[\n",
        "        log_evaluation(period=0)  # ✅ verbose_eval=False랑 같음!\n",
        "        ]\n",
        ")"
      ],
      "metadata": {
        "id": "Lbb5-VXCw9B1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 258
        },
        "outputId": "8aba264c-594c-4ab7-9192-c861348580e5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/lightgbm/engine.py:172: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
            "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LGBMClassifier(bagging_fraction=0.8999999999999999, bagging_freq=4,\n",
              "               device='gpu', feature_fraction=0.8, gpu_device_id=0,\n",
              "               gpu_platform_id=0, lambda_l1=4.4610495762623494e-05,\n",
              "               lambda_l2=0.6898684039866835, learning_rate=0.16304239034369372,\n",
              "               max_depth=6, metric='multi_logloss', min_data_in_leaf=1200,\n",
              "               min_gain_to_split=0.3944497642389666, num_boost_round=3348,\n",
              "               num_class=5, num_leaves=260, objective='multiclass',\n",
              "               random_state=42, verbosity=-1)"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {\n",
              "  /* Definition of color scheme common for light and dark mode */\n",
              "  --sklearn-color-text: #000;\n",
              "  --sklearn-color-text-muted: #666;\n",
              "  --sklearn-color-line: gray;\n",
              "  /* Definition of color scheme for unfitted estimators */\n",
              "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
              "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
              "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
              "  --sklearn-color-unfitted-level-3: chocolate;\n",
              "  /* Definition of color scheme for fitted estimators */\n",
              "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
              "  --sklearn-color-fitted-level-1: #d4ebff;\n",
              "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
              "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
              "\n",
              "  /* Specific color for light theme */\n",
              "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
              "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-icon: #696969;\n",
              "\n",
              "  @media (prefers-color-scheme: dark) {\n",
              "    /* Redefinition of color scheme for dark theme */\n",
              "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
              "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-icon: #878787;\n",
              "  }\n",
              "}\n",
              "\n",
              "#sk-container-id-1 {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 pre {\n",
              "  padding: 0;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-hidden--visually {\n",
              "  border: 0;\n",
              "  clip: rect(1px 1px 1px 1px);\n",
              "  clip: rect(1px, 1px, 1px, 1px);\n",
              "  height: 1px;\n",
              "  margin: -1px;\n",
              "  overflow: hidden;\n",
              "  padding: 0;\n",
              "  position: absolute;\n",
              "  width: 1px;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-dashed-wrapped {\n",
              "  border: 1px dashed var(--sklearn-color-line);\n",
              "  margin: 0 0.4em 0.5em 0.4em;\n",
              "  box-sizing: border-box;\n",
              "  padding-bottom: 0.4em;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-container {\n",
              "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
              "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
              "     so we also need the `!important` here to be able to override the\n",
              "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
              "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
              "  display: inline-block !important;\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-text-repr-fallback {\n",
              "  display: none;\n",
              "}\n",
              "\n",
              "div.sk-parallel-item,\n",
              "div.sk-serial,\n",
              "div.sk-item {\n",
              "  /* draw centered vertical line to link estimators */\n",
              "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
              "  background-size: 2px 100%;\n",
              "  background-repeat: no-repeat;\n",
              "  background-position: center center;\n",
              "}\n",
              "\n",
              "/* Parallel-specific style estimator block */\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item::after {\n",
              "  content: \"\";\n",
              "  width: 100%;\n",
              "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
              "  flex-grow: 1;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel {\n",
              "  display: flex;\n",
              "  align-items: stretch;\n",
              "  justify-content: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
              "  align-self: flex-end;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
              "  align-self: flex-start;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
              "  width: 0;\n",
              "}\n",
              "\n",
              "/* Serial-specific style estimator block */\n",
              "\n",
              "#sk-container-id-1 div.sk-serial {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "  align-items: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  padding-right: 1em;\n",
              "  padding-left: 1em;\n",
              "}\n",
              "\n",
              "\n",
              "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
              "clickable and can be expanded/collapsed.\n",
              "- Pipeline and ColumnTransformer use this feature and define the default style\n",
              "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
              "*/\n",
              "\n",
              "/* Pipeline and ColumnTransformer style (default) */\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable {\n",
              "  /* Default theme specific background. It is overwritten whether we have a\n",
              "  specific estimator or a Pipeline/ColumnTransformer */\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "/* Toggleable label */\n",
              "#sk-container-id-1 label.sk-toggleable__label {\n",
              "  cursor: pointer;\n",
              "  display: flex;\n",
              "  width: 100%;\n",
              "  margin-bottom: 0;\n",
              "  padding: 0.5em;\n",
              "  box-sizing: border-box;\n",
              "  text-align: center;\n",
              "  align-items: start;\n",
              "  justify-content: space-between;\n",
              "  gap: 0.5em;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 label.sk-toggleable__label .caption {\n",
              "  font-size: 0.6rem;\n",
              "  font-weight: lighter;\n",
              "  color: var(--sklearn-color-text-muted);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
              "  /* Arrow on the left of the label */\n",
              "  content: \"▸\";\n",
              "  float: left;\n",
              "  margin-right: 0.25em;\n",
              "  color: var(--sklearn-color-icon);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "/* Toggleable content - dropdown */\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content {\n",
              "  max-height: 0;\n",
              "  max-width: 0;\n",
              "  overflow: hidden;\n",
              "  text-align: left;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content pre {\n",
              "  margin: 0.2em;\n",
              "  border-radius: 0.25em;\n",
              "  color: var(--sklearn-color-text);\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
              "  /* Expand drop-down */\n",
              "  max-height: 200px;\n",
              "  max-width: 100%;\n",
              "  overflow: auto;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
              "  content: \"▾\";\n",
              "}\n",
              "\n",
              "/* Pipeline/ColumnTransformer-specific style */\n",
              "\n",
              "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator-specific style */\n",
              "\n",
              "/* Colorize estimator box */\n",
              "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
              "#sk-container-id-1 div.sk-label label {\n",
              "  /* The background is the default theme color */\n",
              "  color: var(--sklearn-color-text-on-default-background);\n",
              "}\n",
              "\n",
              "/* On hover, darken the color of the background */\n",
              "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "/* Label box, darken color on hover, fitted */\n",
              "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator label */\n",
              "\n",
              "#sk-container-id-1 div.sk-label label {\n",
              "  font-family: monospace;\n",
              "  font-weight: bold;\n",
              "  display: inline-block;\n",
              "  line-height: 1.2em;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label-container {\n",
              "  text-align: center;\n",
              "}\n",
              "\n",
              "/* Estimator-specific */\n",
              "#sk-container-id-1 div.sk-estimator {\n",
              "  font-family: monospace;\n",
              "  border: 1px dotted var(--sklearn-color-border-box);\n",
              "  border-radius: 0.25em;\n",
              "  box-sizing: border-box;\n",
              "  margin-bottom: 0.5em;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "/* on hover */\n",
              "#sk-container-id-1 div.sk-estimator:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
              "\n",
              "/* Common style for \"i\" and \"?\" */\n",
              "\n",
              ".sk-estimator-doc-link,\n",
              "a:link.sk-estimator-doc-link,\n",
              "a:visited.sk-estimator-doc-link {\n",
              "  float: right;\n",
              "  font-size: smaller;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1em;\n",
              "  height: 1em;\n",
              "  width: 1em;\n",
              "  text-decoration: none !important;\n",
              "  margin-left: 0.5em;\n",
              "  text-align: center;\n",
              "  /* unfitted */\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted,\n",
              "a:link.sk-estimator-doc-link.fitted,\n",
              "a:visited.sk-estimator-doc-link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "/* Span, style for the box shown on hovering the info icon */\n",
              ".sk-estimator-doc-link span {\n",
              "  display: none;\n",
              "  z-index: 9999;\n",
              "  position: relative;\n",
              "  font-weight: normal;\n",
              "  right: .2ex;\n",
              "  padding: .5ex;\n",
              "  margin: .5ex;\n",
              "  width: min-content;\n",
              "  min-width: 20ex;\n",
              "  max-width: 50ex;\n",
              "  color: var(--sklearn-color-text);\n",
              "  box-shadow: 2pt 2pt 4pt #999;\n",
              "  /* unfitted */\n",
              "  background: var(--sklearn-color-unfitted-level-0);\n",
              "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted span {\n",
              "  /* fitted */\n",
              "  background: var(--sklearn-color-fitted-level-0);\n",
              "  border: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link:hover span {\n",
              "  display: block;\n",
              "}\n",
              "\n",
              "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link {\n",
              "  float: right;\n",
              "  font-size: 1rem;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1rem;\n",
              "  height: 1rem;\n",
              "  width: 1rem;\n",
              "  text-decoration: none;\n",
              "  /* unfitted */\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "#sk-container-id-1 a.estimator_doc_link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LGBMClassifier(bagging_fraction=0.8999999999999999, bagging_freq=4,\n",
              "               device=&#x27;gpu&#x27;, feature_fraction=0.8, gpu_device_id=0,\n",
              "               gpu_platform_id=0, lambda_l1=4.4610495762623494e-05,\n",
              "               lambda_l2=0.6898684039866835, learning_rate=0.16304239034369372,\n",
              "               max_depth=6, metric=&#x27;multi_logloss&#x27;, min_data_in_leaf=1200,\n",
              "               min_gain_to_split=0.3944497642389666, num_boost_round=3348,\n",
              "               num_class=5, num_leaves=260, objective=&#x27;multiclass&#x27;,\n",
              "               random_state=42, verbosity=-1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>LGBMClassifier</div></div><div><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>LGBMClassifier(bagging_fraction=0.8999999999999999, bagging_freq=4,\n",
              "               device=&#x27;gpu&#x27;, feature_fraction=0.8, gpu_device_id=0,\n",
              "               gpu_platform_id=0, lambda_l1=4.4610495762623494e-05,\n",
              "               lambda_l2=0.6898684039866835, learning_rate=0.16304239034369372,\n",
              "               max_depth=6, metric=&#x27;multi_logloss&#x27;, min_data_in_leaf=1200,\n",
              "               min_gain_to_split=0.3944497642389666, num_boost_round=3348,\n",
              "               num_class=5, num_leaves=260, objective=&#x27;multiclass&#x27;,\n",
              "               random_state=42, verbosity=-1)</pre></div> </div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lgb_model.booster_.save_model('/content/drive/MyDrive/Dacon/softvoting_lgbm_xgb변수_3_3_25.txt')"
      ],
      "metadata": {
        "id": "MwqIqU6JxPB7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3a0d7306-8c95-4ebf-9a50-144a49316a26"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<lightgbm.basic.Booster at 0x7c8d0155b910>"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## CatBoost 모델 학습"
      ],
      "metadata": {
        "id": "AXJIhMuLoQwA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import gc\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# catboost 설치\n",
        "!pip install catboost\n",
        "\n",
        "import sklearn\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "import imblearn\n",
        "from imblearn.over_sampling import SMOTE\n",
        "import xgboost as xgb\n",
        "from xgboost import XGBClassifier\n",
        "import catboost\n",
        "from catboost import CatBoostClassifier"
      ],
      "metadata": {
        "id": "yLoP8POpsh-L",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "03018b63-6a7b-4c94-a122-760fc0c3a353"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Collecting catboost\n",
            "  Downloading catboost-1.2.8-cp311-cp311-manylinux2014_x86_64.whl.metadata (1.2 kB)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.11/dist-packages (from catboost) (0.20.3)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from catboost) (3.10.0)\n",
            "Requirement already satisfied: numpy<3.0,>=1.16.0 in /usr/local/lib/python3.11/dist-packages (from catboost) (2.0.2)\n",
            "Requirement already satisfied: pandas>=0.24 in /usr/local/lib/python3.11/dist-packages (from catboost) (2.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from catboost) (1.15.2)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.11/dist-packages (from catboost) (5.24.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from catboost) (1.17.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.24->catboost) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.24->catboost) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.24->catboost) (2025.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (4.57.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (11.2.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (3.2.3)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from plotly->catboost) (9.1.2)\n",
            "Downloading catboost-1.2.8-cp311-cp311-manylinux2014_x86_64.whl (99.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.2/99.2 MB\u001b[0m \u001b[31m23.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: catboost\n",
            "Successfully installed catboost-1.2.8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_df = pd.read_parquet('/content/drive/MyDrive/Data/train_df_cleaned.parquet')\n",
        "\n",
        "feature_cols = [col for col in train_df.columns if col not in [\"ID\", \"Segment\"]]\n",
        "X = train_df[feature_cols].copy()\n",
        "y = train_df[\"Segment\"].copy()\n",
        "y = y.map({'A':0, 'B':1,'C':2,'D':3,'E':4})\n",
        "inverse_label_map = {0: 'A', 1: 'B', 2: 'C', 3: 'D', 4: 'E'}\n",
        "\n",
        "# 변수 300개 사용\n",
        "top300_df = pd.read_csv(\"/content/drive/MyDrive/Dacon/top300_features_XGB_balanced.csv\")\n",
        "top300_features = top300_df['feature'].tolist()\n",
        "X_top300 = X[top300_features]\n",
        "\n",
        "# 오버샘플링\n",
        "smote = SMOTE(sampling_strategy={0: 60000, 1: 120000, 2: 240000}, random_state=42)\n",
        "X_resampled, y_resampled = smote.fit_resample(X_top300, y)\n",
        "\n",
        "# 클래스별 weight 계산\n",
        "classes = np.unique(y_resampled)\n",
        "weights = compute_class_weight(class_weight='balanced', classes=classes, y=y_resampled)\n",
        "class_weights = dict(zip(classes, weights))\n",
        "sample_weights = pd.Series(y_resampled).map(class_weights)\n",
        "\n",
        "for cls in sorted(class_weights):\n",
        "    print(f\"클래스 {cls}: weight = {class_weights[cls]:.2f}\")"
      ],
      "metadata": {
        "id": "Aw2Qsa_boSqH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "911c9f92-40af-406b-c68a-e6892a87e5d6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "클래스 0: weight = 8.97\n",
            "클래스 1: weight = 4.49\n",
            "클래스 2: weight = 2.24\n",
            "클래스 3: weight = 1.54\n",
            "클래스 4: weight = 0.28\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cat_model = CatBoostClassifier(\n",
        "    task_type='GPU',\n",
        "    devices='0',\n",
        "    random_state=42,\n",
        "    class_weights=weights.tolist(),\n",
        "    iterations = 5000\n",
        ")\n",
        "\n",
        "# 모델 학습\n",
        "cat_model.fit(X_resampled, y_resampled)"
      ],
      "metadata": {
        "id": "ISrGWFHaxWoJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e9324017-e731-4c12-c109-4f007ff01dc5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43m스트리밍 출력 내용이 길어서 마지막 5000줄이 삭제되었습니다.\u001b[0m\n",
            "0:\tlearn: 1.4404799\ttotal: 570ms\tremaining: 47m 31s\n",
            "1:\tlearn: 1.3145128\ttotal: 727ms\tremaining: 30m 17s\n",
            "2:\tlearn: 1.2159606\ttotal: 855ms\tremaining: 23m 43s\n",
            "3:\tlearn: 1.1369381\ttotal: 969ms\tremaining: 20m 10s\n",
            "4:\tlearn: 1.0668382\ttotal: 1.09s\tremaining: 18m 8s\n",
            "5:\tlearn: 1.0107412\ttotal: 1.19s\tremaining: 16m 33s\n",
            "6:\tlearn: 0.9593553\ttotal: 1.3s\tremaining: 15m 29s\n",
            "7:\tlearn: 0.9158603\ttotal: 1.41s\tremaining: 14m 40s\n",
            "8:\tlearn: 0.8774866\ttotal: 1.53s\tremaining: 14m 6s\n",
            "9:\tlearn: 0.8432782\ttotal: 1.64s\tremaining: 13m 39s\n",
            "10:\tlearn: 0.8111483\ttotal: 1.77s\tremaining: 13m 23s\n",
            "11:\tlearn: 0.7833441\ttotal: 1.9s\tremaining: 13m 9s\n",
            "12:\tlearn: 0.7580101\ttotal: 2.02s\tremaining: 12m 54s\n",
            "13:\tlearn: 0.7334378\ttotal: 2.15s\tremaining: 12m 44s\n",
            "14:\tlearn: 0.7117192\ttotal: 2.26s\tremaining: 12m 32s\n",
            "15:\tlearn: 0.6930203\ttotal: 2.38s\tremaining: 12m 20s\n",
            "16:\tlearn: 0.6742999\ttotal: 2.5s\tremaining: 12m 13s\n",
            "17:\tlearn: 0.6578933\ttotal: 2.63s\tremaining: 12m 7s\n",
            "18:\tlearn: 0.6423834\ttotal: 2.78s\tremaining: 12m 9s\n",
            "19:\tlearn: 0.6279190\ttotal: 2.9s\tremaining: 12m 3s\n",
            "20:\tlearn: 0.6146387\ttotal: 3.03s\tremaining: 11m 58s\n",
            "21:\tlearn: 0.6032387\ttotal: 3.17s\tremaining: 11m 56s\n",
            "22:\tlearn: 0.5914217\ttotal: 3.3s\tremaining: 11m 54s\n",
            "23:\tlearn: 0.5805839\ttotal: 3.45s\tremaining: 11m 56s\n",
            "24:\tlearn: 0.5704116\ttotal: 3.6s\tremaining: 11m 55s\n",
            "25:\tlearn: 0.5610600\ttotal: 3.75s\tremaining: 11m 56s\n",
            "26:\tlearn: 0.5522921\ttotal: 3.88s\tremaining: 11m 54s\n",
            "27:\tlearn: 0.5444565\ttotal: 4s\tremaining: 11m 50s\n",
            "28:\tlearn: 0.5365444\ttotal: 4.17s\tremaining: 11m 54s\n",
            "29:\tlearn: 0.5300733\ttotal: 4.31s\tremaining: 11m 54s\n",
            "30:\tlearn: 0.5240614\ttotal: 4.46s\tremaining: 11m 54s\n",
            "31:\tlearn: 0.5176538\ttotal: 4.57s\tremaining: 11m 50s\n",
            "32:\tlearn: 0.5126767\ttotal: 4.71s\tremaining: 11m 48s\n",
            "33:\tlearn: 0.5062155\ttotal: 4.82s\tremaining: 11m 43s\n",
            "34:\tlearn: 0.5009015\ttotal: 4.94s\tremaining: 11m 41s\n",
            "35:\tlearn: 0.4972015\ttotal: 5.06s\tremaining: 11m 38s\n",
            "36:\tlearn: 0.4923291\ttotal: 5.18s\tremaining: 11m 34s\n",
            "37:\tlearn: 0.4875367\ttotal: 5.28s\tremaining: 11m 29s\n",
            "38:\tlearn: 0.4834461\ttotal: 5.39s\tremaining: 11m 25s\n",
            "39:\tlearn: 0.4795330\ttotal: 5.52s\tremaining: 11m 24s\n",
            "40:\tlearn: 0.4752697\ttotal: 5.68s\tremaining: 11m 27s\n",
            "41:\tlearn: 0.4709348\ttotal: 5.78s\tremaining: 11m 22s\n",
            "42:\tlearn: 0.4678630\ttotal: 5.91s\tremaining: 11m 21s\n",
            "43:\tlearn: 0.4637211\ttotal: 6.02s\tremaining: 11m 18s\n",
            "44:\tlearn: 0.4612569\ttotal: 6.15s\tremaining: 11m 17s\n",
            "45:\tlearn: 0.4580515\ttotal: 6.25s\tremaining: 11m 13s\n",
            "46:\tlearn: 0.4539140\ttotal: 6.38s\tremaining: 11m 12s\n",
            "47:\tlearn: 0.4515529\ttotal: 6.51s\tremaining: 11m 11s\n",
            "48:\tlearn: 0.4487329\ttotal: 6.65s\tremaining: 11m 12s\n",
            "49:\tlearn: 0.4456780\ttotal: 6.76s\tremaining: 11m 8s\n",
            "50:\tlearn: 0.4432194\ttotal: 6.87s\tremaining: 11m 6s\n",
            "51:\tlearn: 0.4410207\ttotal: 6.99s\tremaining: 11m 5s\n",
            "52:\tlearn: 0.4389966\ttotal: 7.12s\tremaining: 11m 4s\n",
            "53:\tlearn: 0.4362743\ttotal: 7.23s\tremaining: 11m 2s\n",
            "54:\tlearn: 0.4348366\ttotal: 7.35s\tremaining: 11m\n",
            "55:\tlearn: 0.4324712\ttotal: 7.49s\tremaining: 11m 1s\n",
            "56:\tlearn: 0.4301369\ttotal: 7.61s\tremaining: 10m 59s\n",
            "57:\tlearn: 0.4268255\ttotal: 7.73s\tremaining: 10m 58s\n",
            "58:\tlearn: 0.4248952\ttotal: 7.86s\tremaining: 10m 57s\n",
            "59:\tlearn: 0.4222580\ttotal: 7.95s\tremaining: 10m 54s\n",
            "60:\tlearn: 0.4206028\ttotal: 8.08s\tremaining: 10m 54s\n",
            "61:\tlearn: 0.4186134\ttotal: 8.23s\tremaining: 10m 55s\n",
            "62:\tlearn: 0.4168378\ttotal: 8.37s\tremaining: 10m 56s\n",
            "63:\tlearn: 0.4150629\ttotal: 8.51s\tremaining: 10m 56s\n",
            "64:\tlearn: 0.4139120\ttotal: 8.59s\tremaining: 10m 52s\n",
            "65:\tlearn: 0.4117814\ttotal: 8.71s\tremaining: 10m 51s\n",
            "66:\tlearn: 0.4098728\ttotal: 8.83s\tremaining: 10m 49s\n",
            "67:\tlearn: 0.4085411\ttotal: 8.94s\tremaining: 10m 48s\n",
            "68:\tlearn: 0.4068319\ttotal: 9.03s\tremaining: 10m 45s\n",
            "69:\tlearn: 0.4057153\ttotal: 9.17s\tremaining: 10m 45s\n",
            "70:\tlearn: 0.4042276\ttotal: 9.31s\tremaining: 10m 46s\n",
            "71:\tlearn: 0.4020957\ttotal: 9.44s\tremaining: 10m 46s\n",
            "72:\tlearn: 0.4004240\ttotal: 9.56s\tremaining: 10m 45s\n",
            "73:\tlearn: 0.3986767\ttotal: 9.68s\tremaining: 10m 44s\n",
            "74:\tlearn: 0.3965862\ttotal: 9.8s\tremaining: 10m 43s\n",
            "75:\tlearn: 0.3945502\ttotal: 9.91s\tremaining: 10m 42s\n",
            "76:\tlearn: 0.3934080\ttotal: 10s\tremaining: 10m 41s\n",
            "77:\tlearn: 0.3923262\ttotal: 10.2s\tremaining: 10m 42s\n",
            "78:\tlearn: 0.3909406\ttotal: 10.3s\tremaining: 10m 43s\n",
            "79:\tlearn: 0.3895133\ttotal: 10.5s\tremaining: 10m 42s\n",
            "80:\tlearn: 0.3882674\ttotal: 10.5s\tremaining: 10m 40s\n",
            "81:\tlearn: 0.3873043\ttotal: 10.6s\tremaining: 10m 38s\n",
            "82:\tlearn: 0.3860815\ttotal: 10.8s\tremaining: 10m 39s\n",
            "83:\tlearn: 0.3851533\ttotal: 10.9s\tremaining: 10m 40s\n",
            "84:\tlearn: 0.3838696\ttotal: 11.1s\tremaining: 10m 42s\n",
            "85:\tlearn: 0.3824568\ttotal: 11.2s\tremaining: 10m 41s\n",
            "86:\tlearn: 0.3814090\ttotal: 11.4s\tremaining: 10m 41s\n",
            "87:\tlearn: 0.3802467\ttotal: 11.5s\tremaining: 10m 43s\n",
            "88:\tlearn: 0.3788790\ttotal: 11.6s\tremaining: 10m 41s\n",
            "89:\tlearn: 0.3768262\ttotal: 11.8s\tremaining: 10m 41s\n",
            "90:\tlearn: 0.3758429\ttotal: 11.9s\tremaining: 10m 42s\n",
            "91:\tlearn: 0.3746465\ttotal: 12s\tremaining: 10m 41s\n",
            "92:\tlearn: 0.3732818\ttotal: 12.1s\tremaining: 10m 40s\n",
            "93:\tlearn: 0.3721961\ttotal: 12.3s\tremaining: 10m 40s\n",
            "94:\tlearn: 0.3711715\ttotal: 12.4s\tremaining: 10m 39s\n",
            "95:\tlearn: 0.3702381\ttotal: 12.5s\tremaining: 10m 39s\n",
            "96:\tlearn: 0.3693818\ttotal: 12.6s\tremaining: 10m 37s\n",
            "97:\tlearn: 0.3682914\ttotal: 12.7s\tremaining: 10m 37s\n",
            "98:\tlearn: 0.3672966\ttotal: 12.9s\tremaining: 10m 36s\n",
            "99:\tlearn: 0.3661985\ttotal: 13s\tremaining: 10m 35s\n",
            "100:\tlearn: 0.3652973\ttotal: 13.1s\tremaining: 10m 35s\n",
            "101:\tlearn: 0.3644264\ttotal: 13.2s\tremaining: 10m 35s\n",
            "102:\tlearn: 0.3631937\ttotal: 13.3s\tremaining: 10m 34s\n",
            "103:\tlearn: 0.3623287\ttotal: 13.4s\tremaining: 10m 32s\n",
            "104:\tlearn: 0.3616800\ttotal: 13.6s\tremaining: 10m 34s\n",
            "105:\tlearn: 0.3610693\ttotal: 13.7s\tremaining: 10m 34s\n",
            "106:\tlearn: 0.3603620\ttotal: 13.8s\tremaining: 10m 32s\n",
            "107:\tlearn: 0.3596061\ttotal: 14s\tremaining: 10m 33s\n",
            "108:\tlearn: 0.3586704\ttotal: 14.1s\tremaining: 10m 33s\n",
            "109:\tlearn: 0.3578634\ttotal: 14.2s\tremaining: 10m 31s\n",
            "110:\tlearn: 0.3571583\ttotal: 14.4s\tremaining: 10m 32s\n",
            "111:\tlearn: 0.3566452\ttotal: 14.5s\tremaining: 10m 32s\n",
            "112:\tlearn: 0.3558293\ttotal: 14.6s\tremaining: 10m 32s\n",
            "113:\tlearn: 0.3551156\ttotal: 14.8s\tremaining: 10m 33s\n",
            "114:\tlearn: 0.3539671\ttotal: 14.9s\tremaining: 10m 33s\n",
            "115:\tlearn: 0.3527190\ttotal: 15.1s\tremaining: 10m 33s\n",
            "116:\tlearn: 0.3518909\ttotal: 15.2s\tremaining: 10m 35s\n",
            "117:\tlearn: 0.3511554\ttotal: 15.3s\tremaining: 10m 35s\n",
            "118:\tlearn: 0.3503192\ttotal: 15.4s\tremaining: 10m 32s\n",
            "119:\tlearn: 0.3494800\ttotal: 15.5s\tremaining: 10m 31s\n",
            "120:\tlearn: 0.3486077\ttotal: 15.6s\tremaining: 10m 30s\n",
            "121:\tlearn: 0.3480497\ttotal: 15.8s\tremaining: 10m 30s\n",
            "122:\tlearn: 0.3475105\ttotal: 15.9s\tremaining: 10m 30s\n",
            "123:\tlearn: 0.3468759\ttotal: 16.1s\tremaining: 10m 31s\n",
            "124:\tlearn: 0.3458291\ttotal: 16.2s\tremaining: 10m 30s\n",
            "125:\tlearn: 0.3450608\ttotal: 16.3s\tremaining: 10m 30s\n",
            "126:\tlearn: 0.3444706\ttotal: 16.4s\tremaining: 10m 31s\n",
            "127:\tlearn: 0.3436159\ttotal: 16.6s\tremaining: 10m 31s\n",
            "128:\tlearn: 0.3428272\ttotal: 16.7s\tremaining: 10m 31s\n",
            "129:\tlearn: 0.3422414\ttotal: 16.8s\tremaining: 10m 31s\n",
            "130:\tlearn: 0.3413694\ttotal: 17s\tremaining: 10m 30s\n",
            "131:\tlearn: 0.3407051\ttotal: 17.1s\tremaining: 10m 30s\n",
            "132:\tlearn: 0.3402391\ttotal: 17.2s\tremaining: 10m 29s\n",
            "133:\tlearn: 0.3396583\ttotal: 17.3s\tremaining: 10m 29s\n",
            "134:\tlearn: 0.3390917\ttotal: 17.5s\tremaining: 10m 30s\n",
            "135:\tlearn: 0.3382488\ttotal: 17.6s\tremaining: 10m 29s\n",
            "136:\tlearn: 0.3377634\ttotal: 17.7s\tremaining: 10m 29s\n",
            "137:\tlearn: 0.3373470\ttotal: 17.8s\tremaining: 10m 27s\n",
            "138:\tlearn: 0.3367954\ttotal: 18s\tremaining: 10m 29s\n",
            "139:\tlearn: 0.3363803\ttotal: 18.1s\tremaining: 10m 28s\n",
            "140:\tlearn: 0.3356414\ttotal: 18.2s\tremaining: 10m 27s\n",
            "141:\tlearn: 0.3352532\ttotal: 18.3s\tremaining: 10m 26s\n",
            "142:\tlearn: 0.3345948\ttotal: 18.4s\tremaining: 10m 25s\n",
            "143:\tlearn: 0.3338185\ttotal: 18.5s\tremaining: 10m 24s\n",
            "144:\tlearn: 0.3331063\ttotal: 18.6s\tremaining: 10m 23s\n",
            "145:\tlearn: 0.3325801\ttotal: 18.8s\tremaining: 10m 24s\n",
            "146:\tlearn: 0.3319931\ttotal: 18.9s\tremaining: 10m 23s\n",
            "147:\tlearn: 0.3312125\ttotal: 19s\tremaining: 10m 23s\n",
            "148:\tlearn: 0.3308160\ttotal: 19.1s\tremaining: 10m 22s\n",
            "149:\tlearn: 0.3300586\ttotal: 19.2s\tremaining: 10m 22s\n",
            "150:\tlearn: 0.3297031\ttotal: 19.4s\tremaining: 10m 21s\n",
            "151:\tlearn: 0.3292953\ttotal: 19.5s\tremaining: 10m 20s\n",
            "152:\tlearn: 0.3288568\ttotal: 19.6s\tremaining: 10m 20s\n",
            "153:\tlearn: 0.3281495\ttotal: 19.7s\tremaining: 10m 20s\n",
            "154:\tlearn: 0.3275026\ttotal: 19.9s\tremaining: 10m 21s\n",
            "155:\tlearn: 0.3269922\ttotal: 20s\tremaining: 10m 19s\n",
            "156:\tlearn: 0.3264224\ttotal: 20.1s\tremaining: 10m 21s\n",
            "157:\tlearn: 0.3259840\ttotal: 20.3s\tremaining: 10m 21s\n",
            "158:\tlearn: 0.3256367\ttotal: 20.4s\tremaining: 10m 20s\n",
            "159:\tlearn: 0.3252506\ttotal: 20.5s\tremaining: 10m 20s\n",
            "160:\tlearn: 0.3247166\ttotal: 20.6s\tremaining: 10m 19s\n",
            "161:\tlearn: 0.3242376\ttotal: 20.8s\tremaining: 10m 19s\n",
            "162:\tlearn: 0.3235018\ttotal: 20.9s\tremaining: 10m 19s\n",
            "163:\tlearn: 0.3228381\ttotal: 21s\tremaining: 10m 19s\n",
            "164:\tlearn: 0.3225079\ttotal: 21.1s\tremaining: 10m 18s\n",
            "165:\tlearn: 0.3219123\ttotal: 21.3s\tremaining: 10m 18s\n",
            "166:\tlearn: 0.3213536\ttotal: 21.4s\tremaining: 10m 19s\n",
            "167:\tlearn: 0.3209279\ttotal: 21.5s\tremaining: 10m 19s\n",
            "168:\tlearn: 0.3203804\ttotal: 21.7s\tremaining: 10m 19s\n",
            "169:\tlearn: 0.3198124\ttotal: 21.8s\tremaining: 10m 19s\n",
            "170:\tlearn: 0.3193991\ttotal: 21.9s\tremaining: 10m 19s\n",
            "171:\tlearn: 0.3189147\ttotal: 22s\tremaining: 10m 17s\n",
            "172:\tlearn: 0.3185387\ttotal: 22.1s\tremaining: 10m 16s\n",
            "173:\tlearn: 0.3180593\ttotal: 22.2s\tremaining: 10m 17s\n",
            "174:\tlearn: 0.3175922\ttotal: 22.3s\tremaining: 10m 16s\n",
            "175:\tlearn: 0.3170304\ttotal: 22.5s\tremaining: 10m 15s\n",
            "176:\tlearn: 0.3166958\ttotal: 22.6s\tremaining: 10m 15s\n",
            "177:\tlearn: 0.3163644\ttotal: 22.7s\tremaining: 10m 15s\n",
            "178:\tlearn: 0.3158942\ttotal: 22.9s\tremaining: 10m 15s\n",
            "179:\tlearn: 0.3154669\ttotal: 23s\tremaining: 10m 16s\n",
            "180:\tlearn: 0.3151468\ttotal: 23.1s\tremaining: 10m 16s\n",
            "181:\tlearn: 0.3146944\ttotal: 23.2s\tremaining: 10m 15s\n",
            "182:\tlearn: 0.3144265\ttotal: 23.4s\tremaining: 10m 14s\n",
            "183:\tlearn: 0.3138686\ttotal: 23.5s\tremaining: 10m 13s\n",
            "184:\tlearn: 0.3134776\ttotal: 23.6s\tremaining: 10m 13s\n",
            "185:\tlearn: 0.3130924\ttotal: 23.7s\tremaining: 10m 13s\n",
            "186:\tlearn: 0.3125709\ttotal: 23.8s\tremaining: 10m 13s\n",
            "187:\tlearn: 0.3122147\ttotal: 24s\tremaining: 10m 13s\n",
            "188:\tlearn: 0.3119124\ttotal: 24.1s\tremaining: 10m 13s\n",
            "189:\tlearn: 0.3114580\ttotal: 24.2s\tremaining: 10m 13s\n",
            "190:\tlearn: 0.3110101\ttotal: 24.4s\tremaining: 10m 13s\n",
            "191:\tlearn: 0.3104984\ttotal: 24.5s\tremaining: 10m 14s\n",
            "192:\tlearn: 0.3101388\ttotal: 24.6s\tremaining: 10m 13s\n",
            "193:\tlearn: 0.3097673\ttotal: 24.7s\tremaining: 10m 13s\n",
            "194:\tlearn: 0.3093453\ttotal: 24.9s\tremaining: 10m 12s\n",
            "195:\tlearn: 0.3088163\ttotal: 25s\tremaining: 10m 11s\n",
            "196:\tlearn: 0.3084988\ttotal: 25.1s\tremaining: 10m 12s\n",
            "197:\tlearn: 0.3081299\ttotal: 25.2s\tremaining: 10m 12s\n",
            "198:\tlearn: 0.3077706\ttotal: 25.3s\tremaining: 10m 11s\n",
            "199:\tlearn: 0.3074912\ttotal: 25.5s\tremaining: 10m 11s\n",
            "200:\tlearn: 0.3071833\ttotal: 25.6s\tremaining: 10m 11s\n",
            "201:\tlearn: 0.3064740\ttotal: 25.8s\tremaining: 10m 11s\n",
            "202:\tlearn: 0.3059509\ttotal: 25.9s\tremaining: 10m 12s\n",
            "203:\tlearn: 0.3057097\ttotal: 26s\tremaining: 10m 11s\n",
            "204:\tlearn: 0.3053197\ttotal: 26.1s\tremaining: 10m 11s\n",
            "205:\tlearn: 0.3050917\ttotal: 26.3s\tremaining: 10m 11s\n",
            "206:\tlearn: 0.3047549\ttotal: 26.4s\tremaining: 10m 10s\n",
            "207:\tlearn: 0.3041892\ttotal: 26.5s\tremaining: 10m 10s\n",
            "208:\tlearn: 0.3037208\ttotal: 26.6s\tremaining: 10m 9s\n",
            "209:\tlearn: 0.3031915\ttotal: 26.7s\tremaining: 10m 9s\n",
            "210:\tlearn: 0.3029517\ttotal: 26.9s\tremaining: 10m 9s\n",
            "211:\tlearn: 0.3026194\ttotal: 27s\tremaining: 10m 9s\n",
            "212:\tlearn: 0.3023329\ttotal: 27.1s\tremaining: 10m 9s\n",
            "213:\tlearn: 0.3020171\ttotal: 27.2s\tremaining: 10m 9s\n",
            "214:\tlearn: 0.3017584\ttotal: 27.4s\tremaining: 10m 9s\n",
            "215:\tlearn: 0.3015238\ttotal: 27.5s\tremaining: 10m 9s\n",
            "216:\tlearn: 0.3010358\ttotal: 27.6s\tremaining: 10m 8s\n",
            "217:\tlearn: 0.3007118\ttotal: 27.7s\tremaining: 10m 8s\n",
            "218:\tlearn: 0.3001948\ttotal: 27.9s\tremaining: 10m 8s\n",
            "219:\tlearn: 0.2998872\ttotal: 28s\tremaining: 10m 8s\n",
            "220:\tlearn: 0.2996081\ttotal: 28.1s\tremaining: 10m 7s\n",
            "221:\tlearn: 0.2992991\ttotal: 28.3s\tremaining: 10m 8s\n",
            "222:\tlearn: 0.2990023\ttotal: 28.4s\tremaining: 10m 8s\n",
            "223:\tlearn: 0.2986975\ttotal: 28.5s\tremaining: 10m 7s\n",
            "224:\tlearn: 0.2982728\ttotal: 28.6s\tremaining: 10m 7s\n",
            "225:\tlearn: 0.2979695\ttotal: 28.8s\tremaining: 10m 7s\n",
            "226:\tlearn: 0.2976339\ttotal: 28.9s\tremaining: 10m 7s\n",
            "227:\tlearn: 0.2972800\ttotal: 29s\tremaining: 10m 7s\n",
            "228:\tlearn: 0.2970342\ttotal: 29.1s\tremaining: 10m 7s\n",
            "229:\tlearn: 0.2966900\ttotal: 29.2s\tremaining: 10m 6s\n",
            "230:\tlearn: 0.2963950\ttotal: 29.4s\tremaining: 10m 6s\n",
            "231:\tlearn: 0.2961961\ttotal: 29.5s\tremaining: 10m 6s\n",
            "232:\tlearn: 0.2957990\ttotal: 29.6s\tremaining: 10m 6s\n",
            "233:\tlearn: 0.2953653\ttotal: 29.8s\tremaining: 10m 6s\n",
            "234:\tlearn: 0.2950908\ttotal: 29.9s\tremaining: 10m 6s\n",
            "235:\tlearn: 0.2948619\ttotal: 30s\tremaining: 10m 6s\n",
            "236:\tlearn: 0.2945624\ttotal: 30.2s\tremaining: 10m 6s\n",
            "237:\tlearn: 0.2943480\ttotal: 30.3s\tremaining: 10m 6s\n",
            "238:\tlearn: 0.2940658\ttotal: 30.5s\tremaining: 10m 6s\n",
            "239:\tlearn: 0.2938393\ttotal: 30.6s\tremaining: 10m 6s\n",
            "240:\tlearn: 0.2935030\ttotal: 30.7s\tremaining: 10m 7s\n",
            "241:\tlearn: 0.2932983\ttotal: 30.8s\tremaining: 10m 6s\n",
            "242:\tlearn: 0.2930511\ttotal: 30.9s\tremaining: 10m 5s\n",
            "243:\tlearn: 0.2927757\ttotal: 31.1s\tremaining: 10m 5s\n",
            "244:\tlearn: 0.2925755\ttotal: 31.2s\tremaining: 10m 5s\n",
            "245:\tlearn: 0.2921393\ttotal: 31.3s\tremaining: 10m 5s\n",
            "246:\tlearn: 0.2919134\ttotal: 31.5s\tremaining: 10m 5s\n",
            "247:\tlearn: 0.2917186\ttotal: 31.6s\tremaining: 10m 4s\n",
            "248:\tlearn: 0.2914064\ttotal: 31.7s\tremaining: 10m 4s\n",
            "249:\tlearn: 0.2911673\ttotal: 31.8s\tremaining: 10m 4s\n",
            "250:\tlearn: 0.2908422\ttotal: 32s\tremaining: 10m 4s\n",
            "251:\tlearn: 0.2904977\ttotal: 32.1s\tremaining: 10m 4s\n",
            "252:\tlearn: 0.2902929\ttotal: 32.2s\tremaining: 10m 4s\n",
            "253:\tlearn: 0.2900892\ttotal: 32.3s\tremaining: 10m 4s\n",
            "254:\tlearn: 0.2897626\ttotal: 32.5s\tremaining: 10m 4s\n",
            "255:\tlearn: 0.2895250\ttotal: 32.6s\tremaining: 10m 4s\n",
            "256:\tlearn: 0.2892955\ttotal: 32.7s\tremaining: 10m 3s\n",
            "257:\tlearn: 0.2890396\ttotal: 32.8s\tremaining: 10m 3s\n",
            "258:\tlearn: 0.2887602\ttotal: 33s\tremaining: 10m 3s\n",
            "259:\tlearn: 0.2883345\ttotal: 33s\tremaining: 10m 2s\n",
            "260:\tlearn: 0.2881345\ttotal: 33.1s\tremaining: 10m 1s\n",
            "261:\tlearn: 0.2879503\ttotal: 33.3s\tremaining: 10m 1s\n",
            "262:\tlearn: 0.2877162\ttotal: 33.4s\tremaining: 10m 1s\n",
            "263:\tlearn: 0.2874884\ttotal: 33.5s\tremaining: 10m 1s\n",
            "264:\tlearn: 0.2872459\ttotal: 33.7s\tremaining: 10m 1s\n",
            "265:\tlearn: 0.2869533\ttotal: 33.8s\tremaining: 10m 1s\n",
            "266:\tlearn: 0.2866562\ttotal: 33.9s\tremaining: 10m 1s\n",
            "267:\tlearn: 0.2864875\ttotal: 34s\tremaining: 10m\n",
            "268:\tlearn: 0.2862056\ttotal: 34.2s\tremaining: 10m\n",
            "269:\tlearn: 0.2859875\ttotal: 34.3s\tremaining: 10m\n",
            "270:\tlearn: 0.2857599\ttotal: 34.4s\tremaining: 10m\n",
            "271:\tlearn: 0.2854176\ttotal: 34.5s\tremaining: 10m\n",
            "272:\tlearn: 0.2850962\ttotal: 34.7s\tremaining: 10m\n",
            "273:\tlearn: 0.2848418\ttotal: 34.8s\tremaining: 9m 59s\n",
            "274:\tlearn: 0.2846588\ttotal: 34.9s\tremaining: 9m 59s\n",
            "275:\tlearn: 0.2844344\ttotal: 35s\tremaining: 9m 59s\n",
            "276:\tlearn: 0.2842096\ttotal: 35.1s\tremaining: 9m 59s\n",
            "277:\tlearn: 0.2840555\ttotal: 35.2s\tremaining: 9m 58s\n",
            "278:\tlearn: 0.2838617\ttotal: 35.4s\tremaining: 9m 58s\n",
            "279:\tlearn: 0.2836363\ttotal: 35.5s\tremaining: 9m 57s\n",
            "280:\tlearn: 0.2833538\ttotal: 35.6s\tremaining: 9m 57s\n",
            "281:\tlearn: 0.2830855\ttotal: 35.7s\tremaining: 9m 57s\n",
            "282:\tlearn: 0.2828974\ttotal: 35.8s\tremaining: 9m 56s\n",
            "283:\tlearn: 0.2826934\ttotal: 36s\tremaining: 9m 57s\n",
            "284:\tlearn: 0.2824896\ttotal: 36.1s\tremaining: 9m 57s\n",
            "285:\tlearn: 0.2823276\ttotal: 36.2s\tremaining: 9m 57s\n",
            "286:\tlearn: 0.2821862\ttotal: 36.3s\tremaining: 9m 56s\n",
            "287:\tlearn: 0.2818090\ttotal: 36.4s\tremaining: 9m 56s\n",
            "288:\tlearn: 0.2816063\ttotal: 36.6s\tremaining: 9m 56s\n",
            "289:\tlearn: 0.2812793\ttotal: 36.7s\tremaining: 9m 55s\n",
            "290:\tlearn: 0.2810732\ttotal: 36.8s\tremaining: 9m 55s\n",
            "291:\tlearn: 0.2807607\ttotal: 36.9s\tremaining: 9m 55s\n",
            "292:\tlearn: 0.2804534\ttotal: 37.1s\tremaining: 9m 55s\n",
            "293:\tlearn: 0.2802202\ttotal: 37.2s\tremaining: 9m 54s\n",
            "294:\tlearn: 0.2800670\ttotal: 37.3s\tremaining: 9m 54s\n",
            "295:\tlearn: 0.2799451\ttotal: 37.4s\tremaining: 9m 54s\n",
            "296:\tlearn: 0.2797746\ttotal: 37.5s\tremaining: 9m 54s\n",
            "297:\tlearn: 0.2795399\ttotal: 37.6s\tremaining: 9m 54s\n",
            "298:\tlearn: 0.2792702\ttotal: 37.7s\tremaining: 9m 53s\n",
            "299:\tlearn: 0.2790511\ttotal: 37.9s\tremaining: 9m 53s\n",
            "300:\tlearn: 0.2788591\ttotal: 38s\tremaining: 9m 53s\n",
            "301:\tlearn: 0.2786276\ttotal: 38.2s\tremaining: 9m 53s\n",
            "302:\tlearn: 0.2784787\ttotal: 38.3s\tremaining: 9m 53s\n",
            "303:\tlearn: 0.2782168\ttotal: 38.4s\tremaining: 9m 53s\n",
            "304:\tlearn: 0.2780494\ttotal: 38.5s\tremaining: 9m 52s\n",
            "305:\tlearn: 0.2778172\ttotal: 38.6s\tremaining: 9m 52s\n",
            "306:\tlearn: 0.2776391\ttotal: 38.7s\tremaining: 9m 52s\n",
            "307:\tlearn: 0.2773814\ttotal: 38.8s\tremaining: 9m 51s\n",
            "308:\tlearn: 0.2772164\ttotal: 38.9s\tremaining: 9m 51s\n",
            "309:\tlearn: 0.2770286\ttotal: 39.1s\tremaining: 9m 51s\n",
            "310:\tlearn: 0.2768135\ttotal: 39.2s\tremaining: 9m 50s\n",
            "311:\tlearn: 0.2765884\ttotal: 39.3s\tremaining: 9m 50s\n",
            "312:\tlearn: 0.2763406\ttotal: 39.4s\tremaining: 9m 50s\n",
            "313:\tlearn: 0.2760568\ttotal: 39.6s\tremaining: 9m 50s\n",
            "314:\tlearn: 0.2758980\ttotal: 39.6s\tremaining: 9m 49s\n",
            "315:\tlearn: 0.2756379\ttotal: 39.8s\tremaining: 9m 50s\n",
            "316:\tlearn: 0.2754459\ttotal: 39.9s\tremaining: 9m 50s\n",
            "317:\tlearn: 0.2752943\ttotal: 40.1s\tremaining: 9m 50s\n",
            "318:\tlearn: 0.2750829\ttotal: 40.2s\tremaining: 9m 50s\n",
            "319:\tlearn: 0.2748717\ttotal: 40.3s\tremaining: 9m 49s\n",
            "320:\tlearn: 0.2746818\ttotal: 40.4s\tremaining: 9m 49s\n",
            "321:\tlearn: 0.2744779\ttotal: 40.6s\tremaining: 9m 49s\n",
            "322:\tlearn: 0.2743172\ttotal: 40.7s\tremaining: 9m 49s\n",
            "323:\tlearn: 0.2741880\ttotal: 40.9s\tremaining: 9m 49s\n",
            "324:\tlearn: 0.2740132\ttotal: 41s\tremaining: 9m 49s\n",
            "325:\tlearn: 0.2737637\ttotal: 41.1s\tremaining: 9m 49s\n",
            "326:\tlearn: 0.2735677\ttotal: 41.3s\tremaining: 9m 50s\n",
            "327:\tlearn: 0.2733824\ttotal: 41.4s\tremaining: 9m 50s\n",
            "328:\tlearn: 0.2731920\ttotal: 41.5s\tremaining: 9m 49s\n",
            "329:\tlearn: 0.2729998\ttotal: 41.6s\tremaining: 9m 49s\n",
            "330:\tlearn: 0.2728218\ttotal: 41.7s\tremaining: 9m 48s\n",
            "331:\tlearn: 0.2726560\ttotal: 41.9s\tremaining: 9m 48s\n",
            "332:\tlearn: 0.2725243\ttotal: 42s\tremaining: 9m 48s\n",
            "333:\tlearn: 0.2723983\ttotal: 42.1s\tremaining: 9m 48s\n",
            "334:\tlearn: 0.2722889\ttotal: 42.2s\tremaining: 9m 48s\n",
            "335:\tlearn: 0.2721702\ttotal: 42.3s\tremaining: 9m 47s\n",
            "336:\tlearn: 0.2719946\ttotal: 42.5s\tremaining: 9m 47s\n",
            "337:\tlearn: 0.2718275\ttotal: 42.6s\tremaining: 9m 47s\n",
            "338:\tlearn: 0.2716655\ttotal: 42.7s\tremaining: 9m 47s\n",
            "339:\tlearn: 0.2713903\ttotal: 42.8s\tremaining: 9m 47s\n",
            "340:\tlearn: 0.2711538\ttotal: 42.9s\tremaining: 9m 46s\n",
            "341:\tlearn: 0.2709854\ttotal: 43s\tremaining: 9m 46s\n",
            "342:\tlearn: 0.2707288\ttotal: 43.2s\tremaining: 9m 45s\n",
            "343:\tlearn: 0.2705163\ttotal: 43.3s\tremaining: 9m 45s\n",
            "344:\tlearn: 0.2703463\ttotal: 43.4s\tremaining: 9m 46s\n",
            "345:\tlearn: 0.2701398\ttotal: 43.5s\tremaining: 9m 45s\n",
            "346:\tlearn: 0.2699565\ttotal: 43.6s\tremaining: 9m 45s\n",
            "347:\tlearn: 0.2698353\ttotal: 43.8s\tremaining: 9m 45s\n",
            "348:\tlearn: 0.2696761\ttotal: 43.9s\tremaining: 9m 45s\n",
            "349:\tlearn: 0.2695031\ttotal: 44s\tremaining: 9m 44s\n",
            "350:\tlearn: 0.2693670\ttotal: 44.1s\tremaining: 9m 44s\n",
            "351:\tlearn: 0.2692562\ttotal: 44.2s\tremaining: 9m 44s\n",
            "352:\tlearn: 0.2691169\ttotal: 44.3s\tremaining: 9m 43s\n",
            "353:\tlearn: 0.2689581\ttotal: 44.4s\tremaining: 9m 43s\n",
            "354:\tlearn: 0.2687889\ttotal: 44.6s\tremaining: 9m 43s\n",
            "355:\tlearn: 0.2686053\ttotal: 44.7s\tremaining: 9m 43s\n",
            "356:\tlearn: 0.2684867\ttotal: 44.8s\tremaining: 9m 43s\n",
            "357:\tlearn: 0.2683300\ttotal: 45s\tremaining: 9m 43s\n",
            "358:\tlearn: 0.2681202\ttotal: 45.1s\tremaining: 9m 42s\n",
            "359:\tlearn: 0.2679576\ttotal: 45.2s\tremaining: 9m 42s\n",
            "360:\tlearn: 0.2677930\ttotal: 45.3s\tremaining: 9m 42s\n",
            "361:\tlearn: 0.2675944\ttotal: 45.5s\tremaining: 9m 42s\n",
            "362:\tlearn: 0.2674526\ttotal: 45.6s\tremaining: 9m 42s\n",
            "363:\tlearn: 0.2673273\ttotal: 45.7s\tremaining: 9m 42s\n",
            "364:\tlearn: 0.2671260\ttotal: 45.8s\tremaining: 9m 42s\n",
            "365:\tlearn: 0.2668616\ttotal: 46s\tremaining: 9m 42s\n",
            "366:\tlearn: 0.2667473\ttotal: 46.1s\tremaining: 9m 41s\n",
            "367:\tlearn: 0.2666068\ttotal: 46.2s\tremaining: 9m 40s\n",
            "368:\tlearn: 0.2664465\ttotal: 46.3s\tremaining: 9m 40s\n",
            "369:\tlearn: 0.2662490\ttotal: 46.3s\tremaining: 9m 39s\n",
            "370:\tlearn: 0.2661311\ttotal: 46.5s\tremaining: 9m 39s\n",
            "371:\tlearn: 0.2659460\ttotal: 46.6s\tremaining: 9m 39s\n",
            "372:\tlearn: 0.2657757\ttotal: 46.7s\tremaining: 9m 38s\n",
            "373:\tlearn: 0.2656451\ttotal: 46.8s\tremaining: 9m 38s\n",
            "374:\tlearn: 0.2654747\ttotal: 46.9s\tremaining: 9m 38s\n",
            "375:\tlearn: 0.2653239\ttotal: 47s\tremaining: 9m 38s\n",
            "376:\tlearn: 0.2651057\ttotal: 47.2s\tremaining: 9m 38s\n",
            "377:\tlearn: 0.2650112\ttotal: 47.3s\tremaining: 9m 38s\n",
            "378:\tlearn: 0.2648423\ttotal: 47.4s\tremaining: 9m 37s\n",
            "379:\tlearn: 0.2646214\ttotal: 47.6s\tremaining: 9m 38s\n",
            "380:\tlearn: 0.2644944\ttotal: 47.7s\tremaining: 9m 38s\n",
            "381:\tlearn: 0.2642213\ttotal: 47.8s\tremaining: 9m 37s\n",
            "382:\tlearn: 0.2640379\ttotal: 48s\tremaining: 9m 38s\n",
            "383:\tlearn: 0.2638656\ttotal: 48.1s\tremaining: 9m 38s\n",
            "384:\tlearn: 0.2637628\ttotal: 48.2s\tremaining: 9m 38s\n",
            "385:\tlearn: 0.2636691\ttotal: 48.4s\tremaining: 9m 37s\n",
            "386:\tlearn: 0.2635162\ttotal: 48.5s\tremaining: 9m 37s\n",
            "387:\tlearn: 0.2633849\ttotal: 48.6s\tremaining: 9m 37s\n",
            "388:\tlearn: 0.2631995\ttotal: 48.8s\tremaining: 9m 38s\n",
            "389:\tlearn: 0.2630835\ttotal: 48.9s\tremaining: 9m 37s\n",
            "390:\tlearn: 0.2629125\ttotal: 49s\tremaining: 9m 37s\n",
            "391:\tlearn: 0.2627382\ttotal: 49.1s\tremaining: 9m 36s\n",
            "392:\tlearn: 0.2625353\ttotal: 49.2s\tremaining: 9m 36s\n",
            "393:\tlearn: 0.2623248\ttotal: 49.3s\tremaining: 9m 36s\n",
            "394:\tlearn: 0.2621803\ttotal: 49.5s\tremaining: 9m 37s\n",
            "395:\tlearn: 0.2620404\ttotal: 49.6s\tremaining: 9m 36s\n",
            "396:\tlearn: 0.2618495\ttotal: 49.8s\tremaining: 9m 36s\n",
            "397:\tlearn: 0.2617665\ttotal: 49.9s\tremaining: 9m 36s\n",
            "398:\tlearn: 0.2616084\ttotal: 50s\tremaining: 9m 36s\n",
            "399:\tlearn: 0.2614915\ttotal: 50.2s\tremaining: 9m 37s\n",
            "400:\tlearn: 0.2613723\ttotal: 50.3s\tremaining: 9m 37s\n",
            "401:\tlearn: 0.2612180\ttotal: 50.4s\tremaining: 9m 37s\n",
            "402:\tlearn: 0.2609840\ttotal: 50.6s\tremaining: 9m 37s\n",
            "403:\tlearn: 0.2607576\ttotal: 50.7s\tremaining: 9m 37s\n",
            "404:\tlearn: 0.2605778\ttotal: 50.8s\tremaining: 9m 36s\n",
            "405:\tlearn: 0.2604479\ttotal: 51s\tremaining: 9m 37s\n",
            "406:\tlearn: 0.2602815\ttotal: 51.1s\tremaining: 9m 36s\n",
            "407:\tlearn: 0.2601249\ttotal: 51.2s\tremaining: 9m 36s\n",
            "408:\tlearn: 0.2599587\ttotal: 51.3s\tremaining: 9m 36s\n",
            "409:\tlearn: 0.2598478\ttotal: 51.4s\tremaining: 9m 35s\n",
            "410:\tlearn: 0.2596869\ttotal: 51.6s\tremaining: 9m 35s\n",
            "411:\tlearn: 0.2595794\ttotal: 51.7s\tremaining: 9m 35s\n",
            "412:\tlearn: 0.2594544\ttotal: 51.8s\tremaining: 9m 35s\n",
            "413:\tlearn: 0.2593062\ttotal: 52s\tremaining: 9m 35s\n",
            "414:\tlearn: 0.2591307\ttotal: 52.1s\tremaining: 9m 35s\n",
            "415:\tlearn: 0.2589505\ttotal: 52.2s\tremaining: 9m 35s\n",
            "416:\tlearn: 0.2587614\ttotal: 52.3s\tremaining: 9m 34s\n",
            "417:\tlearn: 0.2586469\ttotal: 52.4s\tremaining: 9m 34s\n",
            "418:\tlearn: 0.2584743\ttotal: 52.5s\tremaining: 9m 34s\n",
            "419:\tlearn: 0.2583659\ttotal: 52.7s\tremaining: 9m 34s\n",
            "420:\tlearn: 0.2582470\ttotal: 52.8s\tremaining: 9m 34s\n",
            "421:\tlearn: 0.2581444\ttotal: 52.9s\tremaining: 9m 33s\n",
            "422:\tlearn: 0.2580130\ttotal: 53.1s\tremaining: 9m 34s\n",
            "423:\tlearn: 0.2578844\ttotal: 53.2s\tremaining: 9m 34s\n",
            "424:\tlearn: 0.2576244\ttotal: 53.3s\tremaining: 9m 34s\n",
            "425:\tlearn: 0.2574704\ttotal: 53.5s\tremaining: 9m 34s\n",
            "426:\tlearn: 0.2573630\ttotal: 53.6s\tremaining: 9m 34s\n",
            "427:\tlearn: 0.2572747\ttotal: 53.7s\tremaining: 9m 33s\n",
            "428:\tlearn: 0.2571604\ttotal: 53.8s\tremaining: 9m 33s\n",
            "429:\tlearn: 0.2570134\ttotal: 53.9s\tremaining: 9m 33s\n",
            "430:\tlearn: 0.2568192\ttotal: 54.1s\tremaining: 9m 33s\n",
            "431:\tlearn: 0.2565984\ttotal: 54.2s\tremaining: 9m 33s\n",
            "432:\tlearn: 0.2563120\ttotal: 54.3s\tremaining: 9m 33s\n",
            "433:\tlearn: 0.2560747\ttotal: 54.5s\tremaining: 9m 33s\n",
            "434:\tlearn: 0.2559390\ttotal: 54.6s\tremaining: 9m 33s\n",
            "435:\tlearn: 0.2558455\ttotal: 54.8s\tremaining: 9m 33s\n",
            "436:\tlearn: 0.2557199\ttotal: 54.9s\tremaining: 9m 33s\n",
            "437:\tlearn: 0.2555979\ttotal: 55s\tremaining: 9m 33s\n",
            "438:\tlearn: 0.2555159\ttotal: 55.1s\tremaining: 9m 32s\n",
            "439:\tlearn: 0.2554137\ttotal: 55.3s\tremaining: 9m 32s\n",
            "440:\tlearn: 0.2552543\ttotal: 55.4s\tremaining: 9m 32s\n",
            "441:\tlearn: 0.2551483\ttotal: 55.5s\tremaining: 9m 32s\n",
            "442:\tlearn: 0.2550533\ttotal: 55.6s\tremaining: 9m 31s\n",
            "443:\tlearn: 0.2547684\ttotal: 55.7s\tremaining: 9m 31s\n",
            "444:\tlearn: 0.2546904\ttotal: 55.8s\tremaining: 9m 31s\n",
            "445:\tlearn: 0.2545971\ttotal: 55.9s\tremaining: 9m 31s\n",
            "446:\tlearn: 0.2544743\ttotal: 56s\tremaining: 9m 30s\n",
            "447:\tlearn: 0.2542969\ttotal: 56.1s\tremaining: 9m 30s\n",
            "448:\tlearn: 0.2541915\ttotal: 56.2s\tremaining: 9m 30s\n",
            "449:\tlearn: 0.2540275\ttotal: 56.4s\tremaining: 9m 30s\n",
            "450:\tlearn: 0.2538975\ttotal: 56.6s\tremaining: 9m 30s\n",
            "451:\tlearn: 0.2537943\ttotal: 56.7s\tremaining: 9m 30s\n",
            "452:\tlearn: 0.2536279\ttotal: 56.8s\tremaining: 9m 30s\n",
            "453:\tlearn: 0.2535125\ttotal: 56.9s\tremaining: 9m 29s\n",
            "454:\tlearn: 0.2534127\ttotal: 57s\tremaining: 9m 29s\n",
            "455:\tlearn: 0.2532572\ttotal: 57.2s\tremaining: 9m 29s\n",
            "456:\tlearn: 0.2530863\ttotal: 57.3s\tremaining: 9m 29s\n",
            "457:\tlearn: 0.2529689\ttotal: 57.4s\tremaining: 9m 29s\n",
            "458:\tlearn: 0.2528438\ttotal: 57.5s\tremaining: 9m 29s\n",
            "459:\tlearn: 0.2526137\ttotal: 57.7s\tremaining: 9m 29s\n",
            "460:\tlearn: 0.2524156\ttotal: 57.8s\tremaining: 9m 29s\n",
            "461:\tlearn: 0.2522863\ttotal: 57.9s\tremaining: 9m 29s\n",
            "462:\tlearn: 0.2521515\ttotal: 58.1s\tremaining: 9m 29s\n",
            "463:\tlearn: 0.2520958\ttotal: 58.2s\tremaining: 9m 28s\n",
            "464:\tlearn: 0.2519798\ttotal: 58.3s\tremaining: 9m 28s\n",
            "465:\tlearn: 0.2518139\ttotal: 58.4s\tremaining: 9m 28s\n",
            "466:\tlearn: 0.2516834\ttotal: 58.5s\tremaining: 9m 28s\n",
            "467:\tlearn: 0.2515446\ttotal: 58.6s\tremaining: 9m 27s\n",
            "468:\tlearn: 0.2514587\ttotal: 58.8s\tremaining: 9m 27s\n",
            "469:\tlearn: 0.2513125\ttotal: 58.9s\tremaining: 9m 27s\n",
            "470:\tlearn: 0.2511393\ttotal: 59s\tremaining: 9m 27s\n",
            "471:\tlearn: 0.2509965\ttotal: 59.2s\tremaining: 9m 27s\n",
            "472:\tlearn: 0.2508999\ttotal: 59.3s\tremaining: 9m 27s\n",
            "473:\tlearn: 0.2507714\ttotal: 59.4s\tremaining: 9m 27s\n",
            "474:\tlearn: 0.2507042\ttotal: 59.5s\tremaining: 9m 26s\n",
            "475:\tlearn: 0.2506445\ttotal: 59.6s\tremaining: 9m 26s\n",
            "476:\tlearn: 0.2505444\ttotal: 59.7s\tremaining: 9m 26s\n",
            "477:\tlearn: 0.2504411\ttotal: 59.9s\tremaining: 9m 26s\n",
            "478:\tlearn: 0.2503320\ttotal: 60s\tremaining: 9m 26s\n",
            "479:\tlearn: 0.2502088\ttotal: 1m\tremaining: 9m 26s\n",
            "480:\tlearn: 0.2501188\ttotal: 1m\tremaining: 9m 25s\n",
            "481:\tlearn: 0.2500310\ttotal: 1m\tremaining: 9m 25s\n",
            "482:\tlearn: 0.2499155\ttotal: 1m\tremaining: 9m 25s\n",
            "483:\tlearn: 0.2498361\ttotal: 1m\tremaining: 9m 25s\n",
            "484:\tlearn: 0.2497534\ttotal: 1m\tremaining: 9m 25s\n",
            "485:\tlearn: 0.2496727\ttotal: 1m\tremaining: 9m 24s\n",
            "486:\tlearn: 0.2495611\ttotal: 1m\tremaining: 9m 24s\n",
            "487:\tlearn: 0.2494711\ttotal: 1m 1s\tremaining: 9m 24s\n",
            "488:\tlearn: 0.2493925\ttotal: 1m 1s\tremaining: 9m 24s\n",
            "489:\tlearn: 0.2492899\ttotal: 1m 1s\tremaining: 9m 24s\n",
            "490:\tlearn: 0.2492146\ttotal: 1m 1s\tremaining: 9m 23s\n",
            "491:\tlearn: 0.2490860\ttotal: 1m 1s\tremaining: 9m 23s\n",
            "492:\tlearn: 0.2489982\ttotal: 1m 1s\tremaining: 9m 23s\n",
            "493:\tlearn: 0.2488552\ttotal: 1m 1s\tremaining: 9m 23s\n",
            "494:\tlearn: 0.2487538\ttotal: 1m 1s\tremaining: 9m 22s\n",
            "495:\tlearn: 0.2486527\ttotal: 1m 1s\tremaining: 9m 22s\n",
            "496:\tlearn: 0.2485676\ttotal: 1m 2s\tremaining: 9m 22s\n",
            "497:\tlearn: 0.2484515\ttotal: 1m 2s\tremaining: 9m 22s\n",
            "498:\tlearn: 0.2482269\ttotal: 1m 2s\tremaining: 9m 22s\n",
            "499:\tlearn: 0.2481018\ttotal: 1m 2s\tremaining: 9m 21s\n",
            "500:\tlearn: 0.2479821\ttotal: 1m 2s\tremaining: 9m 21s\n",
            "501:\tlearn: 0.2478835\ttotal: 1m 2s\tremaining: 9m 21s\n",
            "502:\tlearn: 0.2477766\ttotal: 1m 2s\tremaining: 9m 21s\n",
            "503:\tlearn: 0.2476272\ttotal: 1m 2s\tremaining: 9m 21s\n",
            "504:\tlearn: 0.2474719\ttotal: 1m 3s\tremaining: 9m 21s\n",
            "505:\tlearn: 0.2473659\ttotal: 1m 3s\tremaining: 9m 21s\n",
            "506:\tlearn: 0.2472229\ttotal: 1m 3s\tremaining: 9m 20s\n",
            "507:\tlearn: 0.2470964\ttotal: 1m 3s\tremaining: 9m 20s\n",
            "508:\tlearn: 0.2469878\ttotal: 1m 3s\tremaining: 9m 20s\n",
            "509:\tlearn: 0.2468956\ttotal: 1m 3s\tremaining: 9m 20s\n",
            "510:\tlearn: 0.2467578\ttotal: 1m 3s\tremaining: 9m 20s\n",
            "511:\tlearn: 0.2466653\ttotal: 1m 3s\tremaining: 9m 20s\n",
            "512:\tlearn: 0.2465392\ttotal: 1m 4s\tremaining: 9m 20s\n",
            "513:\tlearn: 0.2463858\ttotal: 1m 4s\tremaining: 9m 20s\n",
            "514:\tlearn: 0.2461727\ttotal: 1m 4s\tremaining: 9m 20s\n",
            "515:\tlearn: 0.2460816\ttotal: 1m 4s\tremaining: 9m 20s\n",
            "516:\tlearn: 0.2459680\ttotal: 1m 4s\tremaining: 9m 20s\n",
            "517:\tlearn: 0.2458793\ttotal: 1m 4s\tremaining: 9m 20s\n",
            "518:\tlearn: 0.2457212\ttotal: 1m 4s\tremaining: 9m 19s\n",
            "519:\tlearn: 0.2456442\ttotal: 1m 4s\tremaining: 9m 19s\n",
            "520:\tlearn: 0.2455593\ttotal: 1m 5s\tremaining: 9m 19s\n",
            "521:\tlearn: 0.2454639\ttotal: 1m 5s\tremaining: 9m 19s\n",
            "522:\tlearn: 0.2453947\ttotal: 1m 5s\tremaining: 9m 19s\n",
            "523:\tlearn: 0.2452925\ttotal: 1m 5s\tremaining: 9m 18s\n",
            "524:\tlearn: 0.2452163\ttotal: 1m 5s\tremaining: 9m 18s\n",
            "525:\tlearn: 0.2451278\ttotal: 1m 5s\tremaining: 9m 18s\n",
            "526:\tlearn: 0.2450468\ttotal: 1m 5s\tremaining: 9m 18s\n",
            "527:\tlearn: 0.2449334\ttotal: 1m 5s\tremaining: 9m 18s\n",
            "528:\tlearn: 0.2448514\ttotal: 1m 6s\tremaining: 9m 18s\n",
            "529:\tlearn: 0.2447443\ttotal: 1m 6s\tremaining: 9m 18s\n",
            "530:\tlearn: 0.2446027\ttotal: 1m 6s\tremaining: 9m 17s\n",
            "531:\tlearn: 0.2444886\ttotal: 1m 6s\tremaining: 9m 17s\n",
            "532:\tlearn: 0.2443442\ttotal: 1m 6s\tremaining: 9m 17s\n",
            "533:\tlearn: 0.2442556\ttotal: 1m 6s\tremaining: 9m 17s\n",
            "534:\tlearn: 0.2441662\ttotal: 1m 6s\tremaining: 9m 17s\n",
            "535:\tlearn: 0.2440227\ttotal: 1m 6s\tremaining: 9m 17s\n",
            "536:\tlearn: 0.2439343\ttotal: 1m 6s\tremaining: 9m 16s\n",
            "537:\tlearn: 0.2438118\ttotal: 1m 7s\tremaining: 9m 16s\n",
            "538:\tlearn: 0.2437503\ttotal: 1m 7s\tremaining: 9m 16s\n",
            "539:\tlearn: 0.2436470\ttotal: 1m 7s\tremaining: 9m 16s\n",
            "540:\tlearn: 0.2435515\ttotal: 1m 7s\tremaining: 9m 16s\n",
            "541:\tlearn: 0.2434558\ttotal: 1m 7s\tremaining: 9m 16s\n",
            "542:\tlearn: 0.2433213\ttotal: 1m 7s\tremaining: 9m 16s\n",
            "543:\tlearn: 0.2431879\ttotal: 1m 7s\tremaining: 9m 16s\n",
            "544:\tlearn: 0.2430703\ttotal: 1m 8s\tremaining: 9m 16s\n",
            "545:\tlearn: 0.2430223\ttotal: 1m 8s\tremaining: 9m 15s\n",
            "546:\tlearn: 0.2429276\ttotal: 1m 8s\tremaining: 9m 16s\n",
            "547:\tlearn: 0.2428425\ttotal: 1m 8s\tremaining: 9m 15s\n",
            "548:\tlearn: 0.2427389\ttotal: 1m 8s\tremaining: 9m 15s\n",
            "549:\tlearn: 0.2426690\ttotal: 1m 8s\tremaining: 9m 15s\n",
            "550:\tlearn: 0.2425844\ttotal: 1m 8s\tremaining: 9m 15s\n",
            "551:\tlearn: 0.2424888\ttotal: 1m 8s\tremaining: 9m 15s\n",
            "552:\tlearn: 0.2423682\ttotal: 1m 9s\tremaining: 9m 15s\n",
            "553:\tlearn: 0.2422452\ttotal: 1m 9s\tremaining: 9m 14s\n",
            "554:\tlearn: 0.2421489\ttotal: 1m 9s\tremaining: 9m 14s\n",
            "555:\tlearn: 0.2420597\ttotal: 1m 9s\tremaining: 9m 14s\n",
            "556:\tlearn: 0.2419733\ttotal: 1m 9s\tremaining: 9m 14s\n",
            "557:\tlearn: 0.2417902\ttotal: 1m 9s\tremaining: 9m 14s\n",
            "558:\tlearn: 0.2417017\ttotal: 1m 9s\tremaining: 9m 14s\n",
            "559:\tlearn: 0.2416256\ttotal: 1m 9s\tremaining: 9m 14s\n",
            "560:\tlearn: 0.2415390\ttotal: 1m 10s\tremaining: 9m 14s\n",
            "561:\tlearn: 0.2414032\ttotal: 1m 10s\tremaining: 9m 13s\n",
            "562:\tlearn: 0.2413265\ttotal: 1m 10s\tremaining: 9m 13s\n",
            "563:\tlearn: 0.2412124\ttotal: 1m 10s\tremaining: 9m 13s\n",
            "564:\tlearn: 0.2411106\ttotal: 1m 10s\tremaining: 9m 13s\n",
            "565:\tlearn: 0.2410116\ttotal: 1m 10s\tremaining: 9m 13s\n",
            "566:\tlearn: 0.2408610\ttotal: 1m 10s\tremaining: 9m 13s\n",
            "567:\tlearn: 0.2407611\ttotal: 1m 10s\tremaining: 9m 13s\n",
            "568:\tlearn: 0.2406680\ttotal: 1m 10s\tremaining: 9m 12s\n",
            "569:\tlearn: 0.2405833\ttotal: 1m 11s\tremaining: 9m 12s\n",
            "570:\tlearn: 0.2404856\ttotal: 1m 11s\tremaining: 9m 12s\n",
            "571:\tlearn: 0.2403839\ttotal: 1m 11s\tremaining: 9m 12s\n",
            "572:\tlearn: 0.2403187\ttotal: 1m 11s\tremaining: 9m 12s\n",
            "573:\tlearn: 0.2402183\ttotal: 1m 11s\tremaining: 9m 12s\n",
            "574:\tlearn: 0.2401323\ttotal: 1m 11s\tremaining: 9m 11s\n",
            "575:\tlearn: 0.2400241\ttotal: 1m 11s\tremaining: 9m 11s\n",
            "576:\tlearn: 0.2399142\ttotal: 1m 11s\tremaining: 9m 11s\n",
            "577:\tlearn: 0.2398161\ttotal: 1m 12s\tremaining: 9m 11s\n",
            "578:\tlearn: 0.2397182\ttotal: 1m 12s\tremaining: 9m 11s\n",
            "579:\tlearn: 0.2396551\ttotal: 1m 12s\tremaining: 9m 11s\n",
            "580:\tlearn: 0.2395604\ttotal: 1m 12s\tremaining: 9m 10s\n",
            "581:\tlearn: 0.2394816\ttotal: 1m 12s\tremaining: 9m 10s\n",
            "582:\tlearn: 0.2394419\ttotal: 1m 12s\tremaining: 9m 10s\n",
            "583:\tlearn: 0.2393316\ttotal: 1m 12s\tremaining: 9m 10s\n",
            "584:\tlearn: 0.2392723\ttotal: 1m 12s\tremaining: 9m 10s\n",
            "585:\tlearn: 0.2390892\ttotal: 1m 13s\tremaining: 9m 10s\n",
            "586:\tlearn: 0.2390137\ttotal: 1m 13s\tremaining: 9m 10s\n",
            "587:\tlearn: 0.2389435\ttotal: 1m 13s\tremaining: 9m 10s\n",
            "588:\tlearn: 0.2388543\ttotal: 1m 13s\tremaining: 9m 10s\n",
            "589:\tlearn: 0.2387946\ttotal: 1m 13s\tremaining: 9m 10s\n",
            "590:\tlearn: 0.2386632\ttotal: 1m 13s\tremaining: 9m 9s\n",
            "591:\tlearn: 0.2385713\ttotal: 1m 13s\tremaining: 9m 10s\n",
            "592:\tlearn: 0.2384816\ttotal: 1m 14s\tremaining: 9m 10s\n",
            "593:\tlearn: 0.2383913\ttotal: 1m 14s\tremaining: 9m 10s\n",
            "594:\tlearn: 0.2383079\ttotal: 1m 14s\tremaining: 9m 9s\n",
            "595:\tlearn: 0.2382390\ttotal: 1m 14s\tremaining: 9m 9s\n",
            "596:\tlearn: 0.2381924\ttotal: 1m 14s\tremaining: 9m 9s\n",
            "597:\tlearn: 0.2380704\ttotal: 1m 14s\tremaining: 9m 9s\n",
            "598:\tlearn: 0.2379983\ttotal: 1m 14s\tremaining: 9m 9s\n",
            "599:\tlearn: 0.2379159\ttotal: 1m 14s\tremaining: 9m 8s\n",
            "600:\tlearn: 0.2378448\ttotal: 1m 14s\tremaining: 9m 8s\n",
            "601:\tlearn: 0.2377680\ttotal: 1m 15s\tremaining: 9m 8s\n",
            "602:\tlearn: 0.2377040\ttotal: 1m 15s\tremaining: 9m 8s\n",
            "603:\tlearn: 0.2376165\ttotal: 1m 15s\tremaining: 9m 8s\n",
            "604:\tlearn: 0.2375157\ttotal: 1m 15s\tremaining: 9m 8s\n",
            "605:\tlearn: 0.2374291\ttotal: 1m 15s\tremaining: 9m 8s\n",
            "606:\tlearn: 0.2373285\ttotal: 1m 15s\tremaining: 9m 8s\n",
            "607:\tlearn: 0.2372161\ttotal: 1m 15s\tremaining: 9m 8s\n",
            "608:\tlearn: 0.2371257\ttotal: 1m 16s\tremaining: 9m 8s\n",
            "609:\tlearn: 0.2370650\ttotal: 1m 16s\tremaining: 9m 8s\n",
            "610:\tlearn: 0.2370016\ttotal: 1m 16s\tremaining: 9m 7s\n",
            "611:\tlearn: 0.2368843\ttotal: 1m 16s\tremaining: 9m 7s\n",
            "612:\tlearn: 0.2368165\ttotal: 1m 16s\tremaining: 9m 7s\n",
            "613:\tlearn: 0.2367586\ttotal: 1m 16s\tremaining: 9m 7s\n",
            "614:\tlearn: 0.2366757\ttotal: 1m 16s\tremaining: 9m 7s\n",
            "615:\tlearn: 0.2366047\ttotal: 1m 16s\tremaining: 9m 7s\n",
            "616:\tlearn: 0.2364998\ttotal: 1m 16s\tremaining: 9m 6s\n",
            "617:\tlearn: 0.2364275\ttotal: 1m 17s\tremaining: 9m 6s\n",
            "618:\tlearn: 0.2363601\ttotal: 1m 17s\tremaining: 9m 6s\n",
            "619:\tlearn: 0.2362798\ttotal: 1m 17s\tremaining: 9m 6s\n",
            "620:\tlearn: 0.2361718\ttotal: 1m 17s\tremaining: 9m 6s\n",
            "621:\tlearn: 0.2361129\ttotal: 1m 17s\tremaining: 9m 5s\n",
            "622:\tlearn: 0.2360104\ttotal: 1m 17s\tremaining: 9m 5s\n",
            "623:\tlearn: 0.2358763\ttotal: 1m 17s\tremaining: 9m 5s\n",
            "624:\tlearn: 0.2357489\ttotal: 1m 17s\tremaining: 9m 5s\n",
            "625:\tlearn: 0.2356867\ttotal: 1m 18s\tremaining: 9m 5s\n",
            "626:\tlearn: 0.2356200\ttotal: 1m 18s\tremaining: 9m 5s\n",
            "627:\tlearn: 0.2355667\ttotal: 1m 18s\tremaining: 9m 5s\n",
            "628:\tlearn: 0.2354547\ttotal: 1m 18s\tremaining: 9m 5s\n",
            "629:\tlearn: 0.2353743\ttotal: 1m 18s\tremaining: 9m 5s\n",
            "630:\tlearn: 0.2352430\ttotal: 1m 18s\tremaining: 9m 5s\n",
            "631:\tlearn: 0.2351404\ttotal: 1m 18s\tremaining: 9m 4s\n",
            "632:\tlearn: 0.2350413\ttotal: 1m 18s\tremaining: 9m 4s\n",
            "633:\tlearn: 0.2349776\ttotal: 1m 19s\tremaining: 9m 4s\n",
            "634:\tlearn: 0.2349062\ttotal: 1m 19s\tremaining: 9m 4s\n",
            "635:\tlearn: 0.2348518\ttotal: 1m 19s\tremaining: 9m 4s\n",
            "636:\tlearn: 0.2347570\ttotal: 1m 19s\tremaining: 9m 3s\n",
            "637:\tlearn: 0.2346850\ttotal: 1m 19s\tremaining: 9m 3s\n",
            "638:\tlearn: 0.2346040\ttotal: 1m 19s\tremaining: 9m 3s\n",
            "639:\tlearn: 0.2344300\ttotal: 1m 19s\tremaining: 9m 3s\n",
            "640:\tlearn: 0.2343794\ttotal: 1m 19s\tremaining: 9m 3s\n",
            "641:\tlearn: 0.2342926\ttotal: 1m 20s\tremaining: 9m 3s\n",
            "642:\tlearn: 0.2342206\ttotal: 1m 20s\tremaining: 9m 3s\n",
            "643:\tlearn: 0.2341586\ttotal: 1m 20s\tremaining: 9m 3s\n",
            "644:\tlearn: 0.2340850\ttotal: 1m 20s\tremaining: 9m 3s\n",
            "645:\tlearn: 0.2339404\ttotal: 1m 20s\tremaining: 9m 3s\n",
            "646:\tlearn: 0.2338668\ttotal: 1m 20s\tremaining: 9m 3s\n",
            "647:\tlearn: 0.2338026\ttotal: 1m 20s\tremaining: 9m 3s\n",
            "648:\tlearn: 0.2337463\ttotal: 1m 21s\tremaining: 9m 3s\n",
            "649:\tlearn: 0.2336691\ttotal: 1m 21s\tremaining: 9m 3s\n",
            "650:\tlearn: 0.2335578\ttotal: 1m 21s\tremaining: 9m 3s\n",
            "651:\tlearn: 0.2334554\ttotal: 1m 21s\tremaining: 9m 3s\n",
            "652:\tlearn: 0.2333260\ttotal: 1m 21s\tremaining: 9m 2s\n",
            "653:\tlearn: 0.2332527\ttotal: 1m 21s\tremaining: 9m 2s\n",
            "654:\tlearn: 0.2331457\ttotal: 1m 21s\tremaining: 9m 2s\n",
            "655:\tlearn: 0.2330798\ttotal: 1m 21s\tremaining: 9m 2s\n",
            "656:\tlearn: 0.2329747\ttotal: 1m 22s\tremaining: 9m 2s\n",
            "657:\tlearn: 0.2329297\ttotal: 1m 22s\tremaining: 9m 1s\n",
            "658:\tlearn: 0.2328828\ttotal: 1m 22s\tremaining: 9m 1s\n",
            "659:\tlearn: 0.2328112\ttotal: 1m 22s\tremaining: 9m 1s\n",
            "660:\tlearn: 0.2327115\ttotal: 1m 22s\tremaining: 9m 1s\n",
            "661:\tlearn: 0.2326563\ttotal: 1m 22s\tremaining: 9m 1s\n",
            "662:\tlearn: 0.2325743\ttotal: 1m 22s\tremaining: 9m 1s\n",
            "663:\tlearn: 0.2324942\ttotal: 1m 22s\tremaining: 9m\n",
            "664:\tlearn: 0.2323911\ttotal: 1m 22s\tremaining: 9m\n",
            "665:\tlearn: 0.2323233\ttotal: 1m 23s\tremaining: 9m\n",
            "666:\tlearn: 0.2322407\ttotal: 1m 23s\tremaining: 9m\n",
            "667:\tlearn: 0.2321424\ttotal: 1m 23s\tremaining: 9m\n",
            "668:\tlearn: 0.2320839\ttotal: 1m 23s\tremaining: 9m\n",
            "669:\tlearn: 0.2320138\ttotal: 1m 23s\tremaining: 8m 59s\n",
            "670:\tlearn: 0.2319523\ttotal: 1m 23s\tremaining: 8m 59s\n",
            "671:\tlearn: 0.2319062\ttotal: 1m 23s\tremaining: 8m 59s\n",
            "672:\tlearn: 0.2318224\ttotal: 1m 23s\tremaining: 8m 59s\n",
            "673:\tlearn: 0.2317430\ttotal: 1m 24s\tremaining: 8m 59s\n",
            "674:\tlearn: 0.2316784\ttotal: 1m 24s\tremaining: 8m 59s\n",
            "675:\tlearn: 0.2316242\ttotal: 1m 24s\tremaining: 8m 58s\n",
            "676:\tlearn: 0.2315741\ttotal: 1m 24s\tremaining: 8m 59s\n",
            "677:\tlearn: 0.2314808\ttotal: 1m 24s\tremaining: 8m 58s\n",
            "678:\tlearn: 0.2314222\ttotal: 1m 24s\tremaining: 8m 58s\n",
            "679:\tlearn: 0.2313401\ttotal: 1m 24s\tremaining: 8m 58s\n",
            "680:\tlearn: 0.2312805\ttotal: 1m 24s\tremaining: 8m 58s\n",
            "681:\tlearn: 0.2312192\ttotal: 1m 25s\tremaining: 8m 58s\n",
            "682:\tlearn: 0.2311494\ttotal: 1m 25s\tremaining: 8m 58s\n",
            "683:\tlearn: 0.2310825\ttotal: 1m 25s\tremaining: 8m 58s\n",
            "684:\tlearn: 0.2309957\ttotal: 1m 25s\tremaining: 8m 57s\n",
            "685:\tlearn: 0.2308426\ttotal: 1m 25s\tremaining: 8m 57s\n",
            "686:\tlearn: 0.2307691\ttotal: 1m 25s\tremaining: 8m 57s\n",
            "687:\tlearn: 0.2306936\ttotal: 1m 25s\tremaining: 8m 57s\n",
            "688:\tlearn: 0.2306174\ttotal: 1m 25s\tremaining: 8m 57s\n",
            "689:\tlearn: 0.2305487\ttotal: 1m 25s\tremaining: 8m 56s\n",
            "690:\tlearn: 0.2304799\ttotal: 1m 26s\tremaining: 8m 56s\n",
            "691:\tlearn: 0.2304085\ttotal: 1m 26s\tremaining: 8m 56s\n",
            "692:\tlearn: 0.2303514\ttotal: 1m 26s\tremaining: 8m 56s\n",
            "693:\tlearn: 0.2302946\ttotal: 1m 26s\tremaining: 8m 56s\n",
            "694:\tlearn: 0.2302493\ttotal: 1m 26s\tremaining: 8m 55s\n",
            "695:\tlearn: 0.2301651\ttotal: 1m 26s\tremaining: 8m 55s\n",
            "696:\tlearn: 0.2301092\ttotal: 1m 26s\tremaining: 8m 55s\n",
            "697:\tlearn: 0.2299954\ttotal: 1m 26s\tremaining: 8m 55s\n",
            "698:\tlearn: 0.2299065\ttotal: 1m 26s\tremaining: 8m 55s\n",
            "699:\tlearn: 0.2298431\ttotal: 1m 27s\tremaining: 8m 55s\n",
            "700:\tlearn: 0.2297891\ttotal: 1m 27s\tremaining: 8m 55s\n",
            "701:\tlearn: 0.2297265\ttotal: 1m 27s\tremaining: 8m 54s\n",
            "702:\tlearn: 0.2296838\ttotal: 1m 27s\tremaining: 8m 54s\n",
            "703:\tlearn: 0.2296193\ttotal: 1m 27s\tremaining: 8m 54s\n",
            "704:\tlearn: 0.2294820\ttotal: 1m 27s\tremaining: 8m 54s\n",
            "705:\tlearn: 0.2293407\ttotal: 1m 27s\tremaining: 8m 54s\n",
            "706:\tlearn: 0.2292742\ttotal: 1m 27s\tremaining: 8m 54s\n",
            "707:\tlearn: 0.2291977\ttotal: 1m 28s\tremaining: 8m 54s\n",
            "708:\tlearn: 0.2291333\ttotal: 1m 28s\tremaining: 8m 53s\n",
            "709:\tlearn: 0.2290840\ttotal: 1m 28s\tremaining: 8m 53s\n",
            "710:\tlearn: 0.2289928\ttotal: 1m 28s\tremaining: 8m 53s\n",
            "711:\tlearn: 0.2289227\ttotal: 1m 28s\tremaining: 8m 53s\n",
            "712:\tlearn: 0.2288678\ttotal: 1m 28s\tremaining: 8m 53s\n",
            "713:\tlearn: 0.2287736\ttotal: 1m 28s\tremaining: 8m 53s\n",
            "714:\tlearn: 0.2287021\ttotal: 1m 28s\tremaining: 8m 53s\n",
            "715:\tlearn: 0.2286546\ttotal: 1m 29s\tremaining: 8m 52s\n",
            "716:\tlearn: 0.2285674\ttotal: 1m 29s\tremaining: 8m 52s\n",
            "717:\tlearn: 0.2284784\ttotal: 1m 29s\tremaining: 8m 52s\n",
            "718:\tlearn: 0.2284191\ttotal: 1m 29s\tremaining: 8m 52s\n",
            "719:\tlearn: 0.2283449\ttotal: 1m 29s\tremaining: 8m 52s\n",
            "720:\tlearn: 0.2282579\ttotal: 1m 29s\tremaining: 8m 52s\n",
            "721:\tlearn: 0.2281894\ttotal: 1m 29s\tremaining: 8m 51s\n",
            "722:\tlearn: 0.2280978\ttotal: 1m 29s\tremaining: 8m 51s\n",
            "723:\tlearn: 0.2280447\ttotal: 1m 30s\tremaining: 8m 51s\n",
            "724:\tlearn: 0.2279924\ttotal: 1m 30s\tremaining: 8m 51s\n",
            "725:\tlearn: 0.2279156\ttotal: 1m 30s\tremaining: 8m 51s\n",
            "726:\tlearn: 0.2278425\ttotal: 1m 30s\tremaining: 8m 51s\n",
            "727:\tlearn: 0.2277564\ttotal: 1m 30s\tremaining: 8m 51s\n",
            "728:\tlearn: 0.2277212\ttotal: 1m 30s\tremaining: 8m 51s\n",
            "729:\tlearn: 0.2276732\ttotal: 1m 30s\tremaining: 8m 50s\n",
            "730:\tlearn: 0.2276017\ttotal: 1m 30s\tremaining: 8m 50s\n",
            "731:\tlearn: 0.2275546\ttotal: 1m 31s\tremaining: 8m 50s\n",
            "732:\tlearn: 0.2274634\ttotal: 1m 31s\tremaining: 8m 50s\n",
            "733:\tlearn: 0.2274122\ttotal: 1m 31s\tremaining: 8m 50s\n",
            "734:\tlearn: 0.2273120\ttotal: 1m 31s\tremaining: 8m 50s\n",
            "735:\tlearn: 0.2272509\ttotal: 1m 31s\tremaining: 8m 50s\n",
            "736:\tlearn: 0.2272114\ttotal: 1m 31s\tremaining: 8m 49s\n",
            "737:\tlearn: 0.2271337\ttotal: 1m 31s\tremaining: 8m 50s\n",
            "738:\tlearn: 0.2270919\ttotal: 1m 31s\tremaining: 8m 49s\n",
            "739:\tlearn: 0.2270100\ttotal: 1m 32s\tremaining: 8m 49s\n",
            "740:\tlearn: 0.2269263\ttotal: 1m 32s\tremaining: 8m 49s\n",
            "741:\tlearn: 0.2268841\ttotal: 1m 32s\tremaining: 8m 49s\n",
            "742:\tlearn: 0.2268066\ttotal: 1m 32s\tremaining: 8m 49s\n",
            "743:\tlearn: 0.2267449\ttotal: 1m 32s\tremaining: 8m 49s\n",
            "744:\tlearn: 0.2266676\ttotal: 1m 32s\tremaining: 8m 49s\n",
            "745:\tlearn: 0.2266312\ttotal: 1m 32s\tremaining: 8m 49s\n",
            "746:\tlearn: 0.2265747\ttotal: 1m 32s\tremaining: 8m 48s\n",
            "747:\tlearn: 0.2264933\ttotal: 1m 33s\tremaining: 8m 49s\n",
            "748:\tlearn: 0.2264401\ttotal: 1m 33s\tremaining: 8m 48s\n",
            "749:\tlearn: 0.2263787\ttotal: 1m 33s\tremaining: 8m 48s\n",
            "750:\tlearn: 0.2263162\ttotal: 1m 33s\tremaining: 8m 48s\n",
            "751:\tlearn: 0.2262722\ttotal: 1m 33s\tremaining: 8m 48s\n",
            "752:\tlearn: 0.2262079\ttotal: 1m 33s\tremaining: 8m 48s\n",
            "753:\tlearn: 0.2261446\ttotal: 1m 33s\tremaining: 8m 48s\n",
            "754:\tlearn: 0.2260811\ttotal: 1m 33s\tremaining: 8m 48s\n",
            "755:\tlearn: 0.2260254\ttotal: 1m 34s\tremaining: 8m 47s\n",
            "756:\tlearn: 0.2259785\ttotal: 1m 34s\tremaining: 8m 48s\n",
            "757:\tlearn: 0.2259284\ttotal: 1m 34s\tremaining: 8m 47s\n",
            "758:\tlearn: 0.2258393\ttotal: 1m 34s\tremaining: 8m 47s\n",
            "759:\tlearn: 0.2258067\ttotal: 1m 34s\tremaining: 8m 47s\n",
            "760:\tlearn: 0.2257462\ttotal: 1m 34s\tremaining: 8m 47s\n",
            "761:\tlearn: 0.2256841\ttotal: 1m 34s\tremaining: 8m 47s\n",
            "762:\tlearn: 0.2256018\ttotal: 1m 34s\tremaining: 8m 47s\n",
            "763:\tlearn: 0.2255500\ttotal: 1m 35s\tremaining: 8m 47s\n",
            "764:\tlearn: 0.2254935\ttotal: 1m 35s\tremaining: 8m 46s\n",
            "765:\tlearn: 0.2254174\ttotal: 1m 35s\tremaining: 8m 46s\n",
            "766:\tlearn: 0.2253636\ttotal: 1m 35s\tremaining: 8m 46s\n",
            "767:\tlearn: 0.2253022\ttotal: 1m 35s\tremaining: 8m 46s\n",
            "768:\tlearn: 0.2252453\ttotal: 1m 35s\tremaining: 8m 46s\n",
            "769:\tlearn: 0.2251866\ttotal: 1m 35s\tremaining: 8m 46s\n",
            "770:\tlearn: 0.2251348\ttotal: 1m 35s\tremaining: 8m 46s\n",
            "771:\tlearn: 0.2250293\ttotal: 1m 36s\tremaining: 8m 46s\n",
            "772:\tlearn: 0.2249616\ttotal: 1m 36s\tremaining: 8m 46s\n",
            "773:\tlearn: 0.2248570\ttotal: 1m 36s\tremaining: 8m 46s\n",
            "774:\tlearn: 0.2247861\ttotal: 1m 36s\tremaining: 8m 46s\n",
            "775:\tlearn: 0.2247203\ttotal: 1m 36s\tremaining: 8m 46s\n",
            "776:\tlearn: 0.2246817\ttotal: 1m 36s\tremaining: 8m 45s\n",
            "777:\tlearn: 0.2246364\ttotal: 1m 36s\tremaining: 8m 45s\n",
            "778:\tlearn: 0.2245710\ttotal: 1m 37s\tremaining: 8m 45s\n",
            "779:\tlearn: 0.2244516\ttotal: 1m 37s\tremaining: 8m 45s\n",
            "780:\tlearn: 0.2243826\ttotal: 1m 37s\tremaining: 8m 45s\n",
            "781:\tlearn: 0.2243180\ttotal: 1m 37s\tremaining: 8m 45s\n",
            "782:\tlearn: 0.2242165\ttotal: 1m 37s\tremaining: 8m 45s\n",
            "783:\tlearn: 0.2241641\ttotal: 1m 37s\tremaining: 8m 45s\n",
            "784:\tlearn: 0.2240615\ttotal: 1m 37s\tremaining: 8m 45s\n",
            "785:\tlearn: 0.2240142\ttotal: 1m 37s\tremaining: 8m 45s\n",
            "786:\tlearn: 0.2239417\ttotal: 1m 38s\tremaining: 8m 44s\n",
            "787:\tlearn: 0.2238598\ttotal: 1m 38s\tremaining: 8m 44s\n",
            "788:\tlearn: 0.2237876\ttotal: 1m 38s\tremaining: 8m 44s\n",
            "789:\tlearn: 0.2237129\ttotal: 1m 38s\tremaining: 8m 44s\n",
            "790:\tlearn: 0.2236344\ttotal: 1m 38s\tremaining: 8m 44s\n",
            "791:\tlearn: 0.2235698\ttotal: 1m 38s\tremaining: 8m 44s\n",
            "792:\tlearn: 0.2234719\ttotal: 1m 38s\tremaining: 8m 44s\n",
            "793:\tlearn: 0.2234123\ttotal: 1m 38s\tremaining: 8m 44s\n",
            "794:\tlearn: 0.2233467\ttotal: 1m 39s\tremaining: 8m 44s\n",
            "795:\tlearn: 0.2232707\ttotal: 1m 39s\tremaining: 8m 44s\n",
            "796:\tlearn: 0.2232108\ttotal: 1m 39s\tremaining: 8m 44s\n",
            "797:\tlearn: 0.2231352\ttotal: 1m 39s\tremaining: 8m 44s\n",
            "798:\tlearn: 0.2231010\ttotal: 1m 39s\tremaining: 8m 43s\n",
            "799:\tlearn: 0.2230252\ttotal: 1m 39s\tremaining: 8m 43s\n",
            "800:\tlearn: 0.2229816\ttotal: 1m 39s\tremaining: 8m 43s\n",
            "801:\tlearn: 0.2229485\ttotal: 1m 39s\tremaining: 8m 43s\n",
            "802:\tlearn: 0.2228719\ttotal: 1m 40s\tremaining: 8m 43s\n",
            "803:\tlearn: 0.2228063\ttotal: 1m 40s\tremaining: 8m 43s\n",
            "804:\tlearn: 0.2227533\ttotal: 1m 40s\tremaining: 8m 43s\n",
            "805:\tlearn: 0.2226622\ttotal: 1m 40s\tremaining: 8m 42s\n",
            "806:\tlearn: 0.2226055\ttotal: 1m 40s\tremaining: 8m 42s\n",
            "807:\tlearn: 0.2225499\ttotal: 1m 40s\tremaining: 8m 42s\n",
            "808:\tlearn: 0.2224793\ttotal: 1m 40s\tremaining: 8m 42s\n",
            "809:\tlearn: 0.2224360\ttotal: 1m 41s\tremaining: 8m 42s\n",
            "810:\tlearn: 0.2223811\ttotal: 1m 41s\tremaining: 8m 42s\n",
            "811:\tlearn: 0.2223185\ttotal: 1m 41s\tremaining: 8m 42s\n",
            "812:\tlearn: 0.2222169\ttotal: 1m 41s\tremaining: 8m 42s\n",
            "813:\tlearn: 0.2221555\ttotal: 1m 41s\tremaining: 8m 42s\n",
            "814:\tlearn: 0.2221026\ttotal: 1m 41s\tremaining: 8m 41s\n",
            "815:\tlearn: 0.2220407\ttotal: 1m 41s\tremaining: 8m 41s\n",
            "816:\tlearn: 0.2219896\ttotal: 1m 41s\tremaining: 8m 41s\n",
            "817:\tlearn: 0.2219489\ttotal: 1m 41s\tremaining: 8m 41s\n",
            "818:\tlearn: 0.2219088\ttotal: 1m 42s\tremaining: 8m 41s\n",
            "819:\tlearn: 0.2218542\ttotal: 1m 42s\tremaining: 8m 40s\n",
            "820:\tlearn: 0.2217964\ttotal: 1m 42s\tremaining: 8m 40s\n",
            "821:\tlearn: 0.2217199\ttotal: 1m 42s\tremaining: 8m 41s\n",
            "822:\tlearn: 0.2216729\ttotal: 1m 42s\tremaining: 8m 41s\n",
            "823:\tlearn: 0.2216182\ttotal: 1m 42s\tremaining: 8m 40s\n",
            "824:\tlearn: 0.2215609\ttotal: 1m 42s\tremaining: 8m 40s\n",
            "825:\tlearn: 0.2214665\ttotal: 1m 43s\tremaining: 8m 40s\n",
            "826:\tlearn: 0.2214220\ttotal: 1m 43s\tremaining: 8m 40s\n",
            "827:\tlearn: 0.2213227\ttotal: 1m 43s\tremaining: 8m 40s\n",
            "828:\tlearn: 0.2212711\ttotal: 1m 43s\tremaining: 8m 40s\n",
            "829:\tlearn: 0.2212256\ttotal: 1m 43s\tremaining: 8m 40s\n",
            "830:\tlearn: 0.2211565\ttotal: 1m 43s\tremaining: 8m 39s\n",
            "831:\tlearn: 0.2210726\ttotal: 1m 43s\tremaining: 8m 39s\n",
            "832:\tlearn: 0.2210301\ttotal: 1m 43s\tremaining: 8m 39s\n",
            "833:\tlearn: 0.2209708\ttotal: 1m 44s\tremaining: 8m 39s\n",
            "834:\tlearn: 0.2209226\ttotal: 1m 44s\tremaining: 8m 39s\n",
            "835:\tlearn: 0.2208786\ttotal: 1m 44s\tremaining: 8m 39s\n",
            "836:\tlearn: 0.2208180\ttotal: 1m 44s\tremaining: 8m 38s\n",
            "837:\tlearn: 0.2207370\ttotal: 1m 44s\tremaining: 8m 39s\n",
            "838:\tlearn: 0.2207084\ttotal: 1m 44s\tremaining: 8m 38s\n",
            "839:\tlearn: 0.2206565\ttotal: 1m 44s\tremaining: 8m 38s\n",
            "840:\tlearn: 0.2205907\ttotal: 1m 44s\tremaining: 8m 38s\n",
            "841:\tlearn: 0.2205233\ttotal: 1m 44s\tremaining: 8m 38s\n",
            "842:\tlearn: 0.2204157\ttotal: 1m 45s\tremaining: 8m 38s\n",
            "843:\tlearn: 0.2203616\ttotal: 1m 45s\tremaining: 8m 38s\n",
            "844:\tlearn: 0.2202962\ttotal: 1m 45s\tremaining: 8m 38s\n",
            "845:\tlearn: 0.2201995\ttotal: 1m 45s\tremaining: 8m 37s\n",
            "846:\tlearn: 0.2201245\ttotal: 1m 45s\tremaining: 8m 37s\n",
            "847:\tlearn: 0.2200838\ttotal: 1m 45s\tremaining: 8m 37s\n",
            "848:\tlearn: 0.2200475\ttotal: 1m 45s\tremaining: 8m 37s\n",
            "849:\tlearn: 0.2200030\ttotal: 1m 45s\tremaining: 8m 37s\n",
            "850:\tlearn: 0.2199417\ttotal: 1m 46s\tremaining: 8m 37s\n",
            "851:\tlearn: 0.2198999\ttotal: 1m 46s\tremaining: 8m 36s\n",
            "852:\tlearn: 0.2198469\ttotal: 1m 46s\tremaining: 8m 36s\n",
            "853:\tlearn: 0.2197756\ttotal: 1m 46s\tremaining: 8m 36s\n",
            "854:\tlearn: 0.2197326\ttotal: 1m 46s\tremaining: 8m 36s\n",
            "855:\tlearn: 0.2196620\ttotal: 1m 46s\tremaining: 8m 36s\n",
            "856:\tlearn: 0.2195846\ttotal: 1m 46s\tremaining: 8m 36s\n",
            "857:\tlearn: 0.2195310\ttotal: 1m 46s\tremaining: 8m 36s\n",
            "858:\tlearn: 0.2194771\ttotal: 1m 47s\tremaining: 8m 36s\n",
            "859:\tlearn: 0.2194098\ttotal: 1m 47s\tremaining: 8m 36s\n",
            "860:\tlearn: 0.2193257\ttotal: 1m 47s\tremaining: 8m 36s\n",
            "861:\tlearn: 0.2192611\ttotal: 1m 47s\tremaining: 8m 36s\n",
            "862:\tlearn: 0.2192145\ttotal: 1m 47s\tremaining: 8m 35s\n",
            "863:\tlearn: 0.2191376\ttotal: 1m 47s\tremaining: 8m 35s\n",
            "864:\tlearn: 0.2190723\ttotal: 1m 47s\tremaining: 8m 35s\n",
            "865:\tlearn: 0.2190046\ttotal: 1m 48s\tremaining: 8m 35s\n",
            "866:\tlearn: 0.2189498\ttotal: 1m 48s\tremaining: 8m 35s\n",
            "867:\tlearn: 0.2189049\ttotal: 1m 48s\tremaining: 8m 35s\n",
            "868:\tlearn: 0.2188680\ttotal: 1m 48s\tremaining: 8m 35s\n",
            "869:\tlearn: 0.2188159\ttotal: 1m 48s\tremaining: 8m 35s\n",
            "870:\tlearn: 0.2187400\ttotal: 1m 48s\tremaining: 8m 34s\n",
            "871:\tlearn: 0.2186727\ttotal: 1m 48s\tremaining: 8m 34s\n",
            "872:\tlearn: 0.2186170\ttotal: 1m 48s\tremaining: 8m 34s\n",
            "873:\tlearn: 0.2185856\ttotal: 1m 48s\tremaining: 8m 34s\n",
            "874:\tlearn: 0.2185323\ttotal: 1m 49s\tremaining: 8m 34s\n",
            "875:\tlearn: 0.2184856\ttotal: 1m 49s\tremaining: 8m 34s\n",
            "876:\tlearn: 0.2184244\ttotal: 1m 49s\tremaining: 8m 34s\n",
            "877:\tlearn: 0.2183941\ttotal: 1m 49s\tremaining: 8m 33s\n",
            "878:\tlearn: 0.2183256\ttotal: 1m 49s\tremaining: 8m 33s\n",
            "879:\tlearn: 0.2182741\ttotal: 1m 49s\tremaining: 8m 33s\n",
            "880:\tlearn: 0.2182137\ttotal: 1m 49s\tremaining: 8m 33s\n",
            "881:\tlearn: 0.2181736\ttotal: 1m 49s\tremaining: 8m 33s\n",
            "882:\tlearn: 0.2181294\ttotal: 1m 50s\tremaining: 8m 32s\n",
            "883:\tlearn: 0.2180756\ttotal: 1m 50s\tremaining: 8m 32s\n",
            "884:\tlearn: 0.2180473\ttotal: 1m 50s\tremaining: 8m 32s\n",
            "885:\tlearn: 0.2179895\ttotal: 1m 50s\tremaining: 8m 32s\n",
            "886:\tlearn: 0.2179342\ttotal: 1m 50s\tremaining: 8m 32s\n",
            "887:\tlearn: 0.2178928\ttotal: 1m 50s\tremaining: 8m 32s\n",
            "888:\tlearn: 0.2178497\ttotal: 1m 50s\tremaining: 8m 32s\n",
            "889:\tlearn: 0.2177512\ttotal: 1m 50s\tremaining: 8m 31s\n",
            "890:\tlearn: 0.2176983\ttotal: 1m 50s\tremaining: 8m 31s\n",
            "891:\tlearn: 0.2176423\ttotal: 1m 51s\tremaining: 8m 31s\n",
            "892:\tlearn: 0.2175979\ttotal: 1m 51s\tremaining: 8m 31s\n",
            "893:\tlearn: 0.2175355\ttotal: 1m 51s\tremaining: 8m 31s\n",
            "894:\tlearn: 0.2174702\ttotal: 1m 51s\tremaining: 8m 31s\n",
            "895:\tlearn: 0.2174190\ttotal: 1m 51s\tremaining: 8m 31s\n",
            "896:\tlearn: 0.2173687\ttotal: 1m 51s\tremaining: 8m 31s\n",
            "897:\tlearn: 0.2173150\ttotal: 1m 51s\tremaining: 8m 31s\n",
            "898:\tlearn: 0.2172658\ttotal: 1m 51s\tremaining: 8m 30s\n",
            "899:\tlearn: 0.2172218\ttotal: 1m 52s\tremaining: 8m 30s\n",
            "900:\tlearn: 0.2171651\ttotal: 1m 52s\tremaining: 8m 30s\n",
            "901:\tlearn: 0.2170900\ttotal: 1m 52s\tremaining: 8m 30s\n",
            "902:\tlearn: 0.2170619\ttotal: 1m 52s\tremaining: 8m 30s\n",
            "903:\tlearn: 0.2170176\ttotal: 1m 52s\tremaining: 8m 30s\n",
            "904:\tlearn: 0.2169670\ttotal: 1m 52s\tremaining: 8m 30s\n",
            "905:\tlearn: 0.2169335\ttotal: 1m 52s\tremaining: 8m 29s\n",
            "906:\tlearn: 0.2168681\ttotal: 1m 52s\tremaining: 8m 29s\n",
            "907:\tlearn: 0.2168092\ttotal: 1m 53s\tremaining: 8m 29s\n",
            "908:\tlearn: 0.2167509\ttotal: 1m 53s\tremaining: 8m 29s\n",
            "909:\tlearn: 0.2167079\ttotal: 1m 53s\tremaining: 8m 29s\n",
            "910:\tlearn: 0.2166478\ttotal: 1m 53s\tremaining: 8m 29s\n",
            "911:\tlearn: 0.2166016\ttotal: 1m 53s\tremaining: 8m 29s\n",
            "912:\tlearn: 0.2165530\ttotal: 1m 53s\tremaining: 8m 29s\n",
            "913:\tlearn: 0.2165097\ttotal: 1m 53s\tremaining: 8m 28s\n",
            "914:\tlearn: 0.2164216\ttotal: 1m 53s\tremaining: 8m 28s\n",
            "915:\tlearn: 0.2163790\ttotal: 1m 54s\tremaining: 8m 28s\n",
            "916:\tlearn: 0.2163305\ttotal: 1m 54s\tremaining: 8m 28s\n",
            "917:\tlearn: 0.2162741\ttotal: 1m 54s\tremaining: 8m 28s\n",
            "918:\tlearn: 0.2162157\ttotal: 1m 54s\tremaining: 8m 28s\n",
            "919:\tlearn: 0.2161617\ttotal: 1m 54s\tremaining: 8m 28s\n",
            "920:\tlearn: 0.2161050\ttotal: 1m 54s\tremaining: 8m 28s\n",
            "921:\tlearn: 0.2160471\ttotal: 1m 54s\tremaining: 8m 28s\n",
            "922:\tlearn: 0.2159977\ttotal: 1m 55s\tremaining: 8m 27s\n",
            "923:\tlearn: 0.2159489\ttotal: 1m 55s\tremaining: 8m 27s\n",
            "924:\tlearn: 0.2158861\ttotal: 1m 55s\tremaining: 8m 27s\n",
            "925:\tlearn: 0.2158257\ttotal: 1m 55s\tremaining: 8m 27s\n",
            "926:\tlearn: 0.2158056\ttotal: 1m 55s\tremaining: 8m 27s\n",
            "927:\tlearn: 0.2157770\ttotal: 1m 55s\tremaining: 8m 26s\n",
            "928:\tlearn: 0.2157358\ttotal: 1m 55s\tremaining: 8m 26s\n",
            "929:\tlearn: 0.2156913\ttotal: 1m 55s\tremaining: 8m 26s\n",
            "930:\tlearn: 0.2156392\ttotal: 1m 55s\tremaining: 8m 26s\n",
            "931:\tlearn: 0.2155951\ttotal: 1m 56s\tremaining: 8m 26s\n",
            "932:\tlearn: 0.2155320\ttotal: 1m 56s\tremaining: 8m 26s\n",
            "933:\tlearn: 0.2154907\ttotal: 1m 56s\tremaining: 8m 26s\n",
            "934:\tlearn: 0.2154413\ttotal: 1m 56s\tremaining: 8m 25s\n",
            "935:\tlearn: 0.2153548\ttotal: 1m 56s\tremaining: 8m 25s\n",
            "936:\tlearn: 0.2153053\ttotal: 1m 56s\tremaining: 8m 25s\n",
            "937:\tlearn: 0.2152569\ttotal: 1m 56s\tremaining: 8m 25s\n",
            "938:\tlearn: 0.2152053\ttotal: 1m 56s\tremaining: 8m 25s\n",
            "939:\tlearn: 0.2151672\ttotal: 1m 57s\tremaining: 8m 25s\n",
            "940:\tlearn: 0.2151311\ttotal: 1m 57s\tremaining: 8m 25s\n",
            "941:\tlearn: 0.2150847\ttotal: 1m 57s\tremaining: 8m 25s\n",
            "942:\tlearn: 0.2150412\ttotal: 1m 57s\tremaining: 8m 24s\n",
            "943:\tlearn: 0.2150060\ttotal: 1m 57s\tremaining: 8m 24s\n",
            "944:\tlearn: 0.2149260\ttotal: 1m 57s\tremaining: 8m 24s\n",
            "945:\tlearn: 0.2148472\ttotal: 1m 57s\tremaining: 8m 24s\n",
            "946:\tlearn: 0.2148162\ttotal: 1m 57s\tremaining: 8m 24s\n",
            "947:\tlearn: 0.2147689\ttotal: 1m 57s\tremaining: 8m 24s\n",
            "948:\tlearn: 0.2147134\ttotal: 1m 58s\tremaining: 8m 24s\n",
            "949:\tlearn: 0.2146659\ttotal: 1m 58s\tremaining: 8m 24s\n",
            "950:\tlearn: 0.2146194\ttotal: 1m 58s\tremaining: 8m 23s\n",
            "951:\tlearn: 0.2145896\ttotal: 1m 58s\tremaining: 8m 23s\n",
            "952:\tlearn: 0.2145534\ttotal: 1m 58s\tremaining: 8m 23s\n",
            "953:\tlearn: 0.2145134\ttotal: 1m 58s\tremaining: 8m 23s\n",
            "954:\tlearn: 0.2144338\ttotal: 1m 58s\tremaining: 8m 23s\n",
            "955:\tlearn: 0.2143843\ttotal: 1m 58s\tremaining: 8m 23s\n",
            "956:\tlearn: 0.2143404\ttotal: 1m 59s\tremaining: 8m 23s\n",
            "957:\tlearn: 0.2142771\ttotal: 1m 59s\tremaining: 8m 23s\n",
            "958:\tlearn: 0.2142191\ttotal: 1m 59s\tremaining: 8m 22s\n",
            "959:\tlearn: 0.2141816\ttotal: 1m 59s\tremaining: 8m 22s\n",
            "960:\tlearn: 0.2141477\ttotal: 1m 59s\tremaining: 8m 22s\n",
            "961:\tlearn: 0.2140740\ttotal: 1m 59s\tremaining: 8m 22s\n",
            "962:\tlearn: 0.2140284\ttotal: 1m 59s\tremaining: 8m 22s\n",
            "963:\tlearn: 0.2139898\ttotal: 1m 59s\tremaining: 8m 22s\n",
            "964:\tlearn: 0.2139444\ttotal: 2m\tremaining: 8m 21s\n",
            "965:\tlearn: 0.2138882\ttotal: 2m\tremaining: 8m 21s\n",
            "966:\tlearn: 0.2138399\ttotal: 2m\tremaining: 8m 21s\n",
            "967:\tlearn: 0.2137932\ttotal: 2m\tremaining: 8m 21s\n",
            "968:\tlearn: 0.2137774\ttotal: 2m\tremaining: 8m 21s\n",
            "969:\tlearn: 0.2137323\ttotal: 2m\tremaining: 8m 21s\n",
            "970:\tlearn: 0.2137086\ttotal: 2m\tremaining: 8m 21s\n",
            "971:\tlearn: 0.2136558\ttotal: 2m\tremaining: 8m 21s\n",
            "972:\tlearn: 0.2136171\ttotal: 2m 1s\tremaining: 8m 20s\n",
            "973:\tlearn: 0.2135307\ttotal: 2m 1s\tremaining: 8m 20s\n",
            "974:\tlearn: 0.2134833\ttotal: 2m 1s\tremaining: 8m 20s\n",
            "975:\tlearn: 0.2134367\ttotal: 2m 1s\tremaining: 8m 20s\n",
            "976:\tlearn: 0.2134020\ttotal: 2m 1s\tremaining: 8m 20s\n",
            "977:\tlearn: 0.2133570\ttotal: 2m 1s\tremaining: 8m 20s\n",
            "978:\tlearn: 0.2133009\ttotal: 2m 1s\tremaining: 8m 20s\n",
            "979:\tlearn: 0.2132433\ttotal: 2m 1s\tremaining: 8m 20s\n",
            "980:\tlearn: 0.2131877\ttotal: 2m 2s\tremaining: 8m 19s\n",
            "981:\tlearn: 0.2131363\ttotal: 2m 2s\tremaining: 8m 19s\n",
            "982:\tlearn: 0.2131044\ttotal: 2m 2s\tremaining: 8m 19s\n",
            "983:\tlearn: 0.2130328\ttotal: 2m 2s\tremaining: 8m 19s\n",
            "984:\tlearn: 0.2129823\ttotal: 2m 2s\tremaining: 8m 19s\n",
            "985:\tlearn: 0.2129276\ttotal: 2m 2s\tremaining: 8m 19s\n",
            "986:\tlearn: 0.2128762\ttotal: 2m 2s\tremaining: 8m 19s\n",
            "987:\tlearn: 0.2128203\ttotal: 2m 2s\tremaining: 8m 19s\n",
            "988:\tlearn: 0.2127856\ttotal: 2m 3s\tremaining: 8m 19s\n",
            "989:\tlearn: 0.2127382\ttotal: 2m 3s\tremaining: 8m 19s\n",
            "990:\tlearn: 0.2126681\ttotal: 2m 3s\tremaining: 8m 18s\n",
            "991:\tlearn: 0.2125946\ttotal: 2m 3s\tremaining: 8m 18s\n",
            "992:\tlearn: 0.2125803\ttotal: 2m 3s\tremaining: 8m 18s\n",
            "993:\tlearn: 0.2124915\ttotal: 2m 3s\tremaining: 8m 18s\n",
            "994:\tlearn: 0.2124361\ttotal: 2m 3s\tremaining: 8m 18s\n",
            "995:\tlearn: 0.2124100\ttotal: 2m 3s\tremaining: 8m 18s\n",
            "996:\tlearn: 0.2123468\ttotal: 2m 4s\tremaining: 8m 18s\n",
            "997:\tlearn: 0.2123075\ttotal: 2m 4s\tremaining: 8m 18s\n",
            "998:\tlearn: 0.2122690\ttotal: 2m 4s\tremaining: 8m 18s\n",
            "999:\tlearn: 0.2122252\ttotal: 2m 4s\tremaining: 8m 17s\n",
            "1000:\tlearn: 0.2121743\ttotal: 2m 4s\tremaining: 8m 17s\n",
            "1001:\tlearn: 0.2121367\ttotal: 2m 4s\tremaining: 8m 17s\n",
            "1002:\tlearn: 0.2120849\ttotal: 2m 4s\tremaining: 8m 17s\n",
            "1003:\tlearn: 0.2120509\ttotal: 2m 4s\tremaining: 8m 17s\n",
            "1004:\tlearn: 0.2119745\ttotal: 2m 5s\tremaining: 8m 17s\n",
            "1005:\tlearn: 0.2119323\ttotal: 2m 5s\tremaining: 8m 17s\n",
            "1006:\tlearn: 0.2118900\ttotal: 2m 5s\tremaining: 8m 17s\n",
            "1007:\tlearn: 0.2118471\ttotal: 2m 5s\tremaining: 8m 16s\n",
            "1008:\tlearn: 0.2117892\ttotal: 2m 5s\tremaining: 8m 16s\n",
            "1009:\tlearn: 0.2117648\ttotal: 2m 5s\tremaining: 8m 16s\n",
            "1010:\tlearn: 0.2117316\ttotal: 2m 5s\tremaining: 8m 16s\n",
            "1011:\tlearn: 0.2117011\ttotal: 2m 5s\tremaining: 8m 16s\n",
            "1012:\tlearn: 0.2116629\ttotal: 2m 6s\tremaining: 8m 16s\n",
            "1013:\tlearn: 0.2116127\ttotal: 2m 6s\tremaining: 8m 15s\n",
            "1014:\tlearn: 0.2115606\ttotal: 2m 6s\tremaining: 8m 15s\n",
            "1015:\tlearn: 0.2115029\ttotal: 2m 6s\tremaining: 8m 15s\n",
            "1016:\tlearn: 0.2114499\ttotal: 2m 6s\tremaining: 8m 15s\n",
            "1017:\tlearn: 0.2114121\ttotal: 2m 6s\tremaining: 8m 15s\n",
            "1018:\tlearn: 0.2113494\ttotal: 2m 6s\tremaining: 8m 15s\n",
            "1019:\tlearn: 0.2113077\ttotal: 2m 6s\tremaining: 8m 15s\n",
            "1020:\tlearn: 0.2112562\ttotal: 2m 7s\tremaining: 8m 15s\n",
            "1021:\tlearn: 0.2112020\ttotal: 2m 7s\tremaining: 8m 15s\n",
            "1022:\tlearn: 0.2111432\ttotal: 2m 7s\tremaining: 8m 14s\n",
            "1023:\tlearn: 0.2111043\ttotal: 2m 7s\tremaining: 8m 14s\n",
            "1024:\tlearn: 0.2110852\ttotal: 2m 7s\tremaining: 8m 14s\n",
            "1025:\tlearn: 0.2110500\ttotal: 2m 7s\tremaining: 8m 14s\n",
            "1026:\tlearn: 0.2109849\ttotal: 2m 7s\tremaining: 8m 14s\n",
            "1027:\tlearn: 0.2109142\ttotal: 2m 7s\tremaining: 8m 14s\n",
            "1028:\tlearn: 0.2108603\ttotal: 2m 8s\tremaining: 8m 14s\n",
            "1029:\tlearn: 0.2108225\ttotal: 2m 8s\tremaining: 8m 13s\n",
            "1030:\tlearn: 0.2107270\ttotal: 2m 8s\tremaining: 8m 13s\n",
            "1031:\tlearn: 0.2106914\ttotal: 2m 8s\tremaining: 8m 13s\n",
            "1032:\tlearn: 0.2105831\ttotal: 2m 8s\tremaining: 8m 13s\n",
            "1033:\tlearn: 0.2105497\ttotal: 2m 8s\tremaining: 8m 13s\n",
            "1034:\tlearn: 0.2105001\ttotal: 2m 8s\tremaining: 8m 13s\n",
            "1035:\tlearn: 0.2104468\ttotal: 2m 8s\tremaining: 8m 13s\n",
            "1036:\tlearn: 0.2103870\ttotal: 2m 9s\tremaining: 8m 13s\n",
            "1037:\tlearn: 0.2103363\ttotal: 2m 9s\tremaining: 8m 13s\n",
            "1038:\tlearn: 0.2103029\ttotal: 2m 9s\tremaining: 8m 13s\n",
            "1039:\tlearn: 0.2102586\ttotal: 2m 9s\tremaining: 8m 13s\n",
            "1040:\tlearn: 0.2102151\ttotal: 2m 9s\tremaining: 8m 12s\n",
            "1041:\tlearn: 0.2101608\ttotal: 2m 9s\tremaining: 8m 12s\n",
            "1042:\tlearn: 0.2100618\ttotal: 2m 9s\tremaining: 8m 12s\n",
            "1043:\tlearn: 0.2100082\ttotal: 2m 9s\tremaining: 8m 12s\n",
            "1044:\tlearn: 0.2099606\ttotal: 2m 10s\tremaining: 8m 12s\n",
            "1045:\tlearn: 0.2098868\ttotal: 2m 10s\tremaining: 8m 12s\n",
            "1046:\tlearn: 0.2098405\ttotal: 2m 10s\tremaining: 8m 12s\n",
            "1047:\tlearn: 0.2097948\ttotal: 2m 10s\tremaining: 8m 12s\n",
            "1048:\tlearn: 0.2097563\ttotal: 2m 10s\tremaining: 8m 12s\n",
            "1049:\tlearn: 0.2097290\ttotal: 2m 10s\tremaining: 8m 12s\n",
            "1050:\tlearn: 0.2097013\ttotal: 2m 10s\tremaining: 8m 11s\n",
            "1051:\tlearn: 0.2096454\ttotal: 2m 11s\tremaining: 8m 11s\n",
            "1052:\tlearn: 0.2095998\ttotal: 2m 11s\tremaining: 8m 11s\n",
            "1053:\tlearn: 0.2095668\ttotal: 2m 11s\tremaining: 8m 11s\n",
            "1054:\tlearn: 0.2095312\ttotal: 2m 11s\tremaining: 8m 11s\n",
            "1055:\tlearn: 0.2094908\ttotal: 2m 11s\tremaining: 8m 11s\n",
            "1056:\tlearn: 0.2094606\ttotal: 2m 11s\tremaining: 8m 11s\n",
            "1057:\tlearn: 0.2093595\ttotal: 2m 11s\tremaining: 8m 10s\n",
            "1058:\tlearn: 0.2093199\ttotal: 2m 11s\tremaining: 8m 10s\n",
            "1059:\tlearn: 0.2092622\ttotal: 2m 11s\tremaining: 8m 10s\n",
            "1060:\tlearn: 0.2092189\ttotal: 2m 12s\tremaining: 8m 10s\n",
            "1061:\tlearn: 0.2091436\ttotal: 2m 12s\tremaining: 8m 10s\n",
            "1062:\tlearn: 0.2090954\ttotal: 2m 12s\tremaining: 8m 10s\n",
            "1063:\tlearn: 0.2090675\ttotal: 2m 12s\tremaining: 8m 9s\n",
            "1064:\tlearn: 0.2090320\ttotal: 2m 12s\tremaining: 8m 9s\n",
            "1065:\tlearn: 0.2089956\ttotal: 2m 12s\tremaining: 8m 9s\n",
            "1066:\tlearn: 0.2089531\ttotal: 2m 12s\tremaining: 8m 9s\n",
            "1067:\tlearn: 0.2088461\ttotal: 2m 12s\tremaining: 8m 9s\n",
            "1068:\tlearn: 0.2088178\ttotal: 2m 13s\tremaining: 8m 9s\n",
            "1069:\tlearn: 0.2087655\ttotal: 2m 13s\tremaining: 8m 9s\n",
            "1070:\tlearn: 0.2087310\ttotal: 2m 13s\tremaining: 8m 9s\n",
            "1071:\tlearn: 0.2087042\ttotal: 2m 13s\tremaining: 8m 8s\n",
            "1072:\tlearn: 0.2086528\ttotal: 2m 13s\tremaining: 8m 8s\n",
            "1073:\tlearn: 0.2086247\ttotal: 2m 13s\tremaining: 8m 8s\n",
            "1074:\tlearn: 0.2086045\ttotal: 2m 13s\tremaining: 8m 8s\n",
            "1075:\tlearn: 0.2085538\ttotal: 2m 13s\tremaining: 8m 8s\n",
            "1076:\tlearn: 0.2085060\ttotal: 2m 14s\tremaining: 8m 8s\n",
            "1077:\tlearn: 0.2084601\ttotal: 2m 14s\tremaining: 8m 8s\n",
            "1078:\tlearn: 0.2084132\ttotal: 2m 14s\tremaining: 8m 7s\n",
            "1079:\tlearn: 0.2083826\ttotal: 2m 14s\tremaining: 8m 7s\n",
            "1080:\tlearn: 0.2083400\ttotal: 2m 14s\tremaining: 8m 7s\n",
            "1081:\tlearn: 0.2083087\ttotal: 2m 14s\tremaining: 8m 7s\n",
            "1082:\tlearn: 0.2082665\ttotal: 2m 14s\tremaining: 8m 7s\n",
            "1083:\tlearn: 0.2082320\ttotal: 2m 14s\tremaining: 8m 7s\n",
            "1084:\tlearn: 0.2082036\ttotal: 2m 14s\tremaining: 8m 7s\n",
            "1085:\tlearn: 0.2081627\ttotal: 2m 15s\tremaining: 8m 6s\n",
            "1086:\tlearn: 0.2081206\ttotal: 2m 15s\tremaining: 8m 6s\n",
            "1087:\tlearn: 0.2079911\ttotal: 2m 15s\tremaining: 8m 6s\n",
            "1088:\tlearn: 0.2079531\ttotal: 2m 15s\tremaining: 8m 6s\n",
            "1089:\tlearn: 0.2079198\ttotal: 2m 15s\tremaining: 8m 6s\n",
            "1090:\tlearn: 0.2078905\ttotal: 2m 15s\tremaining: 8m 6s\n",
            "1091:\tlearn: 0.2078459\ttotal: 2m 15s\tremaining: 8m 6s\n",
            "1092:\tlearn: 0.2078102\ttotal: 2m 15s\tremaining: 8m 5s\n",
            "1093:\tlearn: 0.2077732\ttotal: 2m 16s\tremaining: 8m 5s\n",
            "1094:\tlearn: 0.2077371\ttotal: 2m 16s\tremaining: 8m 5s\n",
            "1095:\tlearn: 0.2076886\ttotal: 2m 16s\tremaining: 8m 5s\n",
            "1096:\tlearn: 0.2076528\ttotal: 2m 16s\tremaining: 8m 5s\n",
            "1097:\tlearn: 0.2076296\ttotal: 2m 16s\tremaining: 8m 5s\n",
            "1098:\tlearn: 0.2076005\ttotal: 2m 16s\tremaining: 8m 5s\n",
            "1099:\tlearn: 0.2075789\ttotal: 2m 16s\tremaining: 8m 4s\n",
            "1100:\tlearn: 0.2075395\ttotal: 2m 16s\tremaining: 8m 4s\n",
            "1101:\tlearn: 0.2074928\ttotal: 2m 17s\tremaining: 8m 4s\n",
            "1102:\tlearn: 0.2074634\ttotal: 2m 17s\tremaining: 8m 4s\n",
            "1103:\tlearn: 0.2074209\ttotal: 2m 17s\tremaining: 8m 4s\n",
            "1104:\tlearn: 0.2073893\ttotal: 2m 17s\tremaining: 8m 4s\n",
            "1105:\tlearn: 0.2073130\ttotal: 2m 17s\tremaining: 8m 4s\n",
            "1106:\tlearn: 0.2072658\ttotal: 2m 17s\tremaining: 8m 3s\n",
            "1107:\tlearn: 0.2072353\ttotal: 2m 17s\tremaining: 8m 3s\n",
            "1108:\tlearn: 0.2071971\ttotal: 2m 17s\tremaining: 8m 3s\n",
            "1109:\tlearn: 0.2071595\ttotal: 2m 17s\tremaining: 8m 3s\n",
            "1110:\tlearn: 0.2070874\ttotal: 2m 18s\tremaining: 8m 3s\n",
            "1111:\tlearn: 0.2070406\ttotal: 2m 18s\tremaining: 8m 3s\n",
            "1112:\tlearn: 0.2069939\ttotal: 2m 18s\tremaining: 8m 2s\n",
            "1113:\tlearn: 0.2069092\ttotal: 2m 18s\tremaining: 8m 2s\n",
            "1114:\tlearn: 0.2068642\ttotal: 2m 18s\tremaining: 8m 2s\n",
            "1115:\tlearn: 0.2068154\ttotal: 2m 18s\tremaining: 8m 2s\n",
            "1116:\tlearn: 0.2067745\ttotal: 2m 18s\tremaining: 8m 2s\n",
            "1117:\tlearn: 0.2067156\ttotal: 2m 18s\tremaining: 8m 2s\n",
            "1118:\tlearn: 0.2066779\ttotal: 2m 18s\tremaining: 8m 2s\n",
            "1119:\tlearn: 0.2066427\ttotal: 2m 19s\tremaining: 8m 1s\n",
            "1120:\tlearn: 0.2066015\ttotal: 2m 19s\tremaining: 8m 1s\n",
            "1121:\tlearn: 0.2065728\ttotal: 2m 19s\tremaining: 8m 1s\n",
            "1122:\tlearn: 0.2065032\ttotal: 2m 19s\tremaining: 8m 1s\n",
            "1123:\tlearn: 0.2064679\ttotal: 2m 19s\tremaining: 8m 1s\n",
            "1124:\tlearn: 0.2064009\ttotal: 2m 19s\tremaining: 8m 1s\n",
            "1125:\tlearn: 0.2063660\ttotal: 2m 19s\tremaining: 8m 1s\n",
            "1126:\tlearn: 0.2063241\ttotal: 2m 19s\tremaining: 8m\n",
            "1127:\tlearn: 0.2062889\ttotal: 2m 20s\tremaining: 8m\n",
            "1128:\tlearn: 0.2062484\ttotal: 2m 20s\tremaining: 8m\n",
            "1129:\tlearn: 0.2062131\ttotal: 2m 20s\tremaining: 8m\n",
            "1130:\tlearn: 0.2061658\ttotal: 2m 20s\tremaining: 8m\n",
            "1131:\tlearn: 0.2061269\ttotal: 2m 20s\tremaining: 8m\n",
            "1132:\tlearn: 0.2060864\ttotal: 2m 20s\tremaining: 8m\n",
            "1133:\tlearn: 0.2060303\ttotal: 2m 20s\tremaining: 8m\n",
            "1134:\tlearn: 0.2059938\ttotal: 2m 20s\tremaining: 7m 59s\n",
            "1135:\tlearn: 0.2059410\ttotal: 2m 21s\tremaining: 8m\n",
            "1136:\tlearn: 0.2059085\ttotal: 2m 21s\tremaining: 7m 59s\n",
            "1137:\tlearn: 0.2058742\ttotal: 2m 21s\tremaining: 7m 59s\n",
            "1138:\tlearn: 0.2058259\ttotal: 2m 21s\tremaining: 7m 59s\n",
            "1139:\tlearn: 0.2057818\ttotal: 2m 21s\tremaining: 7m 59s\n",
            "1140:\tlearn: 0.2057520\ttotal: 2m 21s\tremaining: 7m 59s\n",
            "1141:\tlearn: 0.2056992\ttotal: 2m 21s\tremaining: 7m 59s\n",
            "1142:\tlearn: 0.2056237\ttotal: 2m 22s\tremaining: 7m 59s\n",
            "1143:\tlearn: 0.2055619\ttotal: 2m 22s\tremaining: 7m 59s\n",
            "1144:\tlearn: 0.2055340\ttotal: 2m 22s\tremaining: 7m 59s\n",
            "1145:\tlearn: 0.2055028\ttotal: 2m 22s\tremaining: 7m 58s\n",
            "1146:\tlearn: 0.2054704\ttotal: 2m 22s\tremaining: 7m 58s\n",
            "1147:\tlearn: 0.2054367\ttotal: 2m 22s\tremaining: 7m 58s\n",
            "1148:\tlearn: 0.2053933\ttotal: 2m 22s\tremaining: 7m 58s\n",
            "1149:\tlearn: 0.2053568\ttotal: 2m 22s\tremaining: 7m 58s\n",
            "1150:\tlearn: 0.2053022\ttotal: 2m 23s\tremaining: 7m 58s\n",
            "1151:\tlearn: 0.2052714\ttotal: 2m 23s\tremaining: 7m 58s\n",
            "1152:\tlearn: 0.2052178\ttotal: 2m 23s\tremaining: 7m 57s\n",
            "1153:\tlearn: 0.2051624\ttotal: 2m 23s\tremaining: 7m 57s\n",
            "1154:\tlearn: 0.2051166\ttotal: 2m 23s\tremaining: 7m 57s\n",
            "1155:\tlearn: 0.2050754\ttotal: 2m 23s\tremaining: 7m 57s\n",
            "1156:\tlearn: 0.2050300\ttotal: 2m 23s\tremaining: 7m 57s\n",
            "1157:\tlearn: 0.2050028\ttotal: 2m 23s\tremaining: 7m 57s\n",
            "1158:\tlearn: 0.2049147\ttotal: 2m 24s\tremaining: 7m 57s\n",
            "1159:\tlearn: 0.2048666\ttotal: 2m 24s\tremaining: 7m 57s\n",
            "1160:\tlearn: 0.2048108\ttotal: 2m 24s\tremaining: 7m 57s\n",
            "1161:\tlearn: 0.2047721\ttotal: 2m 24s\tremaining: 7m 57s\n",
            "1162:\tlearn: 0.2047329\ttotal: 2m 24s\tremaining: 7m 56s\n",
            "1163:\tlearn: 0.2047135\ttotal: 2m 24s\tremaining: 7m 56s\n",
            "1164:\tlearn: 0.2046771\ttotal: 2m 24s\tremaining: 7m 56s\n",
            "1165:\tlearn: 0.2046090\ttotal: 2m 24s\tremaining: 7m 56s\n",
            "1166:\tlearn: 0.2045425\ttotal: 2m 25s\tremaining: 7m 56s\n",
            "1167:\tlearn: 0.2044980\ttotal: 2m 25s\tremaining: 7m 56s\n",
            "1168:\tlearn: 0.2044371\ttotal: 2m 25s\tremaining: 7m 56s\n",
            "1169:\tlearn: 0.2043838\ttotal: 2m 25s\tremaining: 7m 56s\n",
            "1170:\tlearn: 0.2043494\ttotal: 2m 25s\tremaining: 7m 56s\n",
            "1171:\tlearn: 0.2043262\ttotal: 2m 25s\tremaining: 7m 55s\n",
            "1172:\tlearn: 0.2042884\ttotal: 2m 25s\tremaining: 7m 55s\n",
            "1173:\tlearn: 0.2042631\ttotal: 2m 25s\tremaining: 7m 55s\n",
            "1174:\tlearn: 0.2042212\ttotal: 2m 26s\tremaining: 7m 55s\n",
            "1175:\tlearn: 0.2041946\ttotal: 2m 26s\tremaining: 7m 55s\n",
            "1176:\tlearn: 0.2041611\ttotal: 2m 26s\tremaining: 7m 55s\n",
            "1177:\tlearn: 0.2041363\ttotal: 2m 26s\tremaining: 7m 55s\n",
            "1178:\tlearn: 0.2040986\ttotal: 2m 26s\tremaining: 7m 54s\n",
            "1179:\tlearn: 0.2040602\ttotal: 2m 26s\tremaining: 7m 54s\n",
            "1180:\tlearn: 0.2039907\ttotal: 2m 26s\tremaining: 7m 54s\n",
            "1181:\tlearn: 0.2039597\ttotal: 2m 26s\tremaining: 7m 54s\n",
            "1182:\tlearn: 0.2039143\ttotal: 2m 27s\tremaining: 7m 54s\n",
            "1183:\tlearn: 0.2038783\ttotal: 2m 27s\tremaining: 7m 54s\n",
            "1184:\tlearn: 0.2038233\ttotal: 2m 27s\tremaining: 7m 54s\n",
            "1185:\tlearn: 0.2037707\ttotal: 2m 27s\tremaining: 7m 54s\n",
            "1186:\tlearn: 0.2037344\ttotal: 2m 27s\tremaining: 7m 53s\n",
            "1187:\tlearn: 0.2036988\ttotal: 2m 27s\tremaining: 7m 53s\n",
            "1188:\tlearn: 0.2036735\ttotal: 2m 27s\tremaining: 7m 53s\n",
            "1189:\tlearn: 0.2036284\ttotal: 2m 27s\tremaining: 7m 53s\n",
            "1190:\tlearn: 0.2035967\ttotal: 2m 28s\tremaining: 7m 53s\n",
            "1191:\tlearn: 0.2035442\ttotal: 2m 28s\tremaining: 7m 53s\n",
            "1192:\tlearn: 0.2035066\ttotal: 2m 28s\tremaining: 7m 53s\n",
            "1193:\tlearn: 0.2034561\ttotal: 2m 28s\tremaining: 7m 52s\n",
            "1194:\tlearn: 0.2034148\ttotal: 2m 28s\tremaining: 7m 52s\n",
            "1195:\tlearn: 0.2033734\ttotal: 2m 28s\tremaining: 7m 52s\n",
            "1196:\tlearn: 0.2033394\ttotal: 2m 28s\tremaining: 7m 52s\n",
            "1197:\tlearn: 0.2032858\ttotal: 2m 28s\tremaining: 7m 52s\n",
            "1198:\tlearn: 0.2032408\ttotal: 2m 28s\tremaining: 7m 52s\n",
            "1199:\tlearn: 0.2032019\ttotal: 2m 29s\tremaining: 7m 52s\n",
            "1200:\tlearn: 0.2031719\ttotal: 2m 29s\tremaining: 7m 51s\n",
            "1201:\tlearn: 0.2031303\ttotal: 2m 29s\tremaining: 7m 51s\n",
            "1202:\tlearn: 0.2030989\ttotal: 2m 29s\tremaining: 7m 51s\n",
            "1203:\tlearn: 0.2030216\ttotal: 2m 29s\tremaining: 7m 51s\n",
            "1204:\tlearn: 0.2029971\ttotal: 2m 29s\tremaining: 7m 51s\n",
            "1205:\tlearn: 0.2029660\ttotal: 2m 29s\tremaining: 7m 51s\n",
            "1206:\tlearn: 0.2029108\ttotal: 2m 29s\tremaining: 7m 51s\n",
            "1207:\tlearn: 0.2028853\ttotal: 2m 30s\tremaining: 7m 50s\n",
            "1208:\tlearn: 0.2028506\ttotal: 2m 30s\tremaining: 7m 50s\n",
            "1209:\tlearn: 0.2028273\ttotal: 2m 30s\tremaining: 7m 50s\n",
            "1210:\tlearn: 0.2027850\ttotal: 2m 30s\tremaining: 7m 50s\n",
            "1211:\tlearn: 0.2027412\ttotal: 2m 30s\tremaining: 7m 50s\n",
            "1212:\tlearn: 0.2026946\ttotal: 2m 30s\tremaining: 7m 50s\n",
            "1213:\tlearn: 0.2026399\ttotal: 2m 30s\tremaining: 7m 50s\n",
            "1214:\tlearn: 0.2026043\ttotal: 2m 30s\tremaining: 7m 49s\n",
            "1215:\tlearn: 0.2025770\ttotal: 2m 30s\tremaining: 7m 49s\n",
            "1216:\tlearn: 0.2025442\ttotal: 2m 31s\tremaining: 7m 49s\n",
            "1217:\tlearn: 0.2024777\ttotal: 2m 31s\tremaining: 7m 49s\n",
            "1218:\tlearn: 0.2024422\ttotal: 2m 31s\tremaining: 7m 49s\n",
            "1219:\tlearn: 0.2024045\ttotal: 2m 31s\tremaining: 7m 49s\n",
            "1220:\tlearn: 0.2023794\ttotal: 2m 31s\tremaining: 7m 49s\n",
            "1221:\tlearn: 0.2023277\ttotal: 2m 31s\tremaining: 7m 49s\n",
            "1222:\tlearn: 0.2022891\ttotal: 2m 31s\tremaining: 7m 49s\n",
            "1223:\tlearn: 0.2022344\ttotal: 2m 32s\tremaining: 7m 48s\n",
            "1224:\tlearn: 0.2021931\ttotal: 2m 32s\tremaining: 7m 48s\n",
            "1225:\tlearn: 0.2021587\ttotal: 2m 32s\tremaining: 7m 48s\n",
            "1226:\tlearn: 0.2020942\ttotal: 2m 32s\tremaining: 7m 48s\n",
            "1227:\tlearn: 0.2020601\ttotal: 2m 32s\tremaining: 7m 48s\n",
            "1228:\tlearn: 0.2020157\ttotal: 2m 32s\tremaining: 7m 48s\n",
            "1229:\tlearn: 0.2019809\ttotal: 2m 32s\tremaining: 7m 48s\n",
            "1230:\tlearn: 0.2019323\ttotal: 2m 32s\tremaining: 7m 48s\n",
            "1231:\tlearn: 0.2019045\ttotal: 2m 32s\tremaining: 7m 47s\n",
            "1232:\tlearn: 0.2018625\ttotal: 2m 33s\tremaining: 7m 47s\n",
            "1233:\tlearn: 0.2018329\ttotal: 2m 33s\tremaining: 7m 47s\n",
            "1234:\tlearn: 0.2017924\ttotal: 2m 33s\tremaining: 7m 47s\n",
            "1235:\tlearn: 0.2017605\ttotal: 2m 33s\tremaining: 7m 47s\n",
            "1236:\tlearn: 0.2017334\ttotal: 2m 33s\tremaining: 7m 47s\n",
            "1237:\tlearn: 0.2017053\ttotal: 2m 33s\tremaining: 7m 47s\n",
            "1238:\tlearn: 0.2016619\ttotal: 2m 33s\tremaining: 7m 47s\n",
            "1239:\tlearn: 0.2016186\ttotal: 2m 33s\tremaining: 7m 46s\n",
            "1240:\tlearn: 0.2015819\ttotal: 2m 34s\tremaining: 7m 46s\n",
            "1241:\tlearn: 0.2015388\ttotal: 2m 34s\tremaining: 7m 46s\n",
            "1242:\tlearn: 0.2015154\ttotal: 2m 34s\tremaining: 7m 46s\n",
            "1243:\tlearn: 0.2014721\ttotal: 2m 34s\tremaining: 7m 46s\n",
            "1244:\tlearn: 0.2014482\ttotal: 2m 34s\tremaining: 7m 46s\n",
            "1245:\tlearn: 0.2014220\ttotal: 2m 34s\tremaining: 7m 46s\n",
            "1246:\tlearn: 0.2013724\ttotal: 2m 34s\tremaining: 7m 46s\n",
            "1247:\tlearn: 0.2013554\ttotal: 2m 34s\tremaining: 7m 45s\n",
            "1248:\tlearn: 0.2013186\ttotal: 2m 35s\tremaining: 7m 45s\n",
            "1249:\tlearn: 0.2012522\ttotal: 2m 35s\tremaining: 7m 45s\n",
            "1250:\tlearn: 0.2012290\ttotal: 2m 35s\tremaining: 7m 45s\n",
            "1251:\tlearn: 0.2011840\ttotal: 2m 35s\tremaining: 7m 45s\n",
            "1252:\tlearn: 0.2011380\ttotal: 2m 35s\tremaining: 7m 45s\n",
            "1253:\tlearn: 0.2010866\ttotal: 2m 35s\tremaining: 7m 45s\n",
            "1254:\tlearn: 0.2010616\ttotal: 2m 35s\tremaining: 7m 45s\n",
            "1255:\tlearn: 0.2010329\ttotal: 2m 35s\tremaining: 7m 44s\n",
            "1256:\tlearn: 0.2009879\ttotal: 2m 36s\tremaining: 7m 44s\n",
            "1257:\tlearn: 0.2009647\ttotal: 2m 36s\tremaining: 7m 44s\n",
            "1258:\tlearn: 0.2009330\ttotal: 2m 36s\tremaining: 7m 44s\n",
            "1259:\tlearn: 0.2008891\ttotal: 2m 36s\tremaining: 7m 44s\n",
            "1260:\tlearn: 0.2008488\ttotal: 2m 36s\tremaining: 7m 44s\n",
            "1261:\tlearn: 0.2008105\ttotal: 2m 36s\tremaining: 7m 44s\n",
            "1262:\tlearn: 0.2007805\ttotal: 2m 36s\tremaining: 7m 43s\n",
            "1263:\tlearn: 0.2007380\ttotal: 2m 36s\tremaining: 7m 43s\n",
            "1264:\tlearn: 0.2006986\ttotal: 2m 37s\tremaining: 7m 43s\n",
            "1265:\tlearn: 0.2006511\ttotal: 2m 37s\tremaining: 7m 43s\n",
            "1266:\tlearn: 0.2005952\ttotal: 2m 37s\tremaining: 7m 43s\n",
            "1267:\tlearn: 0.2005729\ttotal: 2m 37s\tremaining: 7m 43s\n",
            "1268:\tlearn: 0.2005297\ttotal: 2m 37s\tremaining: 7m 43s\n",
            "1269:\tlearn: 0.2005093\ttotal: 2m 37s\tremaining: 7m 42s\n",
            "1270:\tlearn: 0.2004752\ttotal: 2m 37s\tremaining: 7m 42s\n",
            "1271:\tlearn: 0.2004413\ttotal: 2m 37s\tremaining: 7m 42s\n",
            "1272:\tlearn: 0.2004005\ttotal: 2m 37s\tremaining: 7m 42s\n",
            "1273:\tlearn: 0.2003665\ttotal: 2m 38s\tremaining: 7m 42s\n",
            "1274:\tlearn: 0.2003235\ttotal: 2m 38s\tremaining: 7m 42s\n",
            "1275:\tlearn: 0.2003001\ttotal: 2m 38s\tremaining: 7m 42s\n",
            "1276:\tlearn: 0.2002609\ttotal: 2m 38s\tremaining: 7m 42s\n",
            "1277:\tlearn: 0.2002177\ttotal: 2m 38s\tremaining: 7m 41s\n",
            "1278:\tlearn: 0.2001982\ttotal: 2m 38s\tremaining: 7m 41s\n",
            "1279:\tlearn: 0.2001737\ttotal: 2m 38s\tremaining: 7m 41s\n",
            "1280:\tlearn: 0.2001471\ttotal: 2m 38s\tremaining: 7m 41s\n",
            "1281:\tlearn: 0.2001178\ttotal: 2m 39s\tremaining: 7m 41s\n",
            "1282:\tlearn: 0.2000689\ttotal: 2m 39s\tremaining: 7m 41s\n",
            "1283:\tlearn: 0.2000416\ttotal: 2m 39s\tremaining: 7m 41s\n",
            "1284:\tlearn: 0.2000079\ttotal: 2m 39s\tremaining: 7m 40s\n",
            "1285:\tlearn: 0.1999771\ttotal: 2m 39s\tremaining: 7m 40s\n",
            "1286:\tlearn: 0.1999356\ttotal: 2m 39s\tremaining: 7m 40s\n",
            "1287:\tlearn: 0.1999058\ttotal: 2m 39s\tremaining: 7m 40s\n",
            "1288:\tlearn: 0.1998657\ttotal: 2m 39s\tremaining: 7m 40s\n",
            "1289:\tlearn: 0.1998440\ttotal: 2m 39s\tremaining: 7m 40s\n",
            "1290:\tlearn: 0.1998031\ttotal: 2m 40s\tremaining: 7m 40s\n",
            "1291:\tlearn: 0.1997656\ttotal: 2m 40s\tremaining: 7m 39s\n",
            "1292:\tlearn: 0.1997206\ttotal: 2m 40s\tremaining: 7m 39s\n",
            "1293:\tlearn: 0.1996864\ttotal: 2m 40s\tremaining: 7m 39s\n",
            "1294:\tlearn: 0.1996334\ttotal: 2m 40s\tremaining: 7m 39s\n",
            "1295:\tlearn: 0.1995488\ttotal: 2m 40s\tremaining: 7m 39s\n",
            "1296:\tlearn: 0.1995092\ttotal: 2m 40s\tremaining: 7m 39s\n",
            "1297:\tlearn: 0.1994624\ttotal: 2m 41s\tremaining: 7m 39s\n",
            "1298:\tlearn: 0.1994270\ttotal: 2m 41s\tremaining: 7m 39s\n",
            "1299:\tlearn: 0.1993930\ttotal: 2m 41s\tremaining: 7m 39s\n",
            "1300:\tlearn: 0.1993596\ttotal: 2m 41s\tremaining: 7m 39s\n",
            "1301:\tlearn: 0.1993256\ttotal: 2m 41s\tremaining: 7m 38s\n",
            "1302:\tlearn: 0.1992989\ttotal: 2m 41s\tremaining: 7m 38s\n",
            "1303:\tlearn: 0.1992583\ttotal: 2m 41s\tremaining: 7m 38s\n",
            "1304:\tlearn: 0.1992302\ttotal: 2m 41s\tremaining: 7m 38s\n",
            "1305:\tlearn: 0.1992061\ttotal: 2m 42s\tremaining: 7m 38s\n",
            "1306:\tlearn: 0.1991477\ttotal: 2m 42s\tremaining: 7m 38s\n",
            "1307:\tlearn: 0.1990973\ttotal: 2m 42s\tremaining: 7m 38s\n",
            "1308:\tlearn: 0.1990674\ttotal: 2m 42s\tremaining: 7m 38s\n",
            "1309:\tlearn: 0.1990412\ttotal: 2m 42s\tremaining: 7m 38s\n",
            "1310:\tlearn: 0.1990278\ttotal: 2m 42s\tremaining: 7m 37s\n",
            "1311:\tlearn: 0.1989968\ttotal: 2m 42s\tremaining: 7m 37s\n",
            "1312:\tlearn: 0.1989625\ttotal: 2m 42s\tremaining: 7m 37s\n",
            "1313:\tlearn: 0.1989339\ttotal: 2m 43s\tremaining: 7m 37s\n",
            "1314:\tlearn: 0.1989099\ttotal: 2m 43s\tremaining: 7m 37s\n",
            "1315:\tlearn: 0.1988869\ttotal: 2m 43s\tremaining: 7m 37s\n",
            "1316:\tlearn: 0.1988311\ttotal: 2m 43s\tremaining: 7m 37s\n",
            "1317:\tlearn: 0.1987818\ttotal: 2m 43s\tremaining: 7m 36s\n",
            "1318:\tlearn: 0.1987503\ttotal: 2m 43s\tremaining: 7m 36s\n",
            "1319:\tlearn: 0.1987177\ttotal: 2m 43s\tremaining: 7m 36s\n",
            "1320:\tlearn: 0.1986921\ttotal: 2m 43s\tremaining: 7m 36s\n",
            "1321:\tlearn: 0.1986555\ttotal: 2m 44s\tremaining: 7m 36s\n",
            "1322:\tlearn: 0.1986240\ttotal: 2m 44s\tremaining: 7m 36s\n",
            "1323:\tlearn: 0.1985988\ttotal: 2m 44s\tremaining: 7m 36s\n",
            "1324:\tlearn: 0.1985629\ttotal: 2m 44s\tremaining: 7m 35s\n",
            "1325:\tlearn: 0.1985357\ttotal: 2m 44s\tremaining: 7m 35s\n",
            "1326:\tlearn: 0.1985018\ttotal: 2m 44s\tremaining: 7m 35s\n",
            "1327:\tlearn: 0.1984801\ttotal: 2m 44s\tremaining: 7m 35s\n",
            "1328:\tlearn: 0.1984545\ttotal: 2m 44s\tremaining: 7m 35s\n",
            "1329:\tlearn: 0.1984282\ttotal: 2m 45s\tremaining: 7m 35s\n",
            "1330:\tlearn: 0.1983836\ttotal: 2m 45s\tremaining: 7m 35s\n",
            "1331:\tlearn: 0.1983560\ttotal: 2m 45s\tremaining: 7m 35s\n",
            "1332:\tlearn: 0.1983363\ttotal: 2m 45s\tremaining: 7m 34s\n",
            "1333:\tlearn: 0.1983094\ttotal: 2m 45s\tremaining: 7m 34s\n",
            "1334:\tlearn: 0.1982886\ttotal: 2m 45s\tremaining: 7m 34s\n",
            "1335:\tlearn: 0.1982703\ttotal: 2m 45s\tremaining: 7m 34s\n",
            "1336:\tlearn: 0.1982412\ttotal: 2m 45s\tremaining: 7m 34s\n",
            "1337:\tlearn: 0.1982098\ttotal: 2m 45s\tremaining: 7m 34s\n",
            "1338:\tlearn: 0.1981663\ttotal: 2m 46s\tremaining: 7m 34s\n",
            "1339:\tlearn: 0.1981330\ttotal: 2m 46s\tremaining: 7m 34s\n",
            "1340:\tlearn: 0.1980924\ttotal: 2m 46s\tremaining: 7m 33s\n",
            "1341:\tlearn: 0.1980560\ttotal: 2m 46s\tremaining: 7m 33s\n",
            "1342:\tlearn: 0.1980121\ttotal: 2m 46s\tremaining: 7m 33s\n",
            "1343:\tlearn: 0.1979815\ttotal: 2m 46s\tremaining: 7m 33s\n",
            "1344:\tlearn: 0.1979489\ttotal: 2m 46s\tremaining: 7m 33s\n",
            "1345:\tlearn: 0.1979259\ttotal: 2m 46s\tremaining: 7m 33s\n",
            "1346:\tlearn: 0.1978785\ttotal: 2m 47s\tremaining: 7m 33s\n",
            "1347:\tlearn: 0.1978631\ttotal: 2m 47s\tremaining: 7m 33s\n",
            "1348:\tlearn: 0.1978312\ttotal: 2m 47s\tremaining: 7m 33s\n",
            "1349:\tlearn: 0.1977796\ttotal: 2m 47s\tremaining: 7m 32s\n",
            "1350:\tlearn: 0.1977277\ttotal: 2m 47s\tremaining: 7m 32s\n",
            "1351:\tlearn: 0.1977047\ttotal: 2m 47s\tremaining: 7m 32s\n",
            "1352:\tlearn: 0.1976650\ttotal: 2m 47s\tremaining: 7m 32s\n",
            "1353:\tlearn: 0.1976397\ttotal: 2m 48s\tremaining: 7m 32s\n",
            "1354:\tlearn: 0.1975988\ttotal: 2m 48s\tremaining: 7m 32s\n",
            "1355:\tlearn: 0.1975639\ttotal: 2m 48s\tremaining: 7m 32s\n",
            "1356:\tlearn: 0.1975415\ttotal: 2m 48s\tremaining: 7m 32s\n",
            "1357:\tlearn: 0.1975145\ttotal: 2m 48s\tremaining: 7m 32s\n",
            "1358:\tlearn: 0.1974548\ttotal: 2m 48s\tremaining: 7m 31s\n",
            "1359:\tlearn: 0.1974165\ttotal: 2m 48s\tremaining: 7m 31s\n",
            "1360:\tlearn: 0.1973871\ttotal: 2m 49s\tremaining: 7m 31s\n",
            "1361:\tlearn: 0.1973675\ttotal: 2m 49s\tremaining: 7m 31s\n",
            "1362:\tlearn: 0.1973367\ttotal: 2m 49s\tremaining: 7m 31s\n",
            "1363:\tlearn: 0.1973153\ttotal: 2m 49s\tremaining: 7m 31s\n",
            "1364:\tlearn: 0.1972869\ttotal: 2m 49s\tremaining: 7m 31s\n",
            "1365:\tlearn: 0.1972258\ttotal: 2m 49s\tremaining: 7m 31s\n",
            "1366:\tlearn: 0.1971933\ttotal: 2m 49s\tremaining: 7m 31s\n",
            "1367:\tlearn: 0.1971564\ttotal: 2m 49s\tremaining: 7m 31s\n",
            "1368:\tlearn: 0.1971280\ttotal: 2m 49s\tremaining: 7m 30s\n",
            "1369:\tlearn: 0.1970937\ttotal: 2m 50s\tremaining: 7m 30s\n",
            "1370:\tlearn: 0.1970416\ttotal: 2m 50s\tremaining: 7m 30s\n",
            "1371:\tlearn: 0.1970134\ttotal: 2m 50s\tremaining: 7m 30s\n",
            "1372:\tlearn: 0.1969652\ttotal: 2m 50s\tremaining: 7m 30s\n",
            "1373:\tlearn: 0.1969281\ttotal: 2m 50s\tremaining: 7m 30s\n",
            "1374:\tlearn: 0.1968891\ttotal: 2m 50s\tremaining: 7m 30s\n",
            "1375:\tlearn: 0.1968520\ttotal: 2m 50s\tremaining: 7m 29s\n",
            "1376:\tlearn: 0.1968259\ttotal: 2m 50s\tremaining: 7m 29s\n",
            "1377:\tlearn: 0.1968077\ttotal: 2m 51s\tremaining: 7m 29s\n",
            "1378:\tlearn: 0.1967729\ttotal: 2m 51s\tremaining: 7m 29s\n",
            "1379:\tlearn: 0.1967333\ttotal: 2m 51s\tremaining: 7m 29s\n",
            "1380:\tlearn: 0.1967088\ttotal: 2m 51s\tremaining: 7m 29s\n",
            "1381:\tlearn: 0.1966762\ttotal: 2m 51s\tremaining: 7m 29s\n",
            "1382:\tlearn: 0.1966552\ttotal: 2m 51s\tremaining: 7m 28s\n",
            "1383:\tlearn: 0.1966188\ttotal: 2m 51s\tremaining: 7m 28s\n",
            "1384:\tlearn: 0.1965916\ttotal: 2m 51s\tremaining: 7m 28s\n",
            "1385:\tlearn: 0.1965668\ttotal: 2m 52s\tremaining: 7m 28s\n",
            "1386:\tlearn: 0.1965298\ttotal: 2m 52s\tremaining: 7m 28s\n",
            "1387:\tlearn: 0.1965052\ttotal: 2m 52s\tremaining: 7m 28s\n",
            "1388:\tlearn: 0.1964536\ttotal: 2m 52s\tremaining: 7m 28s\n",
            "1389:\tlearn: 0.1963463\ttotal: 2m 52s\tremaining: 7m 28s\n",
            "1390:\tlearn: 0.1963011\ttotal: 2m 52s\tremaining: 7m 28s\n",
            "1391:\tlearn: 0.1962610\ttotal: 2m 52s\tremaining: 7m 28s\n",
            "1392:\tlearn: 0.1962290\ttotal: 2m 53s\tremaining: 7m 27s\n",
            "1393:\tlearn: 0.1961958\ttotal: 2m 53s\tremaining: 7m 27s\n",
            "1394:\tlearn: 0.1961594\ttotal: 2m 53s\tremaining: 7m 27s\n",
            "1395:\tlearn: 0.1961267\ttotal: 2m 53s\tremaining: 7m 27s\n",
            "1396:\tlearn: 0.1960901\ttotal: 2m 53s\tremaining: 7m 27s\n",
            "1397:\tlearn: 0.1960619\ttotal: 2m 53s\tremaining: 7m 27s\n",
            "1398:\tlearn: 0.1960245\ttotal: 2m 53s\tremaining: 7m 27s\n",
            "1399:\tlearn: 0.1960024\ttotal: 2m 53s\tremaining: 7m 26s\n",
            "1400:\tlearn: 0.1959544\ttotal: 2m 53s\tremaining: 7m 26s\n",
            "1401:\tlearn: 0.1959318\ttotal: 2m 54s\tremaining: 7m 26s\n",
            "1402:\tlearn: 0.1959105\ttotal: 2m 54s\tremaining: 7m 26s\n",
            "1403:\tlearn: 0.1958804\ttotal: 2m 54s\tremaining: 7m 26s\n",
            "1404:\tlearn: 0.1958557\ttotal: 2m 54s\tremaining: 7m 26s\n",
            "1405:\tlearn: 0.1958353\ttotal: 2m 54s\tremaining: 7m 26s\n",
            "1406:\tlearn: 0.1958108\ttotal: 2m 54s\tremaining: 7m 25s\n",
            "1407:\tlearn: 0.1957399\ttotal: 2m 54s\tremaining: 7m 25s\n",
            "1408:\tlearn: 0.1957181\ttotal: 2m 54s\tremaining: 7m 25s\n",
            "1409:\tlearn: 0.1956919\ttotal: 2m 54s\tremaining: 7m 25s\n",
            "1410:\tlearn: 0.1956547\ttotal: 2m 55s\tremaining: 7m 25s\n",
            "1411:\tlearn: 0.1956126\ttotal: 2m 55s\tremaining: 7m 25s\n",
            "1412:\tlearn: 0.1955881\ttotal: 2m 55s\tremaining: 7m 25s\n",
            "1413:\tlearn: 0.1955555\ttotal: 2m 55s\tremaining: 7m 25s\n",
            "1414:\tlearn: 0.1955332\ttotal: 2m 55s\tremaining: 7m 24s\n",
            "1415:\tlearn: 0.1954930\ttotal: 2m 55s\tremaining: 7m 24s\n",
            "1416:\tlearn: 0.1954738\ttotal: 2m 55s\tremaining: 7m 24s\n",
            "1417:\tlearn: 0.1954288\ttotal: 2m 56s\tremaining: 7m 24s\n",
            "1418:\tlearn: 0.1953606\ttotal: 2m 56s\tremaining: 7m 24s\n",
            "1419:\tlearn: 0.1953401\ttotal: 2m 56s\tremaining: 7m 24s\n",
            "1420:\tlearn: 0.1953043\ttotal: 2m 56s\tremaining: 7m 24s\n",
            "1421:\tlearn: 0.1952725\ttotal: 2m 56s\tremaining: 7m 24s\n",
            "1422:\tlearn: 0.1952392\ttotal: 2m 56s\tremaining: 7m 23s\n",
            "1423:\tlearn: 0.1951979\ttotal: 2m 56s\tremaining: 7m 23s\n",
            "1424:\tlearn: 0.1951507\ttotal: 2m 56s\tremaining: 7m 23s\n",
            "1425:\tlearn: 0.1951211\ttotal: 2m 56s\tremaining: 7m 23s\n",
            "1426:\tlearn: 0.1951029\ttotal: 2m 57s\tremaining: 7m 23s\n",
            "1427:\tlearn: 0.1950796\ttotal: 2m 57s\tremaining: 7m 23s\n",
            "1428:\tlearn: 0.1950494\ttotal: 2m 57s\tremaining: 7m 23s\n",
            "1429:\tlearn: 0.1950224\ttotal: 2m 57s\tremaining: 7m 22s\n",
            "1430:\tlearn: 0.1949940\ttotal: 2m 57s\tremaining: 7m 22s\n",
            "1431:\tlearn: 0.1949506\ttotal: 2m 57s\tremaining: 7m 22s\n",
            "1432:\tlearn: 0.1949131\ttotal: 2m 57s\tremaining: 7m 22s\n",
            "1433:\tlearn: 0.1948880\ttotal: 2m 57s\tremaining: 7m 22s\n",
            "1434:\tlearn: 0.1948612\ttotal: 2m 58s\tremaining: 7m 22s\n",
            "1435:\tlearn: 0.1948351\ttotal: 2m 58s\tremaining: 7m 22s\n",
            "1436:\tlearn: 0.1947989\ttotal: 2m 58s\tremaining: 7m 22s\n",
            "1437:\tlearn: 0.1947789\ttotal: 2m 58s\tremaining: 7m 21s\n",
            "1438:\tlearn: 0.1947533\ttotal: 2m 58s\tremaining: 7m 21s\n",
            "1439:\tlearn: 0.1947190\ttotal: 2m 58s\tremaining: 7m 21s\n",
            "1440:\tlearn: 0.1947006\ttotal: 2m 58s\tremaining: 7m 21s\n",
            "1441:\tlearn: 0.1946695\ttotal: 2m 58s\tremaining: 7m 21s\n",
            "1442:\tlearn: 0.1946347\ttotal: 2m 58s\tremaining: 7m 21s\n",
            "1443:\tlearn: 0.1946008\ttotal: 2m 59s\tremaining: 7m 21s\n",
            "1444:\tlearn: 0.1945691\ttotal: 2m 59s\tremaining: 7m 21s\n",
            "1445:\tlearn: 0.1945405\ttotal: 2m 59s\tremaining: 7m 20s\n",
            "1446:\tlearn: 0.1945103\ttotal: 2m 59s\tremaining: 7m 20s\n",
            "1447:\tlearn: 0.1944573\ttotal: 2m 59s\tremaining: 7m 20s\n",
            "1448:\tlearn: 0.1944285\ttotal: 2m 59s\tremaining: 7m 20s\n",
            "1449:\tlearn: 0.1943927\ttotal: 2m 59s\tremaining: 7m 20s\n",
            "1450:\tlearn: 0.1943692\ttotal: 3m\tremaining: 7m 20s\n",
            "1451:\tlearn: 0.1943370\ttotal: 3m\tremaining: 7m 20s\n",
            "1452:\tlearn: 0.1943142\ttotal: 3m\tremaining: 7m 20s\n",
            "1453:\tlearn: 0.1942616\ttotal: 3m\tremaining: 7m 19s\n",
            "1454:\tlearn: 0.1942212\ttotal: 3m\tremaining: 7m 19s\n",
            "1455:\tlearn: 0.1941918\ttotal: 3m\tremaining: 7m 19s\n",
            "1456:\tlearn: 0.1941647\ttotal: 3m\tremaining: 7m 19s\n",
            "1457:\tlearn: 0.1941326\ttotal: 3m\tremaining: 7m 19s\n",
            "1458:\tlearn: 0.1940857\ttotal: 3m 1s\tremaining: 7m 19s\n",
            "1459:\tlearn: 0.1940388\ttotal: 3m 1s\tremaining: 7m 19s\n",
            "1460:\tlearn: 0.1940107\ttotal: 3m 1s\tremaining: 7m 19s\n",
            "1461:\tlearn: 0.1939774\ttotal: 3m 1s\tremaining: 7m 19s\n",
            "1462:\tlearn: 0.1939561\ttotal: 3m 1s\tremaining: 7m 18s\n",
            "1463:\tlearn: 0.1939230\ttotal: 3m 1s\tremaining: 7m 18s\n",
            "1464:\tlearn: 0.1938890\ttotal: 3m 1s\tremaining: 7m 18s\n",
            "1465:\tlearn: 0.1938583\ttotal: 3m 1s\tremaining: 7m 18s\n",
            "1466:\tlearn: 0.1938233\ttotal: 3m 2s\tremaining: 7m 18s\n",
            "1467:\tlearn: 0.1937985\ttotal: 3m 2s\tremaining: 7m 18s\n",
            "1468:\tlearn: 0.1937588\ttotal: 3m 2s\tremaining: 7m 18s\n",
            "1469:\tlearn: 0.1937324\ttotal: 3m 2s\tremaining: 7m 18s\n",
            "1470:\tlearn: 0.1936957\ttotal: 3m 2s\tremaining: 7m 18s\n",
            "1471:\tlearn: 0.1936692\ttotal: 3m 2s\tremaining: 7m 17s\n",
            "1472:\tlearn: 0.1936455\ttotal: 3m 2s\tremaining: 7m 17s\n",
            "1473:\tlearn: 0.1936153\ttotal: 3m 2s\tremaining: 7m 17s\n",
            "1474:\tlearn: 0.1935844\ttotal: 3m 3s\tremaining: 7m 17s\n",
            "1475:\tlearn: 0.1935569\ttotal: 3m 3s\tremaining: 7m 17s\n",
            "1476:\tlearn: 0.1935380\ttotal: 3m 3s\tremaining: 7m 17s\n",
            "1477:\tlearn: 0.1935059\ttotal: 3m 3s\tremaining: 7m 17s\n",
            "1478:\tlearn: 0.1934667\ttotal: 3m 3s\tremaining: 7m 17s\n",
            "1479:\tlearn: 0.1934356\ttotal: 3m 3s\tremaining: 7m 16s\n",
            "1480:\tlearn: 0.1934151\ttotal: 3m 3s\tremaining: 7m 16s\n",
            "1481:\tlearn: 0.1933817\ttotal: 3m 3s\tremaining: 7m 16s\n",
            "1482:\tlearn: 0.1933583\ttotal: 3m 4s\tremaining: 7m 16s\n",
            "1483:\tlearn: 0.1933316\ttotal: 3m 4s\tremaining: 7m 16s\n",
            "1484:\tlearn: 0.1933024\ttotal: 3m 4s\tremaining: 7m 16s\n",
            "1485:\tlearn: 0.1932688\ttotal: 3m 4s\tremaining: 7m 16s\n",
            "1486:\tlearn: 0.1932471\ttotal: 3m 4s\tremaining: 7m 15s\n",
            "1487:\tlearn: 0.1932180\ttotal: 3m 4s\tremaining: 7m 15s\n",
            "1488:\tlearn: 0.1931950\ttotal: 3m 4s\tremaining: 7m 15s\n",
            "1489:\tlearn: 0.1931709\ttotal: 3m 4s\tremaining: 7m 15s\n",
            "1490:\tlearn: 0.1931306\ttotal: 3m 4s\tremaining: 7m 15s\n",
            "1491:\tlearn: 0.1930850\ttotal: 3m 5s\tremaining: 7m 15s\n",
            "1492:\tlearn: 0.1930656\ttotal: 3m 5s\tremaining: 7m 15s\n",
            "1493:\tlearn: 0.1930387\ttotal: 3m 5s\tremaining: 7m 14s\n",
            "1494:\tlearn: 0.1929926\ttotal: 3m 5s\tremaining: 7m 14s\n",
            "1495:\tlearn: 0.1929665\ttotal: 3m 5s\tremaining: 7m 14s\n",
            "1496:\tlearn: 0.1929456\ttotal: 3m 5s\tremaining: 7m 14s\n",
            "1497:\tlearn: 0.1929058\ttotal: 3m 5s\tremaining: 7m 14s\n",
            "1498:\tlearn: 0.1928843\ttotal: 3m 5s\tremaining: 7m 14s\n",
            "1499:\tlearn: 0.1928598\ttotal: 3m 6s\tremaining: 7m 14s\n",
            "1500:\tlearn: 0.1928343\ttotal: 3m 6s\tremaining: 7m 13s\n",
            "1501:\tlearn: 0.1927989\ttotal: 3m 6s\tremaining: 7m 13s\n",
            "1502:\tlearn: 0.1927706\ttotal: 3m 6s\tremaining: 7m 13s\n",
            "1503:\tlearn: 0.1927294\ttotal: 3m 6s\tremaining: 7m 13s\n",
            "1504:\tlearn: 0.1927035\ttotal: 3m 6s\tremaining: 7m 13s\n",
            "1505:\tlearn: 0.1926459\ttotal: 3m 6s\tremaining: 7m 13s\n",
            "1506:\tlearn: 0.1926282\ttotal: 3m 6s\tremaining: 7m 13s\n",
            "1507:\tlearn: 0.1926028\ttotal: 3m 6s\tremaining: 7m 12s\n",
            "1508:\tlearn: 0.1925842\ttotal: 3m 7s\tremaining: 7m 12s\n",
            "1509:\tlearn: 0.1925526\ttotal: 3m 7s\tremaining: 7m 12s\n",
            "1510:\tlearn: 0.1925277\ttotal: 3m 7s\tremaining: 7m 12s\n",
            "1511:\tlearn: 0.1924834\ttotal: 3m 7s\tremaining: 7m 12s\n",
            "1512:\tlearn: 0.1924662\ttotal: 3m 7s\tremaining: 7m 12s\n",
            "1513:\tlearn: 0.1924452\ttotal: 3m 7s\tremaining: 7m 12s\n",
            "1514:\tlearn: 0.1924180\ttotal: 3m 7s\tremaining: 7m 11s\n",
            "1515:\tlearn: 0.1924000\ttotal: 3m 7s\tremaining: 7m 11s\n",
            "1516:\tlearn: 0.1923791\ttotal: 3m 8s\tremaining: 7m 11s\n",
            "1517:\tlearn: 0.1923563\ttotal: 3m 8s\tremaining: 7m 11s\n",
            "1518:\tlearn: 0.1923407\ttotal: 3m 8s\tremaining: 7m 11s\n",
            "1519:\tlearn: 0.1923179\ttotal: 3m 8s\tremaining: 7m 11s\n",
            "1520:\tlearn: 0.1922713\ttotal: 3m 8s\tremaining: 7m 11s\n",
            "1521:\tlearn: 0.1922504\ttotal: 3m 8s\tremaining: 7m 11s\n",
            "1522:\tlearn: 0.1922198\ttotal: 3m 8s\tremaining: 7m 11s\n",
            "1523:\tlearn: 0.1921832\ttotal: 3m 8s\tremaining: 7m 10s\n",
            "1524:\tlearn: 0.1921565\ttotal: 3m 9s\tremaining: 7m 10s\n",
            "1525:\tlearn: 0.1921268\ttotal: 3m 9s\tremaining: 7m 10s\n",
            "1526:\tlearn: 0.1920950\ttotal: 3m 9s\tremaining: 7m 10s\n",
            "1527:\tlearn: 0.1920678\ttotal: 3m 9s\tremaining: 7m 10s\n",
            "1528:\tlearn: 0.1920454\ttotal: 3m 9s\tremaining: 7m 10s\n",
            "1529:\tlearn: 0.1920269\ttotal: 3m 9s\tremaining: 7m 10s\n",
            "1530:\tlearn: 0.1919989\ttotal: 3m 9s\tremaining: 7m 9s\n",
            "1531:\tlearn: 0.1919441\ttotal: 3m 9s\tremaining: 7m 9s\n",
            "1532:\tlearn: 0.1919109\ttotal: 3m 9s\tremaining: 7m 9s\n",
            "1533:\tlearn: 0.1918781\ttotal: 3m 10s\tremaining: 7m 9s\n",
            "1534:\tlearn: 0.1918639\ttotal: 3m 10s\tremaining: 7m 9s\n",
            "1535:\tlearn: 0.1918290\ttotal: 3m 10s\tremaining: 7m 9s\n",
            "1536:\tlearn: 0.1918009\ttotal: 3m 10s\tremaining: 7m 9s\n",
            "1537:\tlearn: 0.1917890\ttotal: 3m 10s\tremaining: 7m 8s\n",
            "1538:\tlearn: 0.1917562\ttotal: 3m 10s\tremaining: 7m 8s\n",
            "1539:\tlearn: 0.1917266\ttotal: 3m 10s\tremaining: 7m 8s\n",
            "1540:\tlearn: 0.1917043\ttotal: 3m 10s\tremaining: 7m 8s\n",
            "1541:\tlearn: 0.1916728\ttotal: 3m 11s\tremaining: 7m 8s\n",
            "1542:\tlearn: 0.1916427\ttotal: 3m 11s\tremaining: 7m 8s\n",
            "1543:\tlearn: 0.1916241\ttotal: 3m 11s\tremaining: 7m 8s\n",
            "1544:\tlearn: 0.1916019\ttotal: 3m 11s\tremaining: 7m 7s\n",
            "1545:\tlearn: 0.1915736\ttotal: 3m 11s\tremaining: 7m 7s\n",
            "1546:\tlearn: 0.1915564\ttotal: 3m 11s\tremaining: 7m 7s\n",
            "1547:\tlearn: 0.1915384\ttotal: 3m 11s\tremaining: 7m 7s\n",
            "1548:\tlearn: 0.1915087\ttotal: 3m 11s\tremaining: 7m 7s\n",
            "1549:\tlearn: 0.1914882\ttotal: 3m 11s\tremaining: 7m 7s\n",
            "1550:\tlearn: 0.1914717\ttotal: 3m 12s\tremaining: 7m 7s\n",
            "1551:\tlearn: 0.1914491\ttotal: 3m 12s\tremaining: 7m 6s\n",
            "1552:\tlearn: 0.1914232\ttotal: 3m 12s\tremaining: 7m 6s\n",
            "1553:\tlearn: 0.1913964\ttotal: 3m 12s\tremaining: 7m 6s\n",
            "1554:\tlearn: 0.1913596\ttotal: 3m 12s\tremaining: 7m 6s\n",
            "1555:\tlearn: 0.1913101\ttotal: 3m 12s\tremaining: 7m 6s\n",
            "1556:\tlearn: 0.1912910\ttotal: 3m 12s\tremaining: 7m 6s\n",
            "1557:\tlearn: 0.1912578\ttotal: 3m 12s\tremaining: 7m 6s\n",
            "1558:\tlearn: 0.1912297\ttotal: 3m 12s\tremaining: 7m 5s\n",
            "1559:\tlearn: 0.1912178\ttotal: 3m 13s\tremaining: 7m 5s\n",
            "1560:\tlearn: 0.1911886\ttotal: 3m 13s\tremaining: 7m 5s\n",
            "1561:\tlearn: 0.1911597\ttotal: 3m 13s\tremaining: 7m 5s\n",
            "1562:\tlearn: 0.1911362\ttotal: 3m 13s\tremaining: 7m 5s\n",
            "1563:\tlearn: 0.1911037\ttotal: 3m 13s\tremaining: 7m 5s\n",
            "1564:\tlearn: 0.1910774\ttotal: 3m 13s\tremaining: 7m 5s\n",
            "1565:\tlearn: 0.1910543\ttotal: 3m 13s\tremaining: 7m 5s\n",
            "1566:\tlearn: 0.1910303\ttotal: 3m 13s\tremaining: 7m 4s\n",
            "1567:\tlearn: 0.1909980\ttotal: 3m 14s\tremaining: 7m 4s\n",
            "1568:\tlearn: 0.1909725\ttotal: 3m 14s\tremaining: 7m 4s\n",
            "1569:\tlearn: 0.1909488\ttotal: 3m 14s\tremaining: 7m 4s\n",
            "1570:\tlearn: 0.1909219\ttotal: 3m 14s\tremaining: 7m 4s\n",
            "1571:\tlearn: 0.1908972\ttotal: 3m 14s\tremaining: 7m 4s\n",
            "1572:\tlearn: 0.1908397\ttotal: 3m 14s\tremaining: 7m 4s\n",
            "1573:\tlearn: 0.1908024\ttotal: 3m 14s\tremaining: 7m 3s\n",
            "1574:\tlearn: 0.1907765\ttotal: 3m 14s\tremaining: 7m 3s\n",
            "1575:\tlearn: 0.1907464\ttotal: 3m 14s\tremaining: 7m 3s\n",
            "1576:\tlearn: 0.1907200\ttotal: 3m 15s\tremaining: 7m 3s\n",
            "1577:\tlearn: 0.1907019\ttotal: 3m 15s\tremaining: 7m 3s\n",
            "1578:\tlearn: 0.1906779\ttotal: 3m 15s\tremaining: 7m 3s\n",
            "1579:\tlearn: 0.1906656\ttotal: 3m 15s\tremaining: 7m 2s\n",
            "1580:\tlearn: 0.1906423\ttotal: 3m 15s\tremaining: 7m 2s\n",
            "1581:\tlearn: 0.1906247\ttotal: 3m 15s\tremaining: 7m 2s\n",
            "1582:\tlearn: 0.1905613\ttotal: 3m 15s\tremaining: 7m 2s\n",
            "1583:\tlearn: 0.1905315\ttotal: 3m 15s\tremaining: 7m 2s\n",
            "1584:\tlearn: 0.1905119\ttotal: 3m 15s\tremaining: 7m 2s\n",
            "1585:\tlearn: 0.1904911\ttotal: 3m 16s\tremaining: 7m 2s\n",
            "1586:\tlearn: 0.1904712\ttotal: 3m 16s\tremaining: 7m 2s\n",
            "1587:\tlearn: 0.1904395\ttotal: 3m 16s\tremaining: 7m 1s\n",
            "1588:\tlearn: 0.1904170\ttotal: 3m 16s\tremaining: 7m 1s\n",
            "1589:\tlearn: 0.1903886\ttotal: 3m 16s\tremaining: 7m 1s\n",
            "1590:\tlearn: 0.1903701\ttotal: 3m 16s\tremaining: 7m 1s\n",
            "1591:\tlearn: 0.1903449\ttotal: 3m 16s\tremaining: 7m 1s\n",
            "1592:\tlearn: 0.1903298\ttotal: 3m 17s\tremaining: 7m 1s\n",
            "1593:\tlearn: 0.1902979\ttotal: 3m 17s\tremaining: 7m 1s\n",
            "1594:\tlearn: 0.1902809\ttotal: 3m 17s\tremaining: 7m 1s\n",
            "1595:\tlearn: 0.1902607\ttotal: 3m 17s\tremaining: 7m 1s\n",
            "1596:\tlearn: 0.1902305\ttotal: 3m 17s\tremaining: 7m\n",
            "1597:\tlearn: 0.1902084\ttotal: 3m 17s\tremaining: 7m\n",
            "1598:\tlearn: 0.1901704\ttotal: 3m 17s\tremaining: 7m\n",
            "1599:\tlearn: 0.1901159\ttotal: 3m 17s\tremaining: 7m\n",
            "1600:\tlearn: 0.1900888\ttotal: 3m 18s\tremaining: 7m\n",
            "1601:\tlearn: 0.1900510\ttotal: 3m 18s\tremaining: 7m\n",
            "1602:\tlearn: 0.1900251\ttotal: 3m 18s\tremaining: 7m\n",
            "1603:\tlearn: 0.1899917\ttotal: 3m 18s\tremaining: 7m\n",
            "1604:\tlearn: 0.1899580\ttotal: 3m 18s\tremaining: 7m\n",
            "1605:\tlearn: 0.1899433\ttotal: 3m 18s\tremaining: 6m 59s\n",
            "1606:\tlearn: 0.1898966\ttotal: 3m 18s\tremaining: 6m 59s\n",
            "1607:\tlearn: 0.1898629\ttotal: 3m 18s\tremaining: 6m 59s\n",
            "1608:\tlearn: 0.1898447\ttotal: 3m 19s\tremaining: 6m 59s\n",
            "1609:\tlearn: 0.1898101\ttotal: 3m 19s\tremaining: 6m 59s\n",
            "1610:\tlearn: 0.1897816\ttotal: 3m 19s\tremaining: 6m 59s\n",
            "1611:\tlearn: 0.1897424\ttotal: 3m 19s\tremaining: 6m 59s\n",
            "1612:\tlearn: 0.1897138\ttotal: 3m 19s\tremaining: 6m 58s\n",
            "1613:\tlearn: 0.1896733\ttotal: 3m 19s\tremaining: 6m 58s\n",
            "1614:\tlearn: 0.1896363\ttotal: 3m 19s\tremaining: 6m 58s\n",
            "1615:\tlearn: 0.1896202\ttotal: 3m 19s\tremaining: 6m 58s\n",
            "1616:\tlearn: 0.1895948\ttotal: 3m 20s\tremaining: 6m 58s\n",
            "1617:\tlearn: 0.1895668\ttotal: 3m 20s\tremaining: 6m 58s\n",
            "1618:\tlearn: 0.1895492\ttotal: 3m 20s\tremaining: 6m 58s\n",
            "1619:\tlearn: 0.1895222\ttotal: 3m 20s\tremaining: 6m 58s\n",
            "1620:\tlearn: 0.1894895\ttotal: 3m 20s\tremaining: 6m 58s\n",
            "1621:\tlearn: 0.1894660\ttotal: 3m 20s\tremaining: 6m 57s\n",
            "1622:\tlearn: 0.1894359\ttotal: 3m 20s\tremaining: 6m 57s\n",
            "1623:\tlearn: 0.1894012\ttotal: 3m 20s\tremaining: 6m 57s\n",
            "1624:\tlearn: 0.1893646\ttotal: 3m 21s\tremaining: 6m 57s\n",
            "1625:\tlearn: 0.1893536\ttotal: 3m 21s\tremaining: 6m 57s\n",
            "1626:\tlearn: 0.1893223\ttotal: 3m 21s\tremaining: 6m 57s\n",
            "1627:\tlearn: 0.1893093\ttotal: 3m 21s\tremaining: 6m 57s\n",
            "1628:\tlearn: 0.1892918\ttotal: 3m 21s\tremaining: 6m 56s\n",
            "1629:\tlearn: 0.1892589\ttotal: 3m 21s\tremaining: 6m 56s\n",
            "1630:\tlearn: 0.1892375\ttotal: 3m 21s\tremaining: 6m 56s\n",
            "1631:\tlearn: 0.1892037\ttotal: 3m 21s\tremaining: 6m 56s\n",
            "1632:\tlearn: 0.1891789\ttotal: 3m 21s\tremaining: 6m 56s\n",
            "1633:\tlearn: 0.1891536\ttotal: 3m 22s\tremaining: 6m 56s\n",
            "1634:\tlearn: 0.1891304\ttotal: 3m 22s\tremaining: 6m 56s\n",
            "1635:\tlearn: 0.1890957\ttotal: 3m 22s\tremaining: 6m 55s\n",
            "1636:\tlearn: 0.1890582\ttotal: 3m 22s\tremaining: 6m 55s\n",
            "1637:\tlearn: 0.1890318\ttotal: 3m 22s\tremaining: 6m 55s\n",
            "1638:\tlearn: 0.1890030\ttotal: 3m 22s\tremaining: 6m 55s\n",
            "1639:\tlearn: 0.1889867\ttotal: 3m 22s\tremaining: 6m 55s\n",
            "1640:\tlearn: 0.1889626\ttotal: 3m 22s\tremaining: 6m 55s\n",
            "1641:\tlearn: 0.1889504\ttotal: 3m 23s\tremaining: 6m 55s\n",
            "1642:\tlearn: 0.1889326\ttotal: 3m 23s\tremaining: 6m 55s\n",
            "1643:\tlearn: 0.1888977\ttotal: 3m 23s\tremaining: 6m 55s\n",
            "1644:\tlearn: 0.1888670\ttotal: 3m 23s\tremaining: 6m 54s\n",
            "1645:\tlearn: 0.1888412\ttotal: 3m 23s\tremaining: 6m 54s\n",
            "1646:\tlearn: 0.1888273\ttotal: 3m 23s\tremaining: 6m 54s\n",
            "1647:\tlearn: 0.1887835\ttotal: 3m 23s\tremaining: 6m 54s\n",
            "1648:\tlearn: 0.1887496\ttotal: 3m 23s\tremaining: 6m 54s\n",
            "1649:\tlearn: 0.1886808\ttotal: 3m 24s\tremaining: 6m 54s\n",
            "1650:\tlearn: 0.1886673\ttotal: 3m 24s\tremaining: 6m 54s\n",
            "1651:\tlearn: 0.1886080\ttotal: 3m 24s\tremaining: 6m 54s\n",
            "1652:\tlearn: 0.1885815\ttotal: 3m 24s\tremaining: 6m 53s\n",
            "1653:\tlearn: 0.1885576\ttotal: 3m 24s\tremaining: 6m 53s\n",
            "1654:\tlearn: 0.1885464\ttotal: 3m 24s\tremaining: 6m 53s\n",
            "1655:\tlearn: 0.1885188\ttotal: 3m 24s\tremaining: 6m 53s\n",
            "1656:\tlearn: 0.1884884\ttotal: 3m 24s\tremaining: 6m 53s\n",
            "1657:\tlearn: 0.1884559\ttotal: 3m 25s\tremaining: 6m 53s\n",
            "1658:\tlearn: 0.1884150\ttotal: 3m 25s\tremaining: 6m 53s\n",
            "1659:\tlearn: 0.1883943\ttotal: 3m 25s\tremaining: 6m 53s\n",
            "1660:\tlearn: 0.1883688\ttotal: 3m 25s\tremaining: 6m 53s\n",
            "1661:\tlearn: 0.1883360\ttotal: 3m 25s\tremaining: 6m 52s\n",
            "1662:\tlearn: 0.1882898\ttotal: 3m 25s\tremaining: 6m 52s\n",
            "1663:\tlearn: 0.1882488\ttotal: 3m 25s\tremaining: 6m 52s\n",
            "1664:\tlearn: 0.1882115\ttotal: 3m 25s\tremaining: 6m 52s\n",
            "1665:\tlearn: 0.1881667\ttotal: 3m 26s\tremaining: 6m 52s\n",
            "1666:\tlearn: 0.1881458\ttotal: 3m 26s\tremaining: 6m 52s\n",
            "1667:\tlearn: 0.1881212\ttotal: 3m 26s\tremaining: 6m 52s\n",
            "1668:\tlearn: 0.1880959\ttotal: 3m 26s\tremaining: 6m 52s\n",
            "1669:\tlearn: 0.1880499\ttotal: 3m 26s\tremaining: 6m 51s\n",
            "1670:\tlearn: 0.1880241\ttotal: 3m 26s\tremaining: 6m 51s\n",
            "1671:\tlearn: 0.1879963\ttotal: 3m 26s\tremaining: 6m 51s\n",
            "1672:\tlearn: 0.1879721\ttotal: 3m 26s\tremaining: 6m 51s\n",
            "1673:\tlearn: 0.1879441\ttotal: 3m 27s\tremaining: 6m 51s\n",
            "1674:\tlearn: 0.1879156\ttotal: 3m 27s\tremaining: 6m 51s\n",
            "1675:\tlearn: 0.1878904\ttotal: 3m 27s\tremaining: 6m 51s\n",
            "1676:\tlearn: 0.1878703\ttotal: 3m 27s\tremaining: 6m 51s\n",
            "1677:\tlearn: 0.1878295\ttotal: 3m 27s\tremaining: 6m 51s\n",
            "1678:\tlearn: 0.1877906\ttotal: 3m 27s\tremaining: 6m 50s\n",
            "1679:\tlearn: 0.1877689\ttotal: 3m 27s\tremaining: 6m 50s\n",
            "1680:\tlearn: 0.1877393\ttotal: 3m 27s\tremaining: 6m 50s\n",
            "1681:\tlearn: 0.1877270\ttotal: 3m 28s\tremaining: 6m 50s\n",
            "1682:\tlearn: 0.1876971\ttotal: 3m 28s\tremaining: 6m 50s\n",
            "1683:\tlearn: 0.1876779\ttotal: 3m 28s\tremaining: 6m 50s\n",
            "1684:\tlearn: 0.1876621\ttotal: 3m 28s\tremaining: 6m 50s\n",
            "1685:\tlearn: 0.1876464\ttotal: 3m 28s\tremaining: 6m 49s\n",
            "1686:\tlearn: 0.1876297\ttotal: 3m 28s\tremaining: 6m 49s\n",
            "1687:\tlearn: 0.1876135\ttotal: 3m 28s\tremaining: 6m 49s\n",
            "1688:\tlearn: 0.1875952\ttotal: 3m 28s\tremaining: 6m 49s\n",
            "1689:\tlearn: 0.1875747\ttotal: 3m 28s\tremaining: 6m 49s\n",
            "1690:\tlearn: 0.1875543\ttotal: 3m 29s\tremaining: 6m 49s\n",
            "1691:\tlearn: 0.1875020\ttotal: 3m 29s\tremaining: 6m 48s\n",
            "1692:\tlearn: 0.1874770\ttotal: 3m 29s\tremaining: 6m 48s\n",
            "1693:\tlearn: 0.1874490\ttotal: 3m 29s\tremaining: 6m 48s\n",
            "1694:\tlearn: 0.1874356\ttotal: 3m 29s\tremaining: 6m 48s\n",
            "1695:\tlearn: 0.1874077\ttotal: 3m 29s\tremaining: 6m 48s\n",
            "1696:\tlearn: 0.1873779\ttotal: 3m 29s\tremaining: 6m 48s\n",
            "1697:\tlearn: 0.1873578\ttotal: 3m 29s\tremaining: 6m 48s\n",
            "1698:\tlearn: 0.1873251\ttotal: 3m 30s\tremaining: 6m 48s\n",
            "1699:\tlearn: 0.1872922\ttotal: 3m 30s\tremaining: 6m 48s\n",
            "1700:\tlearn: 0.1872720\ttotal: 3m 30s\tremaining: 6m 47s\n",
            "1701:\tlearn: 0.1872390\ttotal: 3m 30s\tremaining: 6m 47s\n",
            "1702:\tlearn: 0.1872238\ttotal: 3m 30s\tremaining: 6m 47s\n",
            "1703:\tlearn: 0.1871958\ttotal: 3m 30s\tremaining: 6m 47s\n",
            "1704:\tlearn: 0.1871656\ttotal: 3m 30s\tremaining: 6m 47s\n",
            "1705:\tlearn: 0.1871388\ttotal: 3m 30s\tremaining: 6m 47s\n",
            "1706:\tlearn: 0.1871065\ttotal: 3m 31s\tremaining: 6m 47s\n",
            "1707:\tlearn: 0.1870860\ttotal: 3m 31s\tremaining: 6m 47s\n",
            "1708:\tlearn: 0.1870634\ttotal: 3m 31s\tremaining: 6m 46s\n",
            "1709:\tlearn: 0.1870364\ttotal: 3m 31s\tremaining: 6m 46s\n",
            "1710:\tlearn: 0.1870180\ttotal: 3m 31s\tremaining: 6m 46s\n",
            "1711:\tlearn: 0.1869929\ttotal: 3m 31s\tremaining: 6m 46s\n",
            "1712:\tlearn: 0.1869483\ttotal: 3m 31s\tremaining: 6m 46s\n",
            "1713:\tlearn: 0.1869361\ttotal: 3m 31s\tremaining: 6m 46s\n",
            "1714:\tlearn: 0.1869046\ttotal: 3m 32s\tremaining: 6m 46s\n",
            "1715:\tlearn: 0.1868729\ttotal: 3m 32s\tremaining: 6m 46s\n",
            "1716:\tlearn: 0.1868488\ttotal: 3m 32s\tremaining: 6m 45s\n",
            "1717:\tlearn: 0.1868239\ttotal: 3m 32s\tremaining: 6m 45s\n",
            "1718:\tlearn: 0.1868030\ttotal: 3m 32s\tremaining: 6m 45s\n",
            "1719:\tlearn: 0.1867790\ttotal: 3m 32s\tremaining: 6m 45s\n",
            "1720:\tlearn: 0.1867470\ttotal: 3m 32s\tremaining: 6m 45s\n",
            "1721:\tlearn: 0.1867190\ttotal: 3m 32s\tremaining: 6m 45s\n",
            "1722:\tlearn: 0.1866962\ttotal: 3m 32s\tremaining: 6m 45s\n",
            "1723:\tlearn: 0.1866782\ttotal: 3m 33s\tremaining: 6m 44s\n",
            "1724:\tlearn: 0.1866516\ttotal: 3m 33s\tremaining: 6m 44s\n",
            "1725:\tlearn: 0.1866225\ttotal: 3m 33s\tremaining: 6m 44s\n",
            "1726:\tlearn: 0.1865971\ttotal: 3m 33s\tremaining: 6m 44s\n",
            "1727:\tlearn: 0.1865848\ttotal: 3m 33s\tremaining: 6m 44s\n",
            "1728:\tlearn: 0.1865641\ttotal: 3m 33s\tremaining: 6m 44s\n",
            "1729:\tlearn: 0.1865535\ttotal: 3m 33s\tremaining: 6m 44s\n",
            "1730:\tlearn: 0.1865233\ttotal: 3m 33s\tremaining: 6m 44s\n",
            "1731:\tlearn: 0.1865023\ttotal: 3m 34s\tremaining: 6m 43s\n",
            "1732:\tlearn: 0.1864826\ttotal: 3m 34s\tremaining: 6m 43s\n",
            "1733:\tlearn: 0.1864471\ttotal: 3m 34s\tremaining: 6m 43s\n",
            "1734:\tlearn: 0.1864232\ttotal: 3m 34s\tremaining: 6m 43s\n",
            "1735:\tlearn: 0.1864086\ttotal: 3m 34s\tremaining: 6m 43s\n",
            "1736:\tlearn: 0.1863838\ttotal: 3m 34s\tremaining: 6m 43s\n",
            "1737:\tlearn: 0.1863648\ttotal: 3m 34s\tremaining: 6m 43s\n",
            "1738:\tlearn: 0.1863304\ttotal: 3m 34s\tremaining: 6m 43s\n",
            "1739:\tlearn: 0.1863080\ttotal: 3m 35s\tremaining: 6m 42s\n",
            "1740:\tlearn: 0.1862897\ttotal: 3m 35s\tremaining: 6m 42s\n",
            "1741:\tlearn: 0.1862770\ttotal: 3m 35s\tremaining: 6m 42s\n",
            "1742:\tlearn: 0.1862514\ttotal: 3m 35s\tremaining: 6m 42s\n",
            "1743:\tlearn: 0.1862272\ttotal: 3m 35s\tremaining: 6m 42s\n",
            "1744:\tlearn: 0.1862106\ttotal: 3m 35s\tremaining: 6m 42s\n",
            "1745:\tlearn: 0.1861774\ttotal: 3m 35s\tremaining: 6m 42s\n",
            "1746:\tlearn: 0.1861488\ttotal: 3m 35s\tremaining: 6m 42s\n",
            "1747:\tlearn: 0.1861186\ttotal: 3m 36s\tremaining: 6m 41s\n",
            "1748:\tlearn: 0.1860987\ttotal: 3m 36s\tremaining: 6m 41s\n",
            "1749:\tlearn: 0.1860695\ttotal: 3m 36s\tremaining: 6m 41s\n",
            "1750:\tlearn: 0.1860603\ttotal: 3m 36s\tremaining: 6m 41s\n",
            "1751:\tlearn: 0.1860506\ttotal: 3m 36s\tremaining: 6m 41s\n",
            "1752:\tlearn: 0.1860323\ttotal: 3m 36s\tremaining: 6m 41s\n",
            "1753:\tlearn: 0.1860106\ttotal: 3m 36s\tremaining: 6m 41s\n",
            "1754:\tlearn: 0.1859854\ttotal: 3m 36s\tremaining: 6m 40s\n",
            "1755:\tlearn: 0.1859746\ttotal: 3m 36s\tremaining: 6m 40s\n",
            "1756:\tlearn: 0.1859419\ttotal: 3m 37s\tremaining: 6m 40s\n",
            "1757:\tlearn: 0.1859212\ttotal: 3m 37s\tremaining: 6m 40s\n",
            "1758:\tlearn: 0.1859057\ttotal: 3m 37s\tremaining: 6m 40s\n",
            "1759:\tlearn: 0.1858795\ttotal: 3m 37s\tremaining: 6m 40s\n",
            "1760:\tlearn: 0.1858642\ttotal: 3m 37s\tremaining: 6m 40s\n",
            "1761:\tlearn: 0.1858300\ttotal: 3m 37s\tremaining: 6m 40s\n",
            "1762:\tlearn: 0.1858105\ttotal: 3m 37s\tremaining: 6m 39s\n",
            "1763:\tlearn: 0.1857881\ttotal: 3m 37s\tremaining: 6m 39s\n",
            "1764:\tlearn: 0.1857660\ttotal: 3m 38s\tremaining: 6m 39s\n",
            "1765:\tlearn: 0.1857412\ttotal: 3m 38s\tremaining: 6m 39s\n",
            "1766:\tlearn: 0.1857184\ttotal: 3m 38s\tremaining: 6m 39s\n",
            "1767:\tlearn: 0.1857005\ttotal: 3m 38s\tremaining: 6m 39s\n",
            "1768:\tlearn: 0.1856754\ttotal: 3m 38s\tremaining: 6m 39s\n",
            "1769:\tlearn: 0.1856535\ttotal: 3m 38s\tremaining: 6m 39s\n",
            "1770:\tlearn: 0.1856330\ttotal: 3m 38s\tremaining: 6m 38s\n",
            "1771:\tlearn: 0.1856097\ttotal: 3m 38s\tremaining: 6m 38s\n",
            "1772:\tlearn: 0.1855770\ttotal: 3m 39s\tremaining: 6m 38s\n",
            "1773:\tlearn: 0.1855516\ttotal: 3m 39s\tremaining: 6m 38s\n",
            "1774:\tlearn: 0.1855198\ttotal: 3m 39s\tremaining: 6m 38s\n",
            "1775:\tlearn: 0.1854969\ttotal: 3m 39s\tremaining: 6m 38s\n",
            "1776:\tlearn: 0.1854695\ttotal: 3m 39s\tremaining: 6m 38s\n",
            "1777:\tlearn: 0.1854558\ttotal: 3m 39s\tremaining: 6m 37s\n",
            "1778:\tlearn: 0.1854112\ttotal: 3m 39s\tremaining: 6m 37s\n",
            "1779:\tlearn: 0.1854000\ttotal: 3m 39s\tremaining: 6m 37s\n",
            "1780:\tlearn: 0.1853679\ttotal: 3m 39s\tremaining: 6m 37s\n",
            "1781:\tlearn: 0.1853488\ttotal: 3m 40s\tremaining: 6m 37s\n",
            "1782:\tlearn: 0.1853187\ttotal: 3m 40s\tremaining: 6m 37s\n",
            "1783:\tlearn: 0.1852961\ttotal: 3m 40s\tremaining: 6m 37s\n",
            "1784:\tlearn: 0.1852644\ttotal: 3m 40s\tremaining: 6m 37s\n",
            "1785:\tlearn: 0.1852484\ttotal: 3m 40s\tremaining: 6m 37s\n",
            "1786:\tlearn: 0.1852248\ttotal: 3m 40s\tremaining: 6m 36s\n",
            "1787:\tlearn: 0.1852109\ttotal: 3m 40s\tremaining: 6m 36s\n",
            "1788:\tlearn: 0.1851959\ttotal: 3m 40s\tremaining: 6m 36s\n",
            "1789:\tlearn: 0.1851675\ttotal: 3m 41s\tremaining: 6m 36s\n",
            "1790:\tlearn: 0.1851482\ttotal: 3m 41s\tremaining: 6m 36s\n",
            "1791:\tlearn: 0.1851183\ttotal: 3m 41s\tremaining: 6m 36s\n",
            "1792:\tlearn: 0.1850998\ttotal: 3m 41s\tremaining: 6m 36s\n",
            "1793:\tlearn: 0.1850630\ttotal: 3m 41s\tremaining: 6m 36s\n",
            "1794:\tlearn: 0.1850401\ttotal: 3m 41s\tremaining: 6m 35s\n",
            "1795:\tlearn: 0.1850246\ttotal: 3m 41s\tremaining: 6m 35s\n",
            "1796:\tlearn: 0.1850098\ttotal: 3m 41s\tremaining: 6m 35s\n",
            "1797:\tlearn: 0.1849673\ttotal: 3m 42s\tremaining: 6m 35s\n",
            "1798:\tlearn: 0.1849381\ttotal: 3m 42s\tremaining: 6m 35s\n",
            "1799:\tlearn: 0.1849272\ttotal: 3m 42s\tremaining: 6m 35s\n",
            "1800:\tlearn: 0.1848922\ttotal: 3m 42s\tremaining: 6m 35s\n",
            "1801:\tlearn: 0.1848725\ttotal: 3m 42s\tremaining: 6m 34s\n",
            "1802:\tlearn: 0.1848526\ttotal: 3m 42s\tremaining: 6m 34s\n",
            "1803:\tlearn: 0.1848347\ttotal: 3m 42s\tremaining: 6m 34s\n",
            "1804:\tlearn: 0.1848079\ttotal: 3m 42s\tremaining: 6m 34s\n",
            "1805:\tlearn: 0.1847901\ttotal: 3m 43s\tremaining: 6m 34s\n",
            "1806:\tlearn: 0.1847618\ttotal: 3m 43s\tremaining: 6m 34s\n",
            "1807:\tlearn: 0.1847396\ttotal: 3m 43s\tremaining: 6m 34s\n",
            "1808:\tlearn: 0.1847153\ttotal: 3m 43s\tremaining: 6m 34s\n",
            "1809:\tlearn: 0.1846853\ttotal: 3m 43s\tremaining: 6m 34s\n",
            "1810:\tlearn: 0.1846662\ttotal: 3m 43s\tremaining: 6m 33s\n",
            "1811:\tlearn: 0.1846402\ttotal: 3m 43s\tremaining: 6m 33s\n",
            "1812:\tlearn: 0.1846201\ttotal: 3m 43s\tremaining: 6m 33s\n",
            "1813:\tlearn: 0.1845942\ttotal: 3m 44s\tremaining: 6m 33s\n",
            "1814:\tlearn: 0.1845736\ttotal: 3m 44s\tremaining: 6m 33s\n",
            "1815:\tlearn: 0.1845588\ttotal: 3m 44s\tremaining: 6m 33s\n",
            "1816:\tlearn: 0.1845256\ttotal: 3m 44s\tremaining: 6m 33s\n",
            "1817:\tlearn: 0.1845045\ttotal: 3m 44s\tremaining: 6m 33s\n",
            "1818:\tlearn: 0.1844772\ttotal: 3m 44s\tremaining: 6m 33s\n",
            "1819:\tlearn: 0.1844550\ttotal: 3m 44s\tremaining: 6m 32s\n",
            "1820:\tlearn: 0.1844078\ttotal: 3m 44s\tremaining: 6m 32s\n",
            "1821:\tlearn: 0.1843671\ttotal: 3m 45s\tremaining: 6m 32s\n",
            "1822:\tlearn: 0.1843425\ttotal: 3m 45s\tremaining: 6m 32s\n",
            "1823:\tlearn: 0.1843277\ttotal: 3m 45s\tremaining: 6m 32s\n",
            "1824:\tlearn: 0.1842972\ttotal: 3m 45s\tremaining: 6m 32s\n",
            "1825:\tlearn: 0.1842883\ttotal: 3m 45s\tremaining: 6m 32s\n",
            "1826:\tlearn: 0.1842667\ttotal: 3m 45s\tremaining: 6m 31s\n",
            "1827:\tlearn: 0.1842255\ttotal: 3m 45s\tremaining: 6m 31s\n",
            "1828:\tlearn: 0.1842008\ttotal: 3m 45s\tremaining: 6m 31s\n",
            "1829:\tlearn: 0.1841801\ttotal: 3m 46s\tremaining: 6m 31s\n",
            "1830:\tlearn: 0.1841593\ttotal: 3m 46s\tremaining: 6m 31s\n",
            "1831:\tlearn: 0.1841462\ttotal: 3m 46s\tremaining: 6m 31s\n",
            "1832:\tlearn: 0.1841263\ttotal: 3m 46s\tremaining: 6m 31s\n",
            "1833:\tlearn: 0.1840977\ttotal: 3m 46s\tremaining: 6m 31s\n",
            "1834:\tlearn: 0.1840798\ttotal: 3m 46s\tremaining: 6m 31s\n",
            "1835:\tlearn: 0.1840553\ttotal: 3m 46s\tremaining: 6m 30s\n",
            "1836:\tlearn: 0.1840317\ttotal: 3m 46s\tremaining: 6m 30s\n",
            "1837:\tlearn: 0.1840149\ttotal: 3m 47s\tremaining: 6m 30s\n",
            "1838:\tlearn: 0.1839934\ttotal: 3m 47s\tremaining: 6m 30s\n",
            "1839:\tlearn: 0.1839703\ttotal: 3m 47s\tremaining: 6m 30s\n",
            "1840:\tlearn: 0.1839462\ttotal: 3m 47s\tremaining: 6m 30s\n",
            "1841:\tlearn: 0.1839255\ttotal: 3m 47s\tremaining: 6m 30s\n",
            "1842:\tlearn: 0.1839076\ttotal: 3m 47s\tremaining: 6m 30s\n",
            "1843:\tlearn: 0.1838868\ttotal: 3m 47s\tremaining: 6m 29s\n",
            "1844:\tlearn: 0.1838595\ttotal: 3m 47s\tremaining: 6m 29s\n",
            "1845:\tlearn: 0.1838184\ttotal: 3m 48s\tremaining: 6m 29s\n",
            "1846:\tlearn: 0.1837961\ttotal: 3m 48s\tremaining: 6m 29s\n",
            "1847:\tlearn: 0.1837701\ttotal: 3m 48s\tremaining: 6m 29s\n",
            "1848:\tlearn: 0.1837506\ttotal: 3m 48s\tremaining: 6m 29s\n",
            "1849:\tlearn: 0.1837245\ttotal: 3m 48s\tremaining: 6m 29s\n",
            "1850:\tlearn: 0.1837014\ttotal: 3m 48s\tremaining: 6m 29s\n",
            "1851:\tlearn: 0.1836596\ttotal: 3m 48s\tremaining: 6m 29s\n",
            "1852:\tlearn: 0.1836384\ttotal: 3m 48s\tremaining: 6m 28s\n",
            "1853:\tlearn: 0.1836187\ttotal: 3m 49s\tremaining: 6m 28s\n",
            "1854:\tlearn: 0.1836026\ttotal: 3m 49s\tremaining: 6m 28s\n",
            "1855:\tlearn: 0.1835837\ttotal: 3m 49s\tremaining: 6m 28s\n",
            "1856:\tlearn: 0.1835617\ttotal: 3m 49s\tremaining: 6m 28s\n",
            "1857:\tlearn: 0.1835297\ttotal: 3m 49s\tremaining: 6m 28s\n",
            "1858:\tlearn: 0.1835064\ttotal: 3m 49s\tremaining: 6m 28s\n",
            "1859:\tlearn: 0.1834880\ttotal: 3m 49s\tremaining: 6m 27s\n",
            "1860:\tlearn: 0.1834682\ttotal: 3m 49s\tremaining: 6m 27s\n",
            "1861:\tlearn: 0.1834410\ttotal: 3m 49s\tremaining: 6m 27s\n",
            "1862:\tlearn: 0.1834089\ttotal: 3m 50s\tremaining: 6m 27s\n",
            "1863:\tlearn: 0.1833878\ttotal: 3m 50s\tremaining: 6m 27s\n",
            "1864:\tlearn: 0.1833640\ttotal: 3m 50s\tremaining: 6m 27s\n",
            "1865:\tlearn: 0.1833233\ttotal: 3m 50s\tremaining: 6m 27s\n",
            "1866:\tlearn: 0.1833054\ttotal: 3m 50s\tremaining: 6m 26s\n",
            "1867:\tlearn: 0.1832830\ttotal: 3m 50s\tremaining: 6m 26s\n",
            "1868:\tlearn: 0.1832692\ttotal: 3m 50s\tremaining: 6m 26s\n",
            "1869:\tlearn: 0.1832431\ttotal: 3m 50s\tremaining: 6m 26s\n",
            "1870:\tlearn: 0.1832255\ttotal: 3m 51s\tremaining: 6m 26s\n",
            "1871:\tlearn: 0.1832097\ttotal: 3m 51s\tremaining: 6m 26s\n",
            "1872:\tlearn: 0.1831926\ttotal: 3m 51s\tremaining: 6m 26s\n",
            "1873:\tlearn: 0.1831663\ttotal: 3m 51s\tremaining: 6m 26s\n",
            "1874:\tlearn: 0.1831300\ttotal: 3m 51s\tremaining: 6m 25s\n",
            "1875:\tlearn: 0.1831095\ttotal: 3m 51s\tremaining: 6m 25s\n",
            "1876:\tlearn: 0.1830785\ttotal: 3m 51s\tremaining: 6m 25s\n",
            "1877:\tlearn: 0.1830582\ttotal: 3m 51s\tremaining: 6m 25s\n",
            "1878:\tlearn: 0.1830153\ttotal: 3m 52s\tremaining: 6m 25s\n",
            "1879:\tlearn: 0.1829843\ttotal: 3m 52s\tremaining: 6m 25s\n",
            "1880:\tlearn: 0.1829672\ttotal: 3m 52s\tremaining: 6m 25s\n",
            "1881:\tlearn: 0.1829460\ttotal: 3m 52s\tremaining: 6m 25s\n",
            "1882:\tlearn: 0.1829236\ttotal: 3m 52s\tremaining: 6m 25s\n",
            "1883:\tlearn: 0.1828875\ttotal: 3m 52s\tremaining: 6m 24s\n",
            "1884:\tlearn: 0.1828704\ttotal: 3m 52s\tremaining: 6m 24s\n",
            "1885:\tlearn: 0.1828496\ttotal: 3m 52s\tremaining: 6m 24s\n",
            "1886:\tlearn: 0.1828294\ttotal: 3m 53s\tremaining: 6m 24s\n",
            "1887:\tlearn: 0.1828136\ttotal: 3m 53s\tremaining: 6m 24s\n",
            "1888:\tlearn: 0.1828019\ttotal: 3m 53s\tremaining: 6m 24s\n",
            "1889:\tlearn: 0.1827838\ttotal: 3m 53s\tremaining: 6m 23s\n",
            "1890:\tlearn: 0.1827448\ttotal: 3m 53s\tremaining: 6m 23s\n",
            "1891:\tlearn: 0.1827172\ttotal: 3m 53s\tremaining: 6m 23s\n",
            "1892:\tlearn: 0.1827015\ttotal: 3m 53s\tremaining: 6m 23s\n",
            "1893:\tlearn: 0.1826777\ttotal: 3m 53s\tremaining: 6m 23s\n",
            "1894:\tlearn: 0.1826568\ttotal: 3m 53s\tremaining: 6m 23s\n",
            "1895:\tlearn: 0.1826321\ttotal: 3m 54s\tremaining: 6m 23s\n",
            "1896:\tlearn: 0.1826076\ttotal: 3m 54s\tremaining: 6m 23s\n",
            "1897:\tlearn: 0.1825871\ttotal: 3m 54s\tremaining: 6m 22s\n",
            "1898:\tlearn: 0.1825539\ttotal: 3m 54s\tremaining: 6m 22s\n",
            "1899:\tlearn: 0.1825375\ttotal: 3m 54s\tremaining: 6m 22s\n",
            "1900:\tlearn: 0.1825127\ttotal: 3m 54s\tremaining: 6m 22s\n",
            "1901:\tlearn: 0.1824965\ttotal: 3m 54s\tremaining: 6m 22s\n",
            "1902:\tlearn: 0.1824611\ttotal: 3m 54s\tremaining: 6m 22s\n",
            "1903:\tlearn: 0.1824371\ttotal: 3m 55s\tremaining: 6m 22s\n",
            "1904:\tlearn: 0.1824250\ttotal: 3m 55s\tremaining: 6m 22s\n",
            "1905:\tlearn: 0.1823978\ttotal: 3m 55s\tremaining: 6m 21s\n",
            "1906:\tlearn: 0.1823720\ttotal: 3m 55s\tremaining: 6m 21s\n",
            "1907:\tlearn: 0.1823481\ttotal: 3m 55s\tremaining: 6m 21s\n",
            "1908:\tlearn: 0.1823370\ttotal: 3m 55s\tremaining: 6m 21s\n",
            "1909:\tlearn: 0.1823273\ttotal: 3m 55s\tremaining: 6m 21s\n",
            "1910:\tlearn: 0.1823015\ttotal: 3m 55s\tremaining: 6m 21s\n",
            "1911:\tlearn: 0.1822725\ttotal: 3m 55s\tremaining: 6m 21s\n",
            "1912:\tlearn: 0.1822587\ttotal: 3m 56s\tremaining: 6m 20s\n",
            "1913:\tlearn: 0.1822288\ttotal: 3m 56s\tremaining: 6m 20s\n",
            "1914:\tlearn: 0.1822035\ttotal: 3m 56s\tremaining: 6m 20s\n",
            "1915:\tlearn: 0.1821913\ttotal: 3m 56s\tremaining: 6m 20s\n",
            "1916:\tlearn: 0.1821751\ttotal: 3m 56s\tremaining: 6m 20s\n",
            "1917:\tlearn: 0.1821659\ttotal: 3m 56s\tremaining: 6m 20s\n",
            "1918:\tlearn: 0.1821426\ttotal: 3m 56s\tremaining: 6m 20s\n",
            "1919:\tlearn: 0.1821269\ttotal: 3m 56s\tremaining: 6m 20s\n",
            "1920:\tlearn: 0.1820904\ttotal: 3m 57s\tremaining: 6m 19s\n",
            "1921:\tlearn: 0.1820519\ttotal: 3m 57s\tremaining: 6m 19s\n",
            "1922:\tlearn: 0.1820369\ttotal: 3m 57s\tremaining: 6m 19s\n",
            "1923:\tlearn: 0.1820064\ttotal: 3m 57s\tremaining: 6m 19s\n",
            "1924:\tlearn: 0.1819790\ttotal: 3m 57s\tremaining: 6m 19s\n",
            "1925:\tlearn: 0.1819561\ttotal: 3m 57s\tremaining: 6m 19s\n",
            "1926:\tlearn: 0.1819318\ttotal: 3m 57s\tremaining: 6m 19s\n",
            "1927:\tlearn: 0.1819154\ttotal: 3m 57s\tremaining: 6m 18s\n",
            "1928:\tlearn: 0.1819047\ttotal: 3m 57s\tremaining: 6m 18s\n",
            "1929:\tlearn: 0.1818925\ttotal: 3m 58s\tremaining: 6m 18s\n",
            "1930:\tlearn: 0.1818753\ttotal: 3m 58s\tremaining: 6m 18s\n",
            "1931:\tlearn: 0.1818569\ttotal: 3m 58s\tremaining: 6m 18s\n",
            "1932:\tlearn: 0.1818300\ttotal: 3m 58s\tremaining: 6m 18s\n",
            "1933:\tlearn: 0.1817982\ttotal: 3m 58s\tremaining: 6m 18s\n",
            "1934:\tlearn: 0.1817586\ttotal: 3m 58s\tremaining: 6m 18s\n",
            "1935:\tlearn: 0.1817448\ttotal: 3m 58s\tremaining: 6m 17s\n",
            "1936:\tlearn: 0.1817274\ttotal: 3m 58s\tremaining: 6m 17s\n",
            "1937:\tlearn: 0.1816917\ttotal: 3m 59s\tremaining: 6m 17s\n",
            "1938:\tlearn: 0.1816711\ttotal: 3m 59s\tremaining: 6m 17s\n",
            "1939:\tlearn: 0.1816539\ttotal: 3m 59s\tremaining: 6m 17s\n",
            "1940:\tlearn: 0.1816243\ttotal: 3m 59s\tremaining: 6m 17s\n",
            "1941:\tlearn: 0.1815915\ttotal: 3m 59s\tremaining: 6m 17s\n",
            "1942:\tlearn: 0.1815768\ttotal: 3m 59s\tremaining: 6m 17s\n",
            "1943:\tlearn: 0.1815563\ttotal: 3m 59s\tremaining: 6m 16s\n",
            "1944:\tlearn: 0.1815428\ttotal: 3m 59s\tremaining: 6m 16s\n",
            "1945:\tlearn: 0.1815288\ttotal: 3m 59s\tremaining: 6m 16s\n",
            "1946:\tlearn: 0.1815074\ttotal: 4m\tremaining: 6m 16s\n",
            "1947:\tlearn: 0.1814955\ttotal: 4m\tremaining: 6m 16s\n",
            "1948:\tlearn: 0.1814612\ttotal: 4m\tremaining: 6m 16s\n",
            "1949:\tlearn: 0.1814427\ttotal: 4m\tremaining: 6m 16s\n",
            "1950:\tlearn: 0.1814266\ttotal: 4m\tremaining: 6m 15s\n",
            "1951:\tlearn: 0.1814030\ttotal: 4m\tremaining: 6m 15s\n",
            "1952:\tlearn: 0.1813754\ttotal: 4m\tremaining: 6m 15s\n",
            "1953:\tlearn: 0.1813583\ttotal: 4m\tremaining: 6m 15s\n",
            "1954:\tlearn: 0.1813445\ttotal: 4m 1s\tremaining: 6m 15s\n",
            "1955:\tlearn: 0.1813261\ttotal: 4m 1s\tremaining: 6m 15s\n",
            "1956:\tlearn: 0.1813023\ttotal: 4m 1s\tremaining: 6m 15s\n",
            "1957:\tlearn: 0.1812841\ttotal: 4m 1s\tremaining: 6m 15s\n",
            "1958:\tlearn: 0.1812482\ttotal: 4m 1s\tremaining: 6m 14s\n",
            "1959:\tlearn: 0.1812147\ttotal: 4m 1s\tremaining: 6m 14s\n",
            "1960:\tlearn: 0.1811925\ttotal: 4m 1s\tremaining: 6m 14s\n",
            "1961:\tlearn: 0.1811616\ttotal: 4m 1s\tremaining: 6m 14s\n",
            "1962:\tlearn: 0.1811410\ttotal: 4m 2s\tremaining: 6m 14s\n",
            "1963:\tlearn: 0.1811210\ttotal: 4m 2s\tremaining: 6m 14s\n",
            "1964:\tlearn: 0.1811000\ttotal: 4m 2s\tremaining: 6m 14s\n",
            "1965:\tlearn: 0.1810646\ttotal: 4m 2s\tremaining: 6m 14s\n",
            "1966:\tlearn: 0.1810474\ttotal: 4m 2s\tremaining: 6m 14s\n",
            "1967:\tlearn: 0.1810286\ttotal: 4m 2s\tremaining: 6m 13s\n",
            "1968:\tlearn: 0.1810128\ttotal: 4m 2s\tremaining: 6m 13s\n",
            "1969:\tlearn: 0.1809821\ttotal: 4m 2s\tremaining: 6m 13s\n",
            "1970:\tlearn: 0.1809490\ttotal: 4m 3s\tremaining: 6m 13s\n",
            "1971:\tlearn: 0.1809337\ttotal: 4m 3s\tremaining: 6m 13s\n",
            "1972:\tlearn: 0.1809092\ttotal: 4m 3s\tremaining: 6m 13s\n",
            "1973:\tlearn: 0.1808943\ttotal: 4m 3s\tremaining: 6m 13s\n",
            "1974:\tlearn: 0.1808811\ttotal: 4m 3s\tremaining: 6m 13s\n",
            "1975:\tlearn: 0.1808663\ttotal: 4m 3s\tremaining: 6m 12s\n",
            "1976:\tlearn: 0.1808542\ttotal: 4m 3s\tremaining: 6m 12s\n",
            "1977:\tlearn: 0.1808385\ttotal: 4m 3s\tremaining: 6m 12s\n",
            "1978:\tlearn: 0.1808139\ttotal: 4m 4s\tremaining: 6m 12s\n",
            "1979:\tlearn: 0.1807778\ttotal: 4m 4s\tremaining: 6m 12s\n",
            "1980:\tlearn: 0.1807612\ttotal: 4m 4s\tremaining: 6m 12s\n",
            "1981:\tlearn: 0.1807416\ttotal: 4m 4s\tremaining: 6m 12s\n",
            "1982:\tlearn: 0.1807159\ttotal: 4m 4s\tremaining: 6m 12s\n",
            "1983:\tlearn: 0.1806966\ttotal: 4m 4s\tremaining: 6m 11s\n",
            "1984:\tlearn: 0.1806674\ttotal: 4m 4s\tremaining: 6m 11s\n",
            "1985:\tlearn: 0.1806499\ttotal: 4m 4s\tremaining: 6m 11s\n",
            "1986:\tlearn: 0.1806266\ttotal: 4m 5s\tremaining: 6m 11s\n",
            "1987:\tlearn: 0.1805863\ttotal: 4m 5s\tremaining: 6m 11s\n",
            "1988:\tlearn: 0.1805678\ttotal: 4m 5s\tremaining: 6m 11s\n",
            "1989:\tlearn: 0.1805560\ttotal: 4m 5s\tremaining: 6m 11s\n",
            "1990:\tlearn: 0.1805305\ttotal: 4m 5s\tremaining: 6m 11s\n",
            "1991:\tlearn: 0.1805060\ttotal: 4m 5s\tremaining: 6m 11s\n",
            "1992:\tlearn: 0.1804889\ttotal: 4m 5s\tremaining: 6m 10s\n",
            "1993:\tlearn: 0.1804620\ttotal: 4m 5s\tremaining: 6m 10s\n",
            "1994:\tlearn: 0.1804245\ttotal: 4m 6s\tremaining: 6m 10s\n",
            "1995:\tlearn: 0.1804039\ttotal: 4m 6s\tremaining: 6m 10s\n",
            "1996:\tlearn: 0.1803857\ttotal: 4m 6s\tremaining: 6m 10s\n",
            "1997:\tlearn: 0.1803707\ttotal: 4m 6s\tremaining: 6m 10s\n",
            "1998:\tlearn: 0.1803505\ttotal: 4m 6s\tremaining: 6m 10s\n",
            "1999:\tlearn: 0.1803280\ttotal: 4m 6s\tremaining: 6m 10s\n",
            "2000:\tlearn: 0.1803146\ttotal: 4m 6s\tremaining: 6m 9s\n",
            "2001:\tlearn: 0.1803065\ttotal: 4m 6s\tremaining: 6m 9s\n",
            "2002:\tlearn: 0.1802867\ttotal: 4m 7s\tremaining: 6m 9s\n",
            "2003:\tlearn: 0.1802664\ttotal: 4m 7s\tremaining: 6m 9s\n",
            "2004:\tlearn: 0.1802553\ttotal: 4m 7s\tremaining: 6m 9s\n",
            "2005:\tlearn: 0.1802416\ttotal: 4m 7s\tremaining: 6m 9s\n",
            "2006:\tlearn: 0.1802214\ttotal: 4m 7s\tremaining: 6m 9s\n",
            "2007:\tlearn: 0.1802107\ttotal: 4m 7s\tremaining: 6m 9s\n",
            "2008:\tlearn: 0.1801931\ttotal: 4m 7s\tremaining: 6m 8s\n",
            "2009:\tlearn: 0.1801679\ttotal: 4m 7s\tremaining: 6m 8s\n",
            "2010:\tlearn: 0.1801295\ttotal: 4m 8s\tremaining: 6m 8s\n",
            "2011:\tlearn: 0.1801057\ttotal: 4m 8s\tremaining: 6m 8s\n",
            "2012:\tlearn: 0.1800939\ttotal: 4m 8s\tremaining: 6m 8s\n",
            "2013:\tlearn: 0.1800844\ttotal: 4m 8s\tremaining: 6m 8s\n",
            "2014:\tlearn: 0.1800628\ttotal: 4m 8s\tremaining: 6m 8s\n",
            "2015:\tlearn: 0.1800510\ttotal: 4m 8s\tremaining: 6m 7s\n",
            "2016:\tlearn: 0.1800301\ttotal: 4m 8s\tremaining: 6m 7s\n",
            "2017:\tlearn: 0.1800172\ttotal: 4m 8s\tremaining: 6m 7s\n",
            "2018:\tlearn: 0.1799989\ttotal: 4m 8s\tremaining: 6m 7s\n",
            "2019:\tlearn: 0.1799839\ttotal: 4m 9s\tremaining: 6m 7s\n",
            "2020:\tlearn: 0.1799617\ttotal: 4m 9s\tremaining: 6m 7s\n",
            "2021:\tlearn: 0.1799393\ttotal: 4m 9s\tremaining: 6m 7s\n",
            "2022:\tlearn: 0.1799201\ttotal: 4m 9s\tremaining: 6m 7s\n",
            "2023:\tlearn: 0.1799011\ttotal: 4m 9s\tremaining: 6m 6s\n",
            "2024:\tlearn: 0.1798866\ttotal: 4m 9s\tremaining: 6m 6s\n",
            "2025:\tlearn: 0.1798695\ttotal: 4m 9s\tremaining: 6m 6s\n",
            "2026:\tlearn: 0.1798452\ttotal: 4m 9s\tremaining: 6m 6s\n",
            "2027:\tlearn: 0.1798148\ttotal: 4m 10s\tremaining: 6m 6s\n",
            "2028:\tlearn: 0.1797956\ttotal: 4m 10s\tremaining: 6m 6s\n",
            "2029:\tlearn: 0.1797756\ttotal: 4m 10s\tremaining: 6m 6s\n",
            "2030:\tlearn: 0.1797557\ttotal: 4m 10s\tremaining: 6m 6s\n",
            "2031:\tlearn: 0.1797374\ttotal: 4m 10s\tremaining: 6m 5s\n",
            "2032:\tlearn: 0.1797138\ttotal: 4m 10s\tremaining: 6m 5s\n",
            "2033:\tlearn: 0.1796866\ttotal: 4m 10s\tremaining: 6m 5s\n",
            "2034:\tlearn: 0.1796709\ttotal: 4m 10s\tremaining: 6m 5s\n",
            "2035:\tlearn: 0.1796601\ttotal: 4m 10s\tremaining: 6m 5s\n",
            "2036:\tlearn: 0.1796359\ttotal: 4m 11s\tremaining: 6m 5s\n",
            "2037:\tlearn: 0.1796133\ttotal: 4m 11s\tremaining: 6m 5s\n",
            "2038:\tlearn: 0.1795761\ttotal: 4m 11s\tremaining: 6m 4s\n",
            "2039:\tlearn: 0.1795589\ttotal: 4m 11s\tremaining: 6m 4s\n",
            "2040:\tlearn: 0.1795328\ttotal: 4m 11s\tremaining: 6m 4s\n",
            "2041:\tlearn: 0.1795072\ttotal: 4m 11s\tremaining: 6m 4s\n",
            "2042:\tlearn: 0.1794887\ttotal: 4m 11s\tremaining: 6m 4s\n",
            "2043:\tlearn: 0.1794150\ttotal: 4m 11s\tremaining: 6m 4s\n",
            "2044:\tlearn: 0.1793971\ttotal: 4m 12s\tremaining: 6m 4s\n",
            "2045:\tlearn: 0.1793710\ttotal: 4m 12s\tremaining: 6m 4s\n",
            "2046:\tlearn: 0.1793541\ttotal: 4m 12s\tremaining: 6m 3s\n",
            "2047:\tlearn: 0.1793340\ttotal: 4m 12s\tremaining: 6m 3s\n",
            "2048:\tlearn: 0.1793142\ttotal: 4m 12s\tremaining: 6m 3s\n",
            "2049:\tlearn: 0.1792817\ttotal: 4m 12s\tremaining: 6m 3s\n",
            "2050:\tlearn: 0.1792685\ttotal: 4m 12s\tremaining: 6m 3s\n",
            "2051:\tlearn: 0.1792579\ttotal: 4m 12s\tremaining: 6m 3s\n",
            "2052:\tlearn: 0.1792325\ttotal: 4m 13s\tremaining: 6m 3s\n",
            "2053:\tlearn: 0.1792149\ttotal: 4m 13s\tremaining: 6m 3s\n",
            "2054:\tlearn: 0.1792041\ttotal: 4m 13s\tremaining: 6m 2s\n",
            "2055:\tlearn: 0.1791914\ttotal: 4m 13s\tremaining: 6m 2s\n",
            "2056:\tlearn: 0.1791692\ttotal: 4m 13s\tremaining: 6m 2s\n",
            "2057:\tlearn: 0.1791575\ttotal: 4m 13s\tremaining: 6m 2s\n",
            "2058:\tlearn: 0.1791302\ttotal: 4m 13s\tremaining: 6m 2s\n",
            "2059:\tlearn: 0.1791134\ttotal: 4m 13s\tremaining: 6m 2s\n",
            "2060:\tlearn: 0.1790876\ttotal: 4m 13s\tremaining: 6m 2s\n",
            "2061:\tlearn: 0.1790693\ttotal: 4m 13s\tremaining: 6m 1s\n",
            "2062:\tlearn: 0.1790498\ttotal: 4m 14s\tremaining: 6m 1s\n",
            "2063:\tlearn: 0.1790396\ttotal: 4m 14s\tremaining: 6m 1s\n",
            "2064:\tlearn: 0.1790131\ttotal: 4m 14s\tremaining: 6m 1s\n",
            "2065:\tlearn: 0.1789874\ttotal: 4m 14s\tremaining: 6m 1s\n",
            "2066:\tlearn: 0.1789593\ttotal: 4m 14s\tremaining: 6m 1s\n",
            "2067:\tlearn: 0.1789406\ttotal: 4m 14s\tremaining: 6m 1s\n",
            "2068:\tlearn: 0.1789185\ttotal: 4m 14s\tremaining: 6m 1s\n",
            "2069:\tlearn: 0.1789044\ttotal: 4m 15s\tremaining: 6m\n",
            "2070:\tlearn: 0.1788785\ttotal: 4m 15s\tremaining: 6m\n",
            "2071:\tlearn: 0.1788410\ttotal: 4m 15s\tremaining: 6m\n",
            "2072:\tlearn: 0.1788157\ttotal: 4m 15s\tremaining: 6m\n",
            "2073:\tlearn: 0.1787992\ttotal: 4m 15s\tremaining: 6m\n",
            "2074:\tlearn: 0.1787812\ttotal: 4m 15s\tremaining: 6m\n",
            "2075:\tlearn: 0.1787390\ttotal: 4m 15s\tremaining: 6m\n",
            "2076:\tlearn: 0.1787254\ttotal: 4m 15s\tremaining: 6m\n",
            "2077:\tlearn: 0.1787041\ttotal: 4m 16s\tremaining: 5m 59s\n",
            "2078:\tlearn: 0.1786924\ttotal: 4m 16s\tremaining: 5m 59s\n",
            "2079:\tlearn: 0.1786785\ttotal: 4m 16s\tremaining: 5m 59s\n",
            "2080:\tlearn: 0.1786582\ttotal: 4m 16s\tremaining: 5m 59s\n",
            "2081:\tlearn: 0.1786341\ttotal: 4m 16s\tremaining: 5m 59s\n",
            "2082:\tlearn: 0.1786201\ttotal: 4m 16s\tremaining: 5m 59s\n",
            "2083:\tlearn: 0.1785974\ttotal: 4m 16s\tremaining: 5m 59s\n",
            "2084:\tlearn: 0.1785715\ttotal: 4m 16s\tremaining: 5m 59s\n",
            "2085:\tlearn: 0.1785249\ttotal: 4m 17s\tremaining: 5m 59s\n",
            "2086:\tlearn: 0.1785073\ttotal: 4m 17s\tremaining: 5m 58s\n",
            "2087:\tlearn: 0.1784704\ttotal: 4m 17s\tremaining: 5m 58s\n",
            "2088:\tlearn: 0.1784519\ttotal: 4m 17s\tremaining: 5m 58s\n",
            "2089:\tlearn: 0.1784237\ttotal: 4m 17s\tremaining: 5m 58s\n",
            "2090:\tlearn: 0.1784014\ttotal: 4m 17s\tremaining: 5m 58s\n",
            "2091:\tlearn: 0.1783764\ttotal: 4m 17s\tremaining: 5m 58s\n",
            "2092:\tlearn: 0.1783609\ttotal: 4m 17s\tremaining: 5m 58s\n",
            "2093:\tlearn: 0.1783399\ttotal: 4m 17s\tremaining: 5m 58s\n",
            "2094:\tlearn: 0.1783271\ttotal: 4m 18s\tremaining: 5m 57s\n",
            "2095:\tlearn: 0.1782996\ttotal: 4m 18s\tremaining: 5m 57s\n",
            "2096:\tlearn: 0.1782876\ttotal: 4m 18s\tremaining: 5m 57s\n",
            "2097:\tlearn: 0.1782731\ttotal: 4m 18s\tremaining: 5m 57s\n",
            "2098:\tlearn: 0.1782565\ttotal: 4m 18s\tremaining: 5m 57s\n",
            "2099:\tlearn: 0.1782405\ttotal: 4m 18s\tremaining: 5m 57s\n",
            "2100:\tlearn: 0.1782177\ttotal: 4m 18s\tremaining: 5m 57s\n",
            "2101:\tlearn: 0.1781988\ttotal: 4m 18s\tremaining: 5m 56s\n",
            "2102:\tlearn: 0.1781818\ttotal: 4m 19s\tremaining: 5m 56s\n",
            "2103:\tlearn: 0.1781632\ttotal: 4m 19s\tremaining: 5m 56s\n",
            "2104:\tlearn: 0.1781543\ttotal: 4m 19s\tremaining: 5m 56s\n",
            "2105:\tlearn: 0.1781382\ttotal: 4m 19s\tremaining: 5m 56s\n",
            "2106:\tlearn: 0.1781262\ttotal: 4m 19s\tremaining: 5m 56s\n",
            "2107:\tlearn: 0.1781084\ttotal: 4m 19s\tremaining: 5m 56s\n",
            "2108:\tlearn: 0.1780886\ttotal: 4m 19s\tremaining: 5m 55s\n",
            "2109:\tlearn: 0.1780743\ttotal: 4m 19s\tremaining: 5m 55s\n",
            "2110:\tlearn: 0.1780470\ttotal: 4m 19s\tremaining: 5m 55s\n",
            "2111:\tlearn: 0.1780285\ttotal: 4m 20s\tremaining: 5m 55s\n",
            "2112:\tlearn: 0.1780119\ttotal: 4m 20s\tremaining: 5m 55s\n",
            "2113:\tlearn: 0.1779981\ttotal: 4m 20s\tremaining: 5m 55s\n",
            "2114:\tlearn: 0.1779754\ttotal: 4m 20s\tremaining: 5m 55s\n",
            "2115:\tlearn: 0.1779654\ttotal: 4m 20s\tremaining: 5m 55s\n",
            "2116:\tlearn: 0.1779480\ttotal: 4m 20s\tremaining: 5m 54s\n",
            "2117:\tlearn: 0.1779235\ttotal: 4m 20s\tremaining: 5m 54s\n",
            "2118:\tlearn: 0.1779004\ttotal: 4m 20s\tremaining: 5m 54s\n",
            "2119:\tlearn: 0.1778756\ttotal: 4m 21s\tremaining: 5m 54s\n",
            "2120:\tlearn: 0.1778541\ttotal: 4m 21s\tremaining: 5m 54s\n",
            "2121:\tlearn: 0.1778316\ttotal: 4m 21s\tremaining: 5m 54s\n",
            "2122:\tlearn: 0.1778178\ttotal: 4m 21s\tremaining: 5m 54s\n",
            "2123:\tlearn: 0.1778018\ttotal: 4m 21s\tremaining: 5m 54s\n",
            "2124:\tlearn: 0.1777863\ttotal: 4m 21s\tremaining: 5m 54s\n",
            "2125:\tlearn: 0.1777719\ttotal: 4m 21s\tremaining: 5m 53s\n",
            "2126:\tlearn: 0.1777503\ttotal: 4m 21s\tremaining: 5m 53s\n",
            "2127:\tlearn: 0.1777255\ttotal: 4m 22s\tremaining: 5m 53s\n",
            "2128:\tlearn: 0.1776991\ttotal: 4m 22s\tremaining: 5m 53s\n",
            "2129:\tlearn: 0.1776890\ttotal: 4m 22s\tremaining: 5m 53s\n",
            "2130:\tlearn: 0.1776785\ttotal: 4m 22s\tremaining: 5m 53s\n",
            "2131:\tlearn: 0.1776628\ttotal: 4m 22s\tremaining: 5m 53s\n",
            "2132:\tlearn: 0.1776534\ttotal: 4m 22s\tremaining: 5m 52s\n",
            "2133:\tlearn: 0.1776377\ttotal: 4m 22s\tremaining: 5m 52s\n",
            "2134:\tlearn: 0.1776108\ttotal: 4m 22s\tremaining: 5m 52s\n",
            "2135:\tlearn: 0.1776025\ttotal: 4m 22s\tremaining: 5m 52s\n",
            "2136:\tlearn: 0.1775618\ttotal: 4m 23s\tremaining: 5m 52s\n",
            "2137:\tlearn: 0.1775282\ttotal: 4m 23s\tremaining: 5m 52s\n",
            "2138:\tlearn: 0.1775125\ttotal: 4m 23s\tremaining: 5m 52s\n",
            "2139:\tlearn: 0.1775021\ttotal: 4m 23s\tremaining: 5m 52s\n",
            "2140:\tlearn: 0.1774872\ttotal: 4m 23s\tremaining: 5m 51s\n",
            "2141:\tlearn: 0.1774671\ttotal: 4m 23s\tremaining: 5m 51s\n",
            "2142:\tlearn: 0.1774572\ttotal: 4m 23s\tremaining: 5m 51s\n",
            "2143:\tlearn: 0.1774388\ttotal: 4m 23s\tremaining: 5m 51s\n",
            "2144:\tlearn: 0.1774225\ttotal: 4m 23s\tremaining: 5m 51s\n",
            "2145:\tlearn: 0.1774072\ttotal: 4m 24s\tremaining: 5m 51s\n",
            "2146:\tlearn: 0.1773814\ttotal: 4m 24s\tremaining: 5m 51s\n",
            "2147:\tlearn: 0.1773632\ttotal: 4m 24s\tremaining: 5m 50s\n",
            "2148:\tlearn: 0.1773423\ttotal: 4m 24s\tremaining: 5m 50s\n",
            "2149:\tlearn: 0.1773096\ttotal: 4m 24s\tremaining: 5m 50s\n",
            "2150:\tlearn: 0.1772912\ttotal: 4m 24s\tremaining: 5m 50s\n",
            "2151:\tlearn: 0.1772734\ttotal: 4m 24s\tremaining: 5m 50s\n",
            "2152:\tlearn: 0.1772434\ttotal: 4m 24s\tremaining: 5m 50s\n",
            "2153:\tlearn: 0.1772216\ttotal: 4m 25s\tremaining: 5m 50s\n",
            "2154:\tlearn: 0.1772038\ttotal: 4m 25s\tremaining: 5m 50s\n",
            "2155:\tlearn: 0.1771764\ttotal: 4m 25s\tremaining: 5m 49s\n",
            "2156:\tlearn: 0.1771559\ttotal: 4m 25s\tremaining: 5m 49s\n",
            "2157:\tlearn: 0.1771399\ttotal: 4m 25s\tremaining: 5m 49s\n",
            "2158:\tlearn: 0.1771205\ttotal: 4m 25s\tremaining: 5m 49s\n",
            "2159:\tlearn: 0.1770843\ttotal: 4m 25s\tremaining: 5m 49s\n",
            "2160:\tlearn: 0.1770674\ttotal: 4m 25s\tremaining: 5m 49s\n",
            "2161:\tlearn: 0.1770458\ttotal: 4m 26s\tremaining: 5m 49s\n",
            "2162:\tlearn: 0.1770361\ttotal: 4m 26s\tremaining: 5m 49s\n",
            "2163:\tlearn: 0.1770211\ttotal: 4m 26s\tremaining: 5m 48s\n",
            "2164:\tlearn: 0.1770104\ttotal: 4m 26s\tremaining: 5m 48s\n",
            "2165:\tlearn: 0.1769923\ttotal: 4m 26s\tremaining: 5m 48s\n",
            "2166:\tlearn: 0.1769681\ttotal: 4m 26s\tremaining: 5m 48s\n",
            "2167:\tlearn: 0.1769518\ttotal: 4m 26s\tremaining: 5m 48s\n",
            "2168:\tlearn: 0.1769309\ttotal: 4m 26s\tremaining: 5m 48s\n",
            "2169:\tlearn: 0.1769125\ttotal: 4m 27s\tremaining: 5m 48s\n",
            "2170:\tlearn: 0.1769000\ttotal: 4m 27s\tremaining: 5m 48s\n",
            "2171:\tlearn: 0.1768761\ttotal: 4m 27s\tremaining: 5m 47s\n",
            "2172:\tlearn: 0.1768533\ttotal: 4m 27s\tremaining: 5m 47s\n",
            "2173:\tlearn: 0.1768400\ttotal: 4m 27s\tremaining: 5m 47s\n",
            "2174:\tlearn: 0.1767915\ttotal: 4m 27s\tremaining: 5m 47s\n",
            "2175:\tlearn: 0.1767612\ttotal: 4m 27s\tremaining: 5m 47s\n",
            "2176:\tlearn: 0.1767499\ttotal: 4m 27s\tremaining: 5m 47s\n",
            "2177:\tlearn: 0.1767207\ttotal: 4m 27s\tremaining: 5m 47s\n",
            "2178:\tlearn: 0.1766936\ttotal: 4m 28s\tremaining: 5m 47s\n",
            "2179:\tlearn: 0.1766766\ttotal: 4m 28s\tremaining: 5m 46s\n",
            "2180:\tlearn: 0.1766565\ttotal: 4m 28s\tremaining: 5m 46s\n",
            "2181:\tlearn: 0.1766436\ttotal: 4m 28s\tremaining: 5m 46s\n",
            "2182:\tlearn: 0.1766269\ttotal: 4m 28s\tremaining: 5m 46s\n",
            "2183:\tlearn: 0.1766034\ttotal: 4m 28s\tremaining: 5m 46s\n",
            "2184:\tlearn: 0.1765899\ttotal: 4m 28s\tremaining: 5m 46s\n",
            "2185:\tlearn: 0.1765718\ttotal: 4m 28s\tremaining: 5m 46s\n",
            "2186:\tlearn: 0.1765389\ttotal: 4m 28s\tremaining: 5m 45s\n",
            "2187:\tlearn: 0.1765188\ttotal: 4m 29s\tremaining: 5m 45s\n",
            "2188:\tlearn: 0.1765033\ttotal: 4m 29s\tremaining: 5m 45s\n",
            "2189:\tlearn: 0.1764798\ttotal: 4m 29s\tremaining: 5m 45s\n",
            "2190:\tlearn: 0.1764502\ttotal: 4m 29s\tremaining: 5m 45s\n",
            "2191:\tlearn: 0.1764327\ttotal: 4m 29s\tremaining: 5m 45s\n",
            "2192:\tlearn: 0.1764198\ttotal: 4m 29s\tremaining: 5m 45s\n",
            "2193:\tlearn: 0.1763764\ttotal: 4m 29s\tremaining: 5m 45s\n",
            "2194:\tlearn: 0.1763646\ttotal: 4m 30s\tremaining: 5m 45s\n",
            "2195:\tlearn: 0.1763490\ttotal: 4m 30s\tremaining: 5m 44s\n",
            "2196:\tlearn: 0.1763330\ttotal: 4m 30s\tremaining: 5m 44s\n",
            "2197:\tlearn: 0.1763156\ttotal: 4m 30s\tremaining: 5m 44s\n",
            "2198:\tlearn: 0.1763011\ttotal: 4m 30s\tremaining: 5m 44s\n",
            "2199:\tlearn: 0.1762845\ttotal: 4m 30s\tremaining: 5m 44s\n",
            "2200:\tlearn: 0.1762679\ttotal: 4m 30s\tremaining: 5m 44s\n",
            "2201:\tlearn: 0.1762441\ttotal: 4m 30s\tremaining: 5m 44s\n",
            "2202:\tlearn: 0.1762306\ttotal: 4m 30s\tremaining: 5m 43s\n",
            "2203:\tlearn: 0.1762089\ttotal: 4m 31s\tremaining: 5m 43s\n",
            "2204:\tlearn: 0.1761855\ttotal: 4m 31s\tremaining: 5m 43s\n",
            "2205:\tlearn: 0.1761526\ttotal: 4m 31s\tremaining: 5m 43s\n",
            "2206:\tlearn: 0.1761324\ttotal: 4m 31s\tremaining: 5m 43s\n",
            "2207:\tlearn: 0.1761050\ttotal: 4m 31s\tremaining: 5m 43s\n",
            "2208:\tlearn: 0.1760898\ttotal: 4m 31s\tremaining: 5m 43s\n",
            "2209:\tlearn: 0.1760565\ttotal: 4m 31s\tremaining: 5m 43s\n",
            "2210:\tlearn: 0.1760314\ttotal: 4m 31s\tremaining: 5m 43s\n",
            "2211:\tlearn: 0.1760163\ttotal: 4m 32s\tremaining: 5m 42s\n",
            "2212:\tlearn: 0.1759991\ttotal: 4m 32s\tremaining: 5m 42s\n",
            "2213:\tlearn: 0.1759672\ttotal: 4m 32s\tremaining: 5m 42s\n",
            "2214:\tlearn: 0.1759465\ttotal: 4m 32s\tremaining: 5m 42s\n",
            "2215:\tlearn: 0.1759358\ttotal: 4m 32s\tremaining: 5m 42s\n",
            "2216:\tlearn: 0.1759095\ttotal: 4m 32s\tremaining: 5m 42s\n",
            "2217:\tlearn: 0.1758933\ttotal: 4m 32s\tremaining: 5m 42s\n",
            "2218:\tlearn: 0.1758827\ttotal: 4m 32s\tremaining: 5m 42s\n",
            "2219:\tlearn: 0.1758713\ttotal: 4m 33s\tremaining: 5m 41s\n",
            "2220:\tlearn: 0.1758515\ttotal: 4m 33s\tremaining: 5m 41s\n",
            "2221:\tlearn: 0.1758349\ttotal: 4m 33s\tremaining: 5m 41s\n",
            "2222:\tlearn: 0.1758243\ttotal: 4m 33s\tremaining: 5m 41s\n",
            "2223:\tlearn: 0.1758140\ttotal: 4m 33s\tremaining: 5m 41s\n",
            "2224:\tlearn: 0.1757994\ttotal: 4m 33s\tremaining: 5m 41s\n",
            "2225:\tlearn: 0.1757763\ttotal: 4m 33s\tremaining: 5m 41s\n",
            "2226:\tlearn: 0.1757582\ttotal: 4m 33s\tremaining: 5m 40s\n",
            "2227:\tlearn: 0.1757507\ttotal: 4m 33s\tremaining: 5m 40s\n",
            "2228:\tlearn: 0.1757240\ttotal: 4m 34s\tremaining: 5m 40s\n",
            "2229:\tlearn: 0.1757104\ttotal: 4m 34s\tremaining: 5m 40s\n",
            "2230:\tlearn: 0.1756961\ttotal: 4m 34s\tremaining: 5m 40s\n",
            "2231:\tlearn: 0.1756623\ttotal: 4m 34s\tremaining: 5m 40s\n",
            "2232:\tlearn: 0.1756459\ttotal: 4m 34s\tremaining: 5m 40s\n",
            "2233:\tlearn: 0.1756286\ttotal: 4m 34s\tremaining: 5m 40s\n",
            "2234:\tlearn: 0.1755853\ttotal: 4m 34s\tremaining: 5m 39s\n",
            "2235:\tlearn: 0.1755745\ttotal: 4m 34s\tremaining: 5m 39s\n",
            "2236:\tlearn: 0.1755584\ttotal: 4m 34s\tremaining: 5m 39s\n",
            "2237:\tlearn: 0.1755307\ttotal: 4m 35s\tremaining: 5m 39s\n",
            "2238:\tlearn: 0.1755056\ttotal: 4m 35s\tremaining: 5m 39s\n",
            "2239:\tlearn: 0.1754790\ttotal: 4m 35s\tremaining: 5m 39s\n",
            "2240:\tlearn: 0.1754588\ttotal: 4m 35s\tremaining: 5m 39s\n",
            "2241:\tlearn: 0.1754086\ttotal: 4m 35s\tremaining: 5m 39s\n",
            "2242:\tlearn: 0.1753937\ttotal: 4m 35s\tremaining: 5m 38s\n",
            "2243:\tlearn: 0.1753594\ttotal: 4m 35s\tremaining: 5m 38s\n",
            "2244:\tlearn: 0.1753389\ttotal: 4m 35s\tremaining: 5m 38s\n",
            "2245:\tlearn: 0.1753210\ttotal: 4m 36s\tremaining: 5m 38s\n",
            "2246:\tlearn: 0.1753123\ttotal: 4m 36s\tremaining: 5m 38s\n",
            "2247:\tlearn: 0.1752976\ttotal: 4m 36s\tremaining: 5m 38s\n",
            "2248:\tlearn: 0.1752817\ttotal: 4m 36s\tremaining: 5m 38s\n",
            "2249:\tlearn: 0.1752665\ttotal: 4m 36s\tremaining: 5m 37s\n",
            "2250:\tlearn: 0.1752550\ttotal: 4m 36s\tremaining: 5m 37s\n",
            "2251:\tlearn: 0.1752367\ttotal: 4m 36s\tremaining: 5m 37s\n",
            "2252:\tlearn: 0.1752134\ttotal: 4m 36s\tremaining: 5m 37s\n",
            "2253:\tlearn: 0.1751935\ttotal: 4m 36s\tremaining: 5m 37s\n",
            "2254:\tlearn: 0.1751717\ttotal: 4m 37s\tremaining: 5m 37s\n",
            "2255:\tlearn: 0.1751580\ttotal: 4m 37s\tremaining: 5m 37s\n",
            "2256:\tlearn: 0.1751419\ttotal: 4m 37s\tremaining: 5m 37s\n",
            "2257:\tlearn: 0.1751189\ttotal: 4m 37s\tremaining: 5m 36s\n",
            "2258:\tlearn: 0.1751070\ttotal: 4m 37s\tremaining: 5m 36s\n",
            "2259:\tlearn: 0.1750912\ttotal: 4m 37s\tremaining: 5m 36s\n",
            "2260:\tlearn: 0.1750806\ttotal: 4m 37s\tremaining: 5m 36s\n",
            "2261:\tlearn: 0.1750597\ttotal: 4m 37s\tremaining: 5m 36s\n",
            "2262:\tlearn: 0.1750389\ttotal: 4m 38s\tremaining: 5m 36s\n",
            "2263:\tlearn: 0.1750222\ttotal: 4m 38s\tremaining: 5m 36s\n",
            "2264:\tlearn: 0.1750014\ttotal: 4m 38s\tremaining: 5m 35s\n",
            "2265:\tlearn: 0.1749870\ttotal: 4m 38s\tremaining: 5m 35s\n",
            "2266:\tlearn: 0.1749658\ttotal: 4m 38s\tremaining: 5m 35s\n",
            "2267:\tlearn: 0.1749489\ttotal: 4m 38s\tremaining: 5m 35s\n",
            "2268:\tlearn: 0.1749288\ttotal: 4m 38s\tremaining: 5m 35s\n",
            "2269:\tlearn: 0.1749023\ttotal: 4m 38s\tremaining: 5m 35s\n",
            "2270:\tlearn: 0.1748882\ttotal: 4m 38s\tremaining: 5m 35s\n",
            "2271:\tlearn: 0.1748769\ttotal: 4m 39s\tremaining: 5m 35s\n",
            "2272:\tlearn: 0.1748630\ttotal: 4m 39s\tremaining: 5m 34s\n",
            "2273:\tlearn: 0.1748519\ttotal: 4m 39s\tremaining: 5m 34s\n",
            "2274:\tlearn: 0.1748341\ttotal: 4m 39s\tremaining: 5m 34s\n",
            "2275:\tlearn: 0.1748204\ttotal: 4m 39s\tremaining: 5m 34s\n",
            "2276:\tlearn: 0.1748027\ttotal: 4m 39s\tremaining: 5m 34s\n",
            "2277:\tlearn: 0.1747772\ttotal: 4m 39s\tremaining: 5m 34s\n",
            "2278:\tlearn: 0.1747465\ttotal: 4m 39s\tremaining: 5m 34s\n",
            "2279:\tlearn: 0.1747144\ttotal: 4m 40s\tremaining: 5m 34s\n",
            "2280:\tlearn: 0.1746958\ttotal: 4m 40s\tremaining: 5m 34s\n",
            "2281:\tlearn: 0.1746749\ttotal: 4m 40s\tremaining: 5m 33s\n",
            "2282:\tlearn: 0.1746603\ttotal: 4m 40s\tremaining: 5m 33s\n",
            "2283:\tlearn: 0.1746540\ttotal: 4m 40s\tremaining: 5m 33s\n",
            "2284:\tlearn: 0.1746372\ttotal: 4m 40s\tremaining: 5m 33s\n",
            "2285:\tlearn: 0.1746131\ttotal: 4m 40s\tremaining: 5m 33s\n",
            "2286:\tlearn: 0.1746039\ttotal: 4m 40s\tremaining: 5m 33s\n",
            "2287:\tlearn: 0.1745671\ttotal: 4m 41s\tremaining: 5m 33s\n",
            "2288:\tlearn: 0.1745492\ttotal: 4m 41s\tremaining: 5m 33s\n",
            "2289:\tlearn: 0.1745367\ttotal: 4m 41s\tremaining: 5m 32s\n",
            "2290:\tlearn: 0.1745135\ttotal: 4m 41s\tremaining: 5m 32s\n",
            "2291:\tlearn: 0.1744915\ttotal: 4m 41s\tremaining: 5m 32s\n",
            "2292:\tlearn: 0.1744772\ttotal: 4m 41s\tremaining: 5m 32s\n",
            "2293:\tlearn: 0.1744495\ttotal: 4m 41s\tremaining: 5m 32s\n",
            "2294:\tlearn: 0.1744358\ttotal: 4m 41s\tremaining: 5m 32s\n",
            "2295:\tlearn: 0.1744074\ttotal: 4m 42s\tremaining: 5m 32s\n",
            "2296:\tlearn: 0.1743917\ttotal: 4m 42s\tremaining: 5m 32s\n",
            "2297:\tlearn: 0.1743798\ttotal: 4m 42s\tremaining: 5m 31s\n",
            "2298:\tlearn: 0.1743582\ttotal: 4m 42s\tremaining: 5m 31s\n",
            "2299:\tlearn: 0.1743370\ttotal: 4m 42s\tremaining: 5m 31s\n",
            "2300:\tlearn: 0.1743076\ttotal: 4m 42s\tremaining: 5m 31s\n",
            "2301:\tlearn: 0.1742772\ttotal: 4m 42s\tremaining: 5m 31s\n",
            "2302:\tlearn: 0.1742699\ttotal: 4m 42s\tremaining: 5m 31s\n",
            "2303:\tlearn: 0.1742499\ttotal: 4m 43s\tremaining: 5m 31s\n",
            "2304:\tlearn: 0.1742331\ttotal: 4m 43s\tremaining: 5m 31s\n",
            "2305:\tlearn: 0.1742156\ttotal: 4m 43s\tremaining: 5m 30s\n",
            "2306:\tlearn: 0.1741982\ttotal: 4m 43s\tremaining: 5m 30s\n",
            "2307:\tlearn: 0.1741807\ttotal: 4m 43s\tremaining: 5m 30s\n",
            "2308:\tlearn: 0.1741594\ttotal: 4m 43s\tremaining: 5m 30s\n",
            "2309:\tlearn: 0.1741396\ttotal: 4m 43s\tremaining: 5m 30s\n",
            "2310:\tlearn: 0.1741252\ttotal: 4m 43s\tremaining: 5m 30s\n",
            "2311:\tlearn: 0.1740958\ttotal: 4m 44s\tremaining: 5m 30s\n",
            "2312:\tlearn: 0.1740779\ttotal: 4m 44s\tremaining: 5m 30s\n",
            "2313:\tlearn: 0.1740648\ttotal: 4m 44s\tremaining: 5m 30s\n",
            "2314:\tlearn: 0.1740305\ttotal: 4m 44s\tremaining: 5m 29s\n",
            "2315:\tlearn: 0.1740025\ttotal: 4m 44s\tremaining: 5m 29s\n",
            "2316:\tlearn: 0.1739677\ttotal: 4m 44s\tremaining: 5m 29s\n",
            "2317:\tlearn: 0.1739586\ttotal: 4m 44s\tremaining: 5m 29s\n",
            "2318:\tlearn: 0.1739404\ttotal: 4m 44s\tremaining: 5m 29s\n",
            "2319:\tlearn: 0.1739276\ttotal: 4m 45s\tremaining: 5m 29s\n",
            "2320:\tlearn: 0.1739100\ttotal: 4m 45s\tremaining: 5m 29s\n",
            "2321:\tlearn: 0.1738871\ttotal: 4m 45s\tremaining: 5m 28s\n",
            "2322:\tlearn: 0.1738729\ttotal: 4m 45s\tremaining: 5m 28s\n",
            "2323:\tlearn: 0.1738511\ttotal: 4m 45s\tremaining: 5m 28s\n",
            "2324:\tlearn: 0.1738378\ttotal: 4m 45s\tremaining: 5m 28s\n",
            "2325:\tlearn: 0.1738309\ttotal: 4m 45s\tremaining: 5m 28s\n",
            "2326:\tlearn: 0.1738031\ttotal: 4m 45s\tremaining: 5m 28s\n",
            "2327:\tlearn: 0.1737833\ttotal: 4m 46s\tremaining: 5m 28s\n",
            "2328:\tlearn: 0.1737615\ttotal: 4m 46s\tremaining: 5m 28s\n",
            "2329:\tlearn: 0.1737228\ttotal: 4m 46s\tremaining: 5m 28s\n",
            "2330:\tlearn: 0.1737151\ttotal: 4m 46s\tremaining: 5m 27s\n",
            "2331:\tlearn: 0.1736988\ttotal: 4m 46s\tremaining: 5m 27s\n",
            "2332:\tlearn: 0.1736841\ttotal: 4m 46s\tremaining: 5m 27s\n",
            "2333:\tlearn: 0.1736680\ttotal: 4m 46s\tremaining: 5m 27s\n",
            "2334:\tlearn: 0.1736502\ttotal: 4m 46s\tremaining: 5m 27s\n",
            "2335:\tlearn: 0.1736233\ttotal: 4m 46s\tremaining: 5m 27s\n",
            "2336:\tlearn: 0.1736072\ttotal: 4m 47s\tremaining: 5m 27s\n",
            "2337:\tlearn: 0.1735796\ttotal: 4m 47s\tremaining: 5m 27s\n",
            "2338:\tlearn: 0.1735635\ttotal: 4m 47s\tremaining: 5m 26s\n",
            "2339:\tlearn: 0.1735423\ttotal: 4m 47s\tremaining: 5m 26s\n",
            "2340:\tlearn: 0.1735265\ttotal: 4m 47s\tremaining: 5m 26s\n",
            "2341:\tlearn: 0.1735030\ttotal: 4m 47s\tremaining: 5m 26s\n",
            "2342:\tlearn: 0.1734888\ttotal: 4m 47s\tremaining: 5m 26s\n",
            "2343:\tlearn: 0.1734795\ttotal: 4m 47s\tremaining: 5m 26s\n",
            "2344:\tlearn: 0.1734630\ttotal: 4m 48s\tremaining: 5m 26s\n",
            "2345:\tlearn: 0.1734469\ttotal: 4m 48s\tremaining: 5m 26s\n",
            "2346:\tlearn: 0.1734360\ttotal: 4m 48s\tremaining: 5m 25s\n",
            "2347:\tlearn: 0.1734142\ttotal: 4m 48s\tremaining: 5m 25s\n",
            "2348:\tlearn: 0.1733790\ttotal: 4m 48s\tremaining: 5m 25s\n",
            "2349:\tlearn: 0.1733632\ttotal: 4m 48s\tremaining: 5m 25s\n",
            "2350:\tlearn: 0.1733551\ttotal: 4m 48s\tremaining: 5m 25s\n",
            "2351:\tlearn: 0.1733378\ttotal: 4m 48s\tremaining: 5m 25s\n",
            "2352:\tlearn: 0.1733191\ttotal: 4m 49s\tremaining: 5m 25s\n",
            "2353:\tlearn: 0.1733018\ttotal: 4m 49s\tremaining: 5m 25s\n",
            "2354:\tlearn: 0.1732777\ttotal: 4m 49s\tremaining: 5m 24s\n",
            "2355:\tlearn: 0.1732247\ttotal: 4m 49s\tremaining: 5m 24s\n",
            "2356:\tlearn: 0.1732065\ttotal: 4m 49s\tremaining: 5m 24s\n",
            "2357:\tlearn: 0.1731919\ttotal: 4m 49s\tremaining: 5m 24s\n",
            "2358:\tlearn: 0.1731818\ttotal: 4m 49s\tremaining: 5m 24s\n",
            "2359:\tlearn: 0.1731668\ttotal: 4m 49s\tremaining: 5m 24s\n",
            "2360:\tlearn: 0.1731546\ttotal: 4m 49s\tremaining: 5m 24s\n",
            "2361:\tlearn: 0.1731333\ttotal: 4m 50s\tremaining: 5m 23s\n",
            "2362:\tlearn: 0.1731038\ttotal: 4m 50s\tremaining: 5m 23s\n",
            "2363:\tlearn: 0.1730803\ttotal: 4m 50s\tremaining: 5m 23s\n",
            "2364:\tlearn: 0.1730708\ttotal: 4m 50s\tremaining: 5m 23s\n",
            "2365:\tlearn: 0.1730542\ttotal: 4m 50s\tremaining: 5m 23s\n",
            "2366:\tlearn: 0.1730305\ttotal: 4m 50s\tremaining: 5m 23s\n",
            "2367:\tlearn: 0.1730180\ttotal: 4m 50s\tremaining: 5m 23s\n",
            "2368:\tlearn: 0.1729786\ttotal: 4m 50s\tremaining: 5m 23s\n",
            "2369:\tlearn: 0.1729688\ttotal: 4m 51s\tremaining: 5m 22s\n",
            "2370:\tlearn: 0.1729453\ttotal: 4m 51s\tremaining: 5m 22s\n",
            "2371:\tlearn: 0.1729251\ttotal: 4m 51s\tremaining: 5m 22s\n",
            "2372:\tlearn: 0.1729038\ttotal: 4m 51s\tremaining: 5m 22s\n",
            "2373:\tlearn: 0.1728860\ttotal: 4m 51s\tremaining: 5m 22s\n",
            "2374:\tlearn: 0.1728682\ttotal: 4m 51s\tremaining: 5m 22s\n",
            "2375:\tlearn: 0.1728551\ttotal: 4m 51s\tremaining: 5m 22s\n",
            "2376:\tlearn: 0.1728384\ttotal: 4m 51s\tremaining: 5m 22s\n",
            "2377:\tlearn: 0.1728233\ttotal: 4m 52s\tremaining: 5m 22s\n",
            "2378:\tlearn: 0.1727919\ttotal: 4m 52s\tremaining: 5m 21s\n",
            "2379:\tlearn: 0.1727733\ttotal: 4m 52s\tremaining: 5m 21s\n",
            "2380:\tlearn: 0.1727618\ttotal: 4m 52s\tremaining: 5m 21s\n",
            "2381:\tlearn: 0.1727444\ttotal: 4m 52s\tremaining: 5m 21s\n",
            "2382:\tlearn: 0.1727085\ttotal: 4m 52s\tremaining: 5m 21s\n",
            "2383:\tlearn: 0.1726981\ttotal: 4m 52s\tremaining: 5m 21s\n",
            "2384:\tlearn: 0.1726720\ttotal: 4m 52s\tremaining: 5m 21s\n",
            "2385:\tlearn: 0.1726591\ttotal: 4m 53s\tremaining: 5m 21s\n",
            "2386:\tlearn: 0.1726435\ttotal: 4m 53s\tremaining: 5m 20s\n",
            "2387:\tlearn: 0.1726246\ttotal: 4m 53s\tremaining: 5m 20s\n",
            "2388:\tlearn: 0.1726139\ttotal: 4m 53s\tremaining: 5m 20s\n",
            "2389:\tlearn: 0.1726023\ttotal: 4m 53s\tremaining: 5m 20s\n",
            "2390:\tlearn: 0.1725795\ttotal: 4m 53s\tremaining: 5m 20s\n",
            "2391:\tlearn: 0.1725643\ttotal: 4m 53s\tremaining: 5m 20s\n",
            "2392:\tlearn: 0.1725522\ttotal: 4m 53s\tremaining: 5m 20s\n",
            "2393:\tlearn: 0.1725300\ttotal: 4m 53s\tremaining: 5m 19s\n",
            "2394:\tlearn: 0.1725194\ttotal: 4m 54s\tremaining: 5m 19s\n",
            "2395:\tlearn: 0.1725075\ttotal: 4m 54s\tremaining: 5m 19s\n",
            "2396:\tlearn: 0.1724884\ttotal: 4m 54s\tremaining: 5m 19s\n",
            "2397:\tlearn: 0.1724759\ttotal: 4m 54s\tremaining: 5m 19s\n",
            "2398:\tlearn: 0.1724491\ttotal: 4m 54s\tremaining: 5m 19s\n",
            "2399:\tlearn: 0.1724347\ttotal: 4m 54s\tremaining: 5m 19s\n",
            "2400:\tlearn: 0.1724152\ttotal: 4m 54s\tremaining: 5m 19s\n",
            "2401:\tlearn: 0.1724064\ttotal: 4m 54s\tremaining: 5m 18s\n",
            "2402:\tlearn: 0.1723959\ttotal: 4m 54s\tremaining: 5m 18s\n",
            "2403:\tlearn: 0.1723828\ttotal: 4m 55s\tremaining: 5m 18s\n",
            "2404:\tlearn: 0.1723602\ttotal: 4m 55s\tremaining: 5m 18s\n",
            "2405:\tlearn: 0.1723351\ttotal: 4m 55s\tremaining: 5m 18s\n",
            "2406:\tlearn: 0.1723209\ttotal: 4m 55s\tremaining: 5m 18s\n",
            "2407:\tlearn: 0.1723096\ttotal: 4m 55s\tremaining: 5m 18s\n",
            "2408:\tlearn: 0.1722951\ttotal: 4m 55s\tremaining: 5m 18s\n",
            "2409:\tlearn: 0.1722738\ttotal: 4m 55s\tremaining: 5m 17s\n",
            "2410:\tlearn: 0.1722525\ttotal: 4m 55s\tremaining: 5m 17s\n",
            "2411:\tlearn: 0.1722343\ttotal: 4m 56s\tremaining: 5m 17s\n",
            "2412:\tlearn: 0.1722138\ttotal: 4m 56s\tremaining: 5m 17s\n",
            "2413:\tlearn: 0.1721956\ttotal: 4m 56s\tremaining: 5m 17s\n",
            "2414:\tlearn: 0.1721806\ttotal: 4m 56s\tremaining: 5m 17s\n",
            "2415:\tlearn: 0.1721661\ttotal: 4m 56s\tremaining: 5m 17s\n",
            "2416:\tlearn: 0.1721149\ttotal: 4m 56s\tremaining: 5m 17s\n",
            "2417:\tlearn: 0.1720858\ttotal: 4m 56s\tremaining: 5m 16s\n",
            "2418:\tlearn: 0.1720508\ttotal: 4m 56s\tremaining: 5m 16s\n",
            "2419:\tlearn: 0.1720413\ttotal: 4m 57s\tremaining: 5m 16s\n",
            "2420:\tlearn: 0.1720243\ttotal: 4m 57s\tremaining: 5m 16s\n",
            "2421:\tlearn: 0.1720052\ttotal: 4m 57s\tremaining: 5m 16s\n",
            "2422:\tlearn: 0.1719948\ttotal: 4m 57s\tremaining: 5m 16s\n",
            "2423:\tlearn: 0.1719850\ttotal: 4m 57s\tremaining: 5m 16s\n",
            "2424:\tlearn: 0.1719756\ttotal: 4m 57s\tremaining: 5m 16s\n",
            "2425:\tlearn: 0.1719495\ttotal: 4m 57s\tremaining: 5m 15s\n",
            "2426:\tlearn: 0.1719266\ttotal: 4m 57s\tremaining: 5m 15s\n",
            "2427:\tlearn: 0.1719125\ttotal: 4m 58s\tremaining: 5m 15s\n",
            "2428:\tlearn: 0.1718947\ttotal: 4m 58s\tremaining: 5m 15s\n",
            "2429:\tlearn: 0.1718470\ttotal: 4m 58s\tremaining: 5m 15s\n",
            "2430:\tlearn: 0.1718341\ttotal: 4m 58s\tremaining: 5m 15s\n",
            "2431:\tlearn: 0.1718226\ttotal: 4m 58s\tremaining: 5m 15s\n",
            "2432:\tlearn: 0.1718078\ttotal: 4m 58s\tremaining: 5m 15s\n",
            "2433:\tlearn: 0.1717901\ttotal: 4m 58s\tremaining: 5m 14s\n",
            "2434:\tlearn: 0.1717775\ttotal: 4m 58s\tremaining: 5m 14s\n",
            "2435:\tlearn: 0.1717586\ttotal: 4m 58s\tremaining: 5m 14s\n",
            "2436:\tlearn: 0.1717321\ttotal: 4m 59s\tremaining: 5m 14s\n",
            "2437:\tlearn: 0.1717197\ttotal: 4m 59s\tremaining: 5m 14s\n",
            "2438:\tlearn: 0.1717071\ttotal: 4m 59s\tremaining: 5m 14s\n",
            "2439:\tlearn: 0.1716853\ttotal: 4m 59s\tremaining: 5m 14s\n",
            "2440:\tlearn: 0.1716653\ttotal: 4m 59s\tremaining: 5m 14s\n",
            "2441:\tlearn: 0.1716496\ttotal: 4m 59s\tremaining: 5m 13s\n",
            "2442:\tlearn: 0.1716289\ttotal: 4m 59s\tremaining: 5m 13s\n",
            "2443:\tlearn: 0.1716175\ttotal: 4m 59s\tremaining: 5m 13s\n",
            "2444:\tlearn: 0.1715904\ttotal: 5m\tremaining: 5m 13s\n",
            "2445:\tlearn: 0.1715734\ttotal: 5m\tremaining: 5m 13s\n",
            "2446:\tlearn: 0.1715526\ttotal: 5m\tremaining: 5m 13s\n",
            "2447:\tlearn: 0.1715402\ttotal: 5m\tremaining: 5m 13s\n",
            "2448:\tlearn: 0.1715147\ttotal: 5m\tremaining: 5m 13s\n",
            "2449:\tlearn: 0.1714968\ttotal: 5m\tremaining: 5m 12s\n",
            "2450:\tlearn: 0.1714815\ttotal: 5m\tremaining: 5m 12s\n",
            "2451:\tlearn: 0.1714722\ttotal: 5m\tremaining: 5m 12s\n",
            "2452:\tlearn: 0.1714583\ttotal: 5m 1s\tremaining: 5m 12s\n",
            "2453:\tlearn: 0.1714437\ttotal: 5m 1s\tremaining: 5m 12s\n",
            "2454:\tlearn: 0.1714156\ttotal: 5m 1s\tremaining: 5m 12s\n",
            "2455:\tlearn: 0.1714026\ttotal: 5m 1s\tremaining: 5m 12s\n",
            "2456:\tlearn: 0.1713889\ttotal: 5m 1s\tremaining: 5m 12s\n",
            "2457:\tlearn: 0.1713683\ttotal: 5m 1s\tremaining: 5m 12s\n",
            "2458:\tlearn: 0.1713463\ttotal: 5m 1s\tremaining: 5m 11s\n",
            "2459:\tlearn: 0.1713282\ttotal: 5m 1s\tremaining: 5m 11s\n",
            "2460:\tlearn: 0.1712996\ttotal: 5m 2s\tremaining: 5m 11s\n",
            "2461:\tlearn: 0.1712904\ttotal: 5m 2s\tremaining: 5m 11s\n",
            "2462:\tlearn: 0.1712750\ttotal: 5m 2s\tremaining: 5m 11s\n",
            "2463:\tlearn: 0.1712547\ttotal: 5m 2s\tremaining: 5m 11s\n",
            "2464:\tlearn: 0.1712382\ttotal: 5m 2s\tremaining: 5m 11s\n",
            "2465:\tlearn: 0.1712128\ttotal: 5m 2s\tremaining: 5m 10s\n",
            "2466:\tlearn: 0.1711974\ttotal: 5m 2s\tremaining: 5m 10s\n",
            "2467:\tlearn: 0.1711744\ttotal: 5m 2s\tremaining: 5m 10s\n",
            "2468:\tlearn: 0.1711637\ttotal: 5m 3s\tremaining: 5m 10s\n",
            "2469:\tlearn: 0.1711553\ttotal: 5m 3s\tremaining: 5m 10s\n",
            "2470:\tlearn: 0.1711424\ttotal: 5m 3s\tremaining: 5m 10s\n",
            "2471:\tlearn: 0.1711286\ttotal: 5m 3s\tremaining: 5m 10s\n",
            "2472:\tlearn: 0.1711056\ttotal: 5m 3s\tremaining: 5m 10s\n",
            "2473:\tlearn: 0.1710932\ttotal: 5m 3s\tremaining: 5m 9s\n",
            "2474:\tlearn: 0.1710763\ttotal: 5m 3s\tremaining: 5m 9s\n",
            "2475:\tlearn: 0.1710615\ttotal: 5m 3s\tremaining: 5m 9s\n",
            "2476:\tlearn: 0.1710495\ttotal: 5m 3s\tremaining: 5m 9s\n",
            "2477:\tlearn: 0.1710323\ttotal: 5m 4s\tremaining: 5m 9s\n",
            "2478:\tlearn: 0.1710185\ttotal: 5m 4s\tremaining: 5m 9s\n",
            "2479:\tlearn: 0.1710006\ttotal: 5m 4s\tremaining: 5m 9s\n",
            "2480:\tlearn: 0.1709648\ttotal: 5m 4s\tremaining: 5m 9s\n",
            "2481:\tlearn: 0.1709524\ttotal: 5m 4s\tremaining: 5m 8s\n",
            "2482:\tlearn: 0.1709334\ttotal: 5m 4s\tremaining: 5m 8s\n",
            "2483:\tlearn: 0.1709105\ttotal: 5m 4s\tremaining: 5m 8s\n",
            "2484:\tlearn: 0.1708987\ttotal: 5m 4s\tremaining: 5m 8s\n",
            "2485:\tlearn: 0.1708866\ttotal: 5m 4s\tremaining: 5m 8s\n",
            "2486:\tlearn: 0.1708719\ttotal: 5m 5s\tremaining: 5m 8s\n",
            "2487:\tlearn: 0.1708552\ttotal: 5m 5s\tremaining: 5m 8s\n",
            "2488:\tlearn: 0.1708372\ttotal: 5m 5s\tremaining: 5m 7s\n",
            "2489:\tlearn: 0.1708271\ttotal: 5m 5s\tremaining: 5m 7s\n",
            "2490:\tlearn: 0.1708093\ttotal: 5m 5s\tremaining: 5m 7s\n",
            "2491:\tlearn: 0.1707930\ttotal: 5m 5s\tremaining: 5m 7s\n",
            "2492:\tlearn: 0.1707821\ttotal: 5m 5s\tremaining: 5m 7s\n",
            "2493:\tlearn: 0.1707608\ttotal: 5m 5s\tremaining: 5m 7s\n",
            "2494:\tlearn: 0.1707209\ttotal: 5m 5s\tremaining: 5m 7s\n",
            "2495:\tlearn: 0.1707008\ttotal: 5m 6s\tremaining: 5m 7s\n",
            "2496:\tlearn: 0.1706894\ttotal: 5m 6s\tremaining: 5m 6s\n",
            "2497:\tlearn: 0.1706708\ttotal: 5m 6s\tremaining: 5m 6s\n",
            "2498:\tlearn: 0.1706530\ttotal: 5m 6s\tremaining: 5m 6s\n",
            "2499:\tlearn: 0.1706212\ttotal: 5m 6s\tremaining: 5m 6s\n",
            "2500:\tlearn: 0.1706078\ttotal: 5m 6s\tremaining: 5m 6s\n",
            "2501:\tlearn: 0.1705987\ttotal: 5m 6s\tremaining: 5m 6s\n",
            "2502:\tlearn: 0.1705850\ttotal: 5m 6s\tremaining: 5m 6s\n",
            "2503:\tlearn: 0.1705670\ttotal: 5m 7s\tremaining: 5m 6s\n",
            "2504:\tlearn: 0.1705527\ttotal: 5m 7s\tremaining: 5m 5s\n",
            "2505:\tlearn: 0.1705412\ttotal: 5m 7s\tremaining: 5m 5s\n",
            "2506:\tlearn: 0.1705245\ttotal: 5m 7s\tremaining: 5m 5s\n",
            "2507:\tlearn: 0.1705005\ttotal: 5m 7s\tremaining: 5m 5s\n",
            "2508:\tlearn: 0.1704729\ttotal: 5m 7s\tremaining: 5m 5s\n",
            "2509:\tlearn: 0.1704441\ttotal: 5m 7s\tremaining: 5m 5s\n",
            "2510:\tlearn: 0.1704146\ttotal: 5m 7s\tremaining: 5m 5s\n",
            "2511:\tlearn: 0.1703922\ttotal: 5m 8s\tremaining: 5m 5s\n",
            "2512:\tlearn: 0.1703727\ttotal: 5m 8s\tremaining: 5m 5s\n",
            "2513:\tlearn: 0.1703472\ttotal: 5m 8s\tremaining: 5m 4s\n",
            "2514:\tlearn: 0.1703183\ttotal: 5m 8s\tremaining: 5m 4s\n",
            "2515:\tlearn: 0.1702987\ttotal: 5m 8s\tremaining: 5m 4s\n",
            "2516:\tlearn: 0.1702782\ttotal: 5m 8s\tremaining: 5m 4s\n",
            "2517:\tlearn: 0.1702320\ttotal: 5m 8s\tremaining: 5m 4s\n",
            "2518:\tlearn: 0.1702091\ttotal: 5m 8s\tremaining: 5m 4s\n",
            "2519:\tlearn: 0.1701841\ttotal: 5m 9s\tremaining: 5m 4s\n",
            "2520:\tlearn: 0.1701688\ttotal: 5m 9s\tremaining: 5m 4s\n",
            "2521:\tlearn: 0.1701416\ttotal: 5m 9s\tremaining: 5m 3s\n",
            "2522:\tlearn: 0.1701236\ttotal: 5m 9s\tremaining: 5m 3s\n",
            "2523:\tlearn: 0.1701086\ttotal: 5m 9s\tremaining: 5m 3s\n",
            "2524:\tlearn: 0.1700923\ttotal: 5m 9s\tremaining: 5m 3s\n",
            "2525:\tlearn: 0.1700722\ttotal: 5m 9s\tremaining: 5m 3s\n",
            "2526:\tlearn: 0.1700544\ttotal: 5m 9s\tremaining: 5m 3s\n",
            "2527:\tlearn: 0.1700429\ttotal: 5m 10s\tremaining: 5m 3s\n",
            "2528:\tlearn: 0.1700193\ttotal: 5m 10s\tremaining: 5m 3s\n",
            "2529:\tlearn: 0.1699997\ttotal: 5m 10s\tremaining: 5m 3s\n",
            "2530:\tlearn: 0.1699791\ttotal: 5m 10s\tremaining: 5m 2s\n",
            "2531:\tlearn: 0.1699630\ttotal: 5m 10s\tremaining: 5m 2s\n",
            "2532:\tlearn: 0.1699557\ttotal: 5m 10s\tremaining: 5m 2s\n",
            "2533:\tlearn: 0.1699418\ttotal: 5m 10s\tremaining: 5m 2s\n",
            "2534:\tlearn: 0.1699111\ttotal: 5m 10s\tremaining: 5m 2s\n",
            "2535:\tlearn: 0.1699027\ttotal: 5m 11s\tremaining: 5m 2s\n",
            "2536:\tlearn: 0.1698818\ttotal: 5m 11s\tremaining: 5m 2s\n",
            "2537:\tlearn: 0.1698603\ttotal: 5m 11s\tremaining: 5m 2s\n",
            "2538:\tlearn: 0.1698394\ttotal: 5m 11s\tremaining: 5m 1s\n",
            "2539:\tlearn: 0.1698186\ttotal: 5m 11s\tremaining: 5m 1s\n",
            "2540:\tlearn: 0.1698033\ttotal: 5m 11s\tremaining: 5m 1s\n",
            "2541:\tlearn: 0.1697835\ttotal: 5m 11s\tremaining: 5m 1s\n",
            "2542:\tlearn: 0.1697711\ttotal: 5m 12s\tremaining: 5m 1s\n",
            "2543:\tlearn: 0.1697560\ttotal: 5m 12s\tremaining: 5m 1s\n",
            "2544:\tlearn: 0.1697444\ttotal: 5m 12s\tremaining: 5m 1s\n",
            "2545:\tlearn: 0.1697349\ttotal: 5m 12s\tremaining: 5m 1s\n",
            "2546:\tlearn: 0.1697220\ttotal: 5m 12s\tremaining: 5m 1s\n",
            "2547:\tlearn: 0.1697098\ttotal: 5m 12s\tremaining: 5m\n",
            "2548:\tlearn: 0.1696979\ttotal: 5m 12s\tremaining: 5m\n",
            "2549:\tlearn: 0.1696838\ttotal: 5m 12s\tremaining: 5m\n",
            "2550:\tlearn: 0.1696593\ttotal: 5m 13s\tremaining: 5m\n",
            "2551:\tlearn: 0.1696479\ttotal: 5m 13s\tremaining: 5m\n",
            "2552:\tlearn: 0.1696301\ttotal: 5m 13s\tremaining: 5m\n",
            "2553:\tlearn: 0.1696057\ttotal: 5m 13s\tremaining: 5m\n",
            "2554:\tlearn: 0.1695946\ttotal: 5m 13s\tremaining: 4m 59s\n",
            "2555:\tlearn: 0.1695826\ttotal: 5m 13s\tremaining: 4m 59s\n",
            "2556:\tlearn: 0.1695700\ttotal: 5m 13s\tremaining: 4m 59s\n",
            "2557:\tlearn: 0.1695520\ttotal: 5m 13s\tremaining: 4m 59s\n",
            "2558:\tlearn: 0.1695237\ttotal: 5m 13s\tremaining: 4m 59s\n",
            "2559:\tlearn: 0.1695090\ttotal: 5m 14s\tremaining: 4m 59s\n",
            "2560:\tlearn: 0.1694973\ttotal: 5m 14s\tremaining: 4m 59s\n",
            "2561:\tlearn: 0.1694831\ttotal: 5m 14s\tremaining: 4m 59s\n",
            "2562:\tlearn: 0.1694675\ttotal: 5m 14s\tremaining: 4m 58s\n",
            "2563:\tlearn: 0.1694556\ttotal: 5m 14s\tremaining: 4m 58s\n",
            "2564:\tlearn: 0.1694430\ttotal: 5m 14s\tremaining: 4m 58s\n",
            "2565:\tlearn: 0.1694297\ttotal: 5m 14s\tremaining: 4m 58s\n",
            "2566:\tlearn: 0.1694050\ttotal: 5m 14s\tremaining: 4m 58s\n",
            "2567:\tlearn: 0.1693914\ttotal: 5m 15s\tremaining: 4m 58s\n",
            "2568:\tlearn: 0.1693704\ttotal: 5m 15s\tremaining: 4m 58s\n",
            "2569:\tlearn: 0.1693570\ttotal: 5m 15s\tremaining: 4m 58s\n",
            "2570:\tlearn: 0.1693369\ttotal: 5m 15s\tremaining: 4m 58s\n",
            "2571:\tlearn: 0.1693241\ttotal: 5m 15s\tremaining: 4m 57s\n",
            "2572:\tlearn: 0.1693125\ttotal: 5m 15s\tremaining: 4m 57s\n",
            "2573:\tlearn: 0.1692969\ttotal: 5m 15s\tremaining: 4m 57s\n",
            "2574:\tlearn: 0.1692802\ttotal: 5m 15s\tremaining: 4m 57s\n",
            "2575:\tlearn: 0.1692646\ttotal: 5m 15s\tremaining: 4m 57s\n",
            "2576:\tlearn: 0.1692538\ttotal: 5m 16s\tremaining: 4m 57s\n",
            "2577:\tlearn: 0.1692444\ttotal: 5m 16s\tremaining: 4m 57s\n",
            "2578:\tlearn: 0.1692188\ttotal: 5m 16s\tremaining: 4m 56s\n",
            "2579:\tlearn: 0.1692050\ttotal: 5m 16s\tremaining: 4m 56s\n",
            "2580:\tlearn: 0.1691835\ttotal: 5m 16s\tremaining: 4m 56s\n",
            "2581:\tlearn: 0.1691649\ttotal: 5m 16s\tremaining: 4m 56s\n",
            "2582:\tlearn: 0.1691427\ttotal: 5m 16s\tremaining: 4m 56s\n",
            "2583:\tlearn: 0.1691243\ttotal: 5m 16s\tremaining: 4m 56s\n",
            "2584:\tlearn: 0.1691151\ttotal: 5m 17s\tremaining: 4m 56s\n",
            "2585:\tlearn: 0.1690997\ttotal: 5m 17s\tremaining: 4m 56s\n",
            "2586:\tlearn: 0.1690814\ttotal: 5m 17s\tremaining: 4m 55s\n",
            "2587:\tlearn: 0.1690726\ttotal: 5m 17s\tremaining: 4m 55s\n",
            "2588:\tlearn: 0.1690470\ttotal: 5m 17s\tremaining: 4m 55s\n",
            "2589:\tlearn: 0.1690187\ttotal: 5m 17s\tremaining: 4m 55s\n",
            "2590:\tlearn: 0.1690020\ttotal: 5m 17s\tremaining: 4m 55s\n",
            "2591:\tlearn: 0.1689867\ttotal: 5m 17s\tremaining: 4m 55s\n",
            "2592:\tlearn: 0.1689675\ttotal: 5m 17s\tremaining: 4m 55s\n",
            "2593:\tlearn: 0.1689422\ttotal: 5m 18s\tremaining: 4m 55s\n",
            "2594:\tlearn: 0.1689296\ttotal: 5m 18s\tremaining: 4m 54s\n",
            "2595:\tlearn: 0.1689222\ttotal: 5m 18s\tremaining: 4m 54s\n",
            "2596:\tlearn: 0.1689162\ttotal: 5m 18s\tremaining: 4m 54s\n",
            "2597:\tlearn: 0.1689028\ttotal: 5m 18s\tremaining: 4m 54s\n",
            "2598:\tlearn: 0.1688793\ttotal: 5m 18s\tremaining: 4m 54s\n",
            "2599:\tlearn: 0.1688596\ttotal: 5m 18s\tremaining: 4m 54s\n",
            "2600:\tlearn: 0.1688297\ttotal: 5m 18s\tremaining: 4m 54s\n",
            "2601:\tlearn: 0.1688021\ttotal: 5m 19s\tremaining: 4m 54s\n",
            "2602:\tlearn: 0.1687845\ttotal: 5m 19s\tremaining: 4m 53s\n",
            "2603:\tlearn: 0.1687666\ttotal: 5m 19s\tremaining: 4m 53s\n",
            "2604:\tlearn: 0.1687514\ttotal: 5m 19s\tremaining: 4m 53s\n",
            "2605:\tlearn: 0.1687332\ttotal: 5m 19s\tremaining: 4m 53s\n",
            "2606:\tlearn: 0.1687159\ttotal: 5m 19s\tremaining: 4m 53s\n",
            "2607:\tlearn: 0.1686937\ttotal: 5m 19s\tremaining: 4m 53s\n",
            "2608:\tlearn: 0.1686823\ttotal: 5m 19s\tremaining: 4m 53s\n",
            "2609:\tlearn: 0.1686684\ttotal: 5m 20s\tremaining: 4m 53s\n",
            "2610:\tlearn: 0.1686451\ttotal: 5m 20s\tremaining: 4m 53s\n",
            "2611:\tlearn: 0.1686277\ttotal: 5m 20s\tremaining: 4m 52s\n",
            "2612:\tlearn: 0.1686111\ttotal: 5m 20s\tremaining: 4m 52s\n",
            "2613:\tlearn: 0.1685981\ttotal: 5m 20s\tremaining: 4m 52s\n",
            "2614:\tlearn: 0.1685810\ttotal: 5m 20s\tremaining: 4m 52s\n",
            "2615:\tlearn: 0.1685665\ttotal: 5m 20s\tremaining: 4m 52s\n",
            "2616:\tlearn: 0.1685468\ttotal: 5m 20s\tremaining: 4m 52s\n",
            "2617:\tlearn: 0.1685321\ttotal: 5m 21s\tremaining: 4m 52s\n",
            "2618:\tlearn: 0.1685270\ttotal: 5m 21s\tremaining: 4m 52s\n",
            "2619:\tlearn: 0.1685147\ttotal: 5m 21s\tremaining: 4m 51s\n",
            "2620:\tlearn: 0.1685067\ttotal: 5m 21s\tremaining: 4m 51s\n",
            "2621:\tlearn: 0.1684836\ttotal: 5m 21s\tremaining: 4m 51s\n",
            "2622:\tlearn: 0.1684702\ttotal: 5m 21s\tremaining: 4m 51s\n",
            "2623:\tlearn: 0.1684470\ttotal: 5m 21s\tremaining: 4m 51s\n",
            "2624:\tlearn: 0.1684102\ttotal: 5m 21s\tremaining: 4m 51s\n",
            "2625:\tlearn: 0.1683938\ttotal: 5m 22s\tremaining: 4m 51s\n",
            "2626:\tlearn: 0.1683731\ttotal: 5m 22s\tremaining: 4m 51s\n",
            "2627:\tlearn: 0.1683594\ttotal: 5m 22s\tremaining: 4m 50s\n",
            "2628:\tlearn: 0.1683497\ttotal: 5m 22s\tremaining: 4m 50s\n",
            "2629:\tlearn: 0.1683315\ttotal: 5m 22s\tremaining: 4m 50s\n",
            "2630:\tlearn: 0.1683077\ttotal: 5m 22s\tremaining: 4m 50s\n",
            "2631:\tlearn: 0.1682935\ttotal: 5m 22s\tremaining: 4m 50s\n",
            "2632:\tlearn: 0.1682841\ttotal: 5m 22s\tremaining: 4m 50s\n",
            "2633:\tlearn: 0.1682668\ttotal: 5m 22s\tremaining: 4m 50s\n",
            "2634:\tlearn: 0.1682552\ttotal: 5m 23s\tremaining: 4m 50s\n",
            "2635:\tlearn: 0.1682339\ttotal: 5m 23s\tremaining: 4m 49s\n",
            "2636:\tlearn: 0.1682156\ttotal: 5m 23s\tremaining: 4m 49s\n",
            "2637:\tlearn: 0.1682042\ttotal: 5m 23s\tremaining: 4m 49s\n",
            "2638:\tlearn: 0.1681926\ttotal: 5m 23s\tremaining: 4m 49s\n",
            "2639:\tlearn: 0.1681725\ttotal: 5m 23s\tremaining: 4m 49s\n",
            "2640:\tlearn: 0.1681510\ttotal: 5m 23s\tremaining: 4m 49s\n",
            "2641:\tlearn: 0.1681343\ttotal: 5m 23s\tremaining: 4m 49s\n",
            "2642:\tlearn: 0.1681302\ttotal: 5m 24s\tremaining: 4m 49s\n",
            "2643:\tlearn: 0.1681087\ttotal: 5m 24s\tremaining: 4m 48s\n",
            "2644:\tlearn: 0.1680909\ttotal: 5m 24s\tremaining: 4m 48s\n",
            "2645:\tlearn: 0.1680724\ttotal: 5m 24s\tremaining: 4m 48s\n",
            "2646:\tlearn: 0.1680643\ttotal: 5m 24s\tremaining: 4m 48s\n",
            "2647:\tlearn: 0.1680450\ttotal: 5m 24s\tremaining: 4m 48s\n",
            "2648:\tlearn: 0.1680254\ttotal: 5m 24s\tremaining: 4m 48s\n",
            "2649:\tlearn: 0.1680033\ttotal: 5m 24s\tremaining: 4m 48s\n",
            "2650:\tlearn: 0.1679823\ttotal: 5m 25s\tremaining: 4m 48s\n",
            "2651:\tlearn: 0.1679625\ttotal: 5m 25s\tremaining: 4m 47s\n",
            "2652:\tlearn: 0.1679474\ttotal: 5m 25s\tremaining: 4m 47s\n",
            "2653:\tlearn: 0.1679359\ttotal: 5m 25s\tremaining: 4m 47s\n",
            "2654:\tlearn: 0.1679231\ttotal: 5m 25s\tremaining: 4m 47s\n",
            "2655:\tlearn: 0.1679146\ttotal: 5m 25s\tremaining: 4m 47s\n",
            "2656:\tlearn: 0.1679024\ttotal: 5m 25s\tremaining: 4m 47s\n",
            "2657:\tlearn: 0.1678892\ttotal: 5m 26s\tremaining: 4m 47s\n",
            "2658:\tlearn: 0.1678803\ttotal: 5m 26s\tremaining: 4m 47s\n",
            "2659:\tlearn: 0.1678676\ttotal: 5m 26s\tremaining: 4m 46s\n",
            "2660:\tlearn: 0.1678324\ttotal: 5m 26s\tremaining: 4m 46s\n",
            "2661:\tlearn: 0.1678257\ttotal: 5m 26s\tremaining: 4m 46s\n",
            "2662:\tlearn: 0.1678049\ttotal: 5m 26s\tremaining: 4m 46s\n",
            "2663:\tlearn: 0.1677926\ttotal: 5m 26s\tremaining: 4m 46s\n",
            "2664:\tlearn: 0.1677752\ttotal: 5m 26s\tremaining: 4m 46s\n",
            "2665:\tlearn: 0.1677618\ttotal: 5m 27s\tremaining: 4m 46s\n",
            "2666:\tlearn: 0.1677463\ttotal: 5m 27s\tremaining: 4m 46s\n",
            "2667:\tlearn: 0.1677237\ttotal: 5m 27s\tremaining: 4m 46s\n",
            "2668:\tlearn: 0.1677120\ttotal: 5m 27s\tremaining: 4m 45s\n",
            "2669:\tlearn: 0.1676968\ttotal: 5m 27s\tremaining: 4m 45s\n",
            "2670:\tlearn: 0.1676784\ttotal: 5m 27s\tremaining: 4m 45s\n",
            "2671:\tlearn: 0.1676636\ttotal: 5m 27s\tremaining: 4m 45s\n",
            "2672:\tlearn: 0.1676518\ttotal: 5m 27s\tremaining: 4m 45s\n",
            "2673:\tlearn: 0.1676364\ttotal: 5m 27s\tremaining: 4m 45s\n",
            "2674:\tlearn: 0.1676156\ttotal: 5m 28s\tremaining: 4m 45s\n",
            "2675:\tlearn: 0.1676022\ttotal: 5m 28s\tremaining: 4m 45s\n",
            "2676:\tlearn: 0.1675865\ttotal: 5m 28s\tremaining: 4m 44s\n",
            "2677:\tlearn: 0.1675651\ttotal: 5m 28s\tremaining: 4m 44s\n",
            "2678:\tlearn: 0.1675526\ttotal: 5m 28s\tremaining: 4m 44s\n",
            "2679:\tlearn: 0.1675422\ttotal: 5m 28s\tremaining: 4m 44s\n",
            "2680:\tlearn: 0.1675084\ttotal: 5m 28s\tremaining: 4m 44s\n",
            "2681:\tlearn: 0.1674954\ttotal: 5m 28s\tremaining: 4m 44s\n",
            "2682:\tlearn: 0.1674759\ttotal: 5m 29s\tremaining: 4m 44s\n",
            "2683:\tlearn: 0.1674603\ttotal: 5m 29s\tremaining: 4m 44s\n",
            "2684:\tlearn: 0.1674461\ttotal: 5m 29s\tremaining: 4m 43s\n",
            "2685:\tlearn: 0.1674260\ttotal: 5m 29s\tremaining: 4m 43s\n",
            "2686:\tlearn: 0.1674099\ttotal: 5m 29s\tremaining: 4m 43s\n",
            "2687:\tlearn: 0.1673875\ttotal: 5m 29s\tremaining: 4m 43s\n",
            "2688:\tlearn: 0.1673751\ttotal: 5m 29s\tremaining: 4m 43s\n",
            "2689:\tlearn: 0.1673548\ttotal: 5m 29s\tremaining: 4m 43s\n",
            "2690:\tlearn: 0.1673411\ttotal: 5m 29s\tremaining: 4m 43s\n",
            "2691:\tlearn: 0.1673269\ttotal: 5m 29s\tremaining: 4m 42s\n",
            "2692:\tlearn: 0.1673118\ttotal: 5m 30s\tremaining: 4m 42s\n",
            "2693:\tlearn: 0.1672905\ttotal: 5m 30s\tremaining: 4m 42s\n",
            "2694:\tlearn: 0.1672803\ttotal: 5m 30s\tremaining: 4m 42s\n",
            "2695:\tlearn: 0.1672666\ttotal: 5m 30s\tremaining: 4m 42s\n",
            "2696:\tlearn: 0.1672550\ttotal: 5m 30s\tremaining: 4m 42s\n",
            "2697:\tlearn: 0.1672326\ttotal: 5m 30s\tremaining: 4m 42s\n",
            "2698:\tlearn: 0.1672144\ttotal: 5m 30s\tremaining: 4m 42s\n",
            "2699:\tlearn: 0.1671981\ttotal: 5m 30s\tremaining: 4m 41s\n",
            "2700:\tlearn: 0.1671809\ttotal: 5m 31s\tremaining: 4m 41s\n",
            "2701:\tlearn: 0.1671720\ttotal: 5m 31s\tremaining: 4m 41s\n",
            "2702:\tlearn: 0.1671579\ttotal: 5m 31s\tremaining: 4m 41s\n",
            "2703:\tlearn: 0.1671317\ttotal: 5m 31s\tremaining: 4m 41s\n",
            "2704:\tlearn: 0.1671203\ttotal: 5m 31s\tremaining: 4m 41s\n",
            "2705:\tlearn: 0.1670824\ttotal: 5m 31s\tremaining: 4m 41s\n",
            "2706:\tlearn: 0.1670536\ttotal: 5m 31s\tremaining: 4m 41s\n",
            "2707:\tlearn: 0.1670378\ttotal: 5m 31s\tremaining: 4m 40s\n",
            "2708:\tlearn: 0.1670231\ttotal: 5m 31s\tremaining: 4m 40s\n",
            "2709:\tlearn: 0.1670098\ttotal: 5m 32s\tremaining: 4m 40s\n",
            "2710:\tlearn: 0.1669940\ttotal: 5m 32s\tremaining: 4m 40s\n",
            "2711:\tlearn: 0.1669815\ttotal: 5m 32s\tremaining: 4m 40s\n",
            "2712:\tlearn: 0.1669656\ttotal: 5m 32s\tremaining: 4m 40s\n",
            "2713:\tlearn: 0.1669461\ttotal: 5m 32s\tremaining: 4m 40s\n",
            "2714:\tlearn: 0.1669311\ttotal: 5m 32s\tremaining: 4m 40s\n",
            "2715:\tlearn: 0.1669084\ttotal: 5m 32s\tremaining: 4m 39s\n",
            "2716:\tlearn: 0.1668923\ttotal: 5m 33s\tremaining: 4m 39s\n",
            "2717:\tlearn: 0.1668801\ttotal: 5m 33s\tremaining: 4m 39s\n",
            "2718:\tlearn: 0.1668667\ttotal: 5m 33s\tremaining: 4m 39s\n",
            "2719:\tlearn: 0.1668560\ttotal: 5m 33s\tremaining: 4m 39s\n",
            "2720:\tlearn: 0.1668304\ttotal: 5m 33s\tremaining: 4m 39s\n",
            "2721:\tlearn: 0.1668200\ttotal: 5m 33s\tremaining: 4m 39s\n",
            "2722:\tlearn: 0.1668026\ttotal: 5m 33s\tremaining: 4m 39s\n",
            "2723:\tlearn: 0.1667859\ttotal: 5m 33s\tremaining: 4m 38s\n",
            "2724:\tlearn: 0.1667685\ttotal: 5m 33s\tremaining: 4m 38s\n",
            "2725:\tlearn: 0.1667592\ttotal: 5m 34s\tremaining: 4m 38s\n",
            "2726:\tlearn: 0.1667482\ttotal: 5m 34s\tremaining: 4m 38s\n",
            "2727:\tlearn: 0.1667321\ttotal: 5m 34s\tremaining: 4m 38s\n",
            "2728:\tlearn: 0.1667294\ttotal: 5m 34s\tremaining: 4m 38s\n",
            "2729:\tlearn: 0.1667151\ttotal: 5m 34s\tremaining: 4m 38s\n",
            "2730:\tlearn: 0.1667085\ttotal: 5m 34s\tremaining: 4m 37s\n",
            "2731:\tlearn: 0.1666992\ttotal: 5m 34s\tremaining: 4m 37s\n",
            "2732:\tlearn: 0.1666739\ttotal: 5m 34s\tremaining: 4m 37s\n",
            "2733:\tlearn: 0.1666649\ttotal: 5m 34s\tremaining: 4m 37s\n",
            "2734:\tlearn: 0.1666411\ttotal: 5m 35s\tremaining: 4m 37s\n",
            "2735:\tlearn: 0.1666204\ttotal: 5m 35s\tremaining: 4m 37s\n",
            "2736:\tlearn: 0.1666055\ttotal: 5m 35s\tremaining: 4m 37s\n",
            "2737:\tlearn: 0.1665876\ttotal: 5m 35s\tremaining: 4m 37s\n",
            "2738:\tlearn: 0.1665731\ttotal: 5m 35s\tremaining: 4m 37s\n",
            "2739:\tlearn: 0.1665540\ttotal: 5m 35s\tremaining: 4m 36s\n",
            "2740:\tlearn: 0.1665397\ttotal: 5m 35s\tremaining: 4m 36s\n",
            "2741:\tlearn: 0.1665169\ttotal: 5m 35s\tremaining: 4m 36s\n",
            "2742:\tlearn: 0.1664936\ttotal: 5m 36s\tremaining: 4m 36s\n",
            "2743:\tlearn: 0.1664829\ttotal: 5m 36s\tremaining: 4m 36s\n",
            "2744:\tlearn: 0.1664705\ttotal: 5m 36s\tremaining: 4m 36s\n",
            "2745:\tlearn: 0.1664524\ttotal: 5m 36s\tremaining: 4m 36s\n",
            "2746:\tlearn: 0.1664411\ttotal: 5m 36s\tremaining: 4m 36s\n",
            "2747:\tlearn: 0.1664225\ttotal: 5m 36s\tremaining: 4m 35s\n",
            "2748:\tlearn: 0.1664059\ttotal: 5m 36s\tremaining: 4m 35s\n",
            "2749:\tlearn: 0.1663876\ttotal: 5m 36s\tremaining: 4m 35s\n",
            "2750:\tlearn: 0.1663690\ttotal: 5m 37s\tremaining: 4m 35s\n",
            "2751:\tlearn: 0.1663483\ttotal: 5m 37s\tremaining: 4m 35s\n",
            "2752:\tlearn: 0.1663271\ttotal: 5m 37s\tremaining: 4m 35s\n",
            "2753:\tlearn: 0.1663039\ttotal: 5m 37s\tremaining: 4m 35s\n",
            "2754:\tlearn: 0.1662842\ttotal: 5m 37s\tremaining: 4m 35s\n",
            "2755:\tlearn: 0.1662675\ttotal: 5m 37s\tremaining: 4m 35s\n",
            "2756:\tlearn: 0.1662535\ttotal: 5m 37s\tremaining: 4m 34s\n",
            "2757:\tlearn: 0.1662266\ttotal: 5m 38s\tremaining: 4m 34s\n",
            "2758:\tlearn: 0.1662032\ttotal: 5m 38s\tremaining: 4m 34s\n",
            "2759:\tlearn: 0.1661865\ttotal: 5m 38s\tremaining: 4m 34s\n",
            "2760:\tlearn: 0.1661737\ttotal: 5m 38s\tremaining: 4m 34s\n",
            "2761:\tlearn: 0.1661538\ttotal: 5m 38s\tremaining: 4m 34s\n",
            "2762:\tlearn: 0.1661336\ttotal: 5m 38s\tremaining: 4m 34s\n",
            "2763:\tlearn: 0.1661202\ttotal: 5m 38s\tremaining: 4m 34s\n",
            "2764:\tlearn: 0.1660983\ttotal: 5m 38s\tremaining: 4m 33s\n",
            "2765:\tlearn: 0.1660799\ttotal: 5m 39s\tremaining: 4m 33s\n",
            "2766:\tlearn: 0.1660667\ttotal: 5m 39s\tremaining: 4m 33s\n",
            "2767:\tlearn: 0.1660545\ttotal: 5m 39s\tremaining: 4m 33s\n",
            "2768:\tlearn: 0.1660358\ttotal: 5m 39s\tremaining: 4m 33s\n",
            "2769:\tlearn: 0.1660242\ttotal: 5m 39s\tremaining: 4m 33s\n",
            "2770:\tlearn: 0.1660116\ttotal: 5m 39s\tremaining: 4m 33s\n",
            "2771:\tlearn: 0.1659965\ttotal: 5m 39s\tremaining: 4m 33s\n",
            "2772:\tlearn: 0.1659844\ttotal: 5m 39s\tremaining: 4m 32s\n",
            "2773:\tlearn: 0.1659648\ttotal: 5m 40s\tremaining: 4m 32s\n",
            "2774:\tlearn: 0.1659559\ttotal: 5m 40s\tremaining: 4m 32s\n",
            "2775:\tlearn: 0.1659371\ttotal: 5m 40s\tremaining: 4m 32s\n",
            "2776:\tlearn: 0.1659187\ttotal: 5m 40s\tremaining: 4m 32s\n",
            "2777:\tlearn: 0.1658992\ttotal: 5m 40s\tremaining: 4m 32s\n",
            "2778:\tlearn: 0.1658834\ttotal: 5m 40s\tremaining: 4m 32s\n",
            "2779:\tlearn: 0.1658764\ttotal: 5m 40s\tremaining: 4m 32s\n",
            "2780:\tlearn: 0.1658659\ttotal: 5m 40s\tremaining: 4m 32s\n",
            "2781:\tlearn: 0.1658471\ttotal: 5m 41s\tremaining: 4m 31s\n",
            "2782:\tlearn: 0.1658302\ttotal: 5m 41s\tremaining: 4m 31s\n",
            "2783:\tlearn: 0.1658143\ttotal: 5m 41s\tremaining: 4m 31s\n",
            "2784:\tlearn: 0.1658010\ttotal: 5m 41s\tremaining: 4m 31s\n",
            "2785:\tlearn: 0.1657844\ttotal: 5m 41s\tremaining: 4m 31s\n",
            "2786:\tlearn: 0.1657595\ttotal: 5m 41s\tremaining: 4m 31s\n",
            "2787:\tlearn: 0.1657465\ttotal: 5m 41s\tremaining: 4m 31s\n",
            "2788:\tlearn: 0.1657313\ttotal: 5m 41s\tremaining: 4m 31s\n",
            "2789:\tlearn: 0.1657113\ttotal: 5m 42s\tremaining: 4m 31s\n",
            "2790:\tlearn: 0.1656665\ttotal: 5m 42s\tremaining: 4m 30s\n",
            "2791:\tlearn: 0.1656564\ttotal: 5m 42s\tremaining: 4m 30s\n",
            "2792:\tlearn: 0.1656341\ttotal: 5m 42s\tremaining: 4m 30s\n",
            "2793:\tlearn: 0.1656070\ttotal: 5m 42s\tremaining: 4m 30s\n",
            "2794:\tlearn: 0.1655881\ttotal: 5m 42s\tremaining: 4m 30s\n",
            "2795:\tlearn: 0.1655770\ttotal: 5m 42s\tremaining: 4m 30s\n",
            "2796:\tlearn: 0.1655563\ttotal: 5m 42s\tremaining: 4m 30s\n",
            "2797:\tlearn: 0.1655267\ttotal: 5m 43s\tremaining: 4m 30s\n",
            "2798:\tlearn: 0.1655098\ttotal: 5m 43s\tremaining: 4m 29s\n",
            "2799:\tlearn: 0.1655008\ttotal: 5m 43s\tremaining: 4m 29s\n",
            "2800:\tlearn: 0.1654880\ttotal: 5m 43s\tremaining: 4m 29s\n",
            "2801:\tlearn: 0.1654609\ttotal: 5m 43s\tremaining: 4m 29s\n",
            "2802:\tlearn: 0.1654355\ttotal: 5m 43s\tremaining: 4m 29s\n",
            "2803:\tlearn: 0.1654296\ttotal: 5m 43s\tremaining: 4m 29s\n",
            "2804:\tlearn: 0.1654096\ttotal: 5m 44s\tremaining: 4m 29s\n",
            "2805:\tlearn: 0.1653958\ttotal: 5m 44s\tremaining: 4m 29s\n",
            "2806:\tlearn: 0.1653825\ttotal: 5m 44s\tremaining: 4m 28s\n",
            "2807:\tlearn: 0.1653622\ttotal: 5m 44s\tremaining: 4m 28s\n",
            "2808:\tlearn: 0.1653457\ttotal: 5m 44s\tremaining: 4m 28s\n",
            "2809:\tlearn: 0.1653266\ttotal: 5m 44s\tremaining: 4m 28s\n",
            "2810:\tlearn: 0.1653125\ttotal: 5m 44s\tremaining: 4m 28s\n",
            "2811:\tlearn: 0.1653029\ttotal: 5m 44s\tremaining: 4m 28s\n",
            "2812:\tlearn: 0.1652902\ttotal: 5m 44s\tremaining: 4m 28s\n",
            "2813:\tlearn: 0.1652671\ttotal: 5m 45s\tremaining: 4m 28s\n",
            "2814:\tlearn: 0.1652321\ttotal: 5m 45s\tremaining: 4m 27s\n",
            "2815:\tlearn: 0.1652280\ttotal: 5m 45s\tremaining: 4m 27s\n",
            "2816:\tlearn: 0.1652100\ttotal: 5m 45s\tremaining: 4m 27s\n",
            "2817:\tlearn: 0.1651866\ttotal: 5m 45s\tremaining: 4m 27s\n",
            "2818:\tlearn: 0.1651762\ttotal: 5m 45s\tremaining: 4m 27s\n",
            "2819:\tlearn: 0.1651657\ttotal: 5m 45s\tremaining: 4m 27s\n",
            "2820:\tlearn: 0.1651490\ttotal: 5m 45s\tremaining: 4m 27s\n",
            "2821:\tlearn: 0.1651319\ttotal: 5m 46s\tremaining: 4m 27s\n",
            "2822:\tlearn: 0.1651162\ttotal: 5m 46s\tremaining: 4m 26s\n",
            "2823:\tlearn: 0.1651016\ttotal: 5m 46s\tremaining: 4m 26s\n",
            "2824:\tlearn: 0.1650892\ttotal: 5m 46s\tremaining: 4m 26s\n",
            "2825:\tlearn: 0.1650798\ttotal: 5m 46s\tremaining: 4m 26s\n",
            "2826:\tlearn: 0.1650647\ttotal: 5m 46s\tremaining: 4m 26s\n",
            "2827:\tlearn: 0.1650475\ttotal: 5m 46s\tremaining: 4m 26s\n",
            "2828:\tlearn: 0.1650296\ttotal: 5m 46s\tremaining: 4m 26s\n",
            "2829:\tlearn: 0.1650098\ttotal: 5m 47s\tremaining: 4m 26s\n",
            "2830:\tlearn: 0.1649915\ttotal: 5m 47s\tremaining: 4m 26s\n",
            "2831:\tlearn: 0.1649857\ttotal: 5m 47s\tremaining: 4m 25s\n",
            "2832:\tlearn: 0.1649734\ttotal: 5m 47s\tremaining: 4m 25s\n",
            "2833:\tlearn: 0.1649533\ttotal: 5m 47s\tremaining: 4m 25s\n",
            "2834:\tlearn: 0.1649330\ttotal: 5m 47s\tremaining: 4m 25s\n",
            "2835:\tlearn: 0.1649173\ttotal: 5m 47s\tremaining: 4m 25s\n",
            "2836:\tlearn: 0.1649028\ttotal: 5m 48s\tremaining: 4m 25s\n",
            "2837:\tlearn: 0.1648858\ttotal: 5m 48s\tremaining: 4m 25s\n",
            "2838:\tlearn: 0.1648739\ttotal: 5m 48s\tremaining: 4m 25s\n",
            "2839:\tlearn: 0.1648584\ttotal: 5m 48s\tremaining: 4m 24s\n",
            "2840:\tlearn: 0.1648527\ttotal: 5m 48s\tremaining: 4m 24s\n",
            "2841:\tlearn: 0.1648414\ttotal: 5m 48s\tremaining: 4m 24s\n",
            "2842:\tlearn: 0.1648366\ttotal: 5m 48s\tremaining: 4m 24s\n",
            "2843:\tlearn: 0.1648162\ttotal: 5m 48s\tremaining: 4m 24s\n",
            "2844:\tlearn: 0.1648010\ttotal: 5m 48s\tremaining: 4m 24s\n",
            "2845:\tlearn: 0.1647926\ttotal: 5m 49s\tremaining: 4m 24s\n",
            "2846:\tlearn: 0.1647729\ttotal: 5m 49s\tremaining: 4m 24s\n",
            "2847:\tlearn: 0.1647539\ttotal: 5m 49s\tremaining: 4m 23s\n",
            "2848:\tlearn: 0.1647379\ttotal: 5m 49s\tremaining: 4m 23s\n",
            "2849:\tlearn: 0.1647056\ttotal: 5m 49s\tremaining: 4m 23s\n",
            "2850:\tlearn: 0.1646915\ttotal: 5m 49s\tremaining: 4m 23s\n",
            "2851:\tlearn: 0.1646809\ttotal: 5m 49s\tremaining: 4m 23s\n",
            "2852:\tlearn: 0.1646665\ttotal: 5m 49s\tremaining: 4m 23s\n",
            "2853:\tlearn: 0.1646490\ttotal: 5m 50s\tremaining: 4m 23s\n",
            "2854:\tlearn: 0.1646302\ttotal: 5m 50s\tremaining: 4m 23s\n",
            "2855:\tlearn: 0.1646075\ttotal: 5m 50s\tremaining: 4m 22s\n",
            "2856:\tlearn: 0.1645958\ttotal: 5m 50s\tremaining: 4m 22s\n",
            "2857:\tlearn: 0.1645784\ttotal: 5m 50s\tremaining: 4m 22s\n",
            "2858:\tlearn: 0.1645715\ttotal: 5m 50s\tremaining: 4m 22s\n",
            "2859:\tlearn: 0.1645539\ttotal: 5m 50s\tremaining: 4m 22s\n",
            "2860:\tlearn: 0.1645341\ttotal: 5m 50s\tremaining: 4m 22s\n",
            "2861:\tlearn: 0.1645265\ttotal: 5m 51s\tremaining: 4m 22s\n",
            "2862:\tlearn: 0.1645060\ttotal: 5m 51s\tremaining: 4m 22s\n",
            "2863:\tlearn: 0.1644852\ttotal: 5m 51s\tremaining: 4m 21s\n",
            "2864:\tlearn: 0.1644684\ttotal: 5m 51s\tremaining: 4m 21s\n",
            "2865:\tlearn: 0.1644507\ttotal: 5m 51s\tremaining: 4m 21s\n",
            "2866:\tlearn: 0.1644294\ttotal: 5m 51s\tremaining: 4m 21s\n",
            "2867:\tlearn: 0.1644039\ttotal: 5m 51s\tremaining: 4m 21s\n",
            "2868:\tlearn: 0.1643802\ttotal: 5m 51s\tremaining: 4m 21s\n",
            "2869:\tlearn: 0.1643628\ttotal: 5m 52s\tremaining: 4m 21s\n",
            "2870:\tlearn: 0.1643501\ttotal: 5m 52s\tremaining: 4m 21s\n",
            "2871:\tlearn: 0.1643456\ttotal: 5m 52s\tremaining: 4m 21s\n",
            "2872:\tlearn: 0.1643371\ttotal: 5m 52s\tremaining: 4m 20s\n",
            "2873:\tlearn: 0.1643121\ttotal: 5m 52s\tremaining: 4m 20s\n",
            "2874:\tlearn: 0.1642908\ttotal: 5m 52s\tremaining: 4m 20s\n",
            "2875:\tlearn: 0.1642781\ttotal: 5m 52s\tremaining: 4m 20s\n",
            "2876:\tlearn: 0.1642647\ttotal: 5m 52s\tremaining: 4m 20s\n",
            "2877:\tlearn: 0.1642484\ttotal: 5m 53s\tremaining: 4m 20s\n",
            "2878:\tlearn: 0.1642348\ttotal: 5m 53s\tremaining: 4m 20s\n",
            "2879:\tlearn: 0.1642272\ttotal: 5m 53s\tremaining: 4m 20s\n",
            "2880:\tlearn: 0.1642208\ttotal: 5m 53s\tremaining: 4m 19s\n",
            "2881:\tlearn: 0.1642064\ttotal: 5m 53s\tremaining: 4m 19s\n",
            "2882:\tlearn: 0.1641868\ttotal: 5m 53s\tremaining: 4m 19s\n",
            "2883:\tlearn: 0.1641789\ttotal: 5m 53s\tremaining: 4m 19s\n",
            "2884:\tlearn: 0.1641651\ttotal: 5m 53s\tremaining: 4m 19s\n",
            "2885:\tlearn: 0.1641552\ttotal: 5m 53s\tremaining: 4m 19s\n",
            "2886:\tlearn: 0.1641345\ttotal: 5m 54s\tremaining: 4m 19s\n",
            "2887:\tlearn: 0.1641125\ttotal: 5m 54s\tremaining: 4m 19s\n",
            "2888:\tlearn: 0.1640853\ttotal: 5m 54s\tremaining: 4m 18s\n",
            "2889:\tlearn: 0.1640733\ttotal: 5m 54s\tremaining: 4m 18s\n",
            "2890:\tlearn: 0.1640619\ttotal: 5m 54s\tremaining: 4m 18s\n",
            "2891:\tlearn: 0.1640429\ttotal: 5m 54s\tremaining: 4m 18s\n",
            "2892:\tlearn: 0.1640279\ttotal: 5m 54s\tremaining: 4m 18s\n",
            "2893:\tlearn: 0.1640132\ttotal: 5m 54s\tremaining: 4m 18s\n",
            "2894:\tlearn: 0.1640018\ttotal: 5m 55s\tremaining: 4m 18s\n",
            "2895:\tlearn: 0.1639864\ttotal: 5m 55s\tremaining: 4m 18s\n",
            "2896:\tlearn: 0.1639739\ttotal: 5m 55s\tremaining: 4m 17s\n",
            "2897:\tlearn: 0.1639628\ttotal: 5m 55s\tremaining: 4m 17s\n",
            "2898:\tlearn: 0.1639525\ttotal: 5m 55s\tremaining: 4m 17s\n",
            "2899:\tlearn: 0.1639345\ttotal: 5m 55s\tremaining: 4m 17s\n",
            "2900:\tlearn: 0.1639231\ttotal: 5m 55s\tremaining: 4m 17s\n",
            "2901:\tlearn: 0.1639129\ttotal: 5m 55s\tremaining: 4m 17s\n",
            "2902:\tlearn: 0.1639055\ttotal: 5m 56s\tremaining: 4m 17s\n",
            "2903:\tlearn: 0.1638889\ttotal: 5m 56s\tremaining: 4m 17s\n",
            "2904:\tlearn: 0.1638829\ttotal: 5m 56s\tremaining: 4m 16s\n",
            "2905:\tlearn: 0.1638770\ttotal: 5m 56s\tremaining: 4m 16s\n",
            "2906:\tlearn: 0.1638623\ttotal: 5m 56s\tremaining: 4m 16s\n",
            "2907:\tlearn: 0.1638391\ttotal: 5m 56s\tremaining: 4m 16s\n",
            "2908:\tlearn: 0.1638289\ttotal: 5m 56s\tremaining: 4m 16s\n",
            "2909:\tlearn: 0.1638062\ttotal: 5m 56s\tremaining: 4m 16s\n",
            "2910:\tlearn: 0.1637939\ttotal: 5m 56s\tremaining: 4m 16s\n",
            "2911:\tlearn: 0.1637789\ttotal: 5m 57s\tremaining: 4m 16s\n",
            "2912:\tlearn: 0.1637659\ttotal: 5m 57s\tremaining: 4m 15s\n",
            "2913:\tlearn: 0.1637448\ttotal: 5m 57s\tremaining: 4m 15s\n",
            "2914:\tlearn: 0.1637263\ttotal: 5m 57s\tremaining: 4m 15s\n",
            "2915:\tlearn: 0.1637178\ttotal: 5m 57s\tremaining: 4m 15s\n",
            "2916:\tlearn: 0.1637056\ttotal: 5m 57s\tremaining: 4m 15s\n",
            "2917:\tlearn: 0.1636891\ttotal: 5m 57s\tremaining: 4m 15s\n",
            "2918:\tlearn: 0.1636828\ttotal: 5m 57s\tremaining: 4m 15s\n",
            "2919:\tlearn: 0.1636683\ttotal: 5m 58s\tremaining: 4m 15s\n",
            "2920:\tlearn: 0.1636572\ttotal: 5m 58s\tremaining: 4m 14s\n",
            "2921:\tlearn: 0.1636351\ttotal: 5m 58s\tremaining: 4m 14s\n",
            "2922:\tlearn: 0.1636229\ttotal: 5m 58s\tremaining: 4m 14s\n",
            "2923:\tlearn: 0.1636136\ttotal: 5m 58s\tremaining: 4m 14s\n",
            "2924:\tlearn: 0.1635951\ttotal: 5m 58s\tremaining: 4m 14s\n",
            "2925:\tlearn: 0.1635812\ttotal: 5m 58s\tremaining: 4m 14s\n",
            "2926:\tlearn: 0.1635602\ttotal: 5m 58s\tremaining: 4m 14s\n",
            "2927:\tlearn: 0.1635433\ttotal: 5m 58s\tremaining: 4m 14s\n",
            "2928:\tlearn: 0.1635334\ttotal: 5m 59s\tremaining: 4m 13s\n",
            "2929:\tlearn: 0.1635181\ttotal: 5m 59s\tremaining: 4m 13s\n",
            "2930:\tlearn: 0.1635050\ttotal: 5m 59s\tremaining: 4m 13s\n",
            "2931:\tlearn: 0.1634987\ttotal: 5m 59s\tremaining: 4m 13s\n",
            "2932:\tlearn: 0.1634795\ttotal: 5m 59s\tremaining: 4m 13s\n",
            "2933:\tlearn: 0.1634582\ttotal: 5m 59s\tremaining: 4m 13s\n",
            "2934:\tlearn: 0.1634439\ttotal: 5m 59s\tremaining: 4m 13s\n",
            "2935:\tlearn: 0.1634289\ttotal: 5m 59s\tremaining: 4m 13s\n",
            "2936:\tlearn: 0.1634162\ttotal: 6m\tremaining: 4m 12s\n",
            "2937:\tlearn: 0.1634087\ttotal: 6m\tremaining: 4m 12s\n",
            "2938:\tlearn: 0.1634019\ttotal: 6m\tremaining: 4m 12s\n",
            "2939:\tlearn: 0.1633934\ttotal: 6m\tremaining: 4m 12s\n",
            "2940:\tlearn: 0.1633775\ttotal: 6m\tremaining: 4m 12s\n",
            "2941:\tlearn: 0.1633608\ttotal: 6m\tremaining: 4m 12s\n",
            "2942:\tlearn: 0.1633445\ttotal: 6m\tremaining: 4m 12s\n",
            "2943:\tlearn: 0.1633263\ttotal: 6m\tremaining: 4m 12s\n",
            "2944:\tlearn: 0.1633170\ttotal: 6m 1s\tremaining: 4m 11s\n",
            "2945:\tlearn: 0.1633074\ttotal: 6m 1s\tremaining: 4m 11s\n",
            "2946:\tlearn: 0.1632992\ttotal: 6m 1s\tremaining: 4m 11s\n",
            "2947:\tlearn: 0.1632829\ttotal: 6m 1s\tremaining: 4m 11s\n",
            "2948:\tlearn: 0.1632524\ttotal: 6m 1s\tremaining: 4m 11s\n",
            "2949:\tlearn: 0.1632287\ttotal: 6m 1s\tremaining: 4m 11s\n",
            "2950:\tlearn: 0.1632121\ttotal: 6m 1s\tremaining: 4m 11s\n",
            "2951:\tlearn: 0.1631981\ttotal: 6m 1s\tremaining: 4m 11s\n",
            "2952:\tlearn: 0.1631829\ttotal: 6m 1s\tremaining: 4m 10s\n",
            "2953:\tlearn: 0.1631640\ttotal: 6m 2s\tremaining: 4m 10s\n",
            "2954:\tlearn: 0.1631492\ttotal: 6m 2s\tremaining: 4m 10s\n",
            "2955:\tlearn: 0.1631265\ttotal: 6m 2s\tremaining: 4m 10s\n",
            "2956:\tlearn: 0.1631219\ttotal: 6m 2s\tremaining: 4m 10s\n",
            "2957:\tlearn: 0.1631085\ttotal: 6m 2s\tremaining: 4m 10s\n",
            "2958:\tlearn: 0.1630980\ttotal: 6m 2s\tremaining: 4m 10s\n",
            "2959:\tlearn: 0.1630901\ttotal: 6m 2s\tremaining: 4m 10s\n",
            "2960:\tlearn: 0.1630664\ttotal: 6m 2s\tremaining: 4m 9s\n",
            "2961:\tlearn: 0.1630553\ttotal: 6m 3s\tremaining: 4m 9s\n",
            "2962:\tlearn: 0.1630425\ttotal: 6m 3s\tremaining: 4m 9s\n",
            "2963:\tlearn: 0.1630197\ttotal: 6m 3s\tremaining: 4m 9s\n",
            "2964:\tlearn: 0.1630096\ttotal: 6m 3s\tremaining: 4m 9s\n",
            "2965:\tlearn: 0.1629881\ttotal: 6m 3s\tremaining: 4m 9s\n",
            "2966:\tlearn: 0.1629803\ttotal: 6m 3s\tremaining: 4m 9s\n",
            "2967:\tlearn: 0.1629731\ttotal: 6m 3s\tremaining: 4m 9s\n",
            "2968:\tlearn: 0.1629645\ttotal: 6m 3s\tremaining: 4m 8s\n",
            "2969:\tlearn: 0.1629535\ttotal: 6m 3s\tremaining: 4m 8s\n",
            "2970:\tlearn: 0.1629271\ttotal: 6m 4s\tremaining: 4m 8s\n",
            "2971:\tlearn: 0.1629018\ttotal: 6m 4s\tremaining: 4m 8s\n",
            "2972:\tlearn: 0.1628889\ttotal: 6m 4s\tremaining: 4m 8s\n",
            "2973:\tlearn: 0.1628644\ttotal: 6m 4s\tremaining: 4m 8s\n",
            "2974:\tlearn: 0.1628514\ttotal: 6m 4s\tremaining: 4m 8s\n",
            "2975:\tlearn: 0.1628334\ttotal: 6m 4s\tremaining: 4m 8s\n",
            "2976:\tlearn: 0.1628228\ttotal: 6m 4s\tremaining: 4m 7s\n",
            "2977:\tlearn: 0.1628075\ttotal: 6m 4s\tremaining: 4m 7s\n",
            "2978:\tlearn: 0.1627972\ttotal: 6m 5s\tremaining: 4m 7s\n",
            "2979:\tlearn: 0.1627779\ttotal: 6m 5s\tremaining: 4m 7s\n",
            "2980:\tlearn: 0.1627683\ttotal: 6m 5s\tremaining: 4m 7s\n",
            "2981:\tlearn: 0.1627539\ttotal: 6m 5s\tremaining: 4m 7s\n",
            "2982:\tlearn: 0.1627294\ttotal: 6m 5s\tremaining: 4m 7s\n",
            "2983:\tlearn: 0.1627108\ttotal: 6m 5s\tremaining: 4m 7s\n",
            "2984:\tlearn: 0.1627032\ttotal: 6m 5s\tremaining: 4m 6s\n",
            "2985:\tlearn: 0.1626856\ttotal: 6m 5s\tremaining: 4m 6s\n",
            "2986:\tlearn: 0.1626764\ttotal: 6m 6s\tremaining: 4m 6s\n",
            "2987:\tlearn: 0.1626633\ttotal: 6m 6s\tremaining: 4m 6s\n",
            "2988:\tlearn: 0.1626371\ttotal: 6m 6s\tremaining: 4m 6s\n",
            "2989:\tlearn: 0.1626293\ttotal: 6m 6s\tremaining: 4m 6s\n",
            "2990:\tlearn: 0.1626104\ttotal: 6m 6s\tremaining: 4m 6s\n",
            "2991:\tlearn: 0.1625987\ttotal: 6m 6s\tremaining: 4m 6s\n",
            "2992:\tlearn: 0.1625828\ttotal: 6m 6s\tremaining: 4m 5s\n",
            "2993:\tlearn: 0.1625684\ttotal: 6m 6s\tremaining: 4m 5s\n",
            "2994:\tlearn: 0.1625572\ttotal: 6m 7s\tremaining: 4m 5s\n",
            "2995:\tlearn: 0.1625502\ttotal: 6m 7s\tremaining: 4m 5s\n",
            "2996:\tlearn: 0.1625190\ttotal: 6m 7s\tremaining: 4m 5s\n",
            "2997:\tlearn: 0.1625070\ttotal: 6m 7s\tremaining: 4m 5s\n",
            "2998:\tlearn: 0.1624930\ttotal: 6m 7s\tremaining: 4m 5s\n",
            "2999:\tlearn: 0.1624608\ttotal: 6m 7s\tremaining: 4m 5s\n",
            "3000:\tlearn: 0.1624576\ttotal: 6m 7s\tremaining: 4m 4s\n",
            "3001:\tlearn: 0.1624487\ttotal: 6m 7s\tremaining: 4m 4s\n",
            "3002:\tlearn: 0.1624334\ttotal: 6m 7s\tremaining: 4m 4s\n",
            "3003:\tlearn: 0.1624215\ttotal: 6m 8s\tremaining: 4m 4s\n",
            "3004:\tlearn: 0.1624150\ttotal: 6m 8s\tremaining: 4m 4s\n",
            "3005:\tlearn: 0.1624030\ttotal: 6m 8s\tremaining: 4m 4s\n",
            "3006:\tlearn: 0.1623921\ttotal: 6m 8s\tremaining: 4m 4s\n",
            "3007:\tlearn: 0.1623824\ttotal: 6m 8s\tremaining: 4m 4s\n",
            "3008:\tlearn: 0.1623593\ttotal: 6m 8s\tremaining: 4m 3s\n",
            "3009:\tlearn: 0.1623470\ttotal: 6m 8s\tremaining: 4m 3s\n",
            "3010:\tlearn: 0.1623361\ttotal: 6m 8s\tremaining: 4m 3s\n",
            "3011:\tlearn: 0.1623207\ttotal: 6m 9s\tremaining: 4m 3s\n",
            "3012:\tlearn: 0.1623034\ttotal: 6m 9s\tremaining: 4m 3s\n",
            "3013:\tlearn: 0.1622849\ttotal: 6m 9s\tremaining: 4m 3s\n",
            "3014:\tlearn: 0.1622601\ttotal: 6m 9s\tremaining: 4m 3s\n",
            "3015:\tlearn: 0.1622408\ttotal: 6m 9s\tremaining: 4m 3s\n",
            "3016:\tlearn: 0.1622323\ttotal: 6m 9s\tremaining: 4m 2s\n",
            "3017:\tlearn: 0.1622141\ttotal: 6m 9s\tremaining: 4m 2s\n",
            "3018:\tlearn: 0.1622039\ttotal: 6m 9s\tremaining: 4m 2s\n",
            "3019:\tlearn: 0.1621972\ttotal: 6m 9s\tremaining: 4m 2s\n",
            "3020:\tlearn: 0.1621767\ttotal: 6m 10s\tremaining: 4m 2s\n",
            "3021:\tlearn: 0.1621605\ttotal: 6m 10s\tremaining: 4m 2s\n",
            "3022:\tlearn: 0.1621476\ttotal: 6m 10s\tremaining: 4m 2s\n",
            "3023:\tlearn: 0.1621404\ttotal: 6m 10s\tremaining: 4m 2s\n",
            "3024:\tlearn: 0.1621314\ttotal: 6m 10s\tremaining: 4m 1s\n",
            "3025:\tlearn: 0.1621173\ttotal: 6m 10s\tremaining: 4m 1s\n",
            "3026:\tlearn: 0.1621009\ttotal: 6m 10s\tremaining: 4m 1s\n",
            "3027:\tlearn: 0.1620871\ttotal: 6m 10s\tremaining: 4m 1s\n",
            "3028:\tlearn: 0.1620717\ttotal: 6m 11s\tremaining: 4m 1s\n",
            "3029:\tlearn: 0.1620580\ttotal: 6m 11s\tremaining: 4m 1s\n",
            "3030:\tlearn: 0.1620478\ttotal: 6m 11s\tremaining: 4m 1s\n",
            "3031:\tlearn: 0.1620293\ttotal: 6m 11s\tremaining: 4m 1s\n",
            "3032:\tlearn: 0.1620167\ttotal: 6m 11s\tremaining: 4m 1s\n",
            "3033:\tlearn: 0.1620014\ttotal: 6m 11s\tremaining: 4m\n",
            "3034:\tlearn: 0.1619908\ttotal: 6m 11s\tremaining: 4m\n",
            "3035:\tlearn: 0.1619754\ttotal: 6m 11s\tremaining: 4m\n",
            "3036:\tlearn: 0.1619665\ttotal: 6m 12s\tremaining: 4m\n",
            "3037:\tlearn: 0.1619615\ttotal: 6m 12s\tremaining: 4m\n",
            "3038:\tlearn: 0.1619514\ttotal: 6m 12s\tremaining: 4m\n",
            "3039:\tlearn: 0.1619294\ttotal: 6m 12s\tremaining: 4m\n",
            "3040:\tlearn: 0.1619097\ttotal: 6m 12s\tremaining: 3m 59s\n",
            "3041:\tlearn: 0.1618878\ttotal: 6m 12s\tremaining: 3m 59s\n",
            "3042:\tlearn: 0.1618781\ttotal: 6m 12s\tremaining: 3m 59s\n",
            "3043:\tlearn: 0.1618714\ttotal: 6m 12s\tremaining: 3m 59s\n",
            "3044:\tlearn: 0.1618469\ttotal: 6m 13s\tremaining: 3m 59s\n",
            "3045:\tlearn: 0.1618362\ttotal: 6m 13s\tremaining: 3m 59s\n",
            "3046:\tlearn: 0.1618254\ttotal: 6m 13s\tremaining: 3m 59s\n",
            "3047:\tlearn: 0.1618051\ttotal: 6m 13s\tremaining: 3m 59s\n",
            "3048:\tlearn: 0.1617869\ttotal: 6m 13s\tremaining: 3m 59s\n",
            "3049:\tlearn: 0.1617692\ttotal: 6m 13s\tremaining: 3m 58s\n",
            "3050:\tlearn: 0.1617598\ttotal: 6m 13s\tremaining: 3m 58s\n",
            "3051:\tlearn: 0.1617521\ttotal: 6m 13s\tremaining: 3m 58s\n",
            "3052:\tlearn: 0.1617341\ttotal: 6m 13s\tremaining: 3m 58s\n",
            "3053:\tlearn: 0.1617166\ttotal: 6m 14s\tremaining: 3m 58s\n",
            "3054:\tlearn: 0.1617046\ttotal: 6m 14s\tremaining: 3m 58s\n",
            "3055:\tlearn: 0.1616891\ttotal: 6m 14s\tremaining: 3m 58s\n",
            "3056:\tlearn: 0.1616746\ttotal: 6m 14s\tremaining: 3m 57s\n",
            "3057:\tlearn: 0.1616629\ttotal: 6m 14s\tremaining: 3m 57s\n",
            "3058:\tlearn: 0.1616445\ttotal: 6m 14s\tremaining: 3m 57s\n",
            "3059:\tlearn: 0.1616230\ttotal: 6m 14s\tremaining: 3m 57s\n",
            "3060:\tlearn: 0.1616119\ttotal: 6m 14s\tremaining: 3m 57s\n",
            "3061:\tlearn: 0.1615937\ttotal: 6m 15s\tremaining: 3m 57s\n",
            "3062:\tlearn: 0.1615800\ttotal: 6m 15s\tremaining: 3m 57s\n",
            "3063:\tlearn: 0.1615715\ttotal: 6m 15s\tremaining: 3m 57s\n",
            "3064:\tlearn: 0.1615563\ttotal: 6m 15s\tremaining: 3m 57s\n",
            "3065:\tlearn: 0.1615344\ttotal: 6m 15s\tremaining: 3m 56s\n",
            "3066:\tlearn: 0.1615203\ttotal: 6m 15s\tremaining: 3m 56s\n",
            "3067:\tlearn: 0.1615001\ttotal: 6m 15s\tremaining: 3m 56s\n",
            "3068:\tlearn: 0.1614929\ttotal: 6m 15s\tremaining: 3m 56s\n",
            "3069:\tlearn: 0.1614770\ttotal: 6m 16s\tremaining: 3m 56s\n",
            "3070:\tlearn: 0.1614708\ttotal: 6m 16s\tremaining: 3m 56s\n",
            "3071:\tlearn: 0.1614564\ttotal: 6m 16s\tremaining: 3m 56s\n",
            "3072:\tlearn: 0.1614480\ttotal: 6m 16s\tremaining: 3m 56s\n",
            "3073:\tlearn: 0.1614323\ttotal: 6m 16s\tremaining: 3m 55s\n",
            "3074:\tlearn: 0.1614098\ttotal: 6m 16s\tremaining: 3m 55s\n",
            "3075:\tlearn: 0.1613912\ttotal: 6m 16s\tremaining: 3m 55s\n",
            "3076:\tlearn: 0.1613763\ttotal: 6m 16s\tremaining: 3m 55s\n",
            "3077:\tlearn: 0.1613710\ttotal: 6m 16s\tremaining: 3m 55s\n",
            "3078:\tlearn: 0.1613597\ttotal: 6m 17s\tremaining: 3m 55s\n",
            "3079:\tlearn: 0.1613488\ttotal: 6m 17s\tremaining: 3m 55s\n",
            "3080:\tlearn: 0.1613400\ttotal: 6m 17s\tremaining: 3m 54s\n",
            "3081:\tlearn: 0.1613305\ttotal: 6m 17s\tremaining: 3m 54s\n",
            "3082:\tlearn: 0.1613157\ttotal: 6m 17s\tremaining: 3m 54s\n",
            "3083:\tlearn: 0.1612875\ttotal: 6m 17s\tremaining: 3m 54s\n",
            "3084:\tlearn: 0.1612693\ttotal: 6m 17s\tremaining: 3m 54s\n",
            "3085:\tlearn: 0.1612625\ttotal: 6m 17s\tremaining: 3m 54s\n",
            "3086:\tlearn: 0.1612317\ttotal: 6m 18s\tremaining: 3m 54s\n",
            "3087:\tlearn: 0.1612154\ttotal: 6m 18s\tremaining: 3m 54s\n",
            "3088:\tlearn: 0.1612056\ttotal: 6m 18s\tremaining: 3m 54s\n",
            "3089:\tlearn: 0.1611820\ttotal: 6m 18s\tremaining: 3m 53s\n",
            "3090:\tlearn: 0.1611622\ttotal: 6m 18s\tremaining: 3m 53s\n",
            "3091:\tlearn: 0.1611389\ttotal: 6m 18s\tremaining: 3m 53s\n",
            "3092:\tlearn: 0.1611309\ttotal: 6m 18s\tremaining: 3m 53s\n",
            "3093:\tlearn: 0.1611160\ttotal: 6m 18s\tremaining: 3m 53s\n",
            "3094:\tlearn: 0.1610981\ttotal: 6m 19s\tremaining: 3m 53s\n",
            "3095:\tlearn: 0.1610832\ttotal: 6m 19s\tremaining: 3m 53s\n",
            "3096:\tlearn: 0.1610586\ttotal: 6m 19s\tremaining: 3m 53s\n",
            "3097:\tlearn: 0.1610453\ttotal: 6m 19s\tremaining: 3m 52s\n",
            "3098:\tlearn: 0.1610389\ttotal: 6m 19s\tremaining: 3m 52s\n",
            "3099:\tlearn: 0.1610303\ttotal: 6m 19s\tremaining: 3m 52s\n",
            "3100:\tlearn: 0.1610157\ttotal: 6m 19s\tremaining: 3m 52s\n",
            "3101:\tlearn: 0.1609976\ttotal: 6m 19s\tremaining: 3m 52s\n",
            "3102:\tlearn: 0.1609824\ttotal: 6m 19s\tremaining: 3m 52s\n",
            "3103:\tlearn: 0.1609726\ttotal: 6m 20s\tremaining: 3m 52s\n",
            "3104:\tlearn: 0.1609610\ttotal: 6m 20s\tremaining: 3m 52s\n",
            "3105:\tlearn: 0.1609369\ttotal: 6m 20s\tremaining: 3m 51s\n",
            "3106:\tlearn: 0.1609281\ttotal: 6m 20s\tremaining: 3m 51s\n",
            "3107:\tlearn: 0.1609093\ttotal: 6m 20s\tremaining: 3m 51s\n",
            "3108:\tlearn: 0.1608964\ttotal: 6m 20s\tremaining: 3m 51s\n",
            "3109:\tlearn: 0.1608821\ttotal: 6m 20s\tremaining: 3m 51s\n",
            "3110:\tlearn: 0.1608753\ttotal: 6m 20s\tremaining: 3m 51s\n",
            "3111:\tlearn: 0.1608527\ttotal: 6m 21s\tremaining: 3m 51s\n",
            "3112:\tlearn: 0.1608319\ttotal: 6m 21s\tremaining: 3m 51s\n",
            "3113:\tlearn: 0.1608111\ttotal: 6m 21s\tremaining: 3m 50s\n",
            "3114:\tlearn: 0.1607922\ttotal: 6m 21s\tremaining: 3m 50s\n",
            "3115:\tlearn: 0.1607785\ttotal: 6m 21s\tremaining: 3m 50s\n",
            "3116:\tlearn: 0.1607699\ttotal: 6m 21s\tremaining: 3m 50s\n",
            "3117:\tlearn: 0.1607603\ttotal: 6m 21s\tremaining: 3m 50s\n",
            "3118:\tlearn: 0.1607512\ttotal: 6m 21s\tremaining: 3m 50s\n",
            "3119:\tlearn: 0.1607407\ttotal: 6m 22s\tremaining: 3m 50s\n",
            "3120:\tlearn: 0.1607268\ttotal: 6m 22s\tremaining: 3m 50s\n",
            "3121:\tlearn: 0.1607205\ttotal: 6m 22s\tremaining: 3m 49s\n",
            "3122:\tlearn: 0.1607094\ttotal: 6m 22s\tremaining: 3m 49s\n",
            "3123:\tlearn: 0.1606952\ttotal: 6m 22s\tremaining: 3m 49s\n",
            "3124:\tlearn: 0.1606812\ttotal: 6m 22s\tremaining: 3m 49s\n",
            "3125:\tlearn: 0.1606609\ttotal: 6m 22s\tremaining: 3m 49s\n",
            "3126:\tlearn: 0.1606450\ttotal: 6m 22s\tremaining: 3m 49s\n",
            "3127:\tlearn: 0.1606345\ttotal: 6m 22s\tremaining: 3m 49s\n",
            "3128:\tlearn: 0.1606208\ttotal: 6m 23s\tremaining: 3m 49s\n",
            "3129:\tlearn: 0.1606066\ttotal: 6m 23s\tremaining: 3m 48s\n",
            "3130:\tlearn: 0.1605932\ttotal: 6m 23s\tremaining: 3m 48s\n",
            "3131:\tlearn: 0.1605814\ttotal: 6m 23s\tremaining: 3m 48s\n",
            "3132:\tlearn: 0.1605698\ttotal: 6m 23s\tremaining: 3m 48s\n",
            "3133:\tlearn: 0.1605522\ttotal: 6m 23s\tremaining: 3m 48s\n",
            "3134:\tlearn: 0.1605371\ttotal: 6m 23s\tremaining: 3m 48s\n",
            "3135:\tlearn: 0.1605303\ttotal: 6m 23s\tremaining: 3m 48s\n",
            "3136:\tlearn: 0.1605116\ttotal: 6m 24s\tremaining: 3m 48s\n",
            "3137:\tlearn: 0.1604981\ttotal: 6m 24s\tremaining: 3m 47s\n",
            "3138:\tlearn: 0.1604861\ttotal: 6m 24s\tremaining: 3m 47s\n",
            "3139:\tlearn: 0.1604803\ttotal: 6m 24s\tremaining: 3m 47s\n",
            "3140:\tlearn: 0.1604704\ttotal: 6m 24s\tremaining: 3m 47s\n",
            "3141:\tlearn: 0.1604643\ttotal: 6m 24s\tremaining: 3m 47s\n",
            "3142:\tlearn: 0.1604536\ttotal: 6m 24s\tremaining: 3m 47s\n",
            "3143:\tlearn: 0.1604394\ttotal: 6m 24s\tremaining: 3m 47s\n",
            "3144:\tlearn: 0.1604280\ttotal: 6m 24s\tremaining: 3m 47s\n",
            "3145:\tlearn: 0.1604084\ttotal: 6m 25s\tremaining: 3m 46s\n",
            "3146:\tlearn: 0.1603893\ttotal: 6m 25s\tremaining: 3m 46s\n",
            "3147:\tlearn: 0.1603704\ttotal: 6m 25s\tremaining: 3m 46s\n",
            "3148:\tlearn: 0.1603592\ttotal: 6m 25s\tremaining: 3m 46s\n",
            "3149:\tlearn: 0.1603522\ttotal: 6m 25s\tremaining: 3m 46s\n",
            "3150:\tlearn: 0.1603402\ttotal: 6m 25s\tremaining: 3m 46s\n",
            "3151:\tlearn: 0.1603277\ttotal: 6m 25s\tremaining: 3m 46s\n",
            "3152:\tlearn: 0.1603127\ttotal: 6m 25s\tremaining: 3m 46s\n",
            "3153:\tlearn: 0.1602951\ttotal: 6m 26s\tremaining: 3m 45s\n",
            "3154:\tlearn: 0.1602816\ttotal: 6m 26s\tremaining: 3m 45s\n",
            "3155:\tlearn: 0.1602672\ttotal: 6m 26s\tremaining: 3m 45s\n",
            "3156:\tlearn: 0.1602531\ttotal: 6m 26s\tremaining: 3m 45s\n",
            "3157:\tlearn: 0.1602397\ttotal: 6m 26s\tremaining: 3m 45s\n",
            "3158:\tlearn: 0.1602317\ttotal: 6m 26s\tremaining: 3m 45s\n",
            "3159:\tlearn: 0.1602120\ttotal: 6m 26s\tremaining: 3m 45s\n",
            "3160:\tlearn: 0.1602062\ttotal: 6m 26s\tremaining: 3m 45s\n",
            "3161:\tlearn: 0.1601932\ttotal: 6m 26s\tremaining: 3m 44s\n",
            "3162:\tlearn: 0.1601818\ttotal: 6m 27s\tremaining: 3m 44s\n",
            "3163:\tlearn: 0.1601695\ttotal: 6m 27s\tremaining: 3m 44s\n",
            "3164:\tlearn: 0.1601537\ttotal: 6m 27s\tremaining: 3m 44s\n",
            "3165:\tlearn: 0.1601309\ttotal: 6m 27s\tremaining: 3m 44s\n",
            "3166:\tlearn: 0.1601169\ttotal: 6m 27s\tremaining: 3m 44s\n",
            "3167:\tlearn: 0.1600998\ttotal: 6m 27s\tremaining: 3m 44s\n",
            "3168:\tlearn: 0.1600920\ttotal: 6m 27s\tremaining: 3m 44s\n",
            "3169:\tlearn: 0.1600706\ttotal: 6m 27s\tremaining: 3m 43s\n",
            "3170:\tlearn: 0.1600293\ttotal: 6m 28s\tremaining: 3m 43s\n",
            "3171:\tlearn: 0.1600187\ttotal: 6m 28s\tremaining: 3m 43s\n",
            "3172:\tlearn: 0.1600017\ttotal: 6m 28s\tremaining: 3m 43s\n",
            "3173:\tlearn: 0.1599925\ttotal: 6m 28s\tremaining: 3m 43s\n",
            "3174:\tlearn: 0.1599692\ttotal: 6m 28s\tremaining: 3m 43s\n",
            "3175:\tlearn: 0.1599489\ttotal: 6m 28s\tremaining: 3m 43s\n",
            "3176:\tlearn: 0.1599350\ttotal: 6m 28s\tremaining: 3m 43s\n",
            "3177:\tlearn: 0.1599260\ttotal: 6m 29s\tremaining: 3m 43s\n",
            "3178:\tlearn: 0.1599104\ttotal: 6m 29s\tremaining: 3m 42s\n",
            "3179:\tlearn: 0.1598983\ttotal: 6m 29s\tremaining: 3m 42s\n",
            "3180:\tlearn: 0.1598898\ttotal: 6m 29s\tremaining: 3m 42s\n",
            "3181:\tlearn: 0.1598841\ttotal: 6m 29s\tremaining: 3m 42s\n",
            "3182:\tlearn: 0.1598576\ttotal: 6m 29s\tremaining: 3m 42s\n",
            "3183:\tlearn: 0.1598357\ttotal: 6m 29s\tremaining: 3m 42s\n",
            "3184:\tlearn: 0.1598205\ttotal: 6m 29s\tremaining: 3m 42s\n",
            "3185:\tlearn: 0.1598161\ttotal: 6m 29s\tremaining: 3m 42s\n",
            "3186:\tlearn: 0.1597989\ttotal: 6m 30s\tremaining: 3m 41s\n",
            "3187:\tlearn: 0.1597879\ttotal: 6m 30s\tremaining: 3m 41s\n",
            "3188:\tlearn: 0.1597743\ttotal: 6m 30s\tremaining: 3m 41s\n",
            "3189:\tlearn: 0.1597581\ttotal: 6m 30s\tremaining: 3m 41s\n",
            "3190:\tlearn: 0.1597520\ttotal: 6m 30s\tremaining: 3m 41s\n",
            "3191:\tlearn: 0.1597365\ttotal: 6m 30s\tremaining: 3m 41s\n",
            "3192:\tlearn: 0.1597263\ttotal: 6m 30s\tremaining: 3m 41s\n",
            "3193:\tlearn: 0.1597189\ttotal: 6m 30s\tremaining: 3m 41s\n",
            "3194:\tlearn: 0.1597021\ttotal: 6m 31s\tremaining: 3m 40s\n",
            "3195:\tlearn: 0.1596861\ttotal: 6m 31s\tremaining: 3m 40s\n",
            "3196:\tlearn: 0.1596654\ttotal: 6m 31s\tremaining: 3m 40s\n",
            "3197:\tlearn: 0.1596534\ttotal: 6m 31s\tremaining: 3m 40s\n",
            "3198:\tlearn: 0.1596433\ttotal: 6m 31s\tremaining: 3m 40s\n",
            "3199:\tlearn: 0.1596331\ttotal: 6m 31s\tremaining: 3m 40s\n",
            "3200:\tlearn: 0.1596202\ttotal: 6m 31s\tremaining: 3m 40s\n",
            "3201:\tlearn: 0.1596029\ttotal: 6m 31s\tremaining: 3m 40s\n",
            "3202:\tlearn: 0.1595827\ttotal: 6m 32s\tremaining: 3m 39s\n",
            "3203:\tlearn: 0.1595693\ttotal: 6m 32s\tremaining: 3m 39s\n",
            "3204:\tlearn: 0.1595559\ttotal: 6m 32s\tremaining: 3m 39s\n",
            "3205:\tlearn: 0.1595343\ttotal: 6m 32s\tremaining: 3m 39s\n",
            "3206:\tlearn: 0.1595239\ttotal: 6m 32s\tremaining: 3m 39s\n",
            "3207:\tlearn: 0.1595048\ttotal: 6m 32s\tremaining: 3m 39s\n",
            "3208:\tlearn: 0.1594917\ttotal: 6m 32s\tremaining: 3m 39s\n",
            "3209:\tlearn: 0.1594839\ttotal: 6m 32s\tremaining: 3m 39s\n",
            "3210:\tlearn: 0.1594722\ttotal: 6m 33s\tremaining: 3m 38s\n",
            "3211:\tlearn: 0.1594600\ttotal: 6m 33s\tremaining: 3m 38s\n",
            "3212:\tlearn: 0.1594536\ttotal: 6m 33s\tremaining: 3m 38s\n",
            "3213:\tlearn: 0.1594430\ttotal: 6m 33s\tremaining: 3m 38s\n",
            "3214:\tlearn: 0.1594268\ttotal: 6m 33s\tremaining: 3m 38s\n",
            "3215:\tlearn: 0.1594109\ttotal: 6m 33s\tremaining: 3m 38s\n",
            "3216:\tlearn: 0.1593987\ttotal: 6m 33s\tremaining: 3m 38s\n",
            "3217:\tlearn: 0.1593799\ttotal: 6m 33s\tremaining: 3m 38s\n",
            "3218:\tlearn: 0.1593624\ttotal: 6m 34s\tremaining: 3m 37s\n",
            "3219:\tlearn: 0.1593498\ttotal: 6m 34s\tremaining: 3m 37s\n",
            "3220:\tlearn: 0.1593384\ttotal: 6m 34s\tremaining: 3m 37s\n",
            "3221:\tlearn: 0.1593313\ttotal: 6m 34s\tremaining: 3m 37s\n",
            "3222:\tlearn: 0.1593058\ttotal: 6m 34s\tremaining: 3m 37s\n",
            "3223:\tlearn: 0.1592806\ttotal: 6m 34s\tremaining: 3m 37s\n",
            "3224:\tlearn: 0.1592495\ttotal: 6m 34s\tremaining: 3m 37s\n",
            "3225:\tlearn: 0.1592414\ttotal: 6m 34s\tremaining: 3m 37s\n",
            "3226:\tlearn: 0.1592164\ttotal: 6m 34s\tremaining: 3m 37s\n",
            "3227:\tlearn: 0.1592070\ttotal: 6m 35s\tremaining: 3m 36s\n",
            "3228:\tlearn: 0.1591971\ttotal: 6m 35s\tremaining: 3m 36s\n",
            "3229:\tlearn: 0.1591823\ttotal: 6m 35s\tremaining: 3m 36s\n",
            "3230:\tlearn: 0.1591520\ttotal: 6m 35s\tremaining: 3m 36s\n",
            "3231:\tlearn: 0.1591433\ttotal: 6m 35s\tremaining: 3m 36s\n",
            "3232:\tlearn: 0.1591366\ttotal: 6m 35s\tremaining: 3m 36s\n",
            "3233:\tlearn: 0.1591255\ttotal: 6m 35s\tremaining: 3m 36s\n",
            "3234:\tlearn: 0.1591089\ttotal: 6m 35s\tremaining: 3m 36s\n",
            "3235:\tlearn: 0.1591009\ttotal: 6m 36s\tremaining: 3m 35s\n",
            "3236:\tlearn: 0.1590884\ttotal: 6m 36s\tremaining: 3m 35s\n",
            "3237:\tlearn: 0.1590789\ttotal: 6m 36s\tremaining: 3m 35s\n",
            "3238:\tlearn: 0.1590629\ttotal: 6m 36s\tremaining: 3m 35s\n",
            "3239:\tlearn: 0.1590569\ttotal: 6m 36s\tremaining: 3m 35s\n",
            "3240:\tlearn: 0.1590475\ttotal: 6m 36s\tremaining: 3m 35s\n",
            "3241:\tlearn: 0.1590379\ttotal: 6m 36s\tremaining: 3m 35s\n",
            "3242:\tlearn: 0.1590262\ttotal: 6m 36s\tremaining: 3m 35s\n",
            "3243:\tlearn: 0.1590139\ttotal: 6m 37s\tremaining: 3m 34s\n",
            "3244:\tlearn: 0.1590013\ttotal: 6m 37s\tremaining: 3m 34s\n",
            "3245:\tlearn: 0.1589835\ttotal: 6m 37s\tremaining: 3m 34s\n",
            "3246:\tlearn: 0.1589733\ttotal: 6m 37s\tremaining: 3m 34s\n",
            "3247:\tlearn: 0.1589512\ttotal: 6m 37s\tremaining: 3m 34s\n",
            "3248:\tlearn: 0.1589358\ttotal: 6m 37s\tremaining: 3m 34s\n",
            "3249:\tlearn: 0.1589280\ttotal: 6m 37s\tremaining: 3m 34s\n",
            "3250:\tlearn: 0.1589186\ttotal: 6m 37s\tremaining: 3m 34s\n",
            "3251:\tlearn: 0.1589090\ttotal: 6m 37s\tremaining: 3m 33s\n",
            "3252:\tlearn: 0.1588891\ttotal: 6m 38s\tremaining: 3m 33s\n",
            "3253:\tlearn: 0.1588846\ttotal: 6m 38s\tremaining: 3m 33s\n",
            "3254:\tlearn: 0.1588743\ttotal: 6m 38s\tremaining: 3m 33s\n",
            "3255:\tlearn: 0.1588584\ttotal: 6m 38s\tremaining: 3m 33s\n",
            "3256:\tlearn: 0.1588368\ttotal: 6m 38s\tremaining: 3m 33s\n",
            "3257:\tlearn: 0.1588270\ttotal: 6m 38s\tremaining: 3m 33s\n",
            "3258:\tlearn: 0.1588158\ttotal: 6m 38s\tremaining: 3m 33s\n",
            "3259:\tlearn: 0.1588047\ttotal: 6m 38s\tremaining: 3m 32s\n",
            "3260:\tlearn: 0.1587824\ttotal: 6m 39s\tremaining: 3m 32s\n",
            "3261:\tlearn: 0.1587773\ttotal: 6m 39s\tremaining: 3m 32s\n",
            "3262:\tlearn: 0.1587657\ttotal: 6m 39s\tremaining: 3m 32s\n",
            "3263:\tlearn: 0.1587501\ttotal: 6m 39s\tremaining: 3m 32s\n",
            "3264:\tlearn: 0.1587354\ttotal: 6m 39s\tremaining: 3m 32s\n",
            "3265:\tlearn: 0.1587308\ttotal: 6m 39s\tremaining: 3m 32s\n",
            "3266:\tlearn: 0.1587137\ttotal: 6m 39s\tremaining: 3m 32s\n",
            "3267:\tlearn: 0.1587041\ttotal: 6m 39s\tremaining: 3m 31s\n",
            "3268:\tlearn: 0.1586903\ttotal: 6m 39s\tremaining: 3m 31s\n",
            "3269:\tlearn: 0.1586778\ttotal: 6m 40s\tremaining: 3m 31s\n",
            "3270:\tlearn: 0.1586684\ttotal: 6m 40s\tremaining: 3m 31s\n",
            "3271:\tlearn: 0.1586590\ttotal: 6m 40s\tremaining: 3m 31s\n",
            "3272:\tlearn: 0.1586451\ttotal: 6m 40s\tremaining: 3m 31s\n",
            "3273:\tlearn: 0.1586321\ttotal: 6m 40s\tremaining: 3m 31s\n",
            "3274:\tlearn: 0.1586150\ttotal: 6m 40s\tremaining: 3m 31s\n",
            "3275:\tlearn: 0.1585954\ttotal: 6m 40s\tremaining: 3m 30s\n",
            "3276:\tlearn: 0.1585850\ttotal: 6m 40s\tremaining: 3m 30s\n",
            "3277:\tlearn: 0.1585735\ttotal: 6m 41s\tremaining: 3m 30s\n",
            "3278:\tlearn: 0.1585607\ttotal: 6m 41s\tremaining: 3m 30s\n",
            "3279:\tlearn: 0.1585457\ttotal: 6m 41s\tremaining: 3m 30s\n",
            "3280:\tlearn: 0.1585353\ttotal: 6m 41s\tremaining: 3m 30s\n",
            "3281:\tlearn: 0.1585246\ttotal: 6m 41s\tremaining: 3m 30s\n",
            "3282:\tlearn: 0.1585167\ttotal: 6m 41s\tremaining: 3m 30s\n",
            "3283:\tlearn: 0.1585064\ttotal: 6m 41s\tremaining: 3m 29s\n",
            "3284:\tlearn: 0.1584951\ttotal: 6m 41s\tremaining: 3m 29s\n",
            "3285:\tlearn: 0.1584817\ttotal: 6m 42s\tremaining: 3m 29s\n",
            "3286:\tlearn: 0.1584691\ttotal: 6m 42s\tremaining: 3m 29s\n",
            "3287:\tlearn: 0.1584616\ttotal: 6m 42s\tremaining: 3m 29s\n",
            "3288:\tlearn: 0.1584511\ttotal: 6m 42s\tremaining: 3m 29s\n",
            "3289:\tlearn: 0.1584232\ttotal: 6m 42s\tremaining: 3m 29s\n",
            "3290:\tlearn: 0.1583994\ttotal: 6m 42s\tremaining: 3m 29s\n",
            "3291:\tlearn: 0.1583866\ttotal: 6m 42s\tremaining: 3m 28s\n",
            "3292:\tlearn: 0.1583748\ttotal: 6m 42s\tremaining: 3m 28s\n",
            "3293:\tlearn: 0.1583635\ttotal: 6m 42s\tremaining: 3m 28s\n",
            "3294:\tlearn: 0.1583460\ttotal: 6m 43s\tremaining: 3m 28s\n",
            "3295:\tlearn: 0.1583288\ttotal: 6m 43s\tremaining: 3m 28s\n",
            "3296:\tlearn: 0.1583154\ttotal: 6m 43s\tremaining: 3m 28s\n",
            "3297:\tlearn: 0.1583033\ttotal: 6m 43s\tremaining: 3m 28s\n",
            "3298:\tlearn: 0.1582915\ttotal: 6m 43s\tremaining: 3m 28s\n",
            "3299:\tlearn: 0.1582792\ttotal: 6m 43s\tremaining: 3m 27s\n",
            "3300:\tlearn: 0.1582671\ttotal: 6m 43s\tremaining: 3m 27s\n",
            "3301:\tlearn: 0.1582588\ttotal: 6m 43s\tremaining: 3m 27s\n",
            "3302:\tlearn: 0.1582432\ttotal: 6m 44s\tremaining: 3m 27s\n",
            "3303:\tlearn: 0.1582309\ttotal: 6m 44s\tremaining: 3m 27s\n",
            "3304:\tlearn: 0.1582237\ttotal: 6m 44s\tremaining: 3m 27s\n",
            "3305:\tlearn: 0.1582192\ttotal: 6m 44s\tremaining: 3m 27s\n",
            "3306:\tlearn: 0.1582103\ttotal: 6m 44s\tremaining: 3m 27s\n",
            "3307:\tlearn: 0.1581992\ttotal: 6m 44s\tremaining: 3m 26s\n",
            "3308:\tlearn: 0.1581898\ttotal: 6m 44s\tremaining: 3m 26s\n",
            "3309:\tlearn: 0.1581744\ttotal: 6m 44s\tremaining: 3m 26s\n",
            "3310:\tlearn: 0.1581706\ttotal: 6m 44s\tremaining: 3m 26s\n",
            "3311:\tlearn: 0.1581551\ttotal: 6m 44s\tremaining: 3m 26s\n",
            "3312:\tlearn: 0.1581324\ttotal: 6m 45s\tremaining: 3m 26s\n",
            "3313:\tlearn: 0.1581232\ttotal: 6m 45s\tremaining: 3m 26s\n",
            "3314:\tlearn: 0.1581112\ttotal: 6m 45s\tremaining: 3m 26s\n",
            "3315:\tlearn: 0.1580998\ttotal: 6m 45s\tremaining: 3m 25s\n",
            "3316:\tlearn: 0.1580760\ttotal: 6m 45s\tremaining: 3m 25s\n",
            "3317:\tlearn: 0.1580694\ttotal: 6m 45s\tremaining: 3m 25s\n",
            "3318:\tlearn: 0.1580507\ttotal: 6m 45s\tremaining: 3m 25s\n",
            "3319:\tlearn: 0.1580361\ttotal: 6m 45s\tremaining: 3m 25s\n",
            "3320:\tlearn: 0.1580211\ttotal: 6m 46s\tremaining: 3m 25s\n",
            "3321:\tlearn: 0.1580113\ttotal: 6m 46s\tremaining: 3m 25s\n",
            "3322:\tlearn: 0.1580035\ttotal: 6m 46s\tremaining: 3m 25s\n",
            "3323:\tlearn: 0.1579933\ttotal: 6m 46s\tremaining: 3m 24s\n",
            "3324:\tlearn: 0.1579548\ttotal: 6m 46s\tremaining: 3m 24s\n",
            "3325:\tlearn: 0.1579371\ttotal: 6m 46s\tremaining: 3m 24s\n",
            "3326:\tlearn: 0.1579298\ttotal: 6m 46s\tremaining: 3m 24s\n",
            "3327:\tlearn: 0.1578987\ttotal: 6m 46s\tremaining: 3m 24s\n",
            "3328:\tlearn: 0.1578839\ttotal: 6m 47s\tremaining: 3m 24s\n",
            "3329:\tlearn: 0.1578744\ttotal: 6m 47s\tremaining: 3m 24s\n",
            "3330:\tlearn: 0.1578643\ttotal: 6m 47s\tremaining: 3m 24s\n",
            "3331:\tlearn: 0.1578477\ttotal: 6m 47s\tremaining: 3m 23s\n",
            "3332:\tlearn: 0.1578387\ttotal: 6m 47s\tremaining: 3m 23s\n",
            "3333:\tlearn: 0.1578308\ttotal: 6m 47s\tremaining: 3m 23s\n",
            "3334:\tlearn: 0.1578155\ttotal: 6m 47s\tremaining: 3m 23s\n",
            "3335:\tlearn: 0.1578099\ttotal: 6m 47s\tremaining: 3m 23s\n",
            "3336:\tlearn: 0.1577983\ttotal: 6m 48s\tremaining: 3m 23s\n",
            "3337:\tlearn: 0.1577844\ttotal: 6m 48s\tremaining: 3m 23s\n",
            "3338:\tlearn: 0.1577697\ttotal: 6m 48s\tremaining: 3m 23s\n",
            "3339:\tlearn: 0.1577420\ttotal: 6m 48s\tremaining: 3m 22s\n",
            "3340:\tlearn: 0.1577244\ttotal: 6m 48s\tremaining: 3m 22s\n",
            "3341:\tlearn: 0.1577158\ttotal: 6m 48s\tremaining: 3m 22s\n",
            "3342:\tlearn: 0.1577062\ttotal: 6m 48s\tremaining: 3m 22s\n",
            "3343:\tlearn: 0.1576964\ttotal: 6m 48s\tremaining: 3m 22s\n",
            "3344:\tlearn: 0.1576912\ttotal: 6m 49s\tremaining: 3m 22s\n",
            "3345:\tlearn: 0.1576724\ttotal: 6m 49s\tremaining: 3m 22s\n",
            "3346:\tlearn: 0.1576632\ttotal: 6m 49s\tremaining: 3m 22s\n",
            "3347:\tlearn: 0.1576345\ttotal: 6m 49s\tremaining: 3m 22s\n",
            "3348:\tlearn: 0.1576260\ttotal: 6m 49s\tremaining: 3m 21s\n",
            "3349:\tlearn: 0.1576130\ttotal: 6m 49s\tremaining: 3m 21s\n",
            "3350:\tlearn: 0.1576090\ttotal: 6m 49s\tremaining: 3m 21s\n",
            "3351:\tlearn: 0.1575981\ttotal: 6m 49s\tremaining: 3m 21s\n",
            "3352:\tlearn: 0.1575778\ttotal: 6m 50s\tremaining: 3m 21s\n",
            "3353:\tlearn: 0.1575636\ttotal: 6m 50s\tremaining: 3m 21s\n",
            "3354:\tlearn: 0.1575489\ttotal: 6m 50s\tremaining: 3m 21s\n",
            "3355:\tlearn: 0.1575372\ttotal: 6m 50s\tremaining: 3m 21s\n",
            "3356:\tlearn: 0.1575201\ttotal: 6m 50s\tremaining: 3m 20s\n",
            "3357:\tlearn: 0.1575105\ttotal: 6m 50s\tremaining: 3m 20s\n",
            "3358:\tlearn: 0.1574903\ttotal: 6m 50s\tremaining: 3m 20s\n",
            "3359:\tlearn: 0.1574829\ttotal: 6m 50s\tremaining: 3m 20s\n",
            "3360:\tlearn: 0.1574736\ttotal: 6m 51s\tremaining: 3m 20s\n",
            "3361:\tlearn: 0.1574643\ttotal: 6m 51s\tremaining: 3m 20s\n",
            "3362:\tlearn: 0.1574524\ttotal: 6m 51s\tremaining: 3m 20s\n",
            "3363:\tlearn: 0.1574408\ttotal: 6m 51s\tremaining: 3m 20s\n",
            "3364:\tlearn: 0.1574357\ttotal: 6m 51s\tremaining: 3m 19s\n",
            "3365:\tlearn: 0.1574290\ttotal: 6m 51s\tremaining: 3m 19s\n",
            "3366:\tlearn: 0.1574121\ttotal: 6m 51s\tremaining: 3m 19s\n",
            "3367:\tlearn: 0.1573977\ttotal: 6m 51s\tremaining: 3m 19s\n",
            "3368:\tlearn: 0.1573866\ttotal: 6m 52s\tremaining: 3m 19s\n",
            "3369:\tlearn: 0.1573717\ttotal: 6m 52s\tremaining: 3m 19s\n",
            "3370:\tlearn: 0.1573575\ttotal: 6m 52s\tremaining: 3m 19s\n",
            "3371:\tlearn: 0.1573488\ttotal: 6m 52s\tremaining: 3m 19s\n",
            "3372:\tlearn: 0.1573383\ttotal: 6m 52s\tremaining: 3m 18s\n",
            "3373:\tlearn: 0.1573314\ttotal: 6m 52s\tremaining: 3m 18s\n",
            "3374:\tlearn: 0.1573169\ttotal: 6m 52s\tremaining: 3m 18s\n",
            "3375:\tlearn: 0.1573003\ttotal: 6m 52s\tremaining: 3m 18s\n",
            "3376:\tlearn: 0.1572805\ttotal: 6m 53s\tremaining: 3m 18s\n",
            "3377:\tlearn: 0.1572699\ttotal: 6m 53s\tremaining: 3m 18s\n",
            "3378:\tlearn: 0.1572618\ttotal: 6m 53s\tremaining: 3m 18s\n",
            "3379:\tlearn: 0.1572497\ttotal: 6m 53s\tremaining: 3m 18s\n",
            "3380:\tlearn: 0.1572356\ttotal: 6m 53s\tremaining: 3m 17s\n",
            "3381:\tlearn: 0.1572308\ttotal: 6m 53s\tremaining: 3m 17s\n",
            "3382:\tlearn: 0.1572097\ttotal: 6m 53s\tremaining: 3m 17s\n",
            "3383:\tlearn: 0.1572011\ttotal: 6m 53s\tremaining: 3m 17s\n",
            "3384:\tlearn: 0.1571894\ttotal: 6m 53s\tremaining: 3m 17s\n",
            "3385:\tlearn: 0.1571818\ttotal: 6m 54s\tremaining: 3m 17s\n",
            "3386:\tlearn: 0.1571688\ttotal: 6m 54s\tremaining: 3m 17s\n",
            "3387:\tlearn: 0.1571605\ttotal: 6m 54s\tremaining: 3m 17s\n",
            "3388:\tlearn: 0.1571512\ttotal: 6m 54s\tremaining: 3m 16s\n",
            "3389:\tlearn: 0.1571394\ttotal: 6m 54s\tremaining: 3m 16s\n",
            "3390:\tlearn: 0.1571169\ttotal: 6m 54s\tremaining: 3m 16s\n",
            "3391:\tlearn: 0.1571050\ttotal: 6m 54s\tremaining: 3m 16s\n",
            "3392:\tlearn: 0.1570934\ttotal: 6m 54s\tremaining: 3m 16s\n",
            "3393:\tlearn: 0.1570821\ttotal: 6m 54s\tremaining: 3m 16s\n",
            "3394:\tlearn: 0.1570679\ttotal: 6m 55s\tremaining: 3m 16s\n",
            "3395:\tlearn: 0.1570623\ttotal: 6m 55s\tremaining: 3m 16s\n",
            "3396:\tlearn: 0.1570520\ttotal: 6m 55s\tremaining: 3m 15s\n",
            "3397:\tlearn: 0.1570401\ttotal: 6m 55s\tremaining: 3m 15s\n",
            "3398:\tlearn: 0.1570338\ttotal: 6m 55s\tremaining: 3m 15s\n",
            "3399:\tlearn: 0.1570159\ttotal: 6m 55s\tremaining: 3m 15s\n",
            "3400:\tlearn: 0.1570040\ttotal: 6m 55s\tremaining: 3m 15s\n",
            "3401:\tlearn: 0.1569896\ttotal: 6m 55s\tremaining: 3m 15s\n",
            "3402:\tlearn: 0.1569783\ttotal: 6m 56s\tremaining: 3m 15s\n",
            "3403:\tlearn: 0.1569585\ttotal: 6m 56s\tremaining: 3m 15s\n",
            "3404:\tlearn: 0.1569516\ttotal: 6m 56s\tremaining: 3m 15s\n",
            "3405:\tlearn: 0.1569458\ttotal: 6m 56s\tremaining: 3m 14s\n",
            "3406:\tlearn: 0.1569345\ttotal: 6m 56s\tremaining: 3m 14s\n",
            "3407:\tlearn: 0.1569146\ttotal: 6m 56s\tremaining: 3m 14s\n",
            "3408:\tlearn: 0.1569050\ttotal: 6m 56s\tremaining: 3m 14s\n",
            "3409:\tlearn: 0.1568860\ttotal: 6m 56s\tremaining: 3m 14s\n",
            "3410:\tlearn: 0.1568669\ttotal: 6m 57s\tremaining: 3m 14s\n",
            "3411:\tlearn: 0.1568588\ttotal: 6m 57s\tremaining: 3m 14s\n",
            "3412:\tlearn: 0.1568444\ttotal: 6m 57s\tremaining: 3m 14s\n",
            "3413:\tlearn: 0.1568390\ttotal: 6m 57s\tremaining: 3m 13s\n",
            "3414:\tlearn: 0.1568320\ttotal: 6m 57s\tremaining: 3m 13s\n",
            "3415:\tlearn: 0.1568179\ttotal: 6m 57s\tremaining: 3m 13s\n",
            "3416:\tlearn: 0.1568047\ttotal: 6m 57s\tremaining: 3m 13s\n",
            "3417:\tlearn: 0.1567866\ttotal: 6m 57s\tremaining: 3m 13s\n",
            "3418:\tlearn: 0.1567791\ttotal: 6m 57s\tremaining: 3m 13s\n",
            "3419:\tlearn: 0.1567683\ttotal: 6m 58s\tremaining: 3m 13s\n",
            "3420:\tlearn: 0.1567446\ttotal: 6m 58s\tremaining: 3m 13s\n",
            "3421:\tlearn: 0.1567195\ttotal: 6m 58s\tremaining: 3m 12s\n",
            "3422:\tlearn: 0.1567114\ttotal: 6m 58s\tremaining: 3m 12s\n",
            "3423:\tlearn: 0.1567027\ttotal: 6m 58s\tremaining: 3m 12s\n",
            "3424:\tlearn: 0.1566932\ttotal: 6m 58s\tremaining: 3m 12s\n",
            "3425:\tlearn: 0.1566858\ttotal: 6m 58s\tremaining: 3m 12s\n",
            "3426:\tlearn: 0.1566769\ttotal: 6m 58s\tremaining: 3m 12s\n",
            "3427:\tlearn: 0.1566649\ttotal: 6m 59s\tremaining: 3m 12s\n",
            "3428:\tlearn: 0.1566457\ttotal: 6m 59s\tremaining: 3m 12s\n",
            "3429:\tlearn: 0.1566258\ttotal: 6m 59s\tremaining: 3m 11s\n",
            "3430:\tlearn: 0.1565870\ttotal: 6m 59s\tremaining: 3m 11s\n",
            "3431:\tlearn: 0.1565807\ttotal: 6m 59s\tremaining: 3m 11s\n",
            "3432:\tlearn: 0.1565698\ttotal: 6m 59s\tremaining: 3m 11s\n",
            "3433:\tlearn: 0.1565578\ttotal: 6m 59s\tremaining: 3m 11s\n",
            "3434:\tlearn: 0.1565412\ttotal: 7m\tremaining: 3m 11s\n",
            "3435:\tlearn: 0.1565315\ttotal: 7m\tremaining: 3m 11s\n",
            "3436:\tlearn: 0.1565183\ttotal: 7m\tremaining: 3m 11s\n",
            "3437:\tlearn: 0.1564905\ttotal: 7m\tremaining: 3m 11s\n",
            "3438:\tlearn: 0.1564770\ttotal: 7m\tremaining: 3m 10s\n",
            "3439:\tlearn: 0.1564547\ttotal: 7m\tremaining: 3m 10s\n",
            "3440:\tlearn: 0.1564417\ttotal: 7m\tremaining: 3m 10s\n",
            "3441:\tlearn: 0.1564267\ttotal: 7m\tremaining: 3m 10s\n",
            "3442:\tlearn: 0.1564083\ttotal: 7m 1s\tremaining: 3m 10s\n",
            "3443:\tlearn: 0.1563938\ttotal: 7m 1s\tremaining: 3m 10s\n",
            "3444:\tlearn: 0.1563765\ttotal: 7m 1s\tremaining: 3m 10s\n",
            "3445:\tlearn: 0.1563584\ttotal: 7m 1s\tremaining: 3m 10s\n",
            "3446:\tlearn: 0.1563447\ttotal: 7m 1s\tremaining: 3m 9s\n",
            "3447:\tlearn: 0.1563341\ttotal: 7m 1s\tremaining: 3m 9s\n",
            "3448:\tlearn: 0.1563224\ttotal: 7m 1s\tremaining: 3m 9s\n",
            "3449:\tlearn: 0.1563136\ttotal: 7m 1s\tremaining: 3m 9s\n",
            "3450:\tlearn: 0.1562729\ttotal: 7m 2s\tremaining: 3m 9s\n",
            "3451:\tlearn: 0.1562587\ttotal: 7m 2s\tremaining: 3m 9s\n",
            "3452:\tlearn: 0.1562320\ttotal: 7m 2s\tremaining: 3m 9s\n",
            "3453:\tlearn: 0.1562135\ttotal: 7m 2s\tremaining: 3m 9s\n",
            "3454:\tlearn: 0.1562079\ttotal: 7m 2s\tremaining: 3m 8s\n",
            "3455:\tlearn: 0.1561928\ttotal: 7m 2s\tremaining: 3m 8s\n",
            "3456:\tlearn: 0.1561796\ttotal: 7m 2s\tremaining: 3m 8s\n",
            "3457:\tlearn: 0.1561693\ttotal: 7m 3s\tremaining: 3m 8s\n",
            "3458:\tlearn: 0.1561618\ttotal: 7m 3s\tremaining: 3m 8s\n",
            "3459:\tlearn: 0.1561522\ttotal: 7m 3s\tremaining: 3m 8s\n",
            "3460:\tlearn: 0.1561363\ttotal: 7m 3s\tremaining: 3m 8s\n",
            "3461:\tlearn: 0.1561156\ttotal: 7m 3s\tremaining: 3m 8s\n",
            "3462:\tlearn: 0.1561044\ttotal: 7m 3s\tremaining: 3m 8s\n",
            "3463:\tlearn: 0.1560957\ttotal: 7m 3s\tremaining: 3m 7s\n",
            "3464:\tlearn: 0.1560866\ttotal: 7m 3s\tremaining: 3m 7s\n",
            "3465:\tlearn: 0.1560783\ttotal: 7m 4s\tremaining: 3m 7s\n",
            "3466:\tlearn: 0.1560636\ttotal: 7m 4s\tremaining: 3m 7s\n",
            "3467:\tlearn: 0.1560460\ttotal: 7m 4s\tremaining: 3m 7s\n",
            "3468:\tlearn: 0.1560270\ttotal: 7m 4s\tremaining: 3m 7s\n",
            "3469:\tlearn: 0.1560160\ttotal: 7m 4s\tremaining: 3m 7s\n",
            "3470:\tlearn: 0.1559963\ttotal: 7m 4s\tremaining: 3m 7s\n",
            "3471:\tlearn: 0.1559790\ttotal: 7m 4s\tremaining: 3m 6s\n",
            "3472:\tlearn: 0.1559686\ttotal: 7m 4s\tremaining: 3m 6s\n",
            "3473:\tlearn: 0.1559602\ttotal: 7m 5s\tremaining: 3m 6s\n",
            "3474:\tlearn: 0.1559438\ttotal: 7m 5s\tremaining: 3m 6s\n",
            "3475:\tlearn: 0.1559324\ttotal: 7m 5s\tremaining: 3m 6s\n",
            "3476:\tlearn: 0.1559162\ttotal: 7m 5s\tremaining: 3m 6s\n",
            "3477:\tlearn: 0.1558952\ttotal: 7m 5s\tremaining: 3m 6s\n",
            "3478:\tlearn: 0.1558769\ttotal: 7m 5s\tremaining: 3m 6s\n",
            "3479:\tlearn: 0.1558660\ttotal: 7m 5s\tremaining: 3m 5s\n",
            "3480:\tlearn: 0.1558577\ttotal: 7m 5s\tremaining: 3m 5s\n",
            "3481:\tlearn: 0.1558344\ttotal: 7m 5s\tremaining: 3m 5s\n",
            "3482:\tlearn: 0.1558264\ttotal: 7m 6s\tremaining: 3m 5s\n",
            "3483:\tlearn: 0.1558214\ttotal: 7m 6s\tremaining: 3m 5s\n",
            "3484:\tlearn: 0.1558155\ttotal: 7m 6s\tremaining: 3m 5s\n",
            "3485:\tlearn: 0.1558053\ttotal: 7m 6s\tremaining: 3m 5s\n",
            "3486:\tlearn: 0.1557949\ttotal: 7m 6s\tremaining: 3m 5s\n",
            "3487:\tlearn: 0.1557896\ttotal: 7m 6s\tremaining: 3m 4s\n",
            "3488:\tlearn: 0.1557748\ttotal: 7m 6s\tremaining: 3m 4s\n",
            "3489:\tlearn: 0.1557646\ttotal: 7m 6s\tremaining: 3m 4s\n",
            "3490:\tlearn: 0.1557495\ttotal: 7m 6s\tremaining: 3m 4s\n",
            "3491:\tlearn: 0.1557436\ttotal: 7m 7s\tremaining: 3m 4s\n",
            "3492:\tlearn: 0.1557392\ttotal: 7m 7s\tremaining: 3m 4s\n",
            "3493:\tlearn: 0.1557286\ttotal: 7m 7s\tremaining: 3m 4s\n",
            "3494:\tlearn: 0.1557094\ttotal: 7m 7s\tremaining: 3m 4s\n",
            "3495:\tlearn: 0.1556979\ttotal: 7m 7s\tremaining: 3m 3s\n",
            "3496:\tlearn: 0.1556873\ttotal: 7m 7s\tremaining: 3m 3s\n",
            "3497:\tlearn: 0.1556739\ttotal: 7m 7s\tremaining: 3m 3s\n",
            "3498:\tlearn: 0.1556624\ttotal: 7m 7s\tremaining: 3m 3s\n",
            "3499:\tlearn: 0.1556545\ttotal: 7m 7s\tremaining: 3m 3s\n",
            "3500:\tlearn: 0.1556402\ttotal: 7m 8s\tremaining: 3m 3s\n",
            "3501:\tlearn: 0.1556327\ttotal: 7m 8s\tremaining: 3m 3s\n",
            "3502:\tlearn: 0.1556221\ttotal: 7m 8s\tremaining: 3m 3s\n",
            "3503:\tlearn: 0.1556039\ttotal: 7m 8s\tremaining: 3m 2s\n",
            "3504:\tlearn: 0.1555873\ttotal: 7m 8s\tremaining: 3m 2s\n",
            "3505:\tlearn: 0.1555817\ttotal: 7m 8s\tremaining: 3m 2s\n",
            "3506:\tlearn: 0.1555637\ttotal: 7m 8s\tremaining: 3m 2s\n",
            "3507:\tlearn: 0.1555523\ttotal: 7m 8s\tremaining: 3m 2s\n",
            "3508:\tlearn: 0.1555451\ttotal: 7m 9s\tremaining: 3m 2s\n",
            "3509:\tlearn: 0.1555342\ttotal: 7m 9s\tremaining: 3m 2s\n",
            "3510:\tlearn: 0.1555229\ttotal: 7m 9s\tremaining: 3m 2s\n",
            "3511:\tlearn: 0.1555124\ttotal: 7m 9s\tremaining: 3m 1s\n",
            "3512:\tlearn: 0.1554866\ttotal: 7m 9s\tremaining: 3m 1s\n",
            "3513:\tlearn: 0.1554800\ttotal: 7m 9s\tremaining: 3m 1s\n",
            "3514:\tlearn: 0.1554668\ttotal: 7m 9s\tremaining: 3m 1s\n",
            "3515:\tlearn: 0.1554543\ttotal: 7m 9s\tremaining: 3m 1s\n",
            "3516:\tlearn: 0.1554458\ttotal: 7m 10s\tremaining: 3m 1s\n",
            "3517:\tlearn: 0.1554388\ttotal: 7m 10s\tremaining: 3m 1s\n",
            "3518:\tlearn: 0.1554238\ttotal: 7m 10s\tremaining: 3m 1s\n",
            "3519:\tlearn: 0.1554041\ttotal: 7m 10s\tremaining: 3m\n",
            "3520:\tlearn: 0.1553954\ttotal: 7m 10s\tremaining: 3m\n",
            "3521:\tlearn: 0.1553805\ttotal: 7m 10s\tremaining: 3m\n",
            "3522:\tlearn: 0.1553726\ttotal: 7m 10s\tremaining: 3m\n",
            "3523:\tlearn: 0.1553598\ttotal: 7m 11s\tremaining: 3m\n",
            "3524:\tlearn: 0.1553457\ttotal: 7m 11s\tremaining: 3m\n",
            "3525:\tlearn: 0.1553294\ttotal: 7m 11s\tremaining: 3m\n",
            "3526:\tlearn: 0.1553153\ttotal: 7m 11s\tremaining: 3m\n",
            "3527:\tlearn: 0.1553098\ttotal: 7m 11s\tremaining: 3m\n",
            "3528:\tlearn: 0.1553016\ttotal: 7m 11s\tremaining: 2m 59s\n",
            "3529:\tlearn: 0.1552894\ttotal: 7m 11s\tremaining: 2m 59s\n",
            "3530:\tlearn: 0.1552826\ttotal: 7m 11s\tremaining: 2m 59s\n",
            "3531:\tlearn: 0.1552769\ttotal: 7m 11s\tremaining: 2m 59s\n",
            "3532:\tlearn: 0.1552652\ttotal: 7m 12s\tremaining: 2m 59s\n",
            "3533:\tlearn: 0.1552560\ttotal: 7m 12s\tremaining: 2m 59s\n",
            "3534:\tlearn: 0.1552460\ttotal: 7m 12s\tremaining: 2m 59s\n",
            "3535:\tlearn: 0.1552247\ttotal: 7m 12s\tremaining: 2m 59s\n",
            "3536:\tlearn: 0.1552176\ttotal: 7m 12s\tremaining: 2m 58s\n",
            "3537:\tlearn: 0.1552074\ttotal: 7m 12s\tremaining: 2m 58s\n",
            "3538:\tlearn: 0.1551918\ttotal: 7m 12s\tremaining: 2m 58s\n",
            "3539:\tlearn: 0.1551668\ttotal: 7m 12s\tremaining: 2m 58s\n",
            "3540:\tlearn: 0.1551607\ttotal: 7m 13s\tremaining: 2m 58s\n",
            "3541:\tlearn: 0.1551495\ttotal: 7m 13s\tremaining: 2m 58s\n",
            "3542:\tlearn: 0.1551372\ttotal: 7m 13s\tremaining: 2m 58s\n",
            "3543:\tlearn: 0.1551221\ttotal: 7m 13s\tremaining: 2m 58s\n",
            "3544:\tlearn: 0.1551045\ttotal: 7m 13s\tremaining: 2m 57s\n",
            "3545:\tlearn: 0.1550900\ttotal: 7m 13s\tremaining: 2m 57s\n",
            "3546:\tlearn: 0.1550741\ttotal: 7m 13s\tremaining: 2m 57s\n",
            "3547:\tlearn: 0.1550688\ttotal: 7m 13s\tremaining: 2m 57s\n",
            "3548:\tlearn: 0.1550555\ttotal: 7m 14s\tremaining: 2m 57s\n",
            "3549:\tlearn: 0.1550480\ttotal: 7m 14s\tremaining: 2m 57s\n",
            "3550:\tlearn: 0.1550321\ttotal: 7m 14s\tremaining: 2m 57s\n",
            "3551:\tlearn: 0.1550125\ttotal: 7m 14s\tremaining: 2m 57s\n",
            "3552:\tlearn: 0.1550060\ttotal: 7m 14s\tremaining: 2m 56s\n",
            "3553:\tlearn: 0.1549875\ttotal: 7m 14s\tremaining: 2m 56s\n",
            "3554:\tlearn: 0.1549795\ttotal: 7m 14s\tremaining: 2m 56s\n",
            "3555:\tlearn: 0.1549683\ttotal: 7m 14s\tremaining: 2m 56s\n",
            "3556:\tlearn: 0.1549564\ttotal: 7m 15s\tremaining: 2m 56s\n",
            "3557:\tlearn: 0.1549503\ttotal: 7m 15s\tremaining: 2m 56s\n",
            "3558:\tlearn: 0.1549442\ttotal: 7m 15s\tremaining: 2m 56s\n",
            "3559:\tlearn: 0.1549283\ttotal: 7m 15s\tremaining: 2m 56s\n",
            "3560:\tlearn: 0.1549137\ttotal: 7m 15s\tremaining: 2m 56s\n",
            "3561:\tlearn: 0.1548969\ttotal: 7m 15s\tremaining: 2m 55s\n",
            "3562:\tlearn: 0.1548871\ttotal: 7m 15s\tremaining: 2m 55s\n",
            "3563:\tlearn: 0.1548715\ttotal: 7m 15s\tremaining: 2m 55s\n",
            "3564:\tlearn: 0.1548602\ttotal: 7m 16s\tremaining: 2m 55s\n",
            "3565:\tlearn: 0.1548459\ttotal: 7m 16s\tremaining: 2m 55s\n",
            "3566:\tlearn: 0.1548329\ttotal: 7m 16s\tremaining: 2m 55s\n",
            "3567:\tlearn: 0.1548232\ttotal: 7m 16s\tremaining: 2m 55s\n",
            "3568:\tlearn: 0.1548004\ttotal: 7m 16s\tremaining: 2m 55s\n",
            "3569:\tlearn: 0.1547864\ttotal: 7m 16s\tremaining: 2m 54s\n",
            "3570:\tlearn: 0.1547757\ttotal: 7m 16s\tremaining: 2m 54s\n",
            "3571:\tlearn: 0.1547671\ttotal: 7m 16s\tremaining: 2m 54s\n",
            "3572:\tlearn: 0.1547561\ttotal: 7m 17s\tremaining: 2m 54s\n",
            "3573:\tlearn: 0.1547388\ttotal: 7m 17s\tremaining: 2m 54s\n",
            "3574:\tlearn: 0.1547270\ttotal: 7m 17s\tremaining: 2m 54s\n",
            "3575:\tlearn: 0.1547065\ttotal: 7m 17s\tremaining: 2m 54s\n",
            "3576:\tlearn: 0.1547019\ttotal: 7m 17s\tremaining: 2m 54s\n",
            "3577:\tlearn: 0.1546963\ttotal: 7m 17s\tremaining: 2m 53s\n",
            "3578:\tlearn: 0.1546897\ttotal: 7m 17s\tremaining: 2m 53s\n",
            "3579:\tlearn: 0.1546801\ttotal: 7m 17s\tremaining: 2m 53s\n",
            "3580:\tlearn: 0.1546693\ttotal: 7m 17s\tremaining: 2m 53s\n",
            "3581:\tlearn: 0.1546581\ttotal: 7m 18s\tremaining: 2m 53s\n",
            "3582:\tlearn: 0.1546486\ttotal: 7m 18s\tremaining: 2m 53s\n",
            "3583:\tlearn: 0.1546349\ttotal: 7m 18s\tremaining: 2m 53s\n",
            "3584:\tlearn: 0.1545903\ttotal: 7m 18s\tremaining: 2m 53s\n",
            "3585:\tlearn: 0.1545829\ttotal: 7m 18s\tremaining: 2m 52s\n",
            "3586:\tlearn: 0.1545705\ttotal: 7m 18s\tremaining: 2m 52s\n",
            "3587:\tlearn: 0.1545600\ttotal: 7m 18s\tremaining: 2m 52s\n",
            "3588:\tlearn: 0.1545513\ttotal: 7m 18s\tremaining: 2m 52s\n",
            "3589:\tlearn: 0.1545270\ttotal: 7m 19s\tremaining: 2m 52s\n",
            "3590:\tlearn: 0.1545195\ttotal: 7m 19s\tremaining: 2m 52s\n",
            "3591:\tlearn: 0.1545112\ttotal: 7m 19s\tremaining: 2m 52s\n",
            "3592:\tlearn: 0.1544973\ttotal: 7m 19s\tremaining: 2m 52s\n",
            "3593:\tlearn: 0.1544814\ttotal: 7m 19s\tremaining: 2m 51s\n",
            "3594:\tlearn: 0.1544718\ttotal: 7m 19s\tremaining: 2m 51s\n",
            "3595:\tlearn: 0.1544654\ttotal: 7m 19s\tremaining: 2m 51s\n",
            "3596:\tlearn: 0.1544503\ttotal: 7m 19s\tremaining: 2m 51s\n",
            "3597:\tlearn: 0.1544376\ttotal: 7m 19s\tremaining: 2m 51s\n",
            "3598:\tlearn: 0.1544275\ttotal: 7m 20s\tremaining: 2m 51s\n",
            "3599:\tlearn: 0.1544209\ttotal: 7m 20s\tremaining: 2m 51s\n",
            "3600:\tlearn: 0.1544151\ttotal: 7m 20s\tremaining: 2m 51s\n",
            "3601:\tlearn: 0.1544084\ttotal: 7m 20s\tremaining: 2m 50s\n",
            "3602:\tlearn: 0.1543963\ttotal: 7m 20s\tremaining: 2m 50s\n",
            "3603:\tlearn: 0.1543844\ttotal: 7m 20s\tremaining: 2m 50s\n",
            "3604:\tlearn: 0.1543694\ttotal: 7m 20s\tremaining: 2m 50s\n",
            "3605:\tlearn: 0.1543541\ttotal: 7m 20s\tremaining: 2m 50s\n",
            "3606:\tlearn: 0.1543485\ttotal: 7m 21s\tremaining: 2m 50s\n",
            "3607:\tlearn: 0.1543329\ttotal: 7m 21s\tremaining: 2m 50s\n",
            "3608:\tlearn: 0.1543132\ttotal: 7m 21s\tremaining: 2m 50s\n",
            "3609:\tlearn: 0.1542995\ttotal: 7m 21s\tremaining: 2m 49s\n",
            "3610:\tlearn: 0.1542773\ttotal: 7m 21s\tremaining: 2m 49s\n",
            "3611:\tlearn: 0.1542676\ttotal: 7m 21s\tremaining: 2m 49s\n",
            "3612:\tlearn: 0.1542608\ttotal: 7m 21s\tremaining: 2m 49s\n",
            "3613:\tlearn: 0.1542442\ttotal: 7m 21s\tremaining: 2m 49s\n",
            "3614:\tlearn: 0.1542268\ttotal: 7m 22s\tremaining: 2m 49s\n",
            "3615:\tlearn: 0.1542139\ttotal: 7m 22s\tremaining: 2m 49s\n",
            "3616:\tlearn: 0.1541968\ttotal: 7m 22s\tremaining: 2m 49s\n",
            "3617:\tlearn: 0.1541855\ttotal: 7m 22s\tremaining: 2m 49s\n",
            "3618:\tlearn: 0.1541734\ttotal: 7m 22s\tremaining: 2m 48s\n",
            "3619:\tlearn: 0.1541534\ttotal: 7m 22s\tremaining: 2m 48s\n",
            "3620:\tlearn: 0.1541440\ttotal: 7m 22s\tremaining: 2m 48s\n",
            "3621:\tlearn: 0.1541342\ttotal: 7m 22s\tremaining: 2m 48s\n",
            "3622:\tlearn: 0.1541215\ttotal: 7m 23s\tremaining: 2m 48s\n",
            "3623:\tlearn: 0.1541125\ttotal: 7m 23s\tremaining: 2m 48s\n",
            "3624:\tlearn: 0.1541081\ttotal: 7m 23s\tremaining: 2m 48s\n",
            "3625:\tlearn: 0.1540985\ttotal: 7m 23s\tremaining: 2m 48s\n",
            "3626:\tlearn: 0.1540862\ttotal: 7m 23s\tremaining: 2m 47s\n",
            "3627:\tlearn: 0.1540750\ttotal: 7m 23s\tremaining: 2m 47s\n",
            "3628:\tlearn: 0.1540525\ttotal: 7m 23s\tremaining: 2m 47s\n",
            "3629:\tlearn: 0.1540474\ttotal: 7m 23s\tremaining: 2m 47s\n",
            "3630:\tlearn: 0.1540402\ttotal: 7m 24s\tremaining: 2m 47s\n",
            "3631:\tlearn: 0.1540315\ttotal: 7m 24s\tremaining: 2m 47s\n",
            "3632:\tlearn: 0.1540147\ttotal: 7m 24s\tremaining: 2m 47s\n",
            "3633:\tlearn: 0.1540086\ttotal: 7m 24s\tremaining: 2m 47s\n",
            "3634:\tlearn: 0.1539932\ttotal: 7m 24s\tremaining: 2m 46s\n",
            "3635:\tlearn: 0.1539781\ttotal: 7m 24s\tremaining: 2m 46s\n",
            "3636:\tlearn: 0.1539658\ttotal: 7m 24s\tremaining: 2m 46s\n",
            "3637:\tlearn: 0.1539526\ttotal: 7m 24s\tremaining: 2m 46s\n",
            "3638:\tlearn: 0.1539320\ttotal: 7m 25s\tremaining: 2m 46s\n",
            "3639:\tlearn: 0.1539128\ttotal: 7m 25s\tremaining: 2m 46s\n",
            "3640:\tlearn: 0.1539071\ttotal: 7m 25s\tremaining: 2m 46s\n",
            "3641:\tlearn: 0.1538972\ttotal: 7m 25s\tremaining: 2m 46s\n",
            "3642:\tlearn: 0.1538892\ttotal: 7m 25s\tremaining: 2m 45s\n",
            "3643:\tlearn: 0.1538771\ttotal: 7m 25s\tremaining: 2m 45s\n",
            "3644:\tlearn: 0.1538712\ttotal: 7m 25s\tremaining: 2m 45s\n",
            "3645:\tlearn: 0.1538607\ttotal: 7m 25s\tremaining: 2m 45s\n",
            "3646:\tlearn: 0.1538579\ttotal: 7m 26s\tremaining: 2m 45s\n",
            "3647:\tlearn: 0.1538430\ttotal: 7m 26s\tremaining: 2m 45s\n",
            "3648:\tlearn: 0.1538299\ttotal: 7m 26s\tremaining: 2m 45s\n",
            "3649:\tlearn: 0.1538121\ttotal: 7m 26s\tremaining: 2m 45s\n",
            "3650:\tlearn: 0.1538026\ttotal: 7m 26s\tremaining: 2m 45s\n",
            "3651:\tlearn: 0.1537952\ttotal: 7m 26s\tremaining: 2m 44s\n",
            "3652:\tlearn: 0.1537811\ttotal: 7m 26s\tremaining: 2m 44s\n",
            "3653:\tlearn: 0.1537546\ttotal: 7m 27s\tremaining: 2m 44s\n",
            "3654:\tlearn: 0.1537481\ttotal: 7m 27s\tremaining: 2m 44s\n",
            "3655:\tlearn: 0.1537398\ttotal: 7m 27s\tremaining: 2m 44s\n",
            "3656:\tlearn: 0.1537311\ttotal: 7m 27s\tremaining: 2m 44s\n",
            "3657:\tlearn: 0.1537255\ttotal: 7m 27s\tremaining: 2m 44s\n",
            "3658:\tlearn: 0.1537199\ttotal: 7m 27s\tremaining: 2m 44s\n",
            "3659:\tlearn: 0.1537020\ttotal: 7m 27s\tremaining: 2m 43s\n",
            "3660:\tlearn: 0.1536862\ttotal: 7m 27s\tremaining: 2m 43s\n",
            "3661:\tlearn: 0.1536782\ttotal: 7m 27s\tremaining: 2m 43s\n",
            "3662:\tlearn: 0.1536669\ttotal: 7m 28s\tremaining: 2m 43s\n",
            "3663:\tlearn: 0.1536507\ttotal: 7m 28s\tremaining: 2m 43s\n",
            "3664:\tlearn: 0.1536378\ttotal: 7m 28s\tremaining: 2m 43s\n",
            "3665:\tlearn: 0.1536279\ttotal: 7m 28s\tremaining: 2m 43s\n",
            "3666:\tlearn: 0.1536229\ttotal: 7m 28s\tremaining: 2m 43s\n",
            "3667:\tlearn: 0.1536106\ttotal: 7m 28s\tremaining: 2m 42s\n",
            "3668:\tlearn: 0.1536033\ttotal: 7m 28s\tremaining: 2m 42s\n",
            "3669:\tlearn: 0.1535882\ttotal: 7m 28s\tremaining: 2m 42s\n",
            "3670:\tlearn: 0.1535749\ttotal: 7m 29s\tremaining: 2m 42s\n",
            "3671:\tlearn: 0.1535582\ttotal: 7m 29s\tremaining: 2m 42s\n",
            "3672:\tlearn: 0.1535411\ttotal: 7m 29s\tremaining: 2m 42s\n",
            "3673:\tlearn: 0.1535295\ttotal: 7m 29s\tremaining: 2m 42s\n",
            "3674:\tlearn: 0.1535194\ttotal: 7m 29s\tremaining: 2m 42s\n",
            "3675:\tlearn: 0.1535088\ttotal: 7m 29s\tremaining: 2m 41s\n",
            "3676:\tlearn: 0.1534913\ttotal: 7m 29s\tremaining: 2m 41s\n",
            "3677:\tlearn: 0.1534807\ttotal: 7m 29s\tremaining: 2m 41s\n",
            "3678:\tlearn: 0.1534677\ttotal: 7m 30s\tremaining: 2m 41s\n",
            "3679:\tlearn: 0.1534584\ttotal: 7m 30s\tremaining: 2m 41s\n",
            "3680:\tlearn: 0.1534448\ttotal: 7m 30s\tremaining: 2m 41s\n",
            "3681:\tlearn: 0.1534372\ttotal: 7m 30s\tremaining: 2m 41s\n",
            "3682:\tlearn: 0.1534271\ttotal: 7m 30s\tremaining: 2m 41s\n",
            "3683:\tlearn: 0.1534140\ttotal: 7m 30s\tremaining: 2m 40s\n",
            "3684:\tlearn: 0.1534092\ttotal: 7m 30s\tremaining: 2m 40s\n",
            "3685:\tlearn: 0.1533765\ttotal: 7m 30s\tremaining: 2m 40s\n",
            "3686:\tlearn: 0.1533619\ttotal: 7m 31s\tremaining: 2m 40s\n",
            "3687:\tlearn: 0.1533532\ttotal: 7m 31s\tremaining: 2m 40s\n",
            "3688:\tlearn: 0.1533453\ttotal: 7m 31s\tremaining: 2m 40s\n",
            "3689:\tlearn: 0.1533354\ttotal: 7m 31s\tremaining: 2m 40s\n",
            "3690:\tlearn: 0.1533287\ttotal: 7m 31s\tremaining: 2m 40s\n",
            "3691:\tlearn: 0.1533204\ttotal: 7m 31s\tremaining: 2m 39s\n",
            "3692:\tlearn: 0.1533093\ttotal: 7m 31s\tremaining: 2m 39s\n",
            "3693:\tlearn: 0.1533054\ttotal: 7m 31s\tremaining: 2m 39s\n",
            "3694:\tlearn: 0.1533014\ttotal: 7m 31s\tremaining: 2m 39s\n",
            "3695:\tlearn: 0.1532910\ttotal: 7m 32s\tremaining: 2m 39s\n",
            "3696:\tlearn: 0.1532861\ttotal: 7m 32s\tremaining: 2m 39s\n",
            "3697:\tlearn: 0.1532792\ttotal: 7m 32s\tremaining: 2m 39s\n",
            "3698:\tlearn: 0.1532713\ttotal: 7m 32s\tremaining: 2m 39s\n",
            "3699:\tlearn: 0.1532612\ttotal: 7m 32s\tremaining: 2m 38s\n",
            "3700:\tlearn: 0.1532537\ttotal: 7m 32s\tremaining: 2m 38s\n",
            "3701:\tlearn: 0.1532397\ttotal: 7m 32s\tremaining: 2m 38s\n",
            "3702:\tlearn: 0.1532238\ttotal: 7m 32s\tremaining: 2m 38s\n",
            "3703:\tlearn: 0.1532174\ttotal: 7m 33s\tremaining: 2m 38s\n",
            "3704:\tlearn: 0.1532141\ttotal: 7m 33s\tremaining: 2m 38s\n",
            "3705:\tlearn: 0.1532031\ttotal: 7m 33s\tremaining: 2m 38s\n",
            "3706:\tlearn: 0.1531947\ttotal: 7m 33s\tremaining: 2m 38s\n",
            "3707:\tlearn: 0.1531828\ttotal: 7m 33s\tremaining: 2m 38s\n",
            "3708:\tlearn: 0.1531725\ttotal: 7m 33s\tremaining: 2m 37s\n",
            "3709:\tlearn: 0.1531642\ttotal: 7m 33s\tremaining: 2m 37s\n",
            "3710:\tlearn: 0.1531568\ttotal: 7m 33s\tremaining: 2m 37s\n",
            "3711:\tlearn: 0.1531430\ttotal: 7m 34s\tremaining: 2m 37s\n",
            "3712:\tlearn: 0.1531324\ttotal: 7m 34s\tremaining: 2m 37s\n",
            "3713:\tlearn: 0.1531162\ttotal: 7m 34s\tremaining: 2m 37s\n",
            "3714:\tlearn: 0.1531012\ttotal: 7m 34s\tremaining: 2m 37s\n",
            "3715:\tlearn: 0.1530973\ttotal: 7m 34s\tremaining: 2m 37s\n",
            "3716:\tlearn: 0.1530870\ttotal: 7m 34s\tremaining: 2m 36s\n",
            "3717:\tlearn: 0.1530695\ttotal: 7m 34s\tremaining: 2m 36s\n",
            "3718:\tlearn: 0.1530599\ttotal: 7m 34s\tremaining: 2m 36s\n",
            "3719:\tlearn: 0.1530435\ttotal: 7m 34s\tremaining: 2m 36s\n",
            "3720:\tlearn: 0.1530344\ttotal: 7m 35s\tremaining: 2m 36s\n",
            "3721:\tlearn: 0.1530128\ttotal: 7m 35s\tremaining: 2m 36s\n",
            "3722:\tlearn: 0.1530075\ttotal: 7m 35s\tremaining: 2m 36s\n",
            "3723:\tlearn: 0.1529917\ttotal: 7m 35s\tremaining: 2m 36s\n",
            "3724:\tlearn: 0.1529767\ttotal: 7m 35s\tremaining: 2m 35s\n",
            "3725:\tlearn: 0.1529653\ttotal: 7m 35s\tremaining: 2m 35s\n",
            "3726:\tlearn: 0.1529602\ttotal: 7m 35s\tremaining: 2m 35s\n",
            "3727:\tlearn: 0.1529533\ttotal: 7m 35s\tremaining: 2m 35s\n",
            "3728:\tlearn: 0.1529408\ttotal: 7m 36s\tremaining: 2m 35s\n",
            "3729:\tlearn: 0.1529378\ttotal: 7m 36s\tremaining: 2m 35s\n",
            "3730:\tlearn: 0.1529252\ttotal: 7m 36s\tremaining: 2m 35s\n",
            "3731:\tlearn: 0.1528955\ttotal: 7m 36s\tremaining: 2m 35s\n",
            "3732:\tlearn: 0.1528762\ttotal: 7m 36s\tremaining: 2m 34s\n",
            "3733:\tlearn: 0.1528587\ttotal: 7m 36s\tremaining: 2m 34s\n",
            "3734:\tlearn: 0.1528446\ttotal: 7m 36s\tremaining: 2m 34s\n",
            "3735:\tlearn: 0.1528323\ttotal: 7m 36s\tremaining: 2m 34s\n",
            "3736:\tlearn: 0.1528265\ttotal: 7m 37s\tremaining: 2m 34s\n",
            "3737:\tlearn: 0.1528053\ttotal: 7m 37s\tremaining: 2m 34s\n",
            "3738:\tlearn: 0.1527960\ttotal: 7m 37s\tremaining: 2m 34s\n",
            "3739:\tlearn: 0.1527857\ttotal: 7m 37s\tremaining: 2m 34s\n",
            "3740:\tlearn: 0.1527758\ttotal: 7m 37s\tremaining: 2m 33s\n",
            "3741:\tlearn: 0.1527633\ttotal: 7m 37s\tremaining: 2m 33s\n",
            "3742:\tlearn: 0.1527565\ttotal: 7m 37s\tremaining: 2m 33s\n",
            "3743:\tlearn: 0.1527479\ttotal: 7m 37s\tremaining: 2m 33s\n",
            "3744:\tlearn: 0.1527357\ttotal: 7m 38s\tremaining: 2m 33s\n",
            "3745:\tlearn: 0.1527138\ttotal: 7m 38s\tremaining: 2m 33s\n",
            "3746:\tlearn: 0.1527035\ttotal: 7m 38s\tremaining: 2m 33s\n",
            "3747:\tlearn: 0.1526963\ttotal: 7m 38s\tremaining: 2m 33s\n",
            "3748:\tlearn: 0.1526901\ttotal: 7m 38s\tremaining: 2m 32s\n",
            "3749:\tlearn: 0.1526790\ttotal: 7m 38s\tremaining: 2m 32s\n",
            "3750:\tlearn: 0.1526602\ttotal: 7m 38s\tremaining: 2m 32s\n",
            "3751:\tlearn: 0.1526466\ttotal: 7m 38s\tremaining: 2m 32s\n",
            "3752:\tlearn: 0.1526277\ttotal: 7m 38s\tremaining: 2m 32s\n",
            "3753:\tlearn: 0.1526238\ttotal: 7m 39s\tremaining: 2m 32s\n",
            "3754:\tlearn: 0.1526140\ttotal: 7m 39s\tremaining: 2m 32s\n",
            "3755:\tlearn: 0.1526005\ttotal: 7m 39s\tremaining: 2m 32s\n",
            "3756:\tlearn: 0.1525816\ttotal: 7m 39s\tremaining: 2m 31s\n",
            "3757:\tlearn: 0.1525732\ttotal: 7m 39s\tremaining: 2m 31s\n",
            "3758:\tlearn: 0.1525707\ttotal: 7m 39s\tremaining: 2m 31s\n",
            "3759:\tlearn: 0.1525656\ttotal: 7m 39s\tremaining: 2m 31s\n",
            "3760:\tlearn: 0.1525563\ttotal: 7m 39s\tremaining: 2m 31s\n",
            "3761:\tlearn: 0.1525487\ttotal: 7m 39s\tremaining: 2m 31s\n",
            "3762:\tlearn: 0.1525285\ttotal: 7m 40s\tremaining: 2m 31s\n",
            "3763:\tlearn: 0.1525215\ttotal: 7m 40s\tremaining: 2m 31s\n",
            "3764:\tlearn: 0.1525110\ttotal: 7m 40s\tremaining: 2m 30s\n",
            "3765:\tlearn: 0.1525010\ttotal: 7m 40s\tremaining: 2m 30s\n",
            "3766:\tlearn: 0.1524831\ttotal: 7m 40s\tremaining: 2m 30s\n",
            "3767:\tlearn: 0.1524733\ttotal: 7m 40s\tremaining: 2m 30s\n",
            "3768:\tlearn: 0.1524659\ttotal: 7m 40s\tremaining: 2m 30s\n",
            "3769:\tlearn: 0.1524580\ttotal: 7m 40s\tremaining: 2m 30s\n",
            "3770:\tlearn: 0.1524492\ttotal: 7m 40s\tremaining: 2m 30s\n",
            "3771:\tlearn: 0.1524195\ttotal: 7m 41s\tremaining: 2m 30s\n",
            "3772:\tlearn: 0.1524114\ttotal: 7m 41s\tremaining: 2m 29s\n",
            "3773:\tlearn: 0.1524014\ttotal: 7m 41s\tremaining: 2m 29s\n",
            "3774:\tlearn: 0.1523948\ttotal: 7m 41s\tremaining: 2m 29s\n",
            "3775:\tlearn: 0.1523858\ttotal: 7m 41s\tremaining: 2m 29s\n",
            "3776:\tlearn: 0.1523771\ttotal: 7m 41s\tremaining: 2m 29s\n",
            "3777:\tlearn: 0.1523696\ttotal: 7m 41s\tremaining: 2m 29s\n",
            "3778:\tlearn: 0.1523644\ttotal: 7m 41s\tremaining: 2m 29s\n",
            "3779:\tlearn: 0.1523513\ttotal: 7m 42s\tremaining: 2m 29s\n",
            "3780:\tlearn: 0.1523444\ttotal: 7m 42s\tremaining: 2m 28s\n",
            "3781:\tlearn: 0.1523279\ttotal: 7m 42s\tremaining: 2m 28s\n",
            "3782:\tlearn: 0.1523169\ttotal: 7m 42s\tremaining: 2m 28s\n",
            "3783:\tlearn: 0.1523045\ttotal: 7m 42s\tremaining: 2m 28s\n",
            "3784:\tlearn: 0.1522998\ttotal: 7m 42s\tremaining: 2m 28s\n",
            "3785:\tlearn: 0.1522833\ttotal: 7m 42s\tremaining: 2m 28s\n",
            "3786:\tlearn: 0.1522718\ttotal: 7m 42s\tremaining: 2m 28s\n",
            "3787:\tlearn: 0.1522606\ttotal: 7m 42s\tremaining: 2m 28s\n",
            "3788:\tlearn: 0.1522519\ttotal: 7m 43s\tremaining: 2m 27s\n",
            "3789:\tlearn: 0.1522405\ttotal: 7m 43s\tremaining: 2m 27s\n",
            "3790:\tlearn: 0.1522214\ttotal: 7m 43s\tremaining: 2m 27s\n",
            "3791:\tlearn: 0.1522064\ttotal: 7m 43s\tremaining: 2m 27s\n",
            "3792:\tlearn: 0.1521929\ttotal: 7m 43s\tremaining: 2m 27s\n",
            "3793:\tlearn: 0.1521773\ttotal: 7m 43s\tremaining: 2m 27s\n",
            "3794:\tlearn: 0.1521709\ttotal: 7m 43s\tremaining: 2m 27s\n",
            "3795:\tlearn: 0.1521601\ttotal: 7m 43s\tremaining: 2m 27s\n",
            "3796:\tlearn: 0.1521499\ttotal: 7m 43s\tremaining: 2m 27s\n",
            "3797:\tlearn: 0.1521438\ttotal: 7m 44s\tremaining: 2m 26s\n",
            "3798:\tlearn: 0.1521340\ttotal: 7m 44s\tremaining: 2m 26s\n",
            "3799:\tlearn: 0.1521235\ttotal: 7m 44s\tremaining: 2m 26s\n",
            "3800:\tlearn: 0.1521145\ttotal: 7m 44s\tremaining: 2m 26s\n",
            "3801:\tlearn: 0.1521055\ttotal: 7m 44s\tremaining: 2m 26s\n",
            "3802:\tlearn: 0.1521022\ttotal: 7m 44s\tremaining: 2m 26s\n",
            "3803:\tlearn: 0.1520968\ttotal: 7m 44s\tremaining: 2m 26s\n",
            "3804:\tlearn: 0.1520833\ttotal: 7m 44s\tremaining: 2m 26s\n",
            "3805:\tlearn: 0.1520744\ttotal: 7m 45s\tremaining: 2m 25s\n",
            "3806:\tlearn: 0.1520608\ttotal: 7m 45s\tremaining: 2m 25s\n",
            "3807:\tlearn: 0.1520492\ttotal: 7m 45s\tremaining: 2m 25s\n",
            "3808:\tlearn: 0.1520404\ttotal: 7m 45s\tremaining: 2m 25s\n",
            "3809:\tlearn: 0.1520227\ttotal: 7m 45s\tremaining: 2m 25s\n",
            "3810:\tlearn: 0.1520046\ttotal: 7m 45s\tremaining: 2m 25s\n",
            "3811:\tlearn: 0.1520019\ttotal: 7m 45s\tremaining: 2m 25s\n",
            "3812:\tlearn: 0.1519924\ttotal: 7m 45s\tremaining: 2m 25s\n",
            "3813:\tlearn: 0.1519830\ttotal: 7m 45s\tremaining: 2m 24s\n",
            "3814:\tlearn: 0.1519736\ttotal: 7m 46s\tremaining: 2m 24s\n",
            "3815:\tlearn: 0.1519663\ttotal: 7m 46s\tremaining: 2m 24s\n",
            "3816:\tlearn: 0.1519537\ttotal: 7m 46s\tremaining: 2m 24s\n",
            "3817:\tlearn: 0.1519427\ttotal: 7m 46s\tremaining: 2m 24s\n",
            "3818:\tlearn: 0.1519230\ttotal: 7m 46s\tremaining: 2m 24s\n",
            "3819:\tlearn: 0.1519128\ttotal: 7m 46s\tremaining: 2m 24s\n",
            "3820:\tlearn: 0.1519028\ttotal: 7m 46s\tremaining: 2m 24s\n",
            "3821:\tlearn: 0.1518804\ttotal: 7m 46s\tremaining: 2m 23s\n",
            "3822:\tlearn: 0.1518719\ttotal: 7m 46s\tremaining: 2m 23s\n",
            "3823:\tlearn: 0.1518663\ttotal: 7m 47s\tremaining: 2m 23s\n",
            "3824:\tlearn: 0.1518590\ttotal: 7m 47s\tremaining: 2m 23s\n",
            "3825:\tlearn: 0.1518509\ttotal: 7m 47s\tremaining: 2m 23s\n",
            "3826:\tlearn: 0.1518336\ttotal: 7m 47s\tremaining: 2m 23s\n",
            "3827:\tlearn: 0.1518254\ttotal: 7m 47s\tremaining: 2m 23s\n",
            "3828:\tlearn: 0.1518146\ttotal: 7m 47s\tremaining: 2m 23s\n",
            "3829:\tlearn: 0.1517995\ttotal: 7m 47s\tremaining: 2m 22s\n",
            "3830:\tlearn: 0.1517856\ttotal: 7m 47s\tremaining: 2m 22s\n",
            "3831:\tlearn: 0.1517736\ttotal: 7m 47s\tremaining: 2m 22s\n",
            "3832:\tlearn: 0.1517694\ttotal: 7m 48s\tremaining: 2m 22s\n",
            "3833:\tlearn: 0.1517551\ttotal: 7m 48s\tremaining: 2m 22s\n",
            "3834:\tlearn: 0.1517506\ttotal: 7m 48s\tremaining: 2m 22s\n",
            "3835:\tlearn: 0.1517363\ttotal: 7m 48s\tremaining: 2m 22s\n",
            "3836:\tlearn: 0.1517270\ttotal: 7m 48s\tremaining: 2m 22s\n",
            "3837:\tlearn: 0.1517176\ttotal: 7m 48s\tremaining: 2m 21s\n",
            "3838:\tlearn: 0.1517085\ttotal: 7m 48s\tremaining: 2m 21s\n",
            "3839:\tlearn: 0.1517008\ttotal: 7m 48s\tremaining: 2m 21s\n",
            "3840:\tlearn: 0.1516846\ttotal: 7m 49s\tremaining: 2m 21s\n",
            "3841:\tlearn: 0.1516754\ttotal: 7m 49s\tremaining: 2m 21s\n",
            "3842:\tlearn: 0.1516633\ttotal: 7m 49s\tremaining: 2m 21s\n",
            "3843:\tlearn: 0.1516578\ttotal: 7m 49s\tremaining: 2m 21s\n",
            "3844:\tlearn: 0.1516491\ttotal: 7m 49s\tremaining: 2m 21s\n",
            "3845:\tlearn: 0.1516341\ttotal: 7m 49s\tremaining: 2m 20s\n",
            "3846:\tlearn: 0.1516246\ttotal: 7m 49s\tremaining: 2m 20s\n",
            "3847:\tlearn: 0.1516163\ttotal: 7m 49s\tremaining: 2m 20s\n",
            "3848:\tlearn: 0.1516017\ttotal: 7m 50s\tremaining: 2m 20s\n",
            "3849:\tlearn: 0.1515948\ttotal: 7m 50s\tremaining: 2m 20s\n",
            "3850:\tlearn: 0.1515852\ttotal: 7m 50s\tremaining: 2m 20s\n",
            "3851:\tlearn: 0.1515721\ttotal: 7m 50s\tremaining: 2m 20s\n",
            "3852:\tlearn: 0.1515654\ttotal: 7m 50s\tremaining: 2m 20s\n",
            "3853:\tlearn: 0.1515504\ttotal: 7m 50s\tremaining: 2m 19s\n",
            "3854:\tlearn: 0.1515428\ttotal: 7m 50s\tremaining: 2m 19s\n",
            "3855:\tlearn: 0.1515375\ttotal: 7m 50s\tremaining: 2m 19s\n",
            "3856:\tlearn: 0.1515183\ttotal: 7m 50s\tremaining: 2m 19s\n",
            "3857:\tlearn: 0.1515117\ttotal: 7m 51s\tremaining: 2m 19s\n",
            "3858:\tlearn: 0.1515037\ttotal: 7m 51s\tremaining: 2m 19s\n",
            "3859:\tlearn: 0.1514873\ttotal: 7m 51s\tremaining: 2m 19s\n",
            "3860:\tlearn: 0.1514768\ttotal: 7m 51s\tremaining: 2m 19s\n",
            "3861:\tlearn: 0.1514615\ttotal: 7m 51s\tremaining: 2m 18s\n",
            "3862:\tlearn: 0.1514540\ttotal: 7m 51s\tremaining: 2m 18s\n",
            "3863:\tlearn: 0.1514367\ttotal: 7m 51s\tremaining: 2m 18s\n",
            "3864:\tlearn: 0.1514301\ttotal: 7m 51s\tremaining: 2m 18s\n",
            "3865:\tlearn: 0.1514208\ttotal: 7m 51s\tremaining: 2m 18s\n",
            "3866:\tlearn: 0.1514040\ttotal: 7m 52s\tremaining: 2m 18s\n",
            "3867:\tlearn: 0.1513847\ttotal: 7m 52s\tremaining: 2m 18s\n",
            "3868:\tlearn: 0.1513697\ttotal: 7m 52s\tremaining: 2m 18s\n",
            "3869:\tlearn: 0.1513618\ttotal: 7m 52s\tremaining: 2m 17s\n",
            "3870:\tlearn: 0.1513561\ttotal: 7m 52s\tremaining: 2m 17s\n",
            "3871:\tlearn: 0.1513433\ttotal: 7m 52s\tremaining: 2m 17s\n",
            "3872:\tlearn: 0.1513347\ttotal: 7m 52s\tremaining: 2m 17s\n",
            "3873:\tlearn: 0.1513274\ttotal: 7m 52s\tremaining: 2m 17s\n",
            "3874:\tlearn: 0.1513136\ttotal: 7m 53s\tremaining: 2m 17s\n",
            "3875:\tlearn: 0.1513015\ttotal: 7m 53s\tremaining: 2m 17s\n",
            "3876:\tlearn: 0.1512920\ttotal: 7m 53s\tremaining: 2m 17s\n",
            "3877:\tlearn: 0.1512836\ttotal: 7m 53s\tremaining: 2m 16s\n",
            "3878:\tlearn: 0.1512745\ttotal: 7m 53s\tremaining: 2m 16s\n",
            "3879:\tlearn: 0.1512597\ttotal: 7m 53s\tremaining: 2m 16s\n",
            "3880:\tlearn: 0.1512507\ttotal: 7m 53s\tremaining: 2m 16s\n",
            "3881:\tlearn: 0.1512379\ttotal: 7m 53s\tremaining: 2m 16s\n",
            "3882:\tlearn: 0.1512254\ttotal: 7m 54s\tremaining: 2m 16s\n",
            "3883:\tlearn: 0.1512150\ttotal: 7m 54s\tremaining: 2m 16s\n",
            "3884:\tlearn: 0.1512033\ttotal: 7m 54s\tremaining: 2m 16s\n",
            "3885:\tlearn: 0.1511906\ttotal: 7m 54s\tremaining: 2m 16s\n",
            "3886:\tlearn: 0.1511840\ttotal: 7m 54s\tremaining: 2m 15s\n",
            "3887:\tlearn: 0.1511802\ttotal: 7m 54s\tremaining: 2m 15s\n",
            "3888:\tlearn: 0.1511611\ttotal: 7m 54s\tremaining: 2m 15s\n",
            "3889:\tlearn: 0.1511559\ttotal: 7m 54s\tremaining: 2m 15s\n",
            "3890:\tlearn: 0.1511463\ttotal: 7m 54s\tremaining: 2m 15s\n",
            "3891:\tlearn: 0.1511304\ttotal: 7m 55s\tremaining: 2m 15s\n",
            "3892:\tlearn: 0.1511147\ttotal: 7m 55s\tremaining: 2m 15s\n",
            "3893:\tlearn: 0.1511071\ttotal: 7m 55s\tremaining: 2m 15s\n",
            "3894:\tlearn: 0.1510988\ttotal: 7m 55s\tremaining: 2m 14s\n",
            "3895:\tlearn: 0.1510819\ttotal: 7m 55s\tremaining: 2m 14s\n",
            "3896:\tlearn: 0.1510780\ttotal: 7m 55s\tremaining: 2m 14s\n",
            "3897:\tlearn: 0.1510668\ttotal: 7m 55s\tremaining: 2m 14s\n",
            "3898:\tlearn: 0.1510561\ttotal: 7m 55s\tremaining: 2m 14s\n",
            "3899:\tlearn: 0.1510455\ttotal: 7m 56s\tremaining: 2m 14s\n",
            "3900:\tlearn: 0.1510333\ttotal: 7m 56s\tremaining: 2m 14s\n",
            "3901:\tlearn: 0.1510232\ttotal: 7m 56s\tremaining: 2m 14s\n",
            "3902:\tlearn: 0.1510140\ttotal: 7m 56s\tremaining: 2m 13s\n",
            "3903:\tlearn: 0.1509985\ttotal: 7m 56s\tremaining: 2m 13s\n",
            "3904:\tlearn: 0.1509954\ttotal: 7m 56s\tremaining: 2m 13s\n",
            "3905:\tlearn: 0.1509812\ttotal: 7m 56s\tremaining: 2m 13s\n",
            "3906:\tlearn: 0.1509759\ttotal: 7m 56s\tremaining: 2m 13s\n",
            "3907:\tlearn: 0.1509595\ttotal: 7m 56s\tremaining: 2m 13s\n",
            "3908:\tlearn: 0.1509500\ttotal: 7m 57s\tremaining: 2m 13s\n",
            "3909:\tlearn: 0.1509430\ttotal: 7m 57s\tremaining: 2m 13s\n",
            "3910:\tlearn: 0.1509318\ttotal: 7m 57s\tremaining: 2m 12s\n",
            "3911:\tlearn: 0.1509201\ttotal: 7m 57s\tremaining: 2m 12s\n",
            "3912:\tlearn: 0.1509111\ttotal: 7m 57s\tremaining: 2m 12s\n",
            "3913:\tlearn: 0.1509021\ttotal: 7m 57s\tremaining: 2m 12s\n",
            "3914:\tlearn: 0.1508897\ttotal: 7m 57s\tremaining: 2m 12s\n",
            "3915:\tlearn: 0.1508784\ttotal: 7m 57s\tremaining: 2m 12s\n",
            "3916:\tlearn: 0.1508650\ttotal: 7m 58s\tremaining: 2m 12s\n",
            "3917:\tlearn: 0.1508492\ttotal: 7m 58s\tremaining: 2m 12s\n",
            "3918:\tlearn: 0.1508444\ttotal: 7m 58s\tremaining: 2m 11s\n",
            "3919:\tlearn: 0.1508309\ttotal: 7m 58s\tremaining: 2m 11s\n",
            "3920:\tlearn: 0.1508236\ttotal: 7m 58s\tremaining: 2m 11s\n",
            "3921:\tlearn: 0.1508112\ttotal: 7m 58s\tremaining: 2m 11s\n",
            "3922:\tlearn: 0.1508000\ttotal: 7m 58s\tremaining: 2m 11s\n",
            "3923:\tlearn: 0.1507872\ttotal: 7m 58s\tremaining: 2m 11s\n",
            "3924:\tlearn: 0.1507794\ttotal: 7m 59s\tremaining: 2m 11s\n",
            "3925:\tlearn: 0.1507725\ttotal: 7m 59s\tremaining: 2m 11s\n",
            "3926:\tlearn: 0.1507629\ttotal: 7m 59s\tremaining: 2m 10s\n",
            "3927:\tlearn: 0.1507586\ttotal: 7m 59s\tremaining: 2m 10s\n",
            "3928:\tlearn: 0.1507556\ttotal: 7m 59s\tremaining: 2m 10s\n",
            "3929:\tlearn: 0.1507498\ttotal: 7m 59s\tremaining: 2m 10s\n",
            "3930:\tlearn: 0.1507400\ttotal: 7m 59s\tremaining: 2m 10s\n",
            "3931:\tlearn: 0.1507309\ttotal: 7m 59s\tremaining: 2m 10s\n",
            "3932:\tlearn: 0.1507217\ttotal: 7m 59s\tremaining: 2m 10s\n",
            "3933:\tlearn: 0.1507103\ttotal: 8m\tremaining: 2m 10s\n",
            "3934:\tlearn: 0.1507028\ttotal: 8m\tremaining: 2m 9s\n",
            "3935:\tlearn: 0.1506977\ttotal: 8m\tremaining: 2m 9s\n",
            "3936:\tlearn: 0.1506912\ttotal: 8m\tremaining: 2m 9s\n",
            "3937:\tlearn: 0.1506781\ttotal: 8m\tremaining: 2m 9s\n",
            "3938:\tlearn: 0.1506627\ttotal: 8m\tremaining: 2m 9s\n",
            "3939:\tlearn: 0.1506496\ttotal: 8m\tremaining: 2m 9s\n",
            "3940:\tlearn: 0.1506426\ttotal: 8m\tremaining: 2m 9s\n",
            "3941:\tlearn: 0.1506305\ttotal: 8m\tremaining: 2m 9s\n",
            "3942:\tlearn: 0.1506204\ttotal: 8m 1s\tremaining: 2m 8s\n",
            "3943:\tlearn: 0.1506115\ttotal: 8m 1s\tremaining: 2m 8s\n",
            "3944:\tlearn: 0.1506024\ttotal: 8m 1s\tremaining: 2m 8s\n",
            "3945:\tlearn: 0.1505925\ttotal: 8m 1s\tremaining: 2m 8s\n",
            "3946:\tlearn: 0.1505810\ttotal: 8m 1s\tremaining: 2m 8s\n",
            "3947:\tlearn: 0.1505749\ttotal: 8m 1s\tremaining: 2m 8s\n",
            "3948:\tlearn: 0.1505657\ttotal: 8m 1s\tremaining: 2m 8s\n",
            "3949:\tlearn: 0.1505522\ttotal: 8m 1s\tremaining: 2m 8s\n",
            "3950:\tlearn: 0.1505425\ttotal: 8m 2s\tremaining: 2m 7s\n",
            "3951:\tlearn: 0.1505357\ttotal: 8m 2s\tremaining: 2m 7s\n",
            "3952:\tlearn: 0.1505183\ttotal: 8m 2s\tremaining: 2m 7s\n",
            "3953:\tlearn: 0.1505034\ttotal: 8m 2s\tremaining: 2m 7s\n",
            "3954:\tlearn: 0.1504986\ttotal: 8m 2s\tremaining: 2m 7s\n",
            "3955:\tlearn: 0.1504914\ttotal: 8m 2s\tremaining: 2m 7s\n",
            "3956:\tlearn: 0.1504766\ttotal: 8m 2s\tremaining: 2m 7s\n",
            "3957:\tlearn: 0.1504553\ttotal: 8m 2s\tremaining: 2m 7s\n",
            "3958:\tlearn: 0.1504475\ttotal: 8m 3s\tremaining: 2m 7s\n",
            "3959:\tlearn: 0.1504281\ttotal: 8m 3s\tremaining: 2m 6s\n",
            "3960:\tlearn: 0.1504121\ttotal: 8m 3s\tremaining: 2m 6s\n",
            "3961:\tlearn: 0.1503996\ttotal: 8m 3s\tremaining: 2m 6s\n",
            "3962:\tlearn: 0.1503875\ttotal: 8m 3s\tremaining: 2m 6s\n",
            "3963:\tlearn: 0.1503777\ttotal: 8m 3s\tremaining: 2m 6s\n",
            "3964:\tlearn: 0.1503680\ttotal: 8m 3s\tremaining: 2m 6s\n",
            "3965:\tlearn: 0.1503634\ttotal: 8m 3s\tremaining: 2m 6s\n",
            "3966:\tlearn: 0.1503554\ttotal: 8m 3s\tremaining: 2m 6s\n",
            "3967:\tlearn: 0.1503525\ttotal: 8m 4s\tremaining: 2m 5s\n",
            "3968:\tlearn: 0.1503439\ttotal: 8m 4s\tremaining: 2m 5s\n",
            "3969:\tlearn: 0.1503253\ttotal: 8m 4s\tremaining: 2m 5s\n",
            "3970:\tlearn: 0.1503182\ttotal: 8m 4s\tremaining: 2m 5s\n",
            "3971:\tlearn: 0.1503075\ttotal: 8m 4s\tremaining: 2m 5s\n",
            "3972:\tlearn: 0.1502957\ttotal: 8m 4s\tremaining: 2m 5s\n",
            "3973:\tlearn: 0.1502888\ttotal: 8m 4s\tremaining: 2m 5s\n",
            "3974:\tlearn: 0.1502654\ttotal: 8m 4s\tremaining: 2m 5s\n",
            "3975:\tlearn: 0.1502588\ttotal: 8m 5s\tremaining: 2m 4s\n",
            "3976:\tlearn: 0.1502455\ttotal: 8m 5s\tremaining: 2m 4s\n",
            "3977:\tlearn: 0.1502342\ttotal: 8m 5s\tremaining: 2m 4s\n",
            "3978:\tlearn: 0.1502167\ttotal: 8m 5s\tremaining: 2m 4s\n",
            "3979:\tlearn: 0.1502036\ttotal: 8m 5s\tremaining: 2m 4s\n",
            "3980:\tlearn: 0.1501947\ttotal: 8m 5s\tremaining: 2m 4s\n",
            "3981:\tlearn: 0.1501864\ttotal: 8m 5s\tremaining: 2m 4s\n",
            "3982:\tlearn: 0.1501714\ttotal: 8m 5s\tremaining: 2m 4s\n",
            "3983:\tlearn: 0.1501630\ttotal: 8m 6s\tremaining: 2m 3s\n",
            "3984:\tlearn: 0.1501507\ttotal: 8m 6s\tremaining: 2m 3s\n",
            "3985:\tlearn: 0.1501422\ttotal: 8m 6s\tremaining: 2m 3s\n",
            "3986:\tlearn: 0.1501382\ttotal: 8m 6s\tremaining: 2m 3s\n",
            "3987:\tlearn: 0.1501261\ttotal: 8m 6s\tremaining: 2m 3s\n",
            "3988:\tlearn: 0.1501090\ttotal: 8m 6s\tremaining: 2m 3s\n",
            "3989:\tlearn: 0.1501031\ttotal: 8m 6s\tremaining: 2m 3s\n",
            "3990:\tlearn: 0.1500950\ttotal: 8m 6s\tremaining: 2m 3s\n",
            "3991:\tlearn: 0.1500887\ttotal: 8m 6s\tremaining: 2m 2s\n",
            "3992:\tlearn: 0.1500825\ttotal: 8m 7s\tremaining: 2m 2s\n",
            "3993:\tlearn: 0.1500742\ttotal: 8m 7s\tremaining: 2m 2s\n",
            "3994:\tlearn: 0.1500612\ttotal: 8m 7s\tremaining: 2m 2s\n",
            "3995:\tlearn: 0.1500526\ttotal: 8m 7s\tremaining: 2m 2s\n",
            "3996:\tlearn: 0.1500381\ttotal: 8m 7s\tremaining: 2m 2s\n",
            "3997:\tlearn: 0.1500299\ttotal: 8m 7s\tremaining: 2m 2s\n",
            "3998:\tlearn: 0.1500202\ttotal: 8m 7s\tremaining: 2m 2s\n",
            "3999:\tlearn: 0.1500110\ttotal: 8m 7s\tremaining: 2m 1s\n",
            "4000:\tlearn: 0.1500020\ttotal: 8m 8s\tremaining: 2m 1s\n",
            "4001:\tlearn: 0.1499968\ttotal: 8m 8s\tremaining: 2m 1s\n",
            "4002:\tlearn: 0.1499858\ttotal: 8m 8s\tremaining: 2m 1s\n",
            "4003:\tlearn: 0.1499751\ttotal: 8m 8s\tremaining: 2m 1s\n",
            "4004:\tlearn: 0.1499544\ttotal: 8m 8s\tremaining: 2m 1s\n",
            "4005:\tlearn: 0.1499444\ttotal: 8m 8s\tremaining: 2m 1s\n",
            "4006:\tlearn: 0.1499357\ttotal: 8m 8s\tremaining: 2m 1s\n",
            "4007:\tlearn: 0.1499231\ttotal: 8m 8s\tremaining: 2m 1s\n",
            "4008:\tlearn: 0.1499132\ttotal: 8m 9s\tremaining: 2m\n",
            "4009:\tlearn: 0.1499074\ttotal: 8m 9s\tremaining: 2m\n",
            "4010:\tlearn: 0.1498970\ttotal: 8m 9s\tremaining: 2m\n",
            "4011:\tlearn: 0.1498880\ttotal: 8m 9s\tremaining: 2m\n",
            "4012:\tlearn: 0.1498801\ttotal: 8m 9s\tremaining: 2m\n",
            "4013:\tlearn: 0.1498671\ttotal: 8m 9s\tremaining: 2m\n",
            "4014:\tlearn: 0.1498506\ttotal: 8m 9s\tremaining: 2m\n",
            "4015:\tlearn: 0.1498313\ttotal: 8m 9s\tremaining: 2m\n",
            "4016:\tlearn: 0.1498183\ttotal: 8m 10s\tremaining: 1m 59s\n",
            "4017:\tlearn: 0.1498026\ttotal: 8m 10s\tremaining: 1m 59s\n",
            "4018:\tlearn: 0.1497917\ttotal: 8m 10s\tremaining: 1m 59s\n",
            "4019:\tlearn: 0.1497862\ttotal: 8m 10s\tremaining: 1m 59s\n",
            "4020:\tlearn: 0.1497751\ttotal: 8m 10s\tremaining: 1m 59s\n",
            "4021:\tlearn: 0.1497636\ttotal: 8m 10s\tremaining: 1m 59s\n",
            "4022:\tlearn: 0.1497521\ttotal: 8m 10s\tremaining: 1m 59s\n",
            "4023:\tlearn: 0.1497447\ttotal: 8m 10s\tremaining: 1m 59s\n",
            "4024:\tlearn: 0.1497350\ttotal: 8m 11s\tremaining: 1m 58s\n",
            "4025:\tlearn: 0.1497140\ttotal: 8m 11s\tremaining: 1m 58s\n",
            "4026:\tlearn: 0.1496982\ttotal: 8m 11s\tremaining: 1m 58s\n",
            "4027:\tlearn: 0.1496874\ttotal: 8m 11s\tremaining: 1m 58s\n",
            "4028:\tlearn: 0.1496799\ttotal: 8m 11s\tremaining: 1m 58s\n",
            "4029:\tlearn: 0.1496615\ttotal: 8m 11s\tremaining: 1m 58s\n",
            "4030:\tlearn: 0.1496548\ttotal: 8m 11s\tremaining: 1m 58s\n",
            "4031:\tlearn: 0.1496480\ttotal: 8m 11s\tremaining: 1m 58s\n",
            "4032:\tlearn: 0.1496382\ttotal: 8m 12s\tremaining: 1m 57s\n",
            "4033:\tlearn: 0.1496312\ttotal: 8m 12s\tremaining: 1m 57s\n",
            "4034:\tlearn: 0.1496177\ttotal: 8m 12s\tremaining: 1m 57s\n",
            "4035:\tlearn: 0.1496071\ttotal: 8m 12s\tremaining: 1m 57s\n",
            "4036:\tlearn: 0.1496025\ttotal: 8m 12s\tremaining: 1m 57s\n",
            "4037:\tlearn: 0.1495797\ttotal: 8m 12s\tremaining: 1m 57s\n",
            "4038:\tlearn: 0.1495592\ttotal: 8m 12s\tremaining: 1m 57s\n",
            "4039:\tlearn: 0.1495499\ttotal: 8m 12s\tremaining: 1m 57s\n",
            "4040:\tlearn: 0.1495348\ttotal: 8m 13s\tremaining: 1m 57s\n",
            "4041:\tlearn: 0.1495275\ttotal: 8m 13s\tremaining: 1m 56s\n",
            "4042:\tlearn: 0.1495179\ttotal: 8m 13s\tremaining: 1m 56s\n",
            "4043:\tlearn: 0.1495045\ttotal: 8m 13s\tremaining: 1m 56s\n",
            "4044:\tlearn: 0.1494913\ttotal: 8m 13s\tremaining: 1m 56s\n",
            "4045:\tlearn: 0.1494777\ttotal: 8m 13s\tremaining: 1m 56s\n",
            "4046:\tlearn: 0.1494706\ttotal: 8m 13s\tremaining: 1m 56s\n",
            "4047:\tlearn: 0.1494577\ttotal: 8m 13s\tremaining: 1m 56s\n",
            "4048:\tlearn: 0.1494535\ttotal: 8m 13s\tremaining: 1m 56s\n",
            "4049:\tlearn: 0.1494383\ttotal: 8m 14s\tremaining: 1m 55s\n",
            "4050:\tlearn: 0.1494154\ttotal: 8m 14s\tremaining: 1m 55s\n",
            "4051:\tlearn: 0.1494073\ttotal: 8m 14s\tremaining: 1m 55s\n",
            "4052:\tlearn: 0.1493932\ttotal: 8m 14s\tremaining: 1m 55s\n",
            "4053:\tlearn: 0.1493776\ttotal: 8m 14s\tremaining: 1m 55s\n",
            "4054:\tlearn: 0.1493713\ttotal: 8m 14s\tremaining: 1m 55s\n",
            "4055:\tlearn: 0.1493589\ttotal: 8m 14s\tremaining: 1m 55s\n",
            "4056:\tlearn: 0.1493463\ttotal: 8m 15s\tremaining: 1m 55s\n",
            "4057:\tlearn: 0.1493417\ttotal: 8m 15s\tremaining: 1m 54s\n",
            "4058:\tlearn: 0.1493332\ttotal: 8m 15s\tremaining: 1m 54s\n",
            "4059:\tlearn: 0.1493136\ttotal: 8m 15s\tremaining: 1m 54s\n",
            "4060:\tlearn: 0.1493046\ttotal: 8m 15s\tremaining: 1m 54s\n",
            "4061:\tlearn: 0.1492893\ttotal: 8m 15s\tremaining: 1m 54s\n",
            "4062:\tlearn: 0.1492781\ttotal: 8m 15s\tremaining: 1m 54s\n",
            "4063:\tlearn: 0.1492719\ttotal: 8m 15s\tremaining: 1m 54s\n",
            "4064:\tlearn: 0.1492603\ttotal: 8m 16s\tremaining: 1m 54s\n",
            "4065:\tlearn: 0.1492472\ttotal: 8m 16s\tremaining: 1m 53s\n",
            "4066:\tlearn: 0.1492366\ttotal: 8m 16s\tremaining: 1m 53s\n",
            "4067:\tlearn: 0.1492251\ttotal: 8m 16s\tremaining: 1m 53s\n",
            "4068:\tlearn: 0.1492163\ttotal: 8m 16s\tremaining: 1m 53s\n",
            "4069:\tlearn: 0.1492090\ttotal: 8m 16s\tremaining: 1m 53s\n",
            "4070:\tlearn: 0.1492016\ttotal: 8m 16s\tremaining: 1m 53s\n",
            "4071:\tlearn: 0.1491766\ttotal: 8m 16s\tremaining: 1m 53s\n",
            "4072:\tlearn: 0.1491678\ttotal: 8m 17s\tremaining: 1m 53s\n",
            "4073:\tlearn: 0.1491629\ttotal: 8m 17s\tremaining: 1m 53s\n",
            "4074:\tlearn: 0.1491581\ttotal: 8m 17s\tremaining: 1m 52s\n",
            "4075:\tlearn: 0.1491518\ttotal: 8m 17s\tremaining: 1m 52s\n",
            "4076:\tlearn: 0.1491455\ttotal: 8m 17s\tremaining: 1m 52s\n",
            "4077:\tlearn: 0.1491362\ttotal: 8m 17s\tremaining: 1m 52s\n",
            "4078:\tlearn: 0.1491247\ttotal: 8m 17s\tremaining: 1m 52s\n",
            "4079:\tlearn: 0.1491158\ttotal: 8m 17s\tremaining: 1m 52s\n",
            "4080:\tlearn: 0.1491041\ttotal: 8m 18s\tremaining: 1m 52s\n",
            "4081:\tlearn: 0.1490904\ttotal: 8m 18s\tremaining: 1m 52s\n",
            "4082:\tlearn: 0.1490777\ttotal: 8m 18s\tremaining: 1m 51s\n",
            "4083:\tlearn: 0.1490677\ttotal: 8m 18s\tremaining: 1m 51s\n",
            "4084:\tlearn: 0.1490595\ttotal: 8m 18s\tremaining: 1m 51s\n",
            "4085:\tlearn: 0.1490485\ttotal: 8m 18s\tremaining: 1m 51s\n",
            "4086:\tlearn: 0.1490372\ttotal: 8m 18s\tremaining: 1m 51s\n",
            "4087:\tlearn: 0.1490282\ttotal: 8m 18s\tremaining: 1m 51s\n",
            "4088:\tlearn: 0.1490188\ttotal: 8m 19s\tremaining: 1m 51s\n",
            "4089:\tlearn: 0.1490073\ttotal: 8m 19s\tremaining: 1m 51s\n",
            "4090:\tlearn: 0.1489980\ttotal: 8m 19s\tremaining: 1m 50s\n",
            "4091:\tlearn: 0.1489847\ttotal: 8m 19s\tremaining: 1m 50s\n",
            "4092:\tlearn: 0.1489754\ttotal: 8m 19s\tremaining: 1m 50s\n",
            "4093:\tlearn: 0.1489577\ttotal: 8m 19s\tremaining: 1m 50s\n",
            "4094:\tlearn: 0.1489473\ttotal: 8m 19s\tremaining: 1m 50s\n",
            "4095:\tlearn: 0.1489370\ttotal: 8m 19s\tremaining: 1m 50s\n",
            "4096:\tlearn: 0.1489228\ttotal: 8m 20s\tremaining: 1m 50s\n",
            "4097:\tlearn: 0.1489172\ttotal: 8m 20s\tremaining: 1m 50s\n",
            "4098:\tlearn: 0.1489068\ttotal: 8m 20s\tremaining: 1m 49s\n",
            "4099:\tlearn: 0.1488881\ttotal: 8m 20s\tremaining: 1m 49s\n",
            "4100:\tlearn: 0.1488806\ttotal: 8m 20s\tremaining: 1m 49s\n",
            "4101:\tlearn: 0.1488701\ttotal: 8m 20s\tremaining: 1m 49s\n",
            "4102:\tlearn: 0.1488631\ttotal: 8m 20s\tremaining: 1m 49s\n",
            "4103:\tlearn: 0.1488546\ttotal: 8m 21s\tremaining: 1m 49s\n",
            "4104:\tlearn: 0.1488486\ttotal: 8m 21s\tremaining: 1m 49s\n",
            "4105:\tlearn: 0.1488426\ttotal: 8m 21s\tremaining: 1m 49s\n",
            "4106:\tlearn: 0.1488242\ttotal: 8m 21s\tremaining: 1m 49s\n",
            "4107:\tlearn: 0.1488166\ttotal: 8m 21s\tremaining: 1m 48s\n",
            "4108:\tlearn: 0.1488107\ttotal: 8m 21s\tremaining: 1m 48s\n",
            "4109:\tlearn: 0.1487941\ttotal: 8m 21s\tremaining: 1m 48s\n",
            "4110:\tlearn: 0.1487810\ttotal: 8m 21s\tremaining: 1m 48s\n",
            "4111:\tlearn: 0.1487715\ttotal: 8m 21s\tremaining: 1m 48s\n",
            "4112:\tlearn: 0.1487566\ttotal: 8m 22s\tremaining: 1m 48s\n",
            "4113:\tlearn: 0.1487442\ttotal: 8m 22s\tremaining: 1m 48s\n",
            "4114:\tlearn: 0.1487356\ttotal: 8m 22s\tremaining: 1m 48s\n",
            "4115:\tlearn: 0.1487274\ttotal: 8m 22s\tremaining: 1m 47s\n",
            "4116:\tlearn: 0.1487188\ttotal: 8m 22s\tremaining: 1m 47s\n",
            "4117:\tlearn: 0.1487054\ttotal: 8m 22s\tremaining: 1m 47s\n",
            "4118:\tlearn: 0.1486944\ttotal: 8m 22s\tremaining: 1m 47s\n",
            "4119:\tlearn: 0.1486815\ttotal: 8m 23s\tremaining: 1m 47s\n",
            "4120:\tlearn: 0.1486714\ttotal: 8m 23s\tremaining: 1m 47s\n",
            "4121:\tlearn: 0.1486549\ttotal: 8m 23s\tremaining: 1m 47s\n",
            "4122:\tlearn: 0.1486459\ttotal: 8m 23s\tremaining: 1m 47s\n",
            "4123:\tlearn: 0.1486345\ttotal: 8m 23s\tremaining: 1m 46s\n",
            "4124:\tlearn: 0.1486169\ttotal: 8m 23s\tremaining: 1m 46s\n",
            "4125:\tlearn: 0.1486097\ttotal: 8m 23s\tremaining: 1m 46s\n",
            "4126:\tlearn: 0.1486011\ttotal: 8m 23s\tremaining: 1m 46s\n",
            "4127:\tlearn: 0.1485881\ttotal: 8m 24s\tremaining: 1m 46s\n",
            "4128:\tlearn: 0.1485732\ttotal: 8m 24s\tremaining: 1m 46s\n",
            "4129:\tlearn: 0.1485600\ttotal: 8m 24s\tremaining: 1m 46s\n",
            "4130:\tlearn: 0.1485306\ttotal: 8m 24s\tremaining: 1m 46s\n",
            "4131:\tlearn: 0.1485211\ttotal: 8m 24s\tremaining: 1m 45s\n",
            "4132:\tlearn: 0.1485097\ttotal: 8m 24s\tremaining: 1m 45s\n",
            "4133:\tlearn: 0.1484998\ttotal: 8m 24s\tremaining: 1m 45s\n",
            "4134:\tlearn: 0.1484968\ttotal: 8m 24s\tremaining: 1m 45s\n",
            "4135:\tlearn: 0.1484911\ttotal: 8m 24s\tremaining: 1m 45s\n",
            "4136:\tlearn: 0.1484804\ttotal: 8m 25s\tremaining: 1m 45s\n",
            "4137:\tlearn: 0.1484772\ttotal: 8m 25s\tremaining: 1m 45s\n",
            "4138:\tlearn: 0.1484659\ttotal: 8m 25s\tremaining: 1m 45s\n",
            "4139:\tlearn: 0.1484597\ttotal: 8m 25s\tremaining: 1m 45s\n",
            "4140:\tlearn: 0.1484475\ttotal: 8m 25s\tremaining: 1m 44s\n",
            "4141:\tlearn: 0.1484396\ttotal: 8m 25s\tremaining: 1m 44s\n",
            "4142:\tlearn: 0.1484305\ttotal: 8m 25s\tremaining: 1m 44s\n",
            "4143:\tlearn: 0.1484254\ttotal: 8m 25s\tremaining: 1m 44s\n",
            "4144:\tlearn: 0.1484161\ttotal: 8m 26s\tremaining: 1m 44s\n",
            "4145:\tlearn: 0.1484018\ttotal: 8m 26s\tremaining: 1m 44s\n",
            "4146:\tlearn: 0.1483922\ttotal: 8m 26s\tremaining: 1m 44s\n",
            "4147:\tlearn: 0.1483887\ttotal: 8m 26s\tremaining: 1m 44s\n",
            "4148:\tlearn: 0.1483845\ttotal: 8m 26s\tremaining: 1m 43s\n",
            "4149:\tlearn: 0.1483703\ttotal: 8m 26s\tremaining: 1m 43s\n",
            "4150:\tlearn: 0.1483662\ttotal: 8m 26s\tremaining: 1m 43s\n",
            "4151:\tlearn: 0.1483573\ttotal: 8m 26s\tremaining: 1m 43s\n",
            "4152:\tlearn: 0.1483406\ttotal: 8m 27s\tremaining: 1m 43s\n",
            "4153:\tlearn: 0.1483364\ttotal: 8m 27s\tremaining: 1m 43s\n",
            "4154:\tlearn: 0.1483246\ttotal: 8m 27s\tremaining: 1m 43s\n",
            "4155:\tlearn: 0.1483184\ttotal: 8m 27s\tremaining: 1m 43s\n",
            "4156:\tlearn: 0.1483128\ttotal: 8m 27s\tremaining: 1m 42s\n",
            "4157:\tlearn: 0.1482992\ttotal: 8m 27s\tremaining: 1m 42s\n",
            "4158:\tlearn: 0.1482880\ttotal: 8m 27s\tremaining: 1m 42s\n",
            "4159:\tlearn: 0.1482789\ttotal: 8m 27s\tremaining: 1m 42s\n",
            "4160:\tlearn: 0.1482648\ttotal: 8m 28s\tremaining: 1m 42s\n",
            "4161:\tlearn: 0.1482515\ttotal: 8m 28s\tremaining: 1m 42s\n",
            "4162:\tlearn: 0.1482427\ttotal: 8m 28s\tremaining: 1m 42s\n",
            "4163:\tlearn: 0.1482388\ttotal: 8m 28s\tremaining: 1m 42s\n",
            "4164:\tlearn: 0.1482268\ttotal: 8m 28s\tremaining: 1m 41s\n",
            "4165:\tlearn: 0.1481968\ttotal: 8m 28s\tremaining: 1m 41s\n",
            "4166:\tlearn: 0.1481898\ttotal: 8m 28s\tremaining: 1m 41s\n",
            "4167:\tlearn: 0.1481839\ttotal: 8m 28s\tremaining: 1m 41s\n",
            "4168:\tlearn: 0.1481764\ttotal: 8m 28s\tremaining: 1m 41s\n",
            "4169:\tlearn: 0.1481696\ttotal: 8m 29s\tremaining: 1m 41s\n",
            "4170:\tlearn: 0.1481523\ttotal: 8m 29s\tremaining: 1m 41s\n",
            "4171:\tlearn: 0.1481441\ttotal: 8m 29s\tremaining: 1m 41s\n",
            "4172:\tlearn: 0.1481310\ttotal: 8m 29s\tremaining: 1m 40s\n",
            "4173:\tlearn: 0.1481267\ttotal: 8m 29s\tremaining: 1m 40s\n",
            "4174:\tlearn: 0.1481170\ttotal: 8m 29s\tremaining: 1m 40s\n",
            "4175:\tlearn: 0.1480996\ttotal: 8m 29s\tremaining: 1m 40s\n",
            "4176:\tlearn: 0.1480887\ttotal: 8m 29s\tremaining: 1m 40s\n",
            "4177:\tlearn: 0.1480837\ttotal: 8m 30s\tremaining: 1m 40s\n",
            "4178:\tlearn: 0.1480793\ttotal: 8m 30s\tremaining: 1m 40s\n",
            "4179:\tlearn: 0.1480710\ttotal: 8m 30s\tremaining: 1m 40s\n",
            "4180:\tlearn: 0.1480610\ttotal: 8m 30s\tremaining: 1m 39s\n",
            "4181:\tlearn: 0.1480515\ttotal: 8m 30s\tremaining: 1m 39s\n",
            "4182:\tlearn: 0.1480388\ttotal: 8m 30s\tremaining: 1m 39s\n",
            "4183:\tlearn: 0.1480246\ttotal: 8m 30s\tremaining: 1m 39s\n",
            "4184:\tlearn: 0.1480104\ttotal: 8m 30s\tremaining: 1m 39s\n",
            "4185:\tlearn: 0.1479926\ttotal: 8m 31s\tremaining: 1m 39s\n",
            "4186:\tlearn: 0.1479848\ttotal: 8m 31s\tremaining: 1m 39s\n",
            "4187:\tlearn: 0.1479791\ttotal: 8m 31s\tremaining: 1m 39s\n",
            "4188:\tlearn: 0.1479713\ttotal: 8m 31s\tremaining: 1m 39s\n",
            "4189:\tlearn: 0.1479470\ttotal: 8m 31s\tremaining: 1m 38s\n",
            "4190:\tlearn: 0.1479331\ttotal: 8m 31s\tremaining: 1m 38s\n",
            "4191:\tlearn: 0.1479302\ttotal: 8m 31s\tremaining: 1m 38s\n",
            "4192:\tlearn: 0.1479152\ttotal: 8m 31s\tremaining: 1m 38s\n",
            "4193:\tlearn: 0.1479079\ttotal: 8m 32s\tremaining: 1m 38s\n",
            "4194:\tlearn: 0.1478925\ttotal: 8m 32s\tremaining: 1m 38s\n",
            "4195:\tlearn: 0.1478861\ttotal: 8m 32s\tremaining: 1m 38s\n",
            "4196:\tlearn: 0.1478810\ttotal: 8m 32s\tremaining: 1m 38s\n",
            "4197:\tlearn: 0.1478741\ttotal: 8m 32s\tremaining: 1m 37s\n",
            "4198:\tlearn: 0.1478635\ttotal: 8m 32s\tremaining: 1m 37s\n",
            "4199:\tlearn: 0.1478590\ttotal: 8m 32s\tremaining: 1m 37s\n",
            "4200:\tlearn: 0.1478497\ttotal: 8m 32s\tremaining: 1m 37s\n",
            "4201:\tlearn: 0.1478421\ttotal: 8m 32s\tremaining: 1m 37s\n",
            "4202:\tlearn: 0.1478265\ttotal: 8m 33s\tremaining: 1m 37s\n",
            "4203:\tlearn: 0.1478203\ttotal: 8m 33s\tremaining: 1m 37s\n",
            "4204:\tlearn: 0.1478120\ttotal: 8m 33s\tremaining: 1m 37s\n",
            "4205:\tlearn: 0.1478015\ttotal: 8m 33s\tremaining: 1m 36s\n",
            "4206:\tlearn: 0.1477921\ttotal: 8m 33s\tremaining: 1m 36s\n",
            "4207:\tlearn: 0.1477775\ttotal: 8m 33s\tremaining: 1m 36s\n",
            "4208:\tlearn: 0.1477720\ttotal: 8m 33s\tremaining: 1m 36s\n",
            "4209:\tlearn: 0.1477621\ttotal: 8m 33s\tremaining: 1m 36s\n",
            "4210:\tlearn: 0.1477528\ttotal: 8m 34s\tremaining: 1m 36s\n",
            "4211:\tlearn: 0.1477474\ttotal: 8m 34s\tremaining: 1m 36s\n",
            "4212:\tlearn: 0.1477268\ttotal: 8m 34s\tremaining: 1m 36s\n",
            "4213:\tlearn: 0.1477137\ttotal: 8m 34s\tremaining: 1m 35s\n",
            "4214:\tlearn: 0.1476955\ttotal: 8m 34s\tremaining: 1m 35s\n",
            "4215:\tlearn: 0.1476858\ttotal: 8m 34s\tremaining: 1m 35s\n",
            "4216:\tlearn: 0.1476691\ttotal: 8m 34s\tremaining: 1m 35s\n",
            "4217:\tlearn: 0.1476585\ttotal: 8m 34s\tremaining: 1m 35s\n",
            "4218:\tlearn: 0.1476481\ttotal: 8m 35s\tremaining: 1m 35s\n",
            "4219:\tlearn: 0.1476339\ttotal: 8m 35s\tremaining: 1m 35s\n",
            "4220:\tlearn: 0.1476236\ttotal: 8m 35s\tremaining: 1m 35s\n",
            "4221:\tlearn: 0.1476053\ttotal: 8m 35s\tremaining: 1m 34s\n",
            "4222:\tlearn: 0.1475963\ttotal: 8m 35s\tremaining: 1m 34s\n",
            "4223:\tlearn: 0.1475752\ttotal: 8m 35s\tremaining: 1m 34s\n",
            "4224:\tlearn: 0.1475687\ttotal: 8m 35s\tremaining: 1m 34s\n",
            "4225:\tlearn: 0.1475634\ttotal: 8m 35s\tremaining: 1m 34s\n",
            "4226:\tlearn: 0.1475548\ttotal: 8m 36s\tremaining: 1m 34s\n",
            "4227:\tlearn: 0.1475444\ttotal: 8m 36s\tremaining: 1m 34s\n",
            "4228:\tlearn: 0.1475368\ttotal: 8m 36s\tremaining: 1m 34s\n",
            "4229:\tlearn: 0.1475242\ttotal: 8m 36s\tremaining: 1m 34s\n",
            "4230:\tlearn: 0.1475093\ttotal: 8m 36s\tremaining: 1m 33s\n",
            "4231:\tlearn: 0.1474984\ttotal: 8m 36s\tremaining: 1m 33s\n",
            "4232:\tlearn: 0.1474916\ttotal: 8m 36s\tremaining: 1m 33s\n",
            "4233:\tlearn: 0.1474779\ttotal: 8m 36s\tremaining: 1m 33s\n",
            "4234:\tlearn: 0.1474702\ttotal: 8m 37s\tremaining: 1m 33s\n",
            "4235:\tlearn: 0.1474561\ttotal: 8m 37s\tremaining: 1m 33s\n",
            "4236:\tlearn: 0.1474501\ttotal: 8m 37s\tremaining: 1m 33s\n",
            "4237:\tlearn: 0.1474409\ttotal: 8m 37s\tremaining: 1m 33s\n",
            "4238:\tlearn: 0.1474291\ttotal: 8m 37s\tremaining: 1m 32s\n",
            "4239:\tlearn: 0.1474161\ttotal: 8m 37s\tremaining: 1m 32s\n",
            "4240:\tlearn: 0.1474092\ttotal: 8m 37s\tremaining: 1m 32s\n",
            "4241:\tlearn: 0.1474023\ttotal: 8m 37s\tremaining: 1m 32s\n",
            "4242:\tlearn: 0.1473926\ttotal: 8m 38s\tremaining: 1m 32s\n",
            "4243:\tlearn: 0.1473789\ttotal: 8m 38s\tremaining: 1m 32s\n",
            "4244:\tlearn: 0.1473760\ttotal: 8m 38s\tremaining: 1m 32s\n",
            "4245:\tlearn: 0.1473701\ttotal: 8m 38s\tremaining: 1m 32s\n",
            "4246:\tlearn: 0.1473584\ttotal: 8m 38s\tremaining: 1m 31s\n",
            "4247:\tlearn: 0.1473451\ttotal: 8m 38s\tremaining: 1m 31s\n",
            "4248:\tlearn: 0.1473317\ttotal: 8m 38s\tremaining: 1m 31s\n",
            "4249:\tlearn: 0.1473179\ttotal: 8m 38s\tremaining: 1m 31s\n",
            "4250:\tlearn: 0.1473111\ttotal: 8m 39s\tremaining: 1m 31s\n",
            "4251:\tlearn: 0.1473044\ttotal: 8m 39s\tremaining: 1m 31s\n",
            "4252:\tlearn: 0.1472930\ttotal: 8m 39s\tremaining: 1m 31s\n",
            "4253:\tlearn: 0.1472856\ttotal: 8m 39s\tremaining: 1m 31s\n",
            "4254:\tlearn: 0.1472823\ttotal: 8m 39s\tremaining: 1m 30s\n",
            "4255:\tlearn: 0.1472724\ttotal: 8m 39s\tremaining: 1m 30s\n",
            "4256:\tlearn: 0.1472675\ttotal: 8m 39s\tremaining: 1m 30s\n",
            "4257:\tlearn: 0.1472610\ttotal: 8m 39s\tremaining: 1m 30s\n",
            "4258:\tlearn: 0.1472516\ttotal: 8m 39s\tremaining: 1m 30s\n",
            "4259:\tlearn: 0.1472432\ttotal: 8m 40s\tremaining: 1m 30s\n",
            "4260:\tlearn: 0.1472336\ttotal: 8m 40s\tremaining: 1m 30s\n",
            "4261:\tlearn: 0.1472238\ttotal: 8m 40s\tremaining: 1m 30s\n",
            "4262:\tlearn: 0.1472189\ttotal: 8m 40s\tremaining: 1m 29s\n",
            "4263:\tlearn: 0.1472122\ttotal: 8m 40s\tremaining: 1m 29s\n",
            "4264:\tlearn: 0.1472012\ttotal: 8m 40s\tremaining: 1m 29s\n",
            "4265:\tlearn: 0.1471957\ttotal: 8m 40s\tremaining: 1m 29s\n",
            "4266:\tlearn: 0.1471784\ttotal: 8m 40s\tremaining: 1m 29s\n",
            "4267:\tlearn: 0.1471707\ttotal: 8m 41s\tremaining: 1m 29s\n",
            "4268:\tlearn: 0.1471632\ttotal: 8m 41s\tremaining: 1m 29s\n",
            "4269:\tlearn: 0.1471430\ttotal: 8m 41s\tremaining: 1m 29s\n",
            "4270:\tlearn: 0.1471400\ttotal: 8m 41s\tremaining: 1m 28s\n",
            "4271:\tlearn: 0.1471281\ttotal: 8m 41s\tremaining: 1m 28s\n",
            "4272:\tlearn: 0.1471202\ttotal: 8m 41s\tremaining: 1m 28s\n",
            "4273:\tlearn: 0.1471173\ttotal: 8m 41s\tremaining: 1m 28s\n",
            "4274:\tlearn: 0.1471051\ttotal: 8m 41s\tremaining: 1m 28s\n",
            "4275:\tlearn: 0.1470924\ttotal: 8m 42s\tremaining: 1m 28s\n",
            "4276:\tlearn: 0.1470729\ttotal: 8m 42s\tremaining: 1m 28s\n",
            "4277:\tlearn: 0.1470604\ttotal: 8m 42s\tremaining: 1m 28s\n",
            "4278:\tlearn: 0.1470526\ttotal: 8m 42s\tremaining: 1m 28s\n",
            "4279:\tlearn: 0.1470417\ttotal: 8m 42s\tremaining: 1m 27s\n",
            "4280:\tlearn: 0.1470273\ttotal: 8m 42s\tremaining: 1m 27s\n",
            "4281:\tlearn: 0.1470216\ttotal: 8m 42s\tremaining: 1m 27s\n",
            "4282:\tlearn: 0.1470139\ttotal: 8m 42s\tremaining: 1m 27s\n",
            "4283:\tlearn: 0.1469978\ttotal: 8m 43s\tremaining: 1m 27s\n",
            "4284:\tlearn: 0.1469861\ttotal: 8m 43s\tremaining: 1m 27s\n",
            "4285:\tlearn: 0.1469664\ttotal: 8m 43s\tremaining: 1m 27s\n",
            "4286:\tlearn: 0.1469493\ttotal: 8m 43s\tremaining: 1m 27s\n",
            "4287:\tlearn: 0.1469368\ttotal: 8m 43s\tremaining: 1m 26s\n",
            "4288:\tlearn: 0.1469252\ttotal: 8m 43s\tremaining: 1m 26s\n",
            "4289:\tlearn: 0.1469188\ttotal: 8m 43s\tremaining: 1m 26s\n",
            "4290:\tlearn: 0.1469034\ttotal: 8m 43s\tremaining: 1m 26s\n",
            "4291:\tlearn: 0.1468955\ttotal: 8m 44s\tremaining: 1m 26s\n",
            "4292:\tlearn: 0.1468875\ttotal: 8m 44s\tremaining: 1m 26s\n",
            "4293:\tlearn: 0.1468764\ttotal: 8m 44s\tremaining: 1m 26s\n",
            "4294:\tlearn: 0.1468725\ttotal: 8m 44s\tremaining: 1m 26s\n",
            "4295:\tlearn: 0.1468621\ttotal: 8m 44s\tremaining: 1m 25s\n",
            "4296:\tlearn: 0.1468422\ttotal: 8m 44s\tremaining: 1m 25s\n",
            "4297:\tlearn: 0.1468333\ttotal: 8m 44s\tremaining: 1m 25s\n",
            "4298:\tlearn: 0.1468195\ttotal: 8m 44s\tremaining: 1m 25s\n",
            "4299:\tlearn: 0.1468050\ttotal: 8m 45s\tremaining: 1m 25s\n",
            "4300:\tlearn: 0.1467961\ttotal: 8m 45s\tremaining: 1m 25s\n",
            "4301:\tlearn: 0.1467857\ttotal: 8m 45s\tremaining: 1m 25s\n",
            "4302:\tlearn: 0.1467727\ttotal: 8m 45s\tremaining: 1m 25s\n",
            "4303:\tlearn: 0.1467607\ttotal: 8m 45s\tremaining: 1m 24s\n",
            "4304:\tlearn: 0.1467527\ttotal: 8m 45s\tremaining: 1m 24s\n",
            "4305:\tlearn: 0.1467354\ttotal: 8m 45s\tremaining: 1m 24s\n",
            "4306:\tlearn: 0.1467248\ttotal: 8m 45s\tremaining: 1m 24s\n",
            "4307:\tlearn: 0.1467110\ttotal: 8m 46s\tremaining: 1m 24s\n",
            "4308:\tlearn: 0.1466940\ttotal: 8m 46s\tremaining: 1m 24s\n",
            "4309:\tlearn: 0.1466848\ttotal: 8m 46s\tremaining: 1m 24s\n",
            "4310:\tlearn: 0.1466679\ttotal: 8m 46s\tremaining: 1m 24s\n",
            "4311:\tlearn: 0.1466554\ttotal: 8m 46s\tremaining: 1m 24s\n",
            "4312:\tlearn: 0.1466472\ttotal: 8m 46s\tremaining: 1m 23s\n",
            "4313:\tlearn: 0.1466367\ttotal: 8m 46s\tremaining: 1m 23s\n",
            "4314:\tlearn: 0.1466298\ttotal: 8m 46s\tremaining: 1m 23s\n",
            "4315:\tlearn: 0.1466171\ttotal: 8m 47s\tremaining: 1m 23s\n",
            "4316:\tlearn: 0.1466090\ttotal: 8m 47s\tremaining: 1m 23s\n",
            "4317:\tlearn: 0.1466049\ttotal: 8m 47s\tremaining: 1m 23s\n",
            "4318:\tlearn: 0.1465960\ttotal: 8m 47s\tremaining: 1m 23s\n",
            "4319:\tlearn: 0.1465914\ttotal: 8m 47s\tremaining: 1m 23s\n",
            "4320:\tlearn: 0.1465826\ttotal: 8m 47s\tremaining: 1m 22s\n",
            "4321:\tlearn: 0.1465776\ttotal: 8m 47s\tremaining: 1m 22s\n",
            "4322:\tlearn: 0.1465636\ttotal: 8m 47s\tremaining: 1m 22s\n",
            "4323:\tlearn: 0.1465526\ttotal: 8m 47s\tremaining: 1m 22s\n",
            "4324:\tlearn: 0.1465472\ttotal: 8m 48s\tremaining: 1m 22s\n",
            "4325:\tlearn: 0.1465300\ttotal: 8m 48s\tremaining: 1m 22s\n",
            "4326:\tlearn: 0.1465212\ttotal: 8m 48s\tremaining: 1m 22s\n",
            "4327:\tlearn: 0.1465073\ttotal: 8m 48s\tremaining: 1m 22s\n",
            "4328:\tlearn: 0.1464977\ttotal: 8m 48s\tremaining: 1m 21s\n",
            "4329:\tlearn: 0.1464946\ttotal: 8m 48s\tremaining: 1m 21s\n",
            "4330:\tlearn: 0.1464824\ttotal: 8m 48s\tremaining: 1m 21s\n",
            "4331:\tlearn: 0.1464784\ttotal: 8m 48s\tremaining: 1m 21s\n",
            "4332:\tlearn: 0.1464696\ttotal: 8m 48s\tremaining: 1m 21s\n",
            "4333:\tlearn: 0.1464560\ttotal: 8m 49s\tremaining: 1m 21s\n",
            "4334:\tlearn: 0.1464467\ttotal: 8m 49s\tremaining: 1m 21s\n",
            "4335:\tlearn: 0.1464396\ttotal: 8m 49s\tremaining: 1m 21s\n",
            "4336:\tlearn: 0.1464332\ttotal: 8m 49s\tremaining: 1m 20s\n",
            "4337:\tlearn: 0.1464209\ttotal: 8m 49s\tremaining: 1m 20s\n",
            "4338:\tlearn: 0.1464167\ttotal: 8m 49s\tremaining: 1m 20s\n",
            "4339:\tlearn: 0.1464001\ttotal: 8m 49s\tremaining: 1m 20s\n",
            "4340:\tlearn: 0.1463890\ttotal: 8m 49s\tremaining: 1m 20s\n",
            "4341:\tlearn: 0.1463784\ttotal: 8m 50s\tremaining: 1m 20s\n",
            "4342:\tlearn: 0.1463674\ttotal: 8m 50s\tremaining: 1m 20s\n",
            "4343:\tlearn: 0.1463599\ttotal: 8m 50s\tremaining: 1m 20s\n",
            "4344:\tlearn: 0.1463542\ttotal: 8m 50s\tremaining: 1m 19s\n",
            "4345:\tlearn: 0.1463412\ttotal: 8m 50s\tremaining: 1m 19s\n",
            "4346:\tlearn: 0.1463365\ttotal: 8m 50s\tremaining: 1m 19s\n",
            "4347:\tlearn: 0.1463305\ttotal: 8m 50s\tremaining: 1m 19s\n",
            "4348:\tlearn: 0.1463223\ttotal: 8m 50s\tremaining: 1m 19s\n",
            "4349:\tlearn: 0.1463085\ttotal: 8m 51s\tremaining: 1m 19s\n",
            "4350:\tlearn: 0.1463010\ttotal: 8m 51s\tremaining: 1m 19s\n",
            "4351:\tlearn: 0.1462945\ttotal: 8m 51s\tremaining: 1m 19s\n",
            "4352:\tlearn: 0.1462832\ttotal: 8m 51s\tremaining: 1m 18s\n",
            "4353:\tlearn: 0.1462758\ttotal: 8m 51s\tremaining: 1m 18s\n",
            "4354:\tlearn: 0.1462678\ttotal: 8m 51s\tremaining: 1m 18s\n",
            "4355:\tlearn: 0.1462617\ttotal: 8m 51s\tremaining: 1m 18s\n",
            "4356:\tlearn: 0.1462490\ttotal: 8m 51s\tremaining: 1m 18s\n",
            "4357:\tlearn: 0.1462319\ttotal: 8m 52s\tremaining: 1m 18s\n",
            "4358:\tlearn: 0.1462213\ttotal: 8m 52s\tremaining: 1m 18s\n",
            "4359:\tlearn: 0.1461997\ttotal: 8m 52s\tremaining: 1m 18s\n",
            "4360:\tlearn: 0.1461937\ttotal: 8m 52s\tremaining: 1m 18s\n",
            "4361:\tlearn: 0.1461852\ttotal: 8m 52s\tremaining: 1m 17s\n",
            "4362:\tlearn: 0.1461814\ttotal: 8m 52s\tremaining: 1m 17s\n",
            "4363:\tlearn: 0.1461754\ttotal: 8m 52s\tremaining: 1m 17s\n",
            "4364:\tlearn: 0.1461673\ttotal: 8m 52s\tremaining: 1m 17s\n",
            "4365:\tlearn: 0.1461570\ttotal: 8m 52s\tremaining: 1m 17s\n",
            "4366:\tlearn: 0.1461479\ttotal: 8m 53s\tremaining: 1m 17s\n",
            "4367:\tlearn: 0.1461403\ttotal: 8m 53s\tremaining: 1m 17s\n",
            "4368:\tlearn: 0.1461347\ttotal: 8m 53s\tremaining: 1m 17s\n",
            "4369:\tlearn: 0.1461265\ttotal: 8m 53s\tremaining: 1m 16s\n",
            "4370:\tlearn: 0.1461196\ttotal: 8m 53s\tremaining: 1m 16s\n",
            "4371:\tlearn: 0.1461127\ttotal: 8m 53s\tremaining: 1m 16s\n",
            "4372:\tlearn: 0.1461029\ttotal: 8m 53s\tremaining: 1m 16s\n",
            "4373:\tlearn: 0.1460949\ttotal: 8m 53s\tremaining: 1m 16s\n",
            "4374:\tlearn: 0.1460836\ttotal: 8m 54s\tremaining: 1m 16s\n",
            "4375:\tlearn: 0.1460728\ttotal: 8m 54s\tremaining: 1m 16s\n",
            "4376:\tlearn: 0.1460645\ttotal: 8m 54s\tremaining: 1m 16s\n",
            "4377:\tlearn: 0.1460566\ttotal: 8m 54s\tremaining: 1m 15s\n",
            "4378:\tlearn: 0.1460427\ttotal: 8m 54s\tremaining: 1m 15s\n",
            "4379:\tlearn: 0.1460327\ttotal: 8m 54s\tremaining: 1m 15s\n",
            "4380:\tlearn: 0.1460258\ttotal: 8m 54s\tremaining: 1m 15s\n",
            "4381:\tlearn: 0.1460186\ttotal: 8m 54s\tremaining: 1m 15s\n",
            "4382:\tlearn: 0.1460085\ttotal: 8m 55s\tremaining: 1m 15s\n",
            "4383:\tlearn: 0.1460007\ttotal: 8m 55s\tremaining: 1m 15s\n",
            "4384:\tlearn: 0.1459936\ttotal: 8m 55s\tremaining: 1m 15s\n",
            "4385:\tlearn: 0.1459755\ttotal: 8m 55s\tremaining: 1m 14s\n",
            "4386:\tlearn: 0.1459682\ttotal: 8m 55s\tremaining: 1m 14s\n",
            "4387:\tlearn: 0.1459607\ttotal: 8m 55s\tremaining: 1m 14s\n",
            "4388:\tlearn: 0.1459540\ttotal: 8m 55s\tremaining: 1m 14s\n",
            "4389:\tlearn: 0.1459449\ttotal: 8m 55s\tremaining: 1m 14s\n",
            "4390:\tlearn: 0.1459412\ttotal: 8m 55s\tremaining: 1m 14s\n",
            "4391:\tlearn: 0.1459357\ttotal: 8m 56s\tremaining: 1m 14s\n",
            "4392:\tlearn: 0.1459306\ttotal: 8m 56s\tremaining: 1m 14s\n",
            "4393:\tlearn: 0.1459216\ttotal: 8m 56s\tremaining: 1m 13s\n",
            "4394:\tlearn: 0.1459151\ttotal: 8m 56s\tremaining: 1m 13s\n",
            "4395:\tlearn: 0.1459052\ttotal: 8m 56s\tremaining: 1m 13s\n",
            "4396:\tlearn: 0.1458975\ttotal: 8m 56s\tremaining: 1m 13s\n",
            "4397:\tlearn: 0.1458897\ttotal: 8m 56s\tremaining: 1m 13s\n",
            "4398:\tlearn: 0.1458715\ttotal: 8m 56s\tremaining: 1m 13s\n",
            "4399:\tlearn: 0.1458480\ttotal: 8m 57s\tremaining: 1m 13s\n",
            "4400:\tlearn: 0.1458369\ttotal: 8m 57s\tremaining: 1m 13s\n",
            "4401:\tlearn: 0.1458275\ttotal: 8m 57s\tremaining: 1m 12s\n",
            "4402:\tlearn: 0.1458199\ttotal: 8m 57s\tremaining: 1m 12s\n",
            "4403:\tlearn: 0.1458134\ttotal: 8m 57s\tremaining: 1m 12s\n",
            "4404:\tlearn: 0.1458044\ttotal: 8m 57s\tremaining: 1m 12s\n",
            "4405:\tlearn: 0.1457930\ttotal: 8m 57s\tremaining: 1m 12s\n",
            "4406:\tlearn: 0.1457890\ttotal: 8m 57s\tremaining: 1m 12s\n",
            "4407:\tlearn: 0.1457819\ttotal: 8m 58s\tremaining: 1m 12s\n",
            "4408:\tlearn: 0.1457762\ttotal: 8m 58s\tremaining: 1m 12s\n",
            "4409:\tlearn: 0.1457638\ttotal: 8m 58s\tremaining: 1m 12s\n",
            "4410:\tlearn: 0.1457524\ttotal: 8m 58s\tremaining: 1m 11s\n",
            "4411:\tlearn: 0.1457393\ttotal: 8m 58s\tremaining: 1m 11s\n",
            "4412:\tlearn: 0.1457319\ttotal: 8m 58s\tremaining: 1m 11s\n",
            "4413:\tlearn: 0.1457262\ttotal: 8m 58s\tremaining: 1m 11s\n",
            "4414:\tlearn: 0.1457159\ttotal: 8m 58s\tremaining: 1m 11s\n",
            "4415:\tlearn: 0.1457097\ttotal: 8m 59s\tremaining: 1m 11s\n",
            "4416:\tlearn: 0.1456975\ttotal: 8m 59s\tremaining: 1m 11s\n",
            "4417:\tlearn: 0.1456890\ttotal: 8m 59s\tremaining: 1m 11s\n",
            "4418:\tlearn: 0.1456780\ttotal: 8m 59s\tremaining: 1m 10s\n",
            "4419:\tlearn: 0.1456728\ttotal: 8m 59s\tremaining: 1m 10s\n",
            "4420:\tlearn: 0.1456630\ttotal: 8m 59s\tremaining: 1m 10s\n",
            "4421:\tlearn: 0.1456482\ttotal: 8m 59s\tremaining: 1m 10s\n",
            "4422:\tlearn: 0.1456439\ttotal: 8m 59s\tremaining: 1m 10s\n",
            "4423:\tlearn: 0.1456313\ttotal: 8m 59s\tremaining: 1m 10s\n",
            "4424:\tlearn: 0.1456237\ttotal: 9m\tremaining: 1m 10s\n",
            "4425:\tlearn: 0.1456165\ttotal: 9m\tremaining: 1m 10s\n",
            "4426:\tlearn: 0.1456037\ttotal: 9m\tremaining: 1m 9s\n",
            "4427:\tlearn: 0.1455902\ttotal: 9m\tremaining: 1m 9s\n",
            "4428:\tlearn: 0.1455817\ttotal: 9m\tremaining: 1m 9s\n",
            "4429:\tlearn: 0.1455748\ttotal: 9m\tremaining: 1m 9s\n",
            "4430:\tlearn: 0.1455613\ttotal: 9m\tremaining: 1m 9s\n",
            "4431:\tlearn: 0.1455574\ttotal: 9m\tremaining: 1m 9s\n",
            "4432:\tlearn: 0.1455478\ttotal: 9m 1s\tremaining: 1m 9s\n",
            "4433:\tlearn: 0.1455357\ttotal: 9m 1s\tremaining: 1m 9s\n",
            "4434:\tlearn: 0.1455256\ttotal: 9m 1s\tremaining: 1m 8s\n",
            "4435:\tlearn: 0.1455203\ttotal: 9m 1s\tremaining: 1m 8s\n",
            "4436:\tlearn: 0.1455131\ttotal: 9m 1s\tremaining: 1m 8s\n",
            "4437:\tlearn: 0.1455049\ttotal: 9m 1s\tremaining: 1m 8s\n",
            "4438:\tlearn: 0.1455008\ttotal: 9m 1s\tremaining: 1m 8s\n",
            "4439:\tlearn: 0.1454925\ttotal: 9m 1s\tremaining: 1m 8s\n",
            "4440:\tlearn: 0.1454870\ttotal: 9m 1s\tremaining: 1m 8s\n",
            "4441:\tlearn: 0.1454755\ttotal: 9m 2s\tremaining: 1m 8s\n",
            "4442:\tlearn: 0.1454704\ttotal: 9m 2s\tremaining: 1m 7s\n",
            "4443:\tlearn: 0.1454589\ttotal: 9m 2s\tremaining: 1m 7s\n",
            "4444:\tlearn: 0.1454423\ttotal: 9m 2s\tremaining: 1m 7s\n",
            "4445:\tlearn: 0.1454309\ttotal: 9m 2s\tremaining: 1m 7s\n",
            "4446:\tlearn: 0.1454213\ttotal: 9m 2s\tremaining: 1m 7s\n",
            "4447:\tlearn: 0.1454053\ttotal: 9m 2s\tremaining: 1m 7s\n",
            "4448:\tlearn: 0.1453964\ttotal: 9m 2s\tremaining: 1m 7s\n",
            "4449:\tlearn: 0.1453899\ttotal: 9m 3s\tremaining: 1m 7s\n",
            "4450:\tlearn: 0.1453852\ttotal: 9m 3s\tremaining: 1m 6s\n",
            "4451:\tlearn: 0.1453756\ttotal: 9m 3s\tremaining: 1m 6s\n",
            "4452:\tlearn: 0.1453705\ttotal: 9m 3s\tremaining: 1m 6s\n",
            "4453:\tlearn: 0.1453555\ttotal: 9m 3s\tremaining: 1m 6s\n",
            "4454:\tlearn: 0.1453479\ttotal: 9m 3s\tremaining: 1m 6s\n",
            "4455:\tlearn: 0.1453382\ttotal: 9m 3s\tremaining: 1m 6s\n",
            "4456:\tlearn: 0.1453292\ttotal: 9m 3s\tremaining: 1m 6s\n",
            "4457:\tlearn: 0.1453144\ttotal: 9m 4s\tremaining: 1m 6s\n",
            "4458:\tlearn: 0.1453050\ttotal: 9m 4s\tremaining: 1m 6s\n",
            "4459:\tlearn: 0.1452922\ttotal: 9m 4s\tremaining: 1m 5s\n",
            "4460:\tlearn: 0.1452818\ttotal: 9m 4s\tremaining: 1m 5s\n",
            "4461:\tlearn: 0.1452778\ttotal: 9m 4s\tremaining: 1m 5s\n",
            "4462:\tlearn: 0.1452729\ttotal: 9m 4s\tremaining: 1m 5s\n",
            "4463:\tlearn: 0.1452657\ttotal: 9m 4s\tremaining: 1m 5s\n",
            "4464:\tlearn: 0.1452557\ttotal: 9m 4s\tremaining: 1m 5s\n",
            "4465:\tlearn: 0.1452468\ttotal: 9m 4s\tremaining: 1m 5s\n",
            "4466:\tlearn: 0.1452363\ttotal: 9m 5s\tremaining: 1m 5s\n",
            "4467:\tlearn: 0.1452278\ttotal: 9m 5s\tremaining: 1m 4s\n",
            "4468:\tlearn: 0.1452160\ttotal: 9m 5s\tremaining: 1m 4s\n",
            "4469:\tlearn: 0.1451994\ttotal: 9m 5s\tremaining: 1m 4s\n",
            "4470:\tlearn: 0.1451906\ttotal: 9m 5s\tremaining: 1m 4s\n",
            "4471:\tlearn: 0.1451760\ttotal: 9m 5s\tremaining: 1m 4s\n",
            "4472:\tlearn: 0.1451661\ttotal: 9m 5s\tremaining: 1m 4s\n",
            "4473:\tlearn: 0.1451581\ttotal: 9m 5s\tremaining: 1m 4s\n",
            "4474:\tlearn: 0.1451493\ttotal: 9m 6s\tremaining: 1m 4s\n",
            "4475:\tlearn: 0.1451377\ttotal: 9m 6s\tremaining: 1m 3s\n",
            "4476:\tlearn: 0.1451305\ttotal: 9m 6s\tremaining: 1m 3s\n",
            "4477:\tlearn: 0.1451143\ttotal: 9m 6s\tremaining: 1m 3s\n",
            "4478:\tlearn: 0.1451056\ttotal: 9m 6s\tremaining: 1m 3s\n",
            "4479:\tlearn: 0.1450978\ttotal: 9m 6s\tremaining: 1m 3s\n",
            "4480:\tlearn: 0.1450911\ttotal: 9m 6s\tremaining: 1m 3s\n",
            "4481:\tlearn: 0.1450795\ttotal: 9m 6s\tremaining: 1m 3s\n",
            "4482:\tlearn: 0.1450700\ttotal: 9m 7s\tremaining: 1m 3s\n",
            "4483:\tlearn: 0.1450592\ttotal: 9m 7s\tremaining: 1m 2s\n",
            "4484:\tlearn: 0.1450508\ttotal: 9m 7s\tremaining: 1m 2s\n",
            "4485:\tlearn: 0.1450444\ttotal: 9m 7s\tremaining: 1m 2s\n",
            "4486:\tlearn: 0.1450369\ttotal: 9m 7s\tremaining: 1m 2s\n",
            "4487:\tlearn: 0.1450244\ttotal: 9m 7s\tremaining: 1m 2s\n",
            "4488:\tlearn: 0.1450143\ttotal: 9m 7s\tremaining: 1m 2s\n",
            "4489:\tlearn: 0.1450044\ttotal: 9m 7s\tremaining: 1m 2s\n",
            "4490:\tlearn: 0.1449966\ttotal: 9m 8s\tremaining: 1m 2s\n",
            "4491:\tlearn: 0.1449900\ttotal: 9m 8s\tremaining: 1m 1s\n",
            "4492:\tlearn: 0.1449816\ttotal: 9m 8s\tremaining: 1m 1s\n",
            "4493:\tlearn: 0.1449738\ttotal: 9m 8s\tremaining: 1m 1s\n",
            "4494:\tlearn: 0.1449537\ttotal: 9m 8s\tremaining: 1m 1s\n",
            "4495:\tlearn: 0.1449421\ttotal: 9m 8s\tremaining: 1m 1s\n",
            "4496:\tlearn: 0.1449320\ttotal: 9m 8s\tremaining: 1m 1s\n",
            "4497:\tlearn: 0.1449194\ttotal: 9m 8s\tremaining: 1m 1s\n",
            "4498:\tlearn: 0.1449147\ttotal: 9m 8s\tremaining: 1m 1s\n",
            "4499:\tlearn: 0.1449031\ttotal: 9m 9s\tremaining: 1m 1s\n",
            "4500:\tlearn: 0.1448883\ttotal: 9m 9s\tremaining: 1m\n",
            "4501:\tlearn: 0.1448831\ttotal: 9m 9s\tremaining: 1m\n",
            "4502:\tlearn: 0.1448704\ttotal: 9m 9s\tremaining: 1m\n",
            "4503:\tlearn: 0.1448629\ttotal: 9m 9s\tremaining: 1m\n",
            "4504:\tlearn: 0.1448510\ttotal: 9m 9s\tremaining: 1m\n",
            "4505:\tlearn: 0.1448418\ttotal: 9m 9s\tremaining: 1m\n",
            "4506:\tlearn: 0.1448251\ttotal: 9m 9s\tremaining: 1m\n",
            "4507:\tlearn: 0.1448168\ttotal: 9m 9s\tremaining: 1m\n",
            "4508:\tlearn: 0.1448025\ttotal: 9m 10s\tremaining: 59.9s\n",
            "4509:\tlearn: 0.1447987\ttotal: 9m 10s\tremaining: 59.8s\n",
            "4510:\tlearn: 0.1447949\ttotal: 9m 10s\tremaining: 59.7s\n",
            "4511:\tlearn: 0.1447858\ttotal: 9m 10s\tremaining: 59.5s\n",
            "4512:\tlearn: 0.1447658\ttotal: 9m 10s\tremaining: 59.4s\n",
            "4513:\tlearn: 0.1447543\ttotal: 9m 10s\tremaining: 59.3s\n",
            "4514:\tlearn: 0.1447413\ttotal: 9m 10s\tremaining: 59.2s\n",
            "4515:\tlearn: 0.1447278\ttotal: 9m 10s\tremaining: 59s\n",
            "4516:\tlearn: 0.1447201\ttotal: 9m 11s\tremaining: 58.9s\n",
            "4517:\tlearn: 0.1447096\ttotal: 9m 11s\tremaining: 58.8s\n",
            "4518:\tlearn: 0.1447027\ttotal: 9m 11s\tremaining: 58.7s\n",
            "4519:\tlearn: 0.1446952\ttotal: 9m 11s\tremaining: 58.6s\n",
            "4520:\tlearn: 0.1446844\ttotal: 9m 11s\tremaining: 58.4s\n",
            "4521:\tlearn: 0.1446776\ttotal: 9m 11s\tremaining: 58.3s\n",
            "4522:\tlearn: 0.1446696\ttotal: 9m 11s\tremaining: 58.2s\n",
            "4523:\tlearn: 0.1446608\ttotal: 9m 11s\tremaining: 58.1s\n",
            "4524:\tlearn: 0.1446442\ttotal: 9m 12s\tremaining: 57.9s\n",
            "4525:\tlearn: 0.1446376\ttotal: 9m 12s\tremaining: 57.8s\n",
            "4526:\tlearn: 0.1446285\ttotal: 9m 12s\tremaining: 57.7s\n",
            "4527:\tlearn: 0.1446145\ttotal: 9m 12s\tremaining: 57.6s\n",
            "4528:\tlearn: 0.1446072\ttotal: 9m 12s\tremaining: 57.5s\n",
            "4529:\tlearn: 0.1446038\ttotal: 9m 12s\tremaining: 57.3s\n",
            "4530:\tlearn: 0.1445947\ttotal: 9m 12s\tremaining: 57.2s\n",
            "4531:\tlearn: 0.1445852\ttotal: 9m 12s\tremaining: 57.1s\n",
            "4532:\tlearn: 0.1445702\ttotal: 9m 12s\tremaining: 57s\n",
            "4533:\tlearn: 0.1445652\ttotal: 9m 13s\tremaining: 56.8s\n",
            "4534:\tlearn: 0.1445574\ttotal: 9m 13s\tremaining: 56.7s\n",
            "4535:\tlearn: 0.1445512\ttotal: 9m 13s\tremaining: 56.6s\n",
            "4536:\tlearn: 0.1445418\ttotal: 9m 13s\tremaining: 56.5s\n",
            "4537:\tlearn: 0.1445339\ttotal: 9m 13s\tremaining: 56.4s\n",
            "4538:\tlearn: 0.1445222\ttotal: 9m 13s\tremaining: 56.2s\n",
            "4539:\tlearn: 0.1445155\ttotal: 9m 13s\tremaining: 56.1s\n",
            "4540:\tlearn: 0.1445067\ttotal: 9m 13s\tremaining: 56s\n",
            "4541:\tlearn: 0.1444939\ttotal: 9m 14s\tremaining: 55.9s\n",
            "4542:\tlearn: 0.1444815\ttotal: 9m 14s\tremaining: 55.7s\n",
            "4543:\tlearn: 0.1444734\ttotal: 9m 14s\tremaining: 55.6s\n",
            "4544:\tlearn: 0.1444679\ttotal: 9m 14s\tremaining: 55.5s\n",
            "4545:\tlearn: 0.1444646\ttotal: 9m 14s\tremaining: 55.4s\n",
            "4546:\tlearn: 0.1444610\ttotal: 9m 14s\tremaining: 55.3s\n",
            "4547:\tlearn: 0.1444495\ttotal: 9m 14s\tremaining: 55.1s\n",
            "4548:\tlearn: 0.1444423\ttotal: 9m 14s\tremaining: 55s\n",
            "4549:\tlearn: 0.1444312\ttotal: 9m 15s\tremaining: 54.9s\n",
            "4550:\tlearn: 0.1444216\ttotal: 9m 15s\tremaining: 54.8s\n",
            "4551:\tlearn: 0.1444175\ttotal: 9m 15s\tremaining: 54.6s\n",
            "4552:\tlearn: 0.1444107\ttotal: 9m 15s\tremaining: 54.5s\n",
            "4553:\tlearn: 0.1443934\ttotal: 9m 15s\tremaining: 54.4s\n",
            "4554:\tlearn: 0.1443754\ttotal: 9m 15s\tremaining: 54.3s\n",
            "4555:\tlearn: 0.1443677\ttotal: 9m 15s\tremaining: 54.2s\n",
            "4556:\tlearn: 0.1443562\ttotal: 9m 15s\tremaining: 54s\n",
            "4557:\tlearn: 0.1443440\ttotal: 9m 16s\tremaining: 53.9s\n",
            "4558:\tlearn: 0.1443298\ttotal: 9m 16s\tremaining: 53.8s\n",
            "4559:\tlearn: 0.1443104\ttotal: 9m 16s\tremaining: 53.7s\n",
            "4560:\tlearn: 0.1442943\ttotal: 9m 16s\tremaining: 53.6s\n",
            "4561:\tlearn: 0.1442835\ttotal: 9m 16s\tremaining: 53.4s\n",
            "4562:\tlearn: 0.1442734\ttotal: 9m 16s\tremaining: 53.3s\n",
            "4563:\tlearn: 0.1442679\ttotal: 9m 16s\tremaining: 53.2s\n",
            "4564:\tlearn: 0.1442552\ttotal: 9m 16s\tremaining: 53.1s\n",
            "4565:\tlearn: 0.1442475\ttotal: 9m 17s\tremaining: 52.9s\n",
            "4566:\tlearn: 0.1442388\ttotal: 9m 17s\tremaining: 52.8s\n",
            "4567:\tlearn: 0.1442211\ttotal: 9m 17s\tremaining: 52.7s\n",
            "4568:\tlearn: 0.1442166\ttotal: 9m 17s\tremaining: 52.6s\n",
            "4569:\tlearn: 0.1442061\ttotal: 9m 17s\tremaining: 52.5s\n",
            "4570:\tlearn: 0.1441967\ttotal: 9m 17s\tremaining: 52.3s\n",
            "4571:\tlearn: 0.1441918\ttotal: 9m 17s\tremaining: 52.2s\n",
            "4572:\tlearn: 0.1441877\ttotal: 9m 17s\tremaining: 52.1s\n",
            "4573:\tlearn: 0.1441826\ttotal: 9m 17s\tremaining: 52s\n",
            "4574:\tlearn: 0.1441749\ttotal: 9m 18s\tremaining: 51.8s\n",
            "4575:\tlearn: 0.1441644\ttotal: 9m 18s\tremaining: 51.7s\n",
            "4576:\tlearn: 0.1441585\ttotal: 9m 18s\tremaining: 51.6s\n",
            "4577:\tlearn: 0.1441453\ttotal: 9m 18s\tremaining: 51.5s\n",
            "4578:\tlearn: 0.1441365\ttotal: 9m 18s\tremaining: 51.4s\n",
            "4579:\tlearn: 0.1441235\ttotal: 9m 18s\tremaining: 51.2s\n",
            "4580:\tlearn: 0.1441182\ttotal: 9m 18s\tremaining: 51.1s\n",
            "4581:\tlearn: 0.1441095\ttotal: 9m 18s\tremaining: 51s\n",
            "4582:\tlearn: 0.1441004\ttotal: 9m 18s\tremaining: 50.9s\n",
            "4583:\tlearn: 0.1440875\ttotal: 9m 19s\tremaining: 50.7s\n",
            "4584:\tlearn: 0.1440772\ttotal: 9m 19s\tremaining: 50.6s\n",
            "4585:\tlearn: 0.1440663\ttotal: 9m 19s\tremaining: 50.5s\n",
            "4586:\tlearn: 0.1440601\ttotal: 9m 19s\tremaining: 50.4s\n",
            "4587:\tlearn: 0.1440553\ttotal: 9m 19s\tremaining: 50.3s\n",
            "4588:\tlearn: 0.1440463\ttotal: 9m 19s\tremaining: 50.1s\n",
            "4589:\tlearn: 0.1440314\ttotal: 9m 19s\tremaining: 50s\n",
            "4590:\tlearn: 0.1440205\ttotal: 9m 19s\tremaining: 49.9s\n",
            "4591:\tlearn: 0.1440092\ttotal: 9m 20s\tremaining: 49.8s\n",
            "4592:\tlearn: 0.1439988\ttotal: 9m 20s\tremaining: 49.6s\n",
            "4593:\tlearn: 0.1439931\ttotal: 9m 20s\tremaining: 49.5s\n",
            "4594:\tlearn: 0.1439815\ttotal: 9m 20s\tremaining: 49.4s\n",
            "4595:\tlearn: 0.1439745\ttotal: 9m 20s\tremaining: 49.3s\n",
            "4596:\tlearn: 0.1439696\ttotal: 9m 20s\tremaining: 49.2s\n",
            "4597:\tlearn: 0.1439636\ttotal: 9m 20s\tremaining: 49s\n",
            "4598:\tlearn: 0.1439432\ttotal: 9m 20s\tremaining: 48.9s\n",
            "4599:\tlearn: 0.1439376\ttotal: 9m 21s\tremaining: 48.8s\n",
            "4600:\tlearn: 0.1439283\ttotal: 9m 21s\tremaining: 48.7s\n",
            "4601:\tlearn: 0.1439231\ttotal: 9m 21s\tremaining: 48.5s\n",
            "4602:\tlearn: 0.1439065\ttotal: 9m 21s\tremaining: 48.4s\n",
            "4603:\tlearn: 0.1438974\ttotal: 9m 21s\tremaining: 48.3s\n",
            "4604:\tlearn: 0.1438895\ttotal: 9m 21s\tremaining: 48.2s\n",
            "4605:\tlearn: 0.1438744\ttotal: 9m 21s\tremaining: 48.1s\n",
            "4606:\tlearn: 0.1438696\ttotal: 9m 21s\tremaining: 47.9s\n",
            "4607:\tlearn: 0.1438545\ttotal: 9m 22s\tremaining: 47.8s\n",
            "4608:\tlearn: 0.1438464\ttotal: 9m 22s\tremaining: 47.7s\n",
            "4609:\tlearn: 0.1438329\ttotal: 9m 22s\tremaining: 47.6s\n",
            "4610:\tlearn: 0.1438102\ttotal: 9m 22s\tremaining: 47.5s\n",
            "4611:\tlearn: 0.1437945\ttotal: 9m 22s\tremaining: 47.3s\n",
            "4612:\tlearn: 0.1437800\ttotal: 9m 22s\tremaining: 47.2s\n",
            "4613:\tlearn: 0.1437669\ttotal: 9m 22s\tremaining: 47.1s\n",
            "4614:\tlearn: 0.1437558\ttotal: 9m 23s\tremaining: 47s\n",
            "4615:\tlearn: 0.1437411\ttotal: 9m 23s\tremaining: 46.9s\n",
            "4616:\tlearn: 0.1437343\ttotal: 9m 23s\tremaining: 46.7s\n",
            "4617:\tlearn: 0.1437280\ttotal: 9m 23s\tremaining: 46.6s\n",
            "4618:\tlearn: 0.1437227\ttotal: 9m 23s\tremaining: 46.5s\n",
            "4619:\tlearn: 0.1437121\ttotal: 9m 23s\tremaining: 46.4s\n",
            "4620:\tlearn: 0.1436967\ttotal: 9m 23s\tremaining: 46.2s\n",
            "4621:\tlearn: 0.1436832\ttotal: 9m 23s\tremaining: 46.1s\n",
            "4622:\tlearn: 0.1436754\ttotal: 9m 24s\tremaining: 46s\n",
            "4623:\tlearn: 0.1436674\ttotal: 9m 24s\tremaining: 45.9s\n",
            "4624:\tlearn: 0.1436574\ttotal: 9m 24s\tremaining: 45.7s\n",
            "4625:\tlearn: 0.1436412\ttotal: 9m 24s\tremaining: 45.6s\n",
            "4626:\tlearn: 0.1436325\ttotal: 9m 24s\tremaining: 45.5s\n",
            "4627:\tlearn: 0.1436255\ttotal: 9m 24s\tremaining: 45.4s\n",
            "4628:\tlearn: 0.1436157\ttotal: 9m 24s\tremaining: 45.3s\n",
            "4629:\tlearn: 0.1436040\ttotal: 9m 24s\tremaining: 45.1s\n",
            "4630:\tlearn: 0.1435967\ttotal: 9m 24s\tremaining: 45s\n",
            "4631:\tlearn: 0.1435886\ttotal: 9m 25s\tremaining: 44.9s\n",
            "4632:\tlearn: 0.1435707\ttotal: 9m 25s\tremaining: 44.8s\n",
            "4633:\tlearn: 0.1435615\ttotal: 9m 25s\tremaining: 44.7s\n",
            "4634:\tlearn: 0.1435557\ttotal: 9m 25s\tremaining: 44.5s\n",
            "4635:\tlearn: 0.1435484\ttotal: 9m 25s\tremaining: 44.4s\n",
            "4636:\tlearn: 0.1435374\ttotal: 9m 25s\tremaining: 44.3s\n",
            "4637:\tlearn: 0.1435240\ttotal: 9m 25s\tremaining: 44.2s\n",
            "4638:\tlearn: 0.1435099\ttotal: 9m 25s\tremaining: 44s\n",
            "4639:\tlearn: 0.1434943\ttotal: 9m 26s\tremaining: 43.9s\n",
            "4640:\tlearn: 0.1434888\ttotal: 9m 26s\tremaining: 43.8s\n",
            "4641:\tlearn: 0.1434833\ttotal: 9m 26s\tremaining: 43.7s\n",
            "4642:\tlearn: 0.1434722\ttotal: 9m 26s\tremaining: 43.6s\n",
            "4643:\tlearn: 0.1434648\ttotal: 9m 26s\tremaining: 43.4s\n",
            "4644:\tlearn: 0.1434578\ttotal: 9m 26s\tremaining: 43.3s\n",
            "4645:\tlearn: 0.1434473\ttotal: 9m 26s\tremaining: 43.2s\n",
            "4646:\tlearn: 0.1434387\ttotal: 9m 26s\tremaining: 43.1s\n",
            "4647:\tlearn: 0.1434348\ttotal: 9m 27s\tremaining: 42.9s\n",
            "4648:\tlearn: 0.1434276\ttotal: 9m 27s\tremaining: 42.8s\n",
            "4649:\tlearn: 0.1434127\ttotal: 9m 27s\tremaining: 42.7s\n",
            "4650:\tlearn: 0.1434082\ttotal: 9m 27s\tremaining: 42.6s\n",
            "4651:\tlearn: 0.1433994\ttotal: 9m 27s\tremaining: 42.5s\n",
            "4652:\tlearn: 0.1433864\ttotal: 9m 27s\tremaining: 42.3s\n",
            "4653:\tlearn: 0.1433812\ttotal: 9m 27s\tremaining: 42.2s\n",
            "4654:\tlearn: 0.1433715\ttotal: 9m 27s\tremaining: 42.1s\n",
            "4655:\tlearn: 0.1433596\ttotal: 9m 28s\tremaining: 42s\n",
            "4656:\tlearn: 0.1433522\ttotal: 9m 28s\tremaining: 41.8s\n",
            "4657:\tlearn: 0.1433397\ttotal: 9m 28s\tremaining: 41.7s\n",
            "4658:\tlearn: 0.1433264\ttotal: 9m 28s\tremaining: 41.6s\n",
            "4659:\tlearn: 0.1433189\ttotal: 9m 28s\tremaining: 41.5s\n",
            "4660:\tlearn: 0.1433061\ttotal: 9m 28s\tremaining: 41.4s\n",
            "4661:\tlearn: 0.1432947\ttotal: 9m 28s\tremaining: 41.2s\n",
            "4662:\tlearn: 0.1432865\ttotal: 9m 28s\tremaining: 41.1s\n",
            "4663:\tlearn: 0.1432817\ttotal: 9m 28s\tremaining: 41s\n",
            "4664:\tlearn: 0.1432775\ttotal: 9m 29s\tremaining: 40.9s\n",
            "4665:\tlearn: 0.1432640\ttotal: 9m 29s\tremaining: 40.7s\n",
            "4666:\tlearn: 0.1432576\ttotal: 9m 29s\tremaining: 40.6s\n",
            "4667:\tlearn: 0.1432540\ttotal: 9m 29s\tremaining: 40.5s\n",
            "4668:\tlearn: 0.1432491\ttotal: 9m 29s\tremaining: 40.4s\n",
            "4669:\tlearn: 0.1432414\ttotal: 9m 29s\tremaining: 40.3s\n",
            "4670:\tlearn: 0.1432381\ttotal: 9m 29s\tremaining: 40.1s\n",
            "4671:\tlearn: 0.1432304\ttotal: 9m 29s\tremaining: 40s\n",
            "4672:\tlearn: 0.1432060\ttotal: 9m 29s\tremaining: 39.9s\n",
            "4673:\tlearn: 0.1431980\ttotal: 9m 30s\tremaining: 39.8s\n",
            "4674:\tlearn: 0.1431903\ttotal: 9m 30s\tremaining: 39.6s\n",
            "4675:\tlearn: 0.1431767\ttotal: 9m 30s\tremaining: 39.5s\n",
            "4676:\tlearn: 0.1431675\ttotal: 9m 30s\tremaining: 39.4s\n",
            "4677:\tlearn: 0.1431469\ttotal: 9m 30s\tremaining: 39.3s\n",
            "4678:\tlearn: 0.1431423\ttotal: 9m 30s\tremaining: 39.2s\n",
            "4679:\tlearn: 0.1431242\ttotal: 9m 30s\tremaining: 39s\n",
            "4680:\tlearn: 0.1431128\ttotal: 9m 30s\tremaining: 38.9s\n",
            "4681:\tlearn: 0.1430965\ttotal: 9m 31s\tremaining: 38.8s\n",
            "4682:\tlearn: 0.1430861\ttotal: 9m 31s\tremaining: 38.7s\n",
            "4683:\tlearn: 0.1430786\ttotal: 9m 31s\tremaining: 38.5s\n",
            "4684:\tlearn: 0.1430664\ttotal: 9m 31s\tremaining: 38.4s\n",
            "4685:\tlearn: 0.1430629\ttotal: 9m 31s\tremaining: 38.3s\n",
            "4686:\tlearn: 0.1430543\ttotal: 9m 31s\tremaining: 38.2s\n",
            "4687:\tlearn: 0.1430412\ttotal: 9m 31s\tremaining: 38.1s\n",
            "4688:\tlearn: 0.1430291\ttotal: 9m 31s\tremaining: 37.9s\n",
            "4689:\tlearn: 0.1430230\ttotal: 9m 32s\tremaining: 37.8s\n",
            "4690:\tlearn: 0.1430193\ttotal: 9m 32s\tremaining: 37.7s\n",
            "4691:\tlearn: 0.1430170\ttotal: 9m 32s\tremaining: 37.6s\n",
            "4692:\tlearn: 0.1430066\ttotal: 9m 32s\tremaining: 37.4s\n",
            "4693:\tlearn: 0.1430007\ttotal: 9m 32s\tremaining: 37.3s\n",
            "4694:\tlearn: 0.1429932\ttotal: 9m 32s\tremaining: 37.2s\n",
            "4695:\tlearn: 0.1429794\ttotal: 9m 32s\tremaining: 37.1s\n",
            "4696:\tlearn: 0.1429709\ttotal: 9m 32s\tremaining: 36.9s\n",
            "4697:\tlearn: 0.1429603\ttotal: 9m 32s\tremaining: 36.8s\n",
            "4698:\tlearn: 0.1429435\ttotal: 9m 33s\tremaining: 36.7s\n",
            "4699:\tlearn: 0.1429312\ttotal: 9m 33s\tremaining: 36.6s\n",
            "4700:\tlearn: 0.1429259\ttotal: 9m 33s\tremaining: 36.5s\n",
            "4701:\tlearn: 0.1429233\ttotal: 9m 33s\tremaining: 36.3s\n",
            "4702:\tlearn: 0.1429144\ttotal: 9m 33s\tremaining: 36.2s\n",
            "4703:\tlearn: 0.1428887\ttotal: 9m 33s\tremaining: 36.1s\n",
            "4704:\tlearn: 0.1428837\ttotal: 9m 33s\tremaining: 36s\n",
            "4705:\tlearn: 0.1428680\ttotal: 9m 33s\tremaining: 35.9s\n",
            "4706:\tlearn: 0.1428545\ttotal: 9m 33s\tremaining: 35.7s\n",
            "4707:\tlearn: 0.1428420\ttotal: 9m 34s\tremaining: 35.6s\n",
            "4708:\tlearn: 0.1428382\ttotal: 9m 34s\tremaining: 35.5s\n",
            "4709:\tlearn: 0.1428273\ttotal: 9m 34s\tremaining: 35.4s\n",
            "4710:\tlearn: 0.1428124\ttotal: 9m 34s\tremaining: 35.2s\n",
            "4711:\tlearn: 0.1428074\ttotal: 9m 34s\tremaining: 35.1s\n",
            "4712:\tlearn: 0.1427978\ttotal: 9m 34s\tremaining: 35s\n",
            "4713:\tlearn: 0.1427886\ttotal: 9m 34s\tremaining: 34.9s\n",
            "4714:\tlearn: 0.1427812\ttotal: 9m 34s\tremaining: 34.8s\n",
            "4715:\tlearn: 0.1427766\ttotal: 9m 35s\tremaining: 34.6s\n",
            "4716:\tlearn: 0.1427706\ttotal: 9m 35s\tremaining: 34.5s\n",
            "4717:\tlearn: 0.1427493\ttotal: 9m 35s\tremaining: 34.4s\n",
            "4718:\tlearn: 0.1427404\ttotal: 9m 35s\tremaining: 34.3s\n",
            "4719:\tlearn: 0.1427302\ttotal: 9m 35s\tremaining: 34.1s\n",
            "4720:\tlearn: 0.1427244\ttotal: 9m 35s\tremaining: 34s\n",
            "4721:\tlearn: 0.1427212\ttotal: 9m 35s\tremaining: 33.9s\n",
            "4722:\tlearn: 0.1427064\ttotal: 9m 35s\tremaining: 33.8s\n",
            "4723:\tlearn: 0.1426973\ttotal: 9m 36s\tremaining: 33.7s\n",
            "4724:\tlearn: 0.1426858\ttotal: 9m 36s\tremaining: 33.5s\n",
            "4725:\tlearn: 0.1426717\ttotal: 9m 36s\tremaining: 33.4s\n",
            "4726:\tlearn: 0.1426633\ttotal: 9m 36s\tremaining: 33.3s\n",
            "4727:\tlearn: 0.1426508\ttotal: 9m 36s\tremaining: 33.2s\n",
            "4728:\tlearn: 0.1426430\ttotal: 9m 36s\tremaining: 33s\n",
            "4729:\tlearn: 0.1426363\ttotal: 9m 36s\tremaining: 32.9s\n",
            "4730:\tlearn: 0.1426275\ttotal: 9m 36s\tremaining: 32.8s\n",
            "4731:\tlearn: 0.1426135\ttotal: 9m 37s\tremaining: 32.7s\n",
            "4732:\tlearn: 0.1425985\ttotal: 9m 37s\tremaining: 32.6s\n",
            "4733:\tlearn: 0.1425877\ttotal: 9m 37s\tremaining: 32.4s\n",
            "4734:\tlearn: 0.1425754\ttotal: 9m 37s\tremaining: 32.3s\n",
            "4735:\tlearn: 0.1425691\ttotal: 9m 37s\tremaining: 32.2s\n",
            "4736:\tlearn: 0.1425586\ttotal: 9m 37s\tremaining: 32.1s\n",
            "4737:\tlearn: 0.1425468\ttotal: 9m 37s\tremaining: 32s\n",
            "4738:\tlearn: 0.1425387\ttotal: 9m 38s\tremaining: 31.8s\n",
            "4739:\tlearn: 0.1425233\ttotal: 9m 38s\tremaining: 31.7s\n",
            "4740:\tlearn: 0.1425145\ttotal: 9m 38s\tremaining: 31.6s\n",
            "4741:\tlearn: 0.1425048\ttotal: 9m 38s\tremaining: 31.5s\n",
            "4742:\tlearn: 0.1424994\ttotal: 9m 38s\tremaining: 31.3s\n",
            "4743:\tlearn: 0.1424833\ttotal: 9m 38s\tremaining: 31.2s\n",
            "4744:\tlearn: 0.1424797\ttotal: 9m 38s\tremaining: 31.1s\n",
            "4745:\tlearn: 0.1424761\ttotal: 9m 38s\tremaining: 31s\n",
            "4746:\tlearn: 0.1424659\ttotal: 9m 38s\tremaining: 30.9s\n",
            "4747:\tlearn: 0.1424595\ttotal: 9m 39s\tremaining: 30.7s\n",
            "4748:\tlearn: 0.1424510\ttotal: 9m 39s\tremaining: 30.6s\n",
            "4749:\tlearn: 0.1424408\ttotal: 9m 39s\tremaining: 30.5s\n",
            "4750:\tlearn: 0.1424308\ttotal: 9m 39s\tremaining: 30.4s\n",
            "4751:\tlearn: 0.1424256\ttotal: 9m 39s\tremaining: 30.2s\n",
            "4752:\tlearn: 0.1424165\ttotal: 9m 39s\tremaining: 30.1s\n",
            "4753:\tlearn: 0.1424050\ttotal: 9m 39s\tremaining: 30s\n",
            "4754:\tlearn: 0.1423955\ttotal: 9m 39s\tremaining: 29.9s\n",
            "4755:\tlearn: 0.1423780\ttotal: 9m 40s\tremaining: 29.8s\n",
            "4756:\tlearn: 0.1423670\ttotal: 9m 40s\tremaining: 29.6s\n",
            "4757:\tlearn: 0.1423640\ttotal: 9m 40s\tremaining: 29.5s\n",
            "4758:\tlearn: 0.1423545\ttotal: 9m 40s\tremaining: 29.4s\n",
            "4759:\tlearn: 0.1423428\ttotal: 9m 40s\tremaining: 29.3s\n",
            "4760:\tlearn: 0.1423334\ttotal: 9m 40s\tremaining: 29.2s\n",
            "4761:\tlearn: 0.1423219\ttotal: 9m 40s\tremaining: 29s\n",
            "4762:\tlearn: 0.1423068\ttotal: 9m 41s\tremaining: 28.9s\n",
            "4763:\tlearn: 0.1422939\ttotal: 9m 41s\tremaining: 28.8s\n",
            "4764:\tlearn: 0.1422872\ttotal: 9m 41s\tremaining: 28.7s\n",
            "4765:\tlearn: 0.1422771\ttotal: 9m 41s\tremaining: 28.5s\n",
            "4766:\tlearn: 0.1422701\ttotal: 9m 41s\tremaining: 28.4s\n",
            "4767:\tlearn: 0.1422504\ttotal: 9m 41s\tremaining: 28.3s\n",
            "4768:\tlearn: 0.1422442\ttotal: 9m 41s\tremaining: 28.2s\n",
            "4769:\tlearn: 0.1422395\ttotal: 9m 41s\tremaining: 28.1s\n",
            "4770:\tlearn: 0.1422330\ttotal: 9m 41s\tremaining: 27.9s\n",
            "4771:\tlearn: 0.1422282\ttotal: 9m 42s\tremaining: 27.8s\n",
            "4772:\tlearn: 0.1422179\ttotal: 9m 42s\tremaining: 27.7s\n",
            "4773:\tlearn: 0.1422062\ttotal: 9m 42s\tremaining: 27.6s\n",
            "4774:\tlearn: 0.1422009\ttotal: 9m 42s\tremaining: 27.4s\n",
            "4775:\tlearn: 0.1421950\ttotal: 9m 42s\tremaining: 27.3s\n",
            "4776:\tlearn: 0.1421866\ttotal: 9m 42s\tremaining: 27.2s\n",
            "4777:\tlearn: 0.1421743\ttotal: 9m 42s\tremaining: 27.1s\n",
            "4778:\tlearn: 0.1421678\ttotal: 9m 42s\tremaining: 27s\n",
            "4779:\tlearn: 0.1421589\ttotal: 9m 43s\tremaining: 26.8s\n",
            "4780:\tlearn: 0.1421500\ttotal: 9m 43s\tremaining: 26.7s\n",
            "4781:\tlearn: 0.1421404\ttotal: 9m 43s\tremaining: 26.6s\n",
            "4782:\tlearn: 0.1421262\ttotal: 9m 43s\tremaining: 26.5s\n",
            "4783:\tlearn: 0.1421226\ttotal: 9m 43s\tremaining: 26.3s\n",
            "4784:\tlearn: 0.1421119\ttotal: 9m 43s\tremaining: 26.2s\n",
            "4785:\tlearn: 0.1421077\ttotal: 9m 43s\tremaining: 26.1s\n",
            "4786:\tlearn: 0.1420951\ttotal: 9m 43s\tremaining: 26s\n",
            "4787:\tlearn: 0.1420763\ttotal: 9m 44s\tremaining: 25.9s\n",
            "4788:\tlearn: 0.1420686\ttotal: 9m 44s\tremaining: 25.7s\n",
            "4789:\tlearn: 0.1420590\ttotal: 9m 44s\tremaining: 25.6s\n",
            "4790:\tlearn: 0.1420514\ttotal: 9m 44s\tremaining: 25.5s\n",
            "4791:\tlearn: 0.1420438\ttotal: 9m 44s\tremaining: 25.4s\n",
            "4792:\tlearn: 0.1420362\ttotal: 9m 44s\tremaining: 25.3s\n",
            "4793:\tlearn: 0.1420330\ttotal: 9m 44s\tremaining: 25.1s\n",
            "4794:\tlearn: 0.1420177\ttotal: 9m 44s\tremaining: 25s\n",
            "4795:\tlearn: 0.1420113\ttotal: 9m 44s\tremaining: 24.9s\n",
            "4796:\tlearn: 0.1420071\ttotal: 9m 45s\tremaining: 24.8s\n",
            "4797:\tlearn: 0.1419789\ttotal: 9m 45s\tremaining: 24.6s\n",
            "4798:\tlearn: 0.1419688\ttotal: 9m 45s\tremaining: 24.5s\n",
            "4799:\tlearn: 0.1419449\ttotal: 9m 45s\tremaining: 24.4s\n",
            "4800:\tlearn: 0.1419128\ttotal: 9m 45s\tremaining: 24.3s\n",
            "4801:\tlearn: 0.1418973\ttotal: 9m 45s\tremaining: 24.2s\n",
            "4802:\tlearn: 0.1418907\ttotal: 9m 45s\tremaining: 24s\n",
            "4803:\tlearn: 0.1418827\ttotal: 9m 45s\tremaining: 23.9s\n",
            "4804:\tlearn: 0.1418733\ttotal: 9m 46s\tremaining: 23.8s\n",
            "4805:\tlearn: 0.1418669\ttotal: 9m 46s\tremaining: 23.7s\n",
            "4806:\tlearn: 0.1418589\ttotal: 9m 46s\tremaining: 23.5s\n",
            "4807:\tlearn: 0.1418411\ttotal: 9m 46s\tremaining: 23.4s\n",
            "4808:\tlearn: 0.1418277\ttotal: 9m 46s\tremaining: 23.3s\n",
            "4809:\tlearn: 0.1418204\ttotal: 9m 46s\tremaining: 23.2s\n",
            "4810:\tlearn: 0.1418144\ttotal: 9m 46s\tremaining: 23.1s\n",
            "4811:\tlearn: 0.1418084\ttotal: 9m 46s\tremaining: 22.9s\n",
            "4812:\tlearn: 0.1418014\ttotal: 9m 47s\tremaining: 22.8s\n",
            "4813:\tlearn: 0.1417803\ttotal: 9m 47s\tremaining: 22.7s\n",
            "4814:\tlearn: 0.1417764\ttotal: 9m 47s\tremaining: 22.6s\n",
            "4815:\tlearn: 0.1417637\ttotal: 9m 47s\tremaining: 22.4s\n",
            "4816:\tlearn: 0.1417616\ttotal: 9m 47s\tremaining: 22.3s\n",
            "4817:\tlearn: 0.1417565\ttotal: 9m 47s\tremaining: 22.2s\n",
            "4818:\tlearn: 0.1417506\ttotal: 9m 47s\tremaining: 22.1s\n",
            "4819:\tlearn: 0.1417407\ttotal: 9m 47s\tremaining: 22s\n",
            "4820:\tlearn: 0.1417286\ttotal: 9m 48s\tremaining: 21.8s\n",
            "4821:\tlearn: 0.1417255\ttotal: 9m 48s\tremaining: 21.7s\n",
            "4822:\tlearn: 0.1417121\ttotal: 9m 48s\tremaining: 21.6s\n",
            "4823:\tlearn: 0.1417090\ttotal: 9m 48s\tremaining: 21.5s\n",
            "4824:\tlearn: 0.1416997\ttotal: 9m 48s\tremaining: 21.3s\n",
            "4825:\tlearn: 0.1416944\ttotal: 9m 48s\tremaining: 21.2s\n",
            "4826:\tlearn: 0.1416896\ttotal: 9m 48s\tremaining: 21.1s\n",
            "4827:\tlearn: 0.1416852\ttotal: 9m 48s\tremaining: 21s\n",
            "4828:\tlearn: 0.1416747\ttotal: 9m 48s\tremaining: 20.9s\n",
            "4829:\tlearn: 0.1416693\ttotal: 9m 49s\tremaining: 20.7s\n",
            "4830:\tlearn: 0.1416501\ttotal: 9m 49s\tremaining: 20.6s\n",
            "4831:\tlearn: 0.1416405\ttotal: 9m 49s\tremaining: 20.5s\n",
            "4832:\tlearn: 0.1416339\ttotal: 9m 49s\tremaining: 20.4s\n",
            "4833:\tlearn: 0.1416274\ttotal: 9m 49s\tremaining: 20.2s\n",
            "4834:\tlearn: 0.1416208\ttotal: 9m 49s\tremaining: 20.1s\n",
            "4835:\tlearn: 0.1416095\ttotal: 9m 49s\tremaining: 20s\n",
            "4836:\tlearn: 0.1415993\ttotal: 9m 49s\tremaining: 19.9s\n",
            "4837:\tlearn: 0.1415922\ttotal: 9m 49s\tremaining: 19.8s\n",
            "4838:\tlearn: 0.1415753\ttotal: 9m 50s\tremaining: 19.6s\n",
            "4839:\tlearn: 0.1415667\ttotal: 9m 50s\tremaining: 19.5s\n",
            "4840:\tlearn: 0.1415546\ttotal: 9m 50s\tremaining: 19.4s\n",
            "4841:\tlearn: 0.1415443\ttotal: 9m 50s\tremaining: 19.3s\n",
            "4842:\tlearn: 0.1415351\ttotal: 9m 50s\tremaining: 19.1s\n",
            "4843:\tlearn: 0.1415263\ttotal: 9m 50s\tremaining: 19s\n",
            "4844:\tlearn: 0.1415158\ttotal: 9m 50s\tremaining: 18.9s\n",
            "4845:\tlearn: 0.1415050\ttotal: 9m 51s\tremaining: 18.8s\n",
            "4846:\tlearn: 0.1414937\ttotal: 9m 51s\tremaining: 18.7s\n",
            "4847:\tlearn: 0.1414863\ttotal: 9m 51s\tremaining: 18.5s\n",
            "4848:\tlearn: 0.1414781\ttotal: 9m 51s\tremaining: 18.4s\n",
            "4849:\tlearn: 0.1414714\ttotal: 9m 51s\tremaining: 18.3s\n",
            "4850:\tlearn: 0.1414598\ttotal: 9m 51s\tremaining: 18.2s\n",
            "4851:\tlearn: 0.1414466\ttotal: 9m 51s\tremaining: 18s\n",
            "4852:\tlearn: 0.1414392\ttotal: 9m 51s\tremaining: 17.9s\n",
            "4853:\tlearn: 0.1414354\ttotal: 9m 51s\tremaining: 17.8s\n",
            "4854:\tlearn: 0.1414280\ttotal: 9m 52s\tremaining: 17.7s\n",
            "4855:\tlearn: 0.1414147\ttotal: 9m 52s\tremaining: 17.6s\n",
            "4856:\tlearn: 0.1414080\ttotal: 9m 52s\tremaining: 17.4s\n",
            "4857:\tlearn: 0.1414001\ttotal: 9m 52s\tremaining: 17.3s\n",
            "4858:\tlearn: 0.1413939\ttotal: 9m 52s\tremaining: 17.2s\n",
            "4859:\tlearn: 0.1413903\ttotal: 9m 52s\tremaining: 17.1s\n",
            "4860:\tlearn: 0.1413860\ttotal: 9m 52s\tremaining: 16.9s\n",
            "4861:\tlearn: 0.1413834\ttotal: 9m 52s\tremaining: 16.8s\n",
            "4862:\tlearn: 0.1413785\ttotal: 9m 52s\tremaining: 16.7s\n",
            "4863:\tlearn: 0.1413706\ttotal: 9m 53s\tremaining: 16.6s\n",
            "4864:\tlearn: 0.1413591\ttotal: 9m 53s\tremaining: 16.5s\n",
            "4865:\tlearn: 0.1413538\ttotal: 9m 53s\tremaining: 16.3s\n",
            "4866:\tlearn: 0.1413471\ttotal: 9m 53s\tremaining: 16.2s\n",
            "4867:\tlearn: 0.1413377\ttotal: 9m 53s\tremaining: 16.1s\n",
            "4868:\tlearn: 0.1413254\ttotal: 9m 53s\tremaining: 16s\n",
            "4869:\tlearn: 0.1413140\ttotal: 9m 53s\tremaining: 15.9s\n",
            "4870:\tlearn: 0.1412973\ttotal: 9m 54s\tremaining: 15.7s\n",
            "4871:\tlearn: 0.1412875\ttotal: 9m 54s\tremaining: 15.6s\n",
            "4872:\tlearn: 0.1412789\ttotal: 9m 54s\tremaining: 15.5s\n",
            "4873:\tlearn: 0.1412738\ttotal: 9m 54s\tremaining: 15.4s\n",
            "4874:\tlearn: 0.1412625\ttotal: 9m 54s\tremaining: 15.2s\n",
            "4875:\tlearn: 0.1412551\ttotal: 9m 54s\tremaining: 15.1s\n",
            "4876:\tlearn: 0.1412501\ttotal: 9m 54s\tremaining: 15s\n",
            "4877:\tlearn: 0.1412442\ttotal: 9m 54s\tremaining: 14.9s\n",
            "4878:\tlearn: 0.1412410\ttotal: 9m 54s\tremaining: 14.8s\n",
            "4879:\tlearn: 0.1412198\ttotal: 9m 55s\tremaining: 14.6s\n",
            "4880:\tlearn: 0.1412100\ttotal: 9m 55s\tremaining: 14.5s\n",
            "4881:\tlearn: 0.1412037\ttotal: 9m 55s\tremaining: 14.4s\n",
            "4882:\tlearn: 0.1411999\ttotal: 9m 55s\tremaining: 14.3s\n",
            "4883:\tlearn: 0.1411905\ttotal: 9m 55s\tremaining: 14.1s\n",
            "4884:\tlearn: 0.1411843\ttotal: 9m 55s\tremaining: 14s\n",
            "4885:\tlearn: 0.1411728\ttotal: 9m 55s\tremaining: 13.9s\n",
            "4886:\tlearn: 0.1411600\ttotal: 9m 55s\tremaining: 13.8s\n",
            "4887:\tlearn: 0.1411558\ttotal: 9m 56s\tremaining: 13.7s\n",
            "4888:\tlearn: 0.1411423\ttotal: 9m 56s\tremaining: 13.5s\n",
            "4889:\tlearn: 0.1411396\ttotal: 9m 56s\tremaining: 13.4s\n",
            "4890:\tlearn: 0.1411172\ttotal: 9m 56s\tremaining: 13.3s\n",
            "4891:\tlearn: 0.1411077\ttotal: 9m 56s\tremaining: 13.2s\n",
            "4892:\tlearn: 0.1411021\ttotal: 9m 56s\tremaining: 13s\n",
            "4893:\tlearn: 0.1410914\ttotal: 9m 56s\tremaining: 12.9s\n",
            "4894:\tlearn: 0.1410818\ttotal: 9m 56s\tremaining: 12.8s\n",
            "4895:\tlearn: 0.1410747\ttotal: 9m 56s\tremaining: 12.7s\n",
            "4896:\tlearn: 0.1410647\ttotal: 9m 57s\tremaining: 12.6s\n",
            "4897:\tlearn: 0.1410598\ttotal: 9m 57s\tremaining: 12.4s\n",
            "4898:\tlearn: 0.1410569\ttotal: 9m 57s\tremaining: 12.3s\n",
            "4899:\tlearn: 0.1410482\ttotal: 9m 57s\tremaining: 12.2s\n",
            "4900:\tlearn: 0.1410395\ttotal: 9m 57s\tremaining: 12.1s\n",
            "4901:\tlearn: 0.1410137\ttotal: 9m 57s\tremaining: 11.9s\n",
            "4902:\tlearn: 0.1410083\ttotal: 9m 57s\tremaining: 11.8s\n",
            "4903:\tlearn: 0.1409948\ttotal: 9m 57s\tremaining: 11.7s\n",
            "4904:\tlearn: 0.1409883\ttotal: 9m 58s\tremaining: 11.6s\n",
            "4905:\tlearn: 0.1409794\ttotal: 9m 58s\tremaining: 11.5s\n",
            "4906:\tlearn: 0.1409730\ttotal: 9m 58s\tremaining: 11.3s\n",
            "4907:\tlearn: 0.1409553\ttotal: 9m 58s\tremaining: 11.2s\n",
            "4908:\tlearn: 0.1409453\ttotal: 9m 58s\tremaining: 11.1s\n",
            "4909:\tlearn: 0.1409338\ttotal: 9m 58s\tremaining: 11s\n",
            "4910:\tlearn: 0.1409286\ttotal: 9m 58s\tremaining: 10.9s\n",
            "4911:\tlearn: 0.1409245\ttotal: 9m 58s\tremaining: 10.7s\n",
            "4912:\tlearn: 0.1409094\ttotal: 9m 59s\tremaining: 10.6s\n",
            "4913:\tlearn: 0.1409005\ttotal: 9m 59s\tremaining: 10.5s\n",
            "4914:\tlearn: 0.1408877\ttotal: 9m 59s\tremaining: 10.4s\n",
            "4915:\tlearn: 0.1408826\ttotal: 9m 59s\tremaining: 10.2s\n",
            "4916:\tlearn: 0.1408750\ttotal: 9m 59s\tremaining: 10.1s\n",
            "4917:\tlearn: 0.1408589\ttotal: 9m 59s\tremaining: 10s\n",
            "4918:\tlearn: 0.1408507\ttotal: 9m 59s\tremaining: 9.88s\n",
            "4919:\tlearn: 0.1408438\ttotal: 9m 59s\tremaining: 9.75s\n",
            "4920:\tlearn: 0.1408371\ttotal: 10m\tremaining: 9.63s\n",
            "4921:\tlearn: 0.1408274\ttotal: 10m\tremaining: 9.51s\n",
            "4922:\tlearn: 0.1408188\ttotal: 10m\tremaining: 9.39s\n",
            "4923:\tlearn: 0.1408092\ttotal: 10m\tremaining: 9.27s\n",
            "4924:\tlearn: 0.1408016\ttotal: 10m\tremaining: 9.14s\n",
            "4925:\tlearn: 0.1407914\ttotal: 10m\tremaining: 9.02s\n",
            "4926:\tlearn: 0.1407832\ttotal: 10m\tremaining: 8.9s\n",
            "4927:\tlearn: 0.1407723\ttotal: 10m\tremaining: 8.78s\n",
            "4928:\tlearn: 0.1407677\ttotal: 10m\tremaining: 8.66s\n",
            "4929:\tlearn: 0.1407587\ttotal: 10m 1s\tremaining: 8.53s\n",
            "4930:\tlearn: 0.1407547\ttotal: 10m 1s\tremaining: 8.41s\n",
            "4931:\tlearn: 0.1407477\ttotal: 10m 1s\tremaining: 8.29s\n",
            "4932:\tlearn: 0.1407345\ttotal: 10m 1s\tremaining: 8.17s\n",
            "4933:\tlearn: 0.1407251\ttotal: 10m 1s\tremaining: 8.05s\n",
            "4934:\tlearn: 0.1407191\ttotal: 10m 1s\tremaining: 7.92s\n",
            "4935:\tlearn: 0.1407106\ttotal: 10m 1s\tremaining: 7.8s\n",
            "4936:\tlearn: 0.1407036\ttotal: 10m 1s\tremaining: 7.68s\n",
            "4937:\tlearn: 0.1406893\ttotal: 10m 2s\tremaining: 7.56s\n",
            "4938:\tlearn: 0.1406803\ttotal: 10m 2s\tremaining: 7.44s\n",
            "4939:\tlearn: 0.1406715\ttotal: 10m 2s\tremaining: 7.32s\n",
            "4940:\tlearn: 0.1406588\ttotal: 10m 2s\tremaining: 7.19s\n",
            "4941:\tlearn: 0.1406484\ttotal: 10m 2s\tremaining: 7.07s\n",
            "4942:\tlearn: 0.1406409\ttotal: 10m 2s\tremaining: 6.95s\n",
            "4943:\tlearn: 0.1406338\ttotal: 10m 2s\tremaining: 6.83s\n",
            "4944:\tlearn: 0.1406271\ttotal: 10m 2s\tremaining: 6.71s\n",
            "4945:\tlearn: 0.1406166\ttotal: 10m 3s\tremaining: 6.58s\n",
            "4946:\tlearn: 0.1406103\ttotal: 10m 3s\tremaining: 6.46s\n",
            "4947:\tlearn: 0.1405986\ttotal: 10m 3s\tremaining: 6.34s\n",
            "4948:\tlearn: 0.1405895\ttotal: 10m 3s\tremaining: 6.22s\n",
            "4949:\tlearn: 0.1405793\ttotal: 10m 3s\tremaining: 6.09s\n",
            "4950:\tlearn: 0.1405730\ttotal: 10m 3s\tremaining: 5.97s\n",
            "4951:\tlearn: 0.1405678\ttotal: 10m 3s\tremaining: 5.85s\n",
            "4952:\tlearn: 0.1405579\ttotal: 10m 3s\tremaining: 5.73s\n",
            "4953:\tlearn: 0.1405438\ttotal: 10m 3s\tremaining: 5.61s\n",
            "4954:\tlearn: 0.1405171\ttotal: 10m 4s\tremaining: 5.49s\n",
            "4955:\tlearn: 0.1405093\ttotal: 10m 4s\tremaining: 5.36s\n",
            "4956:\tlearn: 0.1404964\ttotal: 10m 4s\tremaining: 5.24s\n",
            "4957:\tlearn: 0.1404755\ttotal: 10m 4s\tremaining: 5.12s\n",
            "4958:\tlearn: 0.1404715\ttotal: 10m 4s\tremaining: 5s\n",
            "4959:\tlearn: 0.1404514\ttotal: 10m 4s\tremaining: 4.88s\n",
            "4960:\tlearn: 0.1404426\ttotal: 10m 4s\tremaining: 4.75s\n",
            "4961:\tlearn: 0.1404358\ttotal: 10m 4s\tremaining: 4.63s\n",
            "4962:\tlearn: 0.1404263\ttotal: 10m 5s\tremaining: 4.51s\n",
            "4963:\tlearn: 0.1404136\ttotal: 10m 5s\tremaining: 4.39s\n",
            "4964:\tlearn: 0.1404067\ttotal: 10m 5s\tremaining: 4.27s\n",
            "4965:\tlearn: 0.1404010\ttotal: 10m 5s\tremaining: 4.14s\n",
            "4966:\tlearn: 0.1403903\ttotal: 10m 5s\tremaining: 4.02s\n",
            "4967:\tlearn: 0.1403839\ttotal: 10m 5s\tremaining: 3.9s\n",
            "4968:\tlearn: 0.1403804\ttotal: 10m 5s\tremaining: 3.78s\n",
            "4969:\tlearn: 0.1403694\ttotal: 10m 5s\tremaining: 3.66s\n",
            "4970:\tlearn: 0.1403616\ttotal: 10m 6s\tremaining: 3.54s\n",
            "4971:\tlearn: 0.1403561\ttotal: 10m 6s\tremaining: 3.41s\n",
            "4972:\tlearn: 0.1403479\ttotal: 10m 6s\tremaining: 3.29s\n",
            "4973:\tlearn: 0.1403388\ttotal: 10m 6s\tremaining: 3.17s\n",
            "4974:\tlearn: 0.1403322\ttotal: 10m 6s\tremaining: 3.05s\n",
            "4975:\tlearn: 0.1403273\ttotal: 10m 6s\tremaining: 2.92s\n",
            "4976:\tlearn: 0.1403165\ttotal: 10m 6s\tremaining: 2.8s\n",
            "4977:\tlearn: 0.1403043\ttotal: 10m 6s\tremaining: 2.68s\n",
            "4978:\tlearn: 0.1402894\ttotal: 10m 7s\tremaining: 2.56s\n",
            "4979:\tlearn: 0.1402848\ttotal: 10m 7s\tremaining: 2.44s\n",
            "4980:\tlearn: 0.1402815\ttotal: 10m 7s\tremaining: 2.32s\n",
            "4981:\tlearn: 0.1402747\ttotal: 10m 7s\tremaining: 2.19s\n",
            "4982:\tlearn: 0.1402668\ttotal: 10m 7s\tremaining: 2.07s\n",
            "4983:\tlearn: 0.1402533\ttotal: 10m 7s\tremaining: 1.95s\n",
            "4984:\tlearn: 0.1402443\ttotal: 10m 7s\tremaining: 1.83s\n",
            "4985:\tlearn: 0.1402301\ttotal: 10m 7s\tremaining: 1.71s\n",
            "4986:\tlearn: 0.1402225\ttotal: 10m 7s\tremaining: 1.58s\n",
            "4987:\tlearn: 0.1402166\ttotal: 10m 8s\tremaining: 1.46s\n",
            "4988:\tlearn: 0.1402105\ttotal: 10m 8s\tremaining: 1.34s\n",
            "4989:\tlearn: 0.1402008\ttotal: 10m 8s\tremaining: 1.22s\n",
            "4990:\tlearn: 0.1401901\ttotal: 10m 8s\tremaining: 1.1s\n",
            "4991:\tlearn: 0.1401853\ttotal: 10m 8s\tremaining: 975ms\n",
            "4992:\tlearn: 0.1401721\ttotal: 10m 8s\tremaining: 853ms\n",
            "4993:\tlearn: 0.1401635\ttotal: 10m 8s\tremaining: 731ms\n",
            "4994:\tlearn: 0.1401591\ttotal: 10m 8s\tremaining: 609ms\n",
            "4995:\tlearn: 0.1401545\ttotal: 10m 8s\tremaining: 488ms\n",
            "4996:\tlearn: 0.1401469\ttotal: 10m 9s\tremaining: 366ms\n",
            "4997:\tlearn: 0.1401422\ttotal: 10m 9s\tremaining: 244ms\n",
            "4998:\tlearn: 0.1401248\ttotal: 10m 9s\tremaining: 122ms\n",
            "4999:\tlearn: 0.1401178\ttotal: 10m 9s\tremaining: 0us\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<catboost.core.CatBoostClassifier at 0x7e6500fc3610>"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cat_model.save_model('/content/drive/MyDrive/Dacon/softvoting_cat_xgb변수_6_12_24.cbm')"
      ],
      "metadata": {
        "id": "HmTxVlyZxWsz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Predict - Soft voting"
      ],
      "metadata": {
        "id": "HiwIMBFtMlCa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import gc\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# LightGBM을 위한 GPU driver 설치 코드\n",
        "!mkdir -p /etc/OpenCL/vendors && echo \"libnvidia-opencl.so.1\" > /etc/OpenCL/vendors/nvidia.icd\n",
        "!sudo apt install nvidia-driver-460 nvidia-cuda-toolkit clinfo\n",
        "!apt-get update --fix-missing\n",
        "!pip install -q  lightgbm==4.1.0 \\\n",
        "  --config-settings=cmake.define.USE_GPU=ON \\\n",
        "  --config-settings=cmake.define.OpenCL_INCLUDE_DIR=\"/usr/local/cuda/include/\" \\\n",
        "  --config-settings=cmake.define.OpenCL_LIBRARY=\"/usr/local/cuda/lib64/libOpenCL.so\"\n",
        "\n",
        "# catboost 설치\n",
        "!pip install catboost\n",
        "\n",
        "import sklearn\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "import imblearn\n",
        "from imblearn.over_sampling import SMOTE\n",
        "import xgboost as xgb\n",
        "from xgboost import XGBClassifier\n",
        "import catboost\n",
        "from catboost import CatBoostClassifier\n",
        "import lightgbm as lgb\n",
        "from lightgbm import early_stopping, log_evaluation, LGBMClassifier"
      ],
      "metadata": {
        "id": "UW8h2WQlsmCn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6620da6c-7fff-4c23-a1a2-80774cb72000"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "clinfo is already the newest version (3.0.21.02.21-1).\n",
            "Some packages could not be installed. This may mean that you have\n",
            "requested an impossible situation or if you are using the unstable\n",
            "distribution that some required packages have not yet been created\n",
            "or been moved out of Incoming.\n",
            "The following information may help to resolve the situation:\n",
            "\n",
            "The following packages have unmet dependencies:\n",
            " libnvidia-compute-510 : Depends: libnvidia-compute-535 but it is not installable\n",
            " nvidia-cuda-dev : Breaks: libcuda1 (< 495)\n",
            "                   Recommends: libnvcuvid1 but it is not installable\n",
            "\u001b[1;31mE: \u001b[0mUnable to correct problems, you have held broken packages.\u001b[0m\n",
            "Hit:1 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n",
            "Hit:2 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease\n",
            "Hit:3 http://security.ubuntu.com/ubuntu jammy-security InRelease\n",
            "Hit:4 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Hit:5 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:6 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Hit:7 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Hit:8 http://archive.ubuntu.com/ubuntu jammy-updates InRelease\n",
            "Hit:9 https://r2u.stat.illinois.edu/ubuntu jammy InRelease\n",
            "Hit:10 http://archive.ubuntu.com/ubuntu jammy-backports InRelease\n",
            "Reading package lists... Done\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "Requirement already satisfied: catboost in /usr/local/lib/python3.11/dist-packages (1.2.8)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.11/dist-packages (from catboost) (0.20.3)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from catboost) (3.10.0)\n",
            "Requirement already satisfied: numpy<3.0,>=1.16.0 in /usr/local/lib/python3.11/dist-packages (from catboost) (2.0.2)\n",
            "Requirement already satisfied: pandas>=0.24 in /usr/local/lib/python3.11/dist-packages (from catboost) (2.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from catboost) (1.15.2)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.11/dist-packages (from catboost) (5.24.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from catboost) (1.17.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.24->catboost) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.24->catboost) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.24->catboost) (2025.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (4.57.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (11.2.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (3.2.3)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from plotly->catboost) (9.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_df = pd.read_parquet(\"/content/drive/MyDrive/Data/test_df_cleaned.parquet\")\n",
        "\n",
        "# 변수 300개 사용\n",
        "top300_df = pd.read_csv(\"/content/drive/MyDrive/Dacon/top300_features_XGB_balanced.csv\")\n",
        "top300_features = top300_df['feature'].tolist()"
      ],
      "metadata": {
        "id": "4evJ2VEDx9BD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 학습한 모델들 불러오기\n",
        "xgb_model_loaded = xgb.XGBClassifier()\n",
        "xgb_model_loaded.load_model('/content/drive/MyDrive/Dacon/softvoting_xgb_xgb변수_3_3_25.json')\n",
        "\n",
        "lgb_model_loaded = lgb.Booster(model_file='/content/drive/MyDrive/Dacon/softvoting_lgbm_xgb변수_3_3_25.txt')\n",
        "\n",
        "cat_model_loaded = CatBoostClassifier()\n",
        "cat_model_loaded.load_model('/content/drive/MyDrive/Dacon/softvoting_cat_xgb변수_6_12_24.cbm')"
      ],
      "metadata": {
        "id": "NPPYFsAHoVZ9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fcf93e94-f02f-4c5f-e904-42fcf6b52261"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<catboost.core.CatBoostClassifier at 0x7ea962185e50>"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# test 데이터 준비\n",
        "X_test = test_df[top300_features]\n",
        "\n",
        "# XGB predict_proba (iteration_range)\n",
        "proba_xgb = xgb_model_loaded.predict_proba(X_test, iteration_range=(0, 5000))\n",
        "\n",
        "# LGB Booster (predict가 proba)\n",
        "proba_lgb = lgb_model_loaded.predict(X_test, num_iteration=3348)\n",
        "\n",
        "# CAT predict_proba\n",
        "proba_cat = cat_model_loaded.predict_proba(X_test)\n",
        "\n",
        "# soft voting\n",
        "ensemble_proba = (0.4 * proba_xgb) + (0.3 * proba_lgb) + (0.3 * proba_cat)\n",
        "ensemble_preds = np.argmax(ensemble_proba, axis=1)\n",
        "inverse_label_map = {0: 'A', 1: 'B', 2: 'C', 3: 'D', 4: 'E'}\n",
        "ensemble_preds_label = pd.Series(ensemble_preds).map(inverse_label_map)"
      ],
      "metadata": {
        "id": "U-kT6XT_xw32"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 예측값 test_df에 추가\n",
        "test_df[\"pred_label\"] = ensemble_preds_label\n",
        "\n",
        "# ID별 mode aggregation (가장 많이 나온 label)\n",
        "submission = test_df.groupby(\"ID\")[\"pred_label\"] \\\n",
        "    .agg(lambda x: x.value_counts().idxmax()) \\\n",
        "    .reset_index()\n",
        "\n",
        "# 컬럼명 정리\n",
        "submission.columns = [\"ID\", \"Segment\"]\n",
        "\n",
        "# 저장\n",
        "submission.to_csv(\n",
        "    \"/content/drive/MyDrive/Dacon/submission_final.csv\",\n",
        "    index=False,\n",
        "    encoding=\"utf-8-sig\"\n",
        ")\n",
        "\n",
        "print(\"✅ 결과 저장 완료!\")"
      ],
      "metadata": {
        "id": "-ZtGSWz5xw8q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c29aff1a-4c96-412b-a8d0-edc5a6710ead"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ 결과 저장 완료!\n"
          ]
        }
      ]
    }
  ]
}